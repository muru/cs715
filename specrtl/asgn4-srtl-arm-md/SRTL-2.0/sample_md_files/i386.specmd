{:
;; GCC machine description for IA-32 and x86-64.
;; Copyright (C) 1988, 1994, 1995, 1996, 1997, 1998, 1999, 2000,
;; 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012
;; Free Software Foundation, Inc.
;; Mostly by William Schelter.
;; x86_64 support added by Jan Hubicka
;;
;; This file is part of GCC.
;;
;; GCC is free software; you can redistribute it and/or modify
;; it under the terms of the GNU General Public License as published by
;; the Free Software Foundation; either version 3, or (at your option)
;; any later version.
;;
;; GCC is distributed in the hope that it will be useful,
;; but WITHOUT ANY WARRANTY; without even the implied warranty of
;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
;; GNU General Public License for more details.
;;
;; You should have received a copy of the GNU General Public License
;; along with GCC; see the file COPYING3.  If not see
;; <http://www.gnu.org/licenses/>.  */
;;
;; The original PO technology requires these to be ordered by speed,
;; so that assigner will pick the fastest.
;;
;; See file "rtl.def" for documentation on define_insn, match_*, et. al.
;;
;; The special asm out single letter directives following a '%' are:
;; L,W,B,Q,S,T -- print the opcode suffix for specified size of operand.
;; C -- print opcode suffix for set/cmov insn.
;; c -- like C, but print reversed condition
;; F,f -- likewise, but for floating-point.
;; O -- if HAVE_AS_IX86_CMOV_SUN_SYNTAX, expand to "w.", "l." or "q.",
;;      otherwise nothing
;; R -- print the prefix for register names.
;; z -- print the opcode suffix for the size of the current operand.
;; Z -- likewise, with special suffixes for x87 instructions.
;; * -- print a star (in certain assembler syntax)
;; A -- print an absolute memory reference.
;; E -- print address with DImode register names if TARGET_64BIT.
;; w -- print the operand as if it's a "word" (HImode) even if it isn't.
;; s -- print a shift double count, followed by the assemblers argument
;;	delimiter.
;; b -- print the QImode name of the register for the indicated operand.
;;	%b0 would print %al if operands[0] is reg 0.
;; w --  likewise, print the HImode name of the register.
;; k --  likewise, print the SImode name of the register.
;; q --  likewise, print the DImode name of the register.
;; x --  likewise, print the V4SFmode name of the register.
;; t --  likewise, print the V8SFmode name of the register.
;; h -- print the QImode name for a "high" register, either ah, bh, ch or dh.
;; y -- print "st(0)" instead of "st" as a register.
;; d -- print duplicated register operand for AVX instruction.
;; D -- print condition for SSE cmp instruction.
;; P -- if PIC, print an @PLT suffix.
;; p -- print raw symbol name.
;; X -- don't print any sort of PIC '@' suffix for a symbol.
;; & -- print some in-use local-dynamic symbol name.
;; H -- print a memory address offset by 8; used for sse high-parts
;; Y -- print condition for XOP pcom* instruction.
;; + -- print a branch hint as 'cs' or 'ds' prefix
;; ; -- print a semicolon (after prefixes due to bug in older gas).
;; @ -- print a segment register of thread base pointer load
:}

list  "unspec".c_enum [
  UNSPEC_GOT
  ,UNSPEC_GOTOFF
  ,UNSPEC_GOTPCREL
  ,UNSPEC_GOTTPOFF
  ,UNSPEC_TPOFF
  ,UNSPEC_NTPOFF
  ,UNSPEC_DTPOFF
  ,UNSPEC_GOTNTPOFF
  ,UNSPEC_INDNTPOFF
  ,UNSPEC_PLTOFF
  ,UNSPEC_MACHOPIC_OFFSET
  ,UNSPEC_PCREL
  ,UNSPEC_STACK_ALLOC
  ,UNSPEC_SET_GOT
  ,UNSPEC_SET_RIP
  ,UNSPEC_SET_GOT_OFFSET
  ,UNSPEC_MEMORY_BLOCKAGE
  ,UNSPEC_STACK_CHECK
  ,UNSPEC_TP
  ,UNSPEC_TLS_GD
  ,UNSPEC_TLS_LD_BASE
  ,UNSPEC_TLSDESC
  ,UNSPEC_TLS_IE_SUN
  ,UNSPEC_SCAS
  ,UNSPEC_FNSTSW
  ,UNSPEC_SAHF
  ,UNSPEC_PARITY
  ,UNSPEC_FSTCW
  ,UNSPEC_ADD_CARRY
  ,UNSPEC_FLDCW
  ,UNSPEC_REP
  ,UNSPEC_LD_MPIC	
  ,UNSPEC_TRUNC_NOOP
  ,UNSPEC_DIV_ALREADY_SPLIT
  ,UNSPEC_MS_TO_SYSV_CALL
  ,UNSPEC_CALL_NEEDS_VZEROUPPER
  ,UNSPEC_PAUSE
  ,UNSPEC_LEA_ADDR
  ,UNSPEC_FIX_NOTRUNC
  ,UNSPEC_MASKMOV
  ,UNSPEC_MOVMSK
  ,UNSPEC_RCP
  ,UNSPEC_RSQRT
  ,UNSPEC_PSADBW
  ,UNSPEC_COPYSIGN
  ,UNSPEC_IEEE_MIN	
  ,UNSPEC_IEEE_MAX	
  ,UNSPEC_SIN
  ,UNSPEC_COS
  ,UNSPEC_FPATAN
  ,UNSPEC_FYL2X
  ,UNSPEC_FYL2XP1
  ,UNSPEC_FRNDINT
  ,UNSPEC_FIST
  ,UNSPEC_F2XM1
  ,UNSPEC_TAN
  ,UNSPEC_FXAM
  ,UNSPEC_FRNDINT_FLOOR
  ,UNSPEC_FRNDINT_CEIL
  ,UNSPEC_FRNDINT_TRUNC
  ,UNSPEC_FRNDINT_MASK_PM
  ,UNSPEC_FIST_FLOOR
  ,UNSPEC_FIST_CEIL
  ,UNSPEC_SINCOS_COS
  ,UNSPEC_SINCOS_SIN
  ,UNSPEC_XTRACT_FRACT
  ,UNSPEC_XTRACT_EXP
  ,UNSPEC_FSCALE_FRACT
  ,UNSPEC_FSCALE_EXP
  ,UNSPEC_FPREM_F
  ,UNSPEC_FPREM_U
  ,UNSPEC_FPREM1_F
  ,UNSPEC_FPREM1_U
  ,UNSPEC_C2_FLAG
  ,UNSPEC_FXAM_MEM
  ,UNSPEC_SP_SET
  ,UNSPEC_SP_TEST
  ,UNSPEC_SP_TLS_SET
  ,UNSPEC_SP_TLS_TEST
  ,UNSPEC_ROUND
  ,UNSPEC_CRC32
  ,UNSPEC_BEXTR
  ,UNSPEC_PDEP
  ,UNSPEC_PEXT
]

list "unspecv".c_enum [
  UNSPECV_BLOCKAGE
  ,UNSPECV_STACK_PROBE
  ,UNSPECV_PROBE_STACK_RANGE
  ,UNSPECV_ALIGN
  ,UNSPECV_PROLOGUE_USE
  ,UNSPECV_SPLIT_STACK_RETURN
  ,UNSPECV_CLD
  ,UNSPECV_NOPS
  ,UNSPECV_RDTSC
  ,UNSPECV_RDTSCP
  ,UNSPECV_RDPMC
  ,UNSPECV_LLWP_INTRINSIC
  ,UNSPECV_SLWP_INTRINSIC
  ,UNSPECV_LWPVAL_INTRINSIC
  ,UNSPECV_LWPINS_INTRINSIC
  ,UNSPECV_RDFSBASE
  ,UNSPECV_RDGSBASE
  ,UNSPECV_WRFSBASE
  ,UNSPECV_WRGSBASE
  ,UNSPECV_RDRAND
]


{:
;; Constants to represent rounding modes in the ROUND instruction
:}
list noname.constants
  [(ROUND_FLOOR,0x1),(ROUND_CEIL,0x2),
   (ROUND_TRUNC,0x3),(ROUND_MXCSR,0x4),
   (ROUND_NO_EXC,0x8)]

{:
;; Constants to represent pcomtrue/pcomfalse variants 
:}

{:
;; Insns whose names begin with "x86_" are emitted by gen_FOO calls
;; from i386.c.

;; In C guard expressions, put expressions which may be compile-time
;; constants first.  This allows for better optimization.  For
;; example, write "TARGET_64BIT && reload_completed", not
;; "reload_completed && TARGET_64BIT".

;; Processor type.
:}

concrete cpu.attr instantiates const
{
    root (symbol_ref:"ix86_schedule");
    lov:="none,pentium,pentiumpro,geode,k6,athlon,k8,core2,corei7,
		    atom,generic64,amdfam10,bdver1,bdver2,btver1";
}

{:
;; A basic instruction type.  Refinements due to arguments to be
;; provided in other attributes.
:}

concrete type.attr instantiates sequence 
{
    root (const_string:"other");
    lov:="other,multi,
   alu,alu1,negnot,imov,imovx,lea,
   incdec,ishift,ishiftx,ishift1,rotate,rotatex,rotate1,imul,imulx,idiv,
   icmp,test,ibr,setcc,icmov,
   push,pop,call,callv,leave,
   str,bitmanip,
   fmov,fop,fsgn,fmul,fdiv,fpspc,fcmov,fcmp,fxch,fistp,fisttp,frndint,
   sselog,sselog1,sseiadd,sseiadd1,sseishft,sseishft1,sseimul,
   sse,ssemov,sseadd,ssemul,ssecmp,ssecomi,ssecvt,ssecvt1,sseicvt,ssediv,sseins,
   ssemuladd,sse4arg,lwp, mmx,mmxmov,mmxadd,mmxmul,mmxcmp,mmxcvt,mmxshft";
}

{:
;; Main data type used by the insn
:}

concrete mode.attr instantiates sequence
{
    root (const_string:"unknown");
    lov:="unknown,none,QI,HI,SI,DI,TI,OI,SF,DF,XF,TF,V8SF,V4DF,V4SF,V2DF,V2SF,V1DF";
}

{:
;; The CPU unit operations uses.
:}

abstract cond_sequence extends cond
{
    root.1:=sequence;
}

concrete unit.attr instantiates cond_sequence
{
    root ((type:"fmov,fop,fsgn,fmul,fdiv,fpspc,fcmov,fcmp,fxch,fistp,fisttp,frndint",
        const_string:"i387", type:"sselog,sselog1,sseiadd,sseiadd1,sseishft,sseishft1,sseimul,
        sse,ssemov,sseadd,ssemul,ssecmp,ssecomi,ssecvt,ssecvt1,sseicvt,ssediv,sseins,ssemuladd,sse4arg",
        const_string:"sse", type:"mmx,mmxmov,mmxadd,mmxmul,mmxcmp,mmxcvt,mmxshft",
        type:"mmx", const_string:"unknown"), const_string:"integer");
    lov:="integer,i387,sse,mmx,unknown";
}

abstract cond_sequence_ite_x2 extends cond_sequence
{
    root.1.10:=if_then_else;
    root.1.12:=if_then_else;
}

{:
;; The (bounding maximum) length of an instruction immediate.
:}

concrete length_immediate.attr instantiates cond_sequence_ite_x2
{
    root ((type:"incdec,setcc,icmov,str,lea,other,multi,idiv,leave, bitmanip,imulx",
        const_int:0, unit:"i387,sse,mmx", const_int:0, 
        type:"alu,alu1,negnot,imovx,ishift,ishiftx,ishift1,
        rotate,rotatex,rotate1,imul,icmp,push,pop",
        symbol_ref:"ix86_attr_length_immediate_default (insn, true)",
        type:"imov,test", symbol_ref:"ix86_attr_length_immediate_default (insn, false)",
        type:"call", 0=constant_call_address_operand:NULL:"",
        const_int:4, const_int:0, type:"callv", 1=constant_call_address_operand:NULL:"",
        const_int:4, const_int:0,type:"ibr", const_int:1),
        symbol_ref: "gcc_unreachable (),1");
}

{:
;; The (bounding maximum) length of an instruction address.
:}

abstract cond_and3_and5 extends cond_sequence
{
    root.1.3:=and;
    root.1.5:=and;
}

concrete length_address.attr instantiates cond_and3_and5
{
    root ((type:"str,other,multi,fxch", const_int:0,
        type:"call", 0=constant_call_address_operand:NULL:"",const_int:0,
        type:"callv", 1=constant_call_address_operand:NULL:"",const_int:0),
        symbol_ref:"ix86_attr_length_address_default (insn)");
}

{:
;; Set when length prefix is used.
:}
abstract cond_and5 extends cond_sequence
{
    root.1.5:=and;
}
concrete prefix_data16.attr instantiates cond_and5
{
    root ((type:"ssemuladd,sse4arg,sseiadd1,ssecvt1", const_int:0,
        mode:"HI",const_int:1,
        unit:"sse",mode:"V2DF,TI",const_int:1), const_int:0);
}

abstract cond_and3 extends cond_sequence
{
    root.1.3:=and;
}
concrete prefix_rep.attr instantiates cond_and3
{
    root ((type:"ssemuladd,sse4arg,sseiadd1,ssecvt1", const_int:0,
        unit:"sse",mode:"SF,DF", const_int:1), const_int:0);
}

abstract ite_ior1 extends if_then_else
{
    root.1:=ior;
}

concrete prefix_0f.attr instantiates ite_ior1
{
    root (type:"imovx,setcc,icmov,bitmanip", unit:"sse,mmx",
        const_int:1, const_int:0);
}

abstract cond_not1_and3_and2_and5 extends cond_sequence
{
    root.1.1:=not;
    root.1.3:=and;
    root.1.3.2:=and;
    root.1.5:=and;
}

concrete prefix_rex.attr instantiates cond_not1_and3_and2_and5
{
    root ((match_test:"TARGET_64BIT",const_int:0,
        mode:"DI",type:"!push,pop,call,callv,leave,ibr",unit:"!mmx",const_int:1,
        mode:"QI", match_test:"x86_extended_QIreg_mentioned_p (insn)", const_int:1,
        type:"imovx", 1=ext_QIreg_operand:QI:"", const_int:1), const_int:0);
}

{:
;; There are also additional prefixes in 3DNOW, SSSE3.
;; ssemuladd,sse4arg default to 0f24/0f25 and DREX byte,
;; sseiadd1,ssecvt1 to 0f7a with no DREX byte.
;; 3DNOW has 0f0f prefix, SSSE3 and SSE4_{1,2} 0f38/0f3a.
:}

concrete prefix_extra.attr instantiates cond_sequence
{
    root ((type:"ssemuladd,sse4arg", const_int:2,
        type:"sseiadd1,ssecvt1", const_int:1),
        const_int:0);
}
concrete prefix.attr instantiates if_then_else
{
    root (mode:"OI,V8SF,V4DF",
        const_string:"vex", const_string:"orig");
    lov:="orig,vex,maybe_vex";
}

concrete prefix_vex_w.attr instantiates sequence
{
    root (const_int:0);
}

{:
;; The length of VEX prefix
;; Only instructions with 0f prefix can have 2 byte VEX prefix,
;; 0f38/0f3a prefixes can't.  In i386.md 0f3[8a] is
;; still prefix_0f 1, with prefix_extra 1.
:}

abstract ite_and1_ite2_ite3 extends if_then_else
{
    root.1:=and; root.2:=if_then_else; root.3:=if_then_else;
}

concrete length_vex.attr instantiates ite_and1_ite2_ite3
{
    root (prefix_0f:"1", prefix_extra:"0",
        prefix_vex_w:"1", symbol_ref:"ix86_attr_length_vex_default (insn, true, true)",
        symbol_ref:"ix86_attr_length_vex_default (insn, true, false)",
        prefix_vex_w:"1", symbol_ref:"ix86_attr_length_vex_default (insn, false, true)",
        symbol_ref:"ix86_attr_length_vex_default (insn, false, false)");
}

abstract ctree1 extends cond_sequence
{
    root.1.5:=and; root.1.5.2:=and; root.1.5.2.1:=not;
    root.1.5.2.2:=ior; root.1.7:=and; root.1.7.2:=not;
    root.1.9:=and; root.1.9.2:=not; root.1.11:=and;
    root.1.11.2:=and; root.1.11.2.1:=not; root.1.11.2.2:=ior; 
    root.1.11.2.2.1:=and; root.1.11.2.2.2:=ior; 
    root.1.11.2.2.2.1:=and; root.1.11.2.2.2.2:=and;
    root.1.13:=and; root.1.15:=and;
}

{:
;; Set when modrm byte is used.
:}
concrete modrm.attr instantiates ctree1
{
    root ((type:"str,leave", const_int:0,
        unit:"i387",const_int:0,
        type:"incdec", match_test:"TARGET_64BIT",
        1=register_operand:SI:"", 1=register_operand:HI:"", const_int:0,
        type:"push", 1=memory_operand:NULL:"", const_int:0,
        type:"pop", 0=memory_operand:NULL:"", const_int:0,
        type:"imov", mode:"DI", 0=register_operand:NULL:"",
            1=immediate_operand:NULL:"", 0=ax_reg_operand:NULL:"",
            0=memory_displacement_only_operand:NULL:"",
            1=ax_reg_operand:NULL:"",const_int:0,
        type:"call",0=constant_call_address_operand:NULL:"",const_int:0,
        type:"callv",1=constant_call_address_operand:NULL:"", const_int:0,
        type:"alu,alu1,icmp,test",0=ax_reg_operand:NULL:"",
            symbol_ref:"(get_attr_length_immediate (insn) <= (get_attr_mode (insn) != MODE_QI))"),
        const_int:1);
}

abstract ctree3 extends cond_sequence
{   
    root.1.6:=plus; root.1.6.2:=plus; root.1.7:=ior;
    root.1.7.2:=and; root.1.8:=plus; root.1.8.2:=plus; root.1.8.2.2:=plus;
    root.2:=plus; root.2.1:=plus; root.2.1.2:=plus; root.2.1.2.2:=plus;
    root.2.1.2.2.2:=plus; root.2.2:=plus; root.2.2.2:=plus; root.2.2.2.2:=plus;
}

{:
;; The (bounding maximum) length of an instruction in bytes.
;; ??? fistp and frndint are in fact fldcw/{fistp,frndint}/fldcw sequences.
;; Later we may want to split them and compute proper length as for
;; other insns.
:}

concrete length.attr instantiates ctree3
{
    root ((type:"other,multi,fistp,frndint", const_int:16,
        type:"fcmp",const_int:4, 
        unit:"i387", const_int:2, attr:"prefix_data16", attr:"length_address",
        prefix:"vex", prefix:"maybe_vex",  match_test:"TARGET_AVX",
        attr:"length_vex", attr:"length_immediate", attr:"modrm", attr:"length_address"),
        attr:"modrm",attr:"prefix_0f", attr:"prefix_rex", attr:"prefix_extra", const_int:1,
        attr:"prefix_rep",attr:"prefix_data16",attr:"length_immediate",attr:"length_address");
}

abstract ctree2 extends cond_sequence
{
    root.1.10:=if_then_else; root.1.12:=if_then_else;
    root.1.14:=if_then_else; root.1.16:=if_then_else;
    root.1.16.1:=ior; root.1.18:=if_then_else;
    root.1.20:=if_then_else; root.1.22:=if_then_else;
    root.1.23:=and; root.1.25:=and;
    root.1.31:=and; root.1.33:=and;
}

{:
;; The `memory' attribute is `none' if no memory is referenced, `load' or
;; `store' if there is a simple memory reference therein, or `unknown'
;; if the instruction is complex.
:}
concrete memory.attr instantiates ctree2
{
    root ((type:"other,multi,str,lwp",const_string:"unknown",
        type:"lea,fcmov,fpspc", const_string:"none",
        type:"fistp,leave", const_string:"both",
        type:"frndint", const_string:"load",
        type:"push", 1=memory_operand:NULL:"", const_string:"both", const_string:"store",
        type:"pop", 0=memory_operand:NULL:"", const_string:"both", const_string:"load",
        type:"setcc", 0=memory_operand:NULL:"", const_string:"store", const_string:"none",
        type:"icmp,test,ssecmp,ssecomi,mmxcmp,fcmp",
            0=memory_operand:NULL:"", 1=memory_operand:NULL:"", const_string:"load", 
            const_string:"none",
        type:"ibr", 0=memory_operand:NULL:"", const_string:"load",const_string:"none",
        type:"call", 0=constant_call_address_operand:NULL:"", const_string:"none", const_string:"load",
        type:"callv", 1=constant_call_address_operand:NULL:"", const_string:"none", const_string:"load",
        type:"alu1,negnot,ishift1,sselog1", 1=memory_operand:NULL:"", 1=memory_operand:NULL:"", const_string:"both",
        0=memory_operand:NULL:"", 1=memory_operand:NULL:"", const_string:"both",
        0=memory_operand:NULL:"", const_string:"store",
        1=memory_operand:NULL:"", const_string:"load",
        type:"!alu1,negnot,ishift1,imov,imovx,icmp,test,bitmanip,fmov,fcmp,fsgn,
            sse,ssemov,ssecmp,ssecomi,ssecvt,ssecvt1,sseicvt,sselog1,sseiadd1,
            mmx,mmxmov,mmxcmp,mmxcvt",2=memory_operand:NULL:"", const_string:"load",
        type:"icmov,ssemuladd,sse4arg",3=memory_operand:NULL:"", const_string:"load"),
        const_string:"none");
    lov:="none,load,store,both,unknown";
}

abstract cond_and3_and2_and5_and2 extends cond_and3_and5
{
    root.1.3.2:=and;
    root.1.5.2:=and;
}

{:
;; Indicates if an instruction has both an immediate and a displacement.
:}
concrete imm_disp.attr instantiates cond_and3_and2_and5_and2
{
    root ((type:"other,multi", const_string:"unknown",
        type:"icmp,test,imov,alu1,ishift1,rotate1",
            0=memory_displacement_operand:NULL:"",
            1=immediate_operand:NULL:"", const_string:"true",
        type:"alu,ishift,ishiftx,rotate,rotatex,imul,idiv",
            0=memory_displacement_operand:NULL:"",
            2=immediate_operand:NULL:"", const_string:"true"),
        const_string:"false");
}

{:
;; Indicates if an FP operation has an integer source.
:}
concrete fp_int_src.attr instantiates sequence
{
    root (const_string:"false");
    lov:="false,true";
}

{:
;; Defines rounding mode of an FP operation.
:}
concrete i387_cw.attr instantiates sequence
{
    root (const_string:"any");
    lov:="trunc,floor,ceil,mask_pm,uninitialized,any";
}

{:
;; Define attribute to classify add/sub insns that consumes carry flag (CF)
:}
concrete use_carry.attr instantiates sequence
{
    root (const_string:"0");
    lov:="0,1";
}
{:
;; Define attribute to indicate unaligned ssemov insns
:}
concrete movu.attr instantiates sequence
{
    root (const_string:"0");
    lov:="0,1";
}

{:
;; Used to control the "enabled" attribute on a per-instruction basis.
:}
concrete isa.attr instantiates sequence
{
    root (const_string:"base");
    lov:="base,sse2,sse2_noavx,sse3,sse4,sse4_noavx,noavx,avx,bmi2,fma,fma4";
}

{:
;; Fma instruction selection has to be done based on
;; register pressure. For generating fma4, a cost model
;; based on register pressure is required. Till then,
;; fma4 instruction is disabled for targets that implement
;; both fma and fma4 instruction sets.
:}
concrete enabled.attr instantiates cond_sequence
{
    root ((isa:"sse2", symbol_ref:"TARGET_SSE2",
        isa:"sse2_noavx", symbol_ref:"TARGET_SSE2 && !TARGET_AVX",
        isa:"sse3", symbol_ref:"TARGET_SSE3",
        isa:"sse4", symbol_ref:"TARGET_SSE4_1",
        isa:"sse4_noavx", symbol_ref:"TARGET_SSE4_1 && !TARGET_AVX",
        isa:"avx", symbol_ref:"TARGET_AVX",
        isa:"noavx", symbol_ref:"!TARGET_AVX",
        isa:"bmi2", symbol_ref:"TARGET_BMI2",
        isa:"fma", symbol_ref:"TARGET_FMA",
        isa:"fma4", symbol_ref:"TARGET_FMA4 && !TARGET_FMA"),
        const_int:1);
}

{:
;; Describe a user's asm statement.
:}
list noname.asm_attr
[(set_attr,"length","128"),(set_attr,"type","multi")]

list plusminus.c_iter [plus, minus]
list any_extend.c_iter [sign_extend, zero_extend]
list absneg.c_iter [abs, neg]
list any_or.c_iter [ior, xor]
list any_shiftrt.c_iter [lshiftrt, ashiftrt]
list any_rotate.c_iter [rotate, rotatert]
list smaxmin.c_iter [smax, smin]


abstract set_if_then_else_match_operator extends set_if_then_else
{
	root.2.1:=match_operator;
}

abstract set_if_then_else_match_operator_label_ref extends set_if_then_else_match_operator
{
	root.2.2:=label_ref;
}

abstract set_compare_set_if_then_else_match_operator_label_ref extends sequence
{
	root.1:=set_compare;
	root.2:=set_if_then_else_match_operator_label_ref;
}


// SpecRTL Comments.


concrete cbranch<mode>4.exp instantiates set_compare_set_if_then_else_match_operator_label_ref
{
	root(reg(CC:FLAGS_REG),1=nonimmediate_operand:SDWIM:"",2=<general_operand>:SDWIM:"",pc,(0=ordered_comparison_operator,reg(CC:FLAGS_REG),const_int:0),3=NULL:NULL:"",pc);
	root.1.2.mode:=CC;
}
{:
	""
	{
		if (MEM_P (operands[1]) && MEM_P (operands[2]))
			operands[1] = force_reg (<MODE>mode, operands[1]);
		ix86_expand_branch (GET_CODE (operands[0]),
								operands[1], operands[2], operands[3]);
		DONE;
	}
:}

abstract set_compare_set_match_operator extends sequence
{
	root.1:=set_compare;
	root.2:=set_match_operator;
}

concrete cstore<mode>4.exp instantiates set_compare_set_match_operator
{
	root(reg(CC:FLAGS_REG),2=nonimmediate_operand:SWIM:"",3=<general_operand>:SWIM:"",0=register_operand:QI:"",(1=ordered_comparison_operator,reg(CC:FLAGS_REG), const_int:0));
	root.1.2.mode:=CC;
}
{:
	""
	{
		if (MEM_P (operands[2]) && MEM_P (operands[3]))
			operands[2] = force_reg (<MODE>mode, operands[2]);
		ix86_expand_setcc (operands[0], GET_CODE (operands[1]),
						operands[2], operands[3]);
		DONE;
	}
:}

concrete cmp<mode>_1.exp instantiates set_compare
{
        root (reg(CC:FLAGS_REG),0=nonimmediate_operand:SWI48:"",1=<general_operand>:SWI48:"");
        root.2.mode:=CC;
}
{:
:}


concrete *cmp<mode>_ccno_1.insn instantiates set_compare
{
	root(reg(NULL:FLAGS_REG),0=nonimmediate_operand:SWI:"<r>,?m<r>",1=const0_operand:SWI:"");
}
{:
	"ix86_match_ccmode (insn, CCNOmode)"
	"@
		test{<imodesuffix>}\t%0, %0
		cmp{<imodesuffix>}\t{%1, %0|%0,%1}"
	[(set_attr "type" "test,icmp")
	 (set_attr "length_immediate" "0,1")
	 (set_attr "mode" "<MODE>")]
:}

concrete *cmp<mode>_1.insn overrides *cmp<mode>_ccno_1.insn
{
	root.2.1:=nonimmediate_operand:SWI:"<r>m,<r>";
	root.2.2:=<general_operand>:SWI:"<r><i>,<r>m";
}
{:
	"ix86_match_ccmode (insn, CCmode)"
	"cmp{<imodesuffix>}\t{%1, %0|%0, %1}"
	[(set_attr "type" "icmp")
	 (set_attr "mode" "<MODE>")]
:}

concrete *cmp<mode>_minus_1.insn instantiates set_compare_minus
{
	root(reg(NULL:FLAGS_REG),0=nonimmediate_operand:SWI:"<r>m,<r>",1=<general_operand>:SWI:"<r><i>,<r>m",const_int:0);
	root.2.1.mode:=SWI;
}
{:
  "ix86_match_ccmode (insn, CCGOCmode)"
  "cmp{<imodesuffix>}\t{%1, %0|%0, %1}"
  [(set_attr "type" "icmp")
   (set_attr "mode" "<MODE>")]
:}

abstract subreg_zero_extract extends subreg{
	root.1:=zero_extract;
}

abstract set_compare_subreg_zero_extract2 extends set_compare
{
	root.2.2:=subreg_zero_extract;
}

concrete *cmpqi_ext_1.insn instantiates set_compare_subreg_zero_extract2
{
    root (reg(NULL:FLAGS_REG),0=general_operand:QI:"Qm",1=ext_register_operand:NULL:"Q",const_int:8,const_int:8, 0);
	root.2.2.mode:=QI;
	root.2.2.1.mode:=SI;
}
{:
  "!TARGET_64BIT && ix86_match_ccmode (insn, CCmode)"
  "cmp{b}\t{%h1, %0|%0, %h1}"
  [(set_attr "type" "icmp")
   (set_attr "mode" "QI")]
:}

concrete *cmpqi_ext_1_rex64.insn overrides *cmpqi_ext_1.insn
{
    root.2.1.predicate:=register_operand;
    root.2.1.constraint:=Q;
}
{:
    "TARGET_64BIT && ix86_match_ccmode (insn, CCmode)"
  "cmp{b}\t{%h1, %0|%0, %h1}"
  [(set_attr "type" "icmp")
   (set_attr "mode" "QI")]
:}

abstract set_compare_subreg_zero_extract1 extends set_compare
{
	root.2.1:=subreg_zero_extract;
}

concrete *cmpqi_ext_2.insn instantiates set_compare_subreg_zero_extract1
{
root (reg(NULL:FLAGS_REG),0=ext_register_operand:NULL:"Q",const_int:8,const_int:8,<0>,1=const0_operand:QI:"");
	root.2.1.mode:=QI;
	root.2.1.1.mode:=SI;
}
{:
  "ix86_match_ccmode (insn, CCNOmode)"
  "test{b}\t%h0, %h0"
  [(set_attr "type" "test")
   (set_attr "length_immediate" "0")
   (set_attr "mode" "QI")]
:}

concrete cmpqi_ext_3.exp instantiates set_compare_subreg_zero_extract1
{
    root(reg(CC:FLAGS_REG),(0=ext_register_operand:NULL:"",const_int:8,const_int:8,<0>,1=immediate_operand:QI:""));
    root.2.1.mode:=QI;
    root.2.1.1.mode:=SI;
    root.2.mode:=CC;
}
{:
:}

concrete *cmpqi_ext_3_insn.insn overrides *cmpqi_ext_2.insn
{
    root.2.2:=general_operand:QI:"Qmn";
}
{:
    "!TARGET_64BIT && ix86_match_ccmode (insn, CCmode)"
  "cmp{b}\t{%1, %h0|%h0, %1}"
  [(set_attr "type" "icmp")
   (set_attr "modrm" "1")
   (set_attr "mode" "QI")]
:}

concrete *cmpqi_ext_3_insn_rex64.insn overrides *cmpqi_ext_2.insn
{
    root.2.2:=nonmemory_operand:QI:"Qn";
}
{:
  "TARGET_64BIT && ix86_match_ccmode (insn, CCmode)"
  "cmp{b}\t{%1, %h0|%h0, %1}"
  [(set_attr "type" "icmp")
   (set_attr "modrm" "1")
   (set_attr "mode" "QI")]
:}

abstract set_compare_subreg_zero_extract_subreg_zero_extract extends set_compare
{
    root.2.1:=subreg_zero_extract;
    root.2.2:=subreg_zero_extract;
}

concrete *cmpqi_ext_4.insn instantiates set_compare_subreg_zero_extract_subreg_zero_extract
{
    root(reg(NULL:FLAGS_REG),0=ext_register_operand:NULL:"Q",const_int:8,const_int:8,0,1=ext_register_operand:NULL:"Q",const_int:8,const_int:8,0);
    root.2.1.mode:=QI;
    root.2.1.1.mode:=SI;
    root.2.2.mode:=QI;
    root.2.2.1.mode:=SI;
}
{:
  "ix86_match_ccmode (insn, CCmode)"
  "cmp{b}\t{%h1, %h0|%h0, %h1}"
  [(set_attr "type" "icmp")
   (set_attr "mode" "QI")]
:}

{:
;; These implement float point compares.
;; %%% See if we can get away with VOIDmode operands on the actual insns,
;; which would allow mix and match FP modes on the compares.  Which is what
;; the old patterns did, but with many more of them.
:}

concrete cbranchxf4.exp instantiates set_compare_set_if_then_else_match_operator_label_ref
{
    root(reg(CC:FLAGS_REG),1=nonmemory_operand:XF:"",2=nonmemory_operand:XF:"",pc,(0=ix86_fp_comparison_operator,reg(CC:FLAGS_REG),const_int:0),3=NULL:NULL:"",pc);
    root.1.2.mode:=CC;
}
{:
  "TARGET_80387"
{
  ix86_expand_branch (GET_CODE (operands[0]),
              operands[1], operands[2], operands[3]);
  DONE;
}
:}

concrete cstorexf4.exp instantiates set_compare_set_match_operator
{
    root(reg(CC:FLAGS_REG),2=nonmemory_operand:XF:"",3=nonmemory_operand:XF:"",0=register_operand:QI:"",(1=ix86_fp_comparison_operator,reg(CC:FLAGS_REG),const_int:0));
    root.1.2.mode:=CC;
}
{:
  "TARGET_80387"
{
  ix86_expand_setcc (operands[0], GET_CODE (operands[1]),
             operands[2], operands[3]);
  DONE;
}
:}

{:

;; Query #1
(define_expand "cbranch<mode>4"
  [(set (reg:CC FLAGS_REG)
    (compare:CC (match_operand:MODEF 1 "cmp_fp_expander_operand" "")
            (match_operand:MODEF 2 "cmp_fp_expander_operand" "")))
   (set (pc) (if_then_else
              (match_operator 0 "ix86_fp_comparison_operator"
               [(reg:CC FLAGS_REG)
                (const_int 0)])
              (label_ref (match_operand 3 "" ""))
              (pc)))]
  "TARGET_80387 || (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)"
{
  ix86_expand_branch (GET_CODE (operands[0]),
              operands[1], operands[2], operands[3]);
  DONE;
})

(define_expand "cstore<mode>4"
  [(set (reg:CC FLAGS_REG)
    (compare:CC (match_operand:MODEF 2 "cmp_fp_expander_operand" "")
            (match_operand:MODEF 3 "cmp_fp_expander_operand" "")))
   (set (match_operand:QI 0 "register_operand" "")
              (match_operator 1 "ix86_fp_comparison_operator"
               [(reg:CC FLAGS_REG)
                (const_int 0)]))]
  "TARGET_80387 || (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)"
{
  ix86_expand_setcc (operands[0], GET_CODE (operands[1]),
             operands[2], operands[3]);
  DONE;
})

:}

concrete cbranchcc4.exp instantiates set_if_then_else_match_operator_label_ref
{
    root(pc,(0=comparison_operator,1=flags_reg_operand:NULL:"",2=const0_operand:NULL:""),3=NULL:NULL:"",pc);
}
{:
  ""
{
  ix86_expand_branch (GET_CODE (operands[0]),
              operands[1], operands[2], operands[3]);
  DONE;
}
:}

concrete cstorecc4.exp instantiates set_match_operator
{
    root(0=register_operand:QI:"",(1=comparison_operator,2=flags_reg_operand:NULL:"",3=const0_operand:NULL:""));
}
{:
  ""
{
  ix86_expand_setcc (operands[0], GET_CODE (operands[1]),
             operands[2], operands[3]);
  DONE;
}
:}

{:
;; FP compares, step 1:
;; Set the FP condition codes.
;;
;; CCFPmode compare with exceptions
;; CCFPUmode    compare with no exceptions

;; We may not use "#" to split and emit these, since the REG_DEAD notes
;; used to manage the reg stack popping would not be preserved.
:}

concrete *cmpfp_0.insn instantiates set_unspec_compare
{
        root (0=register_operand:HI:"=a",(1=register_operand:NULL:"f",2=const0_operand:NULL:"",<UNSPEC_FNSTSW>));
        root.2.mode:=HI;
        root.2.1.mode:=CCFP;
}
{:
"X87_FLOAT_MODE_P (GET_MODE (operands[1]))
   && GET_MODE (operands[1]) == GET_MODE (operands[2])"
  "* return output_fp_compare (insn, operands, false, false);"
  [(set_attr "type" "multi")
   (set_attr "unit" "i387")
   (set (attr "mode")
     (cond [(match_operand:SF 1 "" "")
              (const_string "SF")
            (match_operand:DF 1 "" "")
              (const_string "DF")
           ]
           (const_string "XF")))]
:}

abstract set_compare_clobber extends sequence
{
    root.1:=set_compare;
    root.2:=clobber;
}

abstract set_unspec_compare_set_unspec extends sequence
{
    root.1:=set_unspec_compare;
    root.2:=set_unspec;
}


concrete *cmpfp_0_cc.insn_and_split instantiates.in set_compare_clobber
{
    root (reg(CCFP:FLAGS_REG),1=register_operand:NULL:"f",2=const0_operand:NULL:"",0=register_operand:HI:"=a");
    root.1.2.mode:=CCFP;
}
cmd_spec.in
{:
    "X87_FLOAT_MODE_P (GET_MODE (operands[1]))
   && TARGET_SAHF && !TARGET_CMOVE
   && GET_MODE (operands[1]) == GET_MODE (operands[2])"
  "#"
  "&& reload_completed"
:}
instantiates.out set_unspec_compare_set_unspec
{
    root (duplicate 0,(duplicate 1, duplicate 2,<UNSPEC_FNSTSW>),reg(CC:FLAGS_REG),(duplicate 0,<UNSPEC_SAHF>));
    root.1.2.mode:=HI;
    root.1.2.1.mode:=CCFP;
    root.2.2.mode:=CC;
}
cmd_spec.out
{:
  ""
  [(set_attr "type" "multi")
   (set_attr "unit" "i387")
   (set (attr "mode")
     (cond [(match_operand:SF 1 "" "")
          (const_string "SF")
        (match_operand:DF 1 "" "")
          (const_string "DF")
       ]
       (const_string "XF")))]
:}

concrete *cmpfp_xf.insn overrides *cmpfp_0.insn
{
    root.2.1.1.mode:=XF;
    root.2.1.2:=register_operand:XF:"f";
}
{:
  "TARGET_80387"
  "* return output_fp_compare (insn, operands, false, false);"
  [(set_attr "type" "multi")
   (set_attr "unit" "i387")
   (set_attr "mode" "XF")]
:}

concrete *cmpfp_xf_cc.insn_and_split instantiates.in set_compare_clobber
{
    root (reg(CCFP:FLAGS_REG),1=register_operand:XF:"f",2=register_operand:XF:"f",0=register_operand:HI:"=a");
    root.1.2.mode:=CCFP;
}
cmd_spec.in
{:
    "TARGET_80387
   && TARGET_SAHF && !TARGET_CMOVE"
  "#"
  "&& reload_completed"
:}
instantiates.out set_unspec_compare_set_unspec
{
    root (duplicate 0,(duplicate 1, duplicate 2,<UNSPEC_FNSTSW>),reg(CC:FLAGS_REG),(duplicate 0,<UNSPEC_SAHF>));
    root.1.2.mode:=HI;
    root.1.2.1.mode:=CCFP;
    root.2.2.mode:=CC;
}
cmd_spec.out
{:
  ""
  [(set_attr "type" "multi")
   (set_attr "unit" "i387")
   (set_attr "mode" "XF")]
:}

concrete *cmpfp_<mode>.insn overrides *cmpfp_0.insn
{
    root.2.1.1.mode:=MODEF;
    root.2.1.2:=nonimmediate_operand:MODEF:"fm";
}
{:

  "TARGET_80387"
  "* return output_fp_compare (insn, operands, false, false);"
  [(set_attr "type" "multi")
   (set_attr "unit" "i387")
   (set_attr "mode" "<MODE>")]
:}
concrete *cmpfp_<mode>_cc.insn_and_split
instantiates.in set_compare_clobber
{
    root (reg(CCFP:FLAGS_REG),1=register_operand:MODEF:"f",2=nonimmediate_operand:MODEF:"fm",0=register_operand:HI:"=a");
    root.1.2.mode:=CCFP;
}
cmd_spec.in
{:
  "TARGET_80387
   && TARGET_SAHF && !TARGET_CMOVE"
  "#"
  "&& reload_completed"
:}
instantiates.out set_unspec_compare_set_unspec
{
    root (duplicate 0, (duplicate 1,duplicate 2,<UNSPEC_FNSTSW>),reg(CC:FLAGS_REG),(duplicate 0,<UNSPEC_SAHF>));
    root.1.2.mode:=HI;
    root.1.2.1.mode:=CCFP;
    root.2.2.mode:=CC;
}
cmd_spec.out
{:
  ""
  [(set_attr "type" "multi")
   (set_attr "unit" "i387")
   (set_attr "mode" "<MODE>")]
:}

concrete *cmpfp_u.insn overrides *cmpfp_0.insn
{
    root.2.1.mode:=CCFPU;
    root.2.1.1.mode:=NULL;
    root.2.1.2.mode:=NULL;
    root.2.1.2:=register_operand:XF:"f";
}
{:
  "X87_FLOAT_MODE_P (GET_MODE (operands[1]))
   && GET_MODE (operands[1]) == GET_MODE (operands[2])"
  "* return output_fp_compare (insn, operands, false, true);"
  [(set_attr "type" "multi")
   (set_attr "unit" "i387")
   (set (attr "mode")
     (cond [(match_operand:SF 1 "" "")
          (const_string "SF")
        (match_operand:DF 1 "" "")
          (const_string "DF")
       ]
       (const_string "XF")))]
:}

concrete *cmpfp_u_cc.insn_and_split instantiates.in set_compare_clobber
{
    root (reg(CCFPU:FLAGS_REG),1=register_operand:NULL:"f",2=register_operand:NULL:"f",0=register_operand:HI:"=a");
        root.1.2.mode:=CCFPU;
}
cmd_spec.in
{:
  "X87_FLOAT_MODE_P (GET_MODE (operands[1]))
   && TARGET_SAHF && !TARGET_CMOVE
   && GET_MODE (operands[1]) == GET_MODE (operands[2])"
  "#"
  "&& reload_completed"
:}
instantiates.out set_unspec_compare_set_unspec
{
    root (duplicate 0,(duplicate 1,duplicate 2,<UNSPEC_FNSTSW>),reg(CC:FLAGS_REG),(duplicate 0,<UNSPEC_SAHF>));
        root.1.2.mode:=HI;
        root.1.2.1.mode:=CCFPU;
        root.2.2.mode:=CC;
}
cmd_spec.out
{:
  ""
  [(set_attr "type" "multi")
   (set_attr "unit" "i387")
   (set (attr "mode")
     (cond [(match_operand:SF 1 "" "")
          (const_string "SF")
        (match_operand:DF 1 "" "")
          (const_string "DF")
       ]
       (const_string "XF")))]
:}

{:
;; This pattern occurs twice.
(define_insn "*cmpfp_<mode>"
  [(set (match_operand:HI 0 "register_operand" "=a")
    (unspec:HI
      [(compare:CCFP
         (match_operand 1 "register_operand" "f")
         (match_operator 3 "float_operator"
           [(match_operand:SWI24 2 "memory_operand" "m")]))]
      UNSPEC_FNSTSW))]
  "X87_FLOAT_MODE_P (GET_MODE (operands[1]))
   && (TARGET_USE_<MODE>MODE_FIOP || optimize_function_for_size_p (cfun))
   && (GET_MODE (operands [3]) == GET_MODE (operands[1]))"
  "* return output_fp_compare (insn, operands, false, false);"
  [(set_attr "type" "multi")
   (set_attr "unit" "i387")
   (set_attr "fp_int_src" "true")
   (set_attr "mode" "<MODE>")])

:}

abstract set_compare_match_operator_clobber extends sequence
{
    root.1:=set;
    root.1.2:=compare;
    root.1.2.2:=match_operator;
    root.2:=clobber;
}


abstract set_unspec_compare_match_op_dup_set_unspec extends set_unspec_compare_set_unspec{
    root.1.2.1.2:=match_op_dup;
}

{:
;; This pattern appears twice.

(define_insn_and_split "*cmpfp_<mode>_cc"
  [(set (reg:CCFP FLAGS_REG)
    (compare:CCFP
      (match_operand 1 "register_operand" "f")
      (match_operator 3 "float_operator"
        [(match_operand:SWI24 2 "memory_operand" "m")])))
   (clobber (match_operand:HI 0 "register_operand" "=a"))]
  "X87_FLOAT_MODE_P (GET_MODE (operands[1]))
   && TARGET_SAHF && !TARGET_CMOVE
   && (TARGET_USE_<MODE>MODE_FIOP || optimize_function_for_size_p (cfun))
   && (GET_MODE (operands [3]) == GET_MODE (operands[1]))"
  "#"
  "&& reload_completed"
  [(set (match_dup 0)
    (unspec:HI
      [(compare:CCFP
         (match_dup 1)
         (match_op_dup 3 [(match_dup 2)]))]
    UNSPEC_FNSTSW))
   (set (reg:CC FLAGS_REG)
    (unspec:CC [(match_dup 0)] UNSPEC_SAHF))]
  ""
  [(set_attr "type" "multi")
   (set_attr "unit" "i387")
   (set_attr "fp_int_src" "true")
   (set_attr "mode" "<MODE>")])


:}

{:
;; FP compares, step 2
;; Move the fpsw to ax.
:}


concrete x86_fnstsw_1.insn instantiates set_unspec
{
    root (0=register_operand:HI:"=a",(reg(CCFP:FPSR_REG),<UNSPEC_FNSTSW>));
    root.2.mode:=HI;
}
{:
  "TARGET_80387"
 "fnstsw\t%0"
  [(set (attr "length")
    (symbol_ref "ix86_attr_length_address_default (insn) + 2"))
   (set_attr "mode" "SI")
   (set_attr "unit" "i387")]
:}

{:

;; FP compares, step 3
;; Get ax into flags, general case.

:}

concrete x86_sahf_1.insn instantiates set_unspec
{
    root(reg(CC:FLAGS_REG),(0=register_operand:HI:"a",<UNSPEC_SAHF>));
    root.2.mode:=CC;
}
{:
  "TARGET_SAHF"
{
#ifndef HAVE_AS_IX86_SAHF
  if (TARGET_64BIT)
    return ASM_BYTE "0x9e";
  else
#endif
  return "sahf";
}
  [(set_attr "length" "1")
   (set_attr "athlon_decode" "vector")
   (set_attr "amdfam10_decode" "direct")
   (set_attr "bdver1_decode" "direct")
   (set_attr "mode" "SI")]
:}

{:
;; Pentium Pro can do steps 1 through 3 in one go.
;; comi*, ucomi*, fcomi*, ficomi*, fucomi*
;; (these i387 instructions set flags directly)
:}

concrete *cmpfp_i_mixed.insn instantiates set_compare
{
    root (reg(CCFP:FLAGS_REG),0=register_operand:NULL:"f,x",1=nonimmediate_operand:NULL:"f,xm");
    root.2.mode:=CCFP;
}
{:
  "TARGET_MIX_SSE_I387
   && SSE_FLOAT_MODE_P (GET_MODE (operands[0]))
   && GET_MODE (operands[0]) == GET_MODE (operands[1])"
  "* return output_fp_compare (insn, operands, true, false);"
  [(set_attr "type" "fcmp,ssecomi")
   (set_attr "prefix" "orig,maybe_vex")
   (set (attr "mode")
     (if_then_else (match_operand:SF 1 "" "")
        (const_string "SF")
        (const_string "DF")))
   (set (attr "prefix_rep")
    (if_then_else (eq_attr "type" "ssecomi")
              (const_string "0")
              (const_string "*")))
   (set (attr "prefix_data16")
    (cond [(eq_attr "type" "fcmp")
         (const_string "*")
           (eq_attr "mode" "DF")
         (const_string "1")
          ]
          (const_string "0")))
   (set_attr "athlon_decode" "vector")
   (set_attr "amdfam10_decode" "direct")
   (set_attr "bdver1_decode" "double")]
:}


concrete *cmpfp_i_sse.insn overrides *cmpfp_i_mixed.insn
{
    root.2.1:=register_operand:NULL:"x";
    root.2.2:=nonimmediate_operand:NULL:"xm";
}
{:
  "TARGET_SSE_MATH
   && SSE_FLOAT_MODE_P (GET_MODE (operands[0]))
   && GET_MODE (operands[0]) == GET_MODE (operands[1])"
  "* return output_fp_compare (insn, operands, true, false);"
  [(set_attr "type" "ssecomi")
   (set_attr "prefix" "maybe_vex")
   (set (attr "mode")
     (if_then_else (match_operand:SF 1 "" "")
        (const_string "SF")
        (const_string "DF")))
   (set_attr "prefix_rep" "0")
   (set (attr "prefix_data16")
    (if_then_else (eq_attr "mode" "DF")
              (const_string "1")
              (const_string "0")))
   (set_attr "athlon_decode" "vector")
   (set_attr "amdfam10_decode" "direct")
   (set_attr "bdver1_decode" "double")]
:}

concrete *cmpfp_i_i387.insn overrides *cmpfp_i_mixed.insn
{
    root.2.1.constraint:=f;
    root.2.2:=register_operand:NULL:"f";
}
{:
    "X87_FLOAT_MODE_P (GET_MODE (operands[0]))
   && TARGET_CMOVE
   && !(SSE_FLOAT_MODE_P (GET_MODE (operands[0])) && TARGET_SSE_MATH)
   && GET_MODE (operands[0]) == GET_MODE (operands[1])"
  "* return output_fp_compare (insn, operands, true, false);"
  [(set_attr "type" "fcmp")
   (set (attr "mode")
     (cond [(match_operand:SF 1 "" "")
          (const_string "SF")
        (match_operand:DF 1 "" "")
          (const_string "DF")
       ]
       (const_string "XF")))
   (set_attr "athlon_decode" "vector")
   (set_attr "amdfam10_decode" "direct")
   (set_attr "bdver1_decode" "double")]
:}

concrete *cmpfp_iu_mixed.insn overrides *cmpfp_i_mixed.insn
{
	root.1.mode:=CCFPU;
    root.2.mode:=CCFPU;
}
{:
  "TARGET_MIX_SSE_I387
   && SSE_FLOAT_MODE_P (GET_MODE (operands[0]))
   && GET_MODE (operands[0]) == GET_MODE (operands[1])"
  "* return output_fp_compare (insn, operands, true, true);"
  [(set_attr "type" "fcmp,ssecomi")
   (set_attr "prefix" "orig,maybe_vex")
   (set (attr "mode")
     (if_then_else (match_operand:SF 1 "" "")
        (const_string "SF")
        (const_string "DF")))
   (set (attr "prefix_rep")
    (if_then_else (eq_attr "type" "ssecomi")
              (const_string "0")
              (const_string "*")))
   (set (attr "prefix_data16")
    (cond [(eq_attr "type" "fcmp")
         (const_string "*")
           (eq_attr "mode" "DF")
         (const_string "1")
          ]
          (const_string "0")))
   (set_attr "athlon_decode" "vector")
   (set_attr "amdfam10_decode" "direct")
   (set_attr "bdver1_decode" "double")]
:}

concrete *cmpfp_iu_sse.insn overrides *cmpfp_iu_mixed.insn
{
    root.2.1:=register_operand:NULL:"x";
    root.2.2:=nonimmediate_operand:NULL:"xm";
    root.2.mode:=CCFPU;
}
{:
  "TARGET_SSE_MATH
   && SSE_FLOAT_MODE_P (GET_MODE (operands[0]))
   && GET_MODE (operands[0]) == GET_MODE (operands[1])"
  "* return output_fp_compare (insn, operands, true, true);"
  [(set_attr "type" "ssecomi")
   (set_attr "prefix" "maybe_vex")
   (set (attr "mode")
     (if_then_else (match_operand:SF 1 "" "")
        (const_string "SF")
        (const_string "DF")))
   (set_attr "prefix_rep" "0")
   (set (attr "prefix_data16")
    (if_then_else (eq_attr "mode" "DF")
              (const_string "1")
              (const_string "0")))
   (set_attr "athlon_decode" "vector")
   (set_attr "amdfam10_decode" "direct")
   (set_attr "bdver1_decode" "double")]
:}


concrete *cmpfp_iu_387.insn overrides *cmpfp_iu_mixed.insn
{
    root.2.1:=register_operand:NULL:"f";
    root.2.2:=register_operand:NULL:"f";
    root.2.mode:=CCFPU;
}
{:
  "X87_FLOAT_MODE_P (GET_MODE (operands[0]))
   && TARGET_CMOVE
   && !(SSE_FLOAT_MODE_P (GET_MODE (operands[0])) && TARGET_SSE_MATH)
   && GET_MODE (operands[0]) == GET_MODE (operands[1])"
  "* return output_fp_compare (insn, operands, true, true);"
  [(set_attr "type" "fcmp")
   (set (attr "mode")
     (cond [(match_operand:SF 1 "" "")
          (const_string "SF")
        (match_operand:DF 1 "" "")
          (const_string "DF")
       ]
       (const_string "XF")))
   (set_attr "athlon_decode" "vector")
   (set_attr "amdfam10_decode" "direct")
   (set_attr "bdver1_decode" "direct")]
:}

{:
;; Push/pop instructions.
:}

concrete *push<mode>2.insn instantiates set
{
    root(0=push_operand:DWI:"=<",1=general_no_elim_operand:DWI:"riF*o");
}
{:
  ""
  "#"
  [(set_attr "type" "multi")
   (set_attr "mode" "<MODE>")]
:}

concrete .split instantiates.in set
{
    root (0=push_operand:TI:"",1=general_operand:TI:"");
}
cmd_spec.in
{:
  "TARGET_64BIT && reload_completed
   && !SSE_REG_P (operands[1])"
:}
instantiates.out sequence
{
    root (const_int:0);
}
cmd_spec.out
{:
  "ix86_split_long_move (operands); DONE;"
:}

concrete *pushdi2_rex64.insn overrides *push<mode>2.insn
{
   	allconstraints:=("=<,!<", "re*m,n");
   	DWI->DI;
}
{:
  "TARGET_64BIT"
  "@
   push{q}\t%1
   #"
  [(set_attr "type" "push,multi")
   (set_attr "mode" "DI")]
:}

{:
;; Convert impossible pushes of immediate to existing instructions.
;; First try to get scratch register and go through it.  In case this
;; fails, push sign extended lower part first and then overwrite
;; upper part by 32bit move.
:}

abstract sequence_set extends sequence
{
    root.2:=set;
}

abstract set_set extends sequence
{
    root.1:=set;
    root.2:=set;
}

concrete .peep2 instantiates.in sequence_set
{
        root (2=DI:"r",0=push_operand:DI:"",1=immediate_operand:DI:"");
}
cmd_spec.in
{:
  "TARGET_64BIT && !symbolic_operand (operands[1], DImode)
   && !x86_64_immediate_operand (operands[1], DImode)"
:}
instantiates.out set_set
{
        root (duplicate 2,duplicate 1,duplicate 0,duplicate 2);
}

{:
;; We need to define this as both peepholer and splitter for case
;; peephole2 pass is not run.
;; "&& 1" is needed to keep it from matching the previous pattern.
:}

concrete .peep2 instantiates.in set
{
    root(0=push_operand:DI:"",1=immediate_operand:DI:"");
}
cmd_spec.in
{:
  "TARGET_64BIT && !symbolic_operand (operands[1], DImode)
   && !x86_64_immediate_operand (operands[1], DImode) && 1"
:}
instantiates.out set_set
{
    root (duplicate 0,duplicate 1,duplicate 2,duplicate 3);
}
cmd_spec.out
{:
{
  split_double_mode (DImode, &operands[1], 1, &operands[2], &operands[3]);

  operands[1] = gen_lowpart (DImode, operands[2]);
  operands[2] = gen_rtx_MEM (SImode, gen_rtx_PLUS (DImode, stack_pointer_rtx,
                           GEN_INT (4)));
}
:}

concrete .split instantiates.in set
{
    root (0=push_operand:DI:"",1=immediate_operand:DI:"");
}
cmd_spec.in
{:
  "TARGET_64BIT && ((optimize > 0 && flag_peephole2)
            ? epilogue_completed : reload_completed)
   && !symbolic_operand (operands[1], DImode)
   && !x86_64_immediate_operand (operands[1], DImode)"
:}
instantiates.out set_set
{
    root(duplicate 0,duplicate 1,duplicate 2,duplicate 3);
}
cmd_spec.out
{:
{
  split_double_mode (DImode, &operands[1], 1, &operands[2], &operands[3]);

  operands[1] = gen_lowpart (DImode, operands[2]);
  operands[2] = gen_rtx_MEM (SImode, gen_rtx_PLUS (DImode, stack_pointer_rtx,
                           GEN_INT (4)));
}
:}

concrete .split instantiates.in set
{
    root (0=push_operand:DI:"",1=general_operand:DI:"");
}
cmd_spec.in
{:
  "!TARGET_64BIT && reload_completed
   && !(MMX_REG_P (operands[1]) || SSE_REG_P (operands[1]))"
:}
instantiates.out sequence
{
    root (const_int:0);
}
cmd_spec.out
{:
    "ix86_split_long_move (operands); DONE;"
:}

concrete *pushsi2.insn overrides *push<mode>2.insn
{
    allconstraints:= ("=<", "ri*m");
    DWI->SI;
}
{:
  "!TARGET_64BIT"
  "push{l}\t%1"
  [(set_attr "type" "push")
   (set_attr "mode" "SI")]
:}

{:
;; emit_push_insn when it calls move_by_pieces requires an insn to
;; "push a byte/word".  But actually we use pushl, which has the effect
;; of rounding the amount pushed up to a word.
;; For TARGET_64BIT we always round up to 8 bytes.
:}

concrete *push<mode>2_rex64.insn overrides *push<mode>2.insn
{
    allconstraints:= ("=X", "r<i>");
    DWI->SWI124;
    root.2.predicate:=nonmemory_no_elim_operand;
}
{:
  "TARGET_64BIT"
  "push{q}\t%q1"
  [(set_attr "type" "push")
   (set_attr "mode" "DI")]
:}

concrete *push<mode>2.insn overrides *push<mode>2_rex64.insn
{
    allconstraints:= ("=X", "rn");
    SWI124->SWI12;
}
{:
  "!TARGET_64BIT"
  "push{l}\t%k1"
  [(set_attr "type" "push")
   (set_attr "mode" "SI")]
:}

abstract set_clobber extends sequence
{
    root.1:=set;
    root.2:=clobber;
}

abstract set_clobber_mem extends set_clobber
{
    root.2.1:=mem;
}

concrete *push<mode>2_prologue.insn instantiates set_clobber_mem
{
    root(0=push_operand:P:"=<",1=general_no_elim_operand:P:"r<i>*m",scratch);
    root.2.1.mode:=BLK;
}
{:
  ""
  "push{<imodesuffix>}\t%1"
  [(set_attr "type" "push")
   (set_attr "mode" "<MODE>")]
:}

concrete *pop<mode>1.insn overrides *push<mode>2_rex64.insn
{
    root.1:=nonimmediate_operand:P:"=r*m";
    root.2:=pop_operand:P:">";
}
{:
  ""
  "pop{<imodesuffix>}\t%0"
  [(set_attr "type" "pop")
   (set_attr "mode" "<MODE>")]
:}

concrete *pop<mode>1_epilogue.insn instantiates set_clobber_mem
{
    root (0=nonimmediate_operand:P:"=r*m",1=pop_operand:P:">",scratch);
    root.2.1.mode:=BLK;
}
{:
  ""
  "pop{<imodesuffix>}\t%0"
  [(set_attr "type" "pop")
   (set_attr "mode" "<MODE>")]
:}

{:
;; Move instructions.
:}

concrete movoi.exp overrides *pop<mode>1.insn
{
	root.1.mode:=OI;
	root.2.mode:=OI;
    root.1.constraint:="";
    root.2:=general_operand:OI:"";
}
{:
  "TARGET_AVX"
  "ix86_expand_move (OImode, operands); DONE;"
:}

concrete movti.exp overrides *pop<mode>1.insn
{
    root.1:=nonimmediate_operand:TI:"";
    root.2:=nonimmediate_operand:TI:"";
}
{:
  "TARGET_64BIT || TARGET_SSE"
{
  if (TARGET_64BIT)
    ix86_expand_move (TImode, operands);
  else if (push_operand (operands[0], TImode))
    ix86_expand_push (TImode, operands[1]);
  else
    ix86_expand_vector_move (TImode, operands);
  DONE;
}
:}

{:
;; This expands to what emit_move_complex would generate if we didn't
;; have a movti pattern.  Having this avoids problems with reload on
;; 32-bit targets when SSE is present, but doesn't seem to be harmful
;; to have around all the time.
:}

concrete movcdi.exp overrides *pop<mode>1.insn
{
    root.1:=nonimmediate_operand:CDI:"";
    root.2:=general_operand:CDI:"";
}
{:
  ""
{
  if (push_operand (operands[0], CDImode))
    emit_move_complex_push (CDImode, operands[0], operands[1]);
  else
    emit_move_complex_parts (operands[0], operands[1]);
  DONE;
}
:}

concrete mov<mode>.exp overrides movcdi.exp
{
    root.1:=nonimmediate_operand:SWI1248x:"";
    root.2:=general_operand:SWI1248x:"";
}
{:
  ""
  "ix86_expand_move (<MODE>mode, operands); DONE;"
:}

concrete *mov<mode>_xor.insn instantiates set_clobber
{
    root (0=register_operand:SWI48:"=r",1=const0_operand:SWI48:"",reg(CC:FLAGS_REG));
}
{:
  "reload_completed"
  "xor{l}\t%k0, %k0"
  [(set_attr "type" "alu1")
   (set_attr "mode" "SI")
   (set_attr "length_immediate" "0")]
:}

concrete *mov<mode>_or.insn overrides *mov<mode>_xor.insn
{
    root.1.2.predicate:=const_int_operand;
}
{:
  "reload_completed
   && operands[1] == constm1_rtx"
  "or{<imodesuffix>}\t{%1, %0|%0, %1}"
  [(set_attr "type" "alu1")
   (set_attr "mode" "<MODE>")
   (set_attr "length_immediate" "1")]
:}

concrete *movoi_internal_avx.insn overrides *pop<mode>1.insn
{
    root.1:=nonimmediate_operand:OI:"=x,x,m";
    root.2:=vector_move_operand:OI:"C,xm,x";
}
{:
  "TARGET_AVX && !(MEM_P (operands[0]) && MEM_P (operands[1]))"
{
  switch (which_alternative)
    {
    case 0:
      return standard_sse_constant_opcode (insn, operands[1]);
    case 1:
    case 2:
      if (misaligned_operand (operands[0], OImode)
      || misaligned_operand (operands[1], OImode))
    return "vmovdqu\t{%1, %0|%0, %1}";
      else
    return "vmovdqa\t{%1, %0|%0, %1}";
    default:
      gcc_unreachable ();
    }
}
  [(set_attr "type" "sselog1,ssemov,ssemov")
   (set_attr "prefix" "vex")
   (set_attr "mode" "OI")]
:}

concrete *movti_internal_rex64.insn overrides *pop<mode>1.insn
{
    root.1:=nonimmediate_operand:TI:"=!r,o,x,x,xm";
    root.2:=general_operand:TI:"riFo,riF,C,xm,x";
}
{:
  "TARGET_64BIT && !(MEM_P (operands[0]) && MEM_P (operands[1]))"
{
  switch (which_alternative)
    {
    case 0:
    case 1:
      return "#";
    case 2:
      return standard_sse_constant_opcode (insn, operands[1]);
    case 3:
    case 4:
      /* TDmode values are passed as TImode on the stack.  Moving them
     to stack may result in unaligned memory access.  */
      if (misaligned_operand (operands[0], TImode)
      || misaligned_operand (operands[1], TImode))
    {
      if (get_attr_mode (insn) == MODE_V4SF)
        return "%vmovups\t{%1, %0|%0, %1}";
      else
        return "%vmovdqu\t{%1, %0|%0, %1}";
    }
      else
    {
      if (get_attr_mode (insn) == MODE_V4SF)
        return "%vmovaps\t{%1, %0|%0, %1}";
      else
        return "%vmovdqa\t{%1, %0|%0, %1}";
    }
    default:
      gcc_unreachable ();
    }
}
  [(set_attr "type" "*,*,sselog1,ssemov,ssemov")
   (set_attr "prefix" "*,*,maybe_vex,maybe_vex,maybe_vex")
   (set (attr "mode")
    (cond [(eq_attr "alternative" "2,3")
         (if_then_else
           (match_test "optimize_function_for_size_p (cfun)")
           (const_string "V4SF")
           (const_string "TI"))
           (eq_attr "alternative" "4")
         (if_then_else
           (ior (match_test "TARGET_SSE_TYPELESS_STORES")
            (match_test "optimize_function_for_size_p (cfun)"))
           (const_string "V4SF")
           (const_string "TI"))]
           (const_string "DI")))]
:}

concrete .split instantiates.in set
{
    root (0=nonimmediate_operand:TI:"",1=general_operand:TI:"");
}
cmd_spec.in
{:
  "reload_completed
   && !SSE_REG_P (operands[0]) && !SSE_REG_P (operands[1])"
:}
instantiates.out sequence
{
    root (const_int:0);
}
cmd_spec.out
{:
  "ix86_split_long_move (operands); DONE;"
:}

concrete *movti_internal_sse.insn overrides *pop<mode>1.insn
{
    root.1:=nonimmediate_operand:TI:"=x,x,m";
    root.2:=vector_move_operand:TI:"C,xm,x";
}
{:  
  "TARGET_SSE && !TARGET_64BIT
   && !(MEM_P (operands[0]) && MEM_P (operands[1]))"
{
  switch (which_alternative)
    {
    case 0:
      return standard_sse_constant_opcode (insn, operands[1]);
    case 1:
    case 2:
      /* TDmode values are passed as TImode on the stack.  Moving them
     to stack may result in unaligned memory access.  */
      if (misaligned_operand (operands[0], TImode)
      || misaligned_operand (operands[1], TImode))
    {
      if (get_attr_mode (insn) == MODE_V4SF)
        return "%vmovups\t{%1, %0|%0, %1}";
      else
        return "%vmovdqu\t{%1, %0|%0, %1}";
    }
      else
    {
      if (get_attr_mode (insn) == MODE_V4SF)
        return "%vmovaps\t{%1, %0|%0, %1}";
      else
        return "%vmovdqa\t{%1, %0|%0, %1}";
    }
    default:
      gcc_unreachable ();
    }
}
  [(set_attr "type" "sselog1,ssemov,ssemov")
   (set_attr "prefix" "maybe_vex")
   (set (attr "mode")
    (cond [(ior (not (match_test "TARGET_SSE2"))
            (match_test "optimize_function_for_size_p (cfun)"))
         (const_string "V4SF")
           (and (eq_attr "alternative" "2")
            (match_test "TARGET_SSE_TYPELESS_STORES"))
         (const_string "V4SF")]
          (const_string "TI")))]
:}

concrete *movdi_internal_rex64.insn overrides *pop<mode>1.insn
{
    root.1:=nonimmediate_operand:DI:"=r,r  ,r,m ,!o,*y,m*y,?*y,?r ,?*Ym,*x,m ,*x,*x,?r ,?*Yi,?*x,?*Ym";
    root.2:=general_operand:DI:"Z ,rem,i,re,n ,C ,*y ,m  ,*Ym,r   ,C ,*x,*x,m ,*Yi,r   ,*Ym,*x";

}
{:
  "TARGET_64BIT && !(MEM_P (operands[0]) && MEM_P (operands[1]))"
{
  switch (get_attr_type (insn))
    {
    case TYPE_SSECVT:
      if (SSE_REG_P (operands[0]))
    return "movq2dq\t{%1, %0|%0, %1}";
      else
    return "movdq2q\t{%1, %0|%0, %1}";

    case TYPE_SSEMOV:
      if (get_attr_mode (insn) == MODE_TI)
    return "%vmovdqa\t{%1, %0|%0, %1}";
      /* Handle broken assemblers that require movd instead of movq.  */
      if (GENERAL_REG_P (operands[0]) || GENERAL_REG_P (operands[1]))
    return "%vmovd\t{%1, %0|%0, %1}";
      else
    return "%vmovq\t{%1, %0|%0, %1}";

    case TYPE_MMXMOV:
      /* Handle broken assemblers that require movd instead of movq.  */
      if (GENERAL_REG_P (operands[0]) || GENERAL_REG_P (operands[1]))
    return "movd\t{%1, %0|%0, %1}";
      else
    return "movq\t{%1, %0|%0, %1}";

    case TYPE_SSELOG1:
      return standard_sse_constant_opcode (insn, operands[1]);

    case TYPE_MMX:
      return "pxor\t%0, %0";

    case TYPE_MULTI:
      return "#";

    case TYPE_LEA:
      return "lea{q}\t{%E1, %0|%0, %E1}";
    default:
      gcc_assert (!flag_pic || LEGITIMATE_PIC_OPERAND_P (operands[1]));
      if (get_attr_mode (insn) == MODE_SI)
    return "mov{l}\t{%k1, %k0|%k0, %k1}";
      else if (which_alternative == 2)
    return "movabs{q}\t{%1, %0|%0, %1}";
      else if (ix86_use_lea_for_mov (insn, operands))
    return "lea{q}\t{%E1, %0|%0, %E1}";
      else
    return "mov{q}\t{%1, %0|%0, %1}";
    }
}
  [(set (attr "type")
     (cond [(eq_attr "alternative" "4")
          (const_string "multi")
        (eq_attr "alternative" "5")
          (const_string "mmx")
        (eq_attr "alternative" "6,7,8,9")
          (const_string "mmxmov")
        (eq_attr "alternative" "10")
          (const_string "sselog1")
        (eq_attr "alternative" "11,12,13,14,15")
          (const_string "ssemov")
        (eq_attr "alternative" "16,17")
          (const_string "ssecvt")
        (match_operand 1 "pic_32bit_operand" "")
          (const_string "lea")
       ]
       (const_string "imov")))
   (set (attr "modrm")
     (if_then_else
       (and (eq_attr "alternative" "2") (eq_attr "type" "imov"))
     (const_string "0")
     (const_string "*")))
   (set (attr "length_immediate")
     (if_then_else
       (and (eq_attr "alternative" "2") (eq_attr "type" "imov"))
     (const_string "8")
     (const_string "*")))
   (set (attr "prefix_rex")
     (if_then_else (eq_attr "alternative" "8,9")
       (const_string "1")
       (const_string "*")))
   (set (attr "prefix_data16")
     (if_then_else (eq_attr "alternative" "11")
       (const_string "1")
       (const_string "*")))
   (set (attr "prefix")
     (if_then_else (eq_attr "alternative" "10,11,12,13,14,15")
       (const_string "maybe_vex")
       (const_string "orig")))
   (set_attr "mode" "SI,DI,DI,DI,SI,DI,DI,DI,DI,DI,TI,DI,TI,DI,DI,DI,DI,DI")]
:}

{:
;; Reload patterns to support multi-word load/store
;; with non-offsetable address.


(define_expand "reload_noff_store"
  [(parallel [(match_operand 0 "memory_operand" "=m")
              (match_operand 1 "register_operand" "r")
              (match_operand:DI 2 "register_operand" "=&r")])]
  "TARGET_64BIT"
{
  rtx mem = operands[0];
  rtx addr = XEXP (mem, 0);

  emit_move_insn (operands[2], addr);
  mem = replace_equiv_address_nv (mem, operands[2]);

  emit_insn (gen_rtx_SET (VOIDmode, mem, operands[1]));
  DONE;
})

(define_expand "reload_noff_load"
  [(parallel [(match_operand 0 "register_operand" "=r")
              (match_operand 1 "memory_operand" "m")
              (match_operand:DI 2 "register_operand" "=r")])]
  "TARGET_64BIT"
{
  rtx mem = operands[1];
  rtx addr = XEXP (mem, 0);

  emit_move_insn (operands[2], addr);
  mem = replace_equiv_address_nv (mem, operands[2]);

  emit_insn (gen_rtx_SET (VOIDmode, operands[0], mem));
  DONE;
})

:}

{:
;; Convert impossible stores of immediate to existing instructions.
;; First try to get scratch register and go through it.  In case this
;; fails, move by 32bit parts.
:}

concrete .peep2 instantiates.in sequence_set
{
    root (2=DI:"r",0=memory_operand:DI:"",1=immediate_operand:DI:"");
}
cmd_spec.in
{:
  "TARGET_64BIT && !symbolic_operand (operands[1], DImode)
   && !x86_64_immediate_operand (operands[1], DImode)"
:}
instantiates.out set_set
{
    root(duplicate 2,duplicate 1,duplicate 0,duplicate 2);
}

{:
;; We need to define this as both peepholer and splitter for case
;; peephole2 pass is not run.
;; "&& 1" is needed to keep it from matching the previous pattern.
:}

concrete .peep2 instantiates.in set
{
    root(0=memory_operand:DI:"",1=immediate_operand:DI:"");
}
cmd_spec.in
{:
  "TARGET_64BIT && !symbolic_operand (operands[1], DImode)
   && !x86_64_immediate_operand (operands[1], DImode) && 1"
:}
instantiates.out set_set
{
    root(duplicate 2,duplicate 3,duplicate 4,duplicate 5);
}
cmd_spec.out
{:
  "split_double_mode (DImode, &operands[0], 2, &operands[2], &operands[4]);"
:}

concrete .split instantiates.in set
{
    root (0=memory_operand:DI:"",1=immediate_operand:DI:"");
}
cmd_spec.in
{:
  "TARGET_64BIT && ((optimize > 0 && flag_peephole2)
            ? epilogue_completed : reload_completed)
   && !symbolic_operand (operands[1], DImode)
   && !x86_64_immediate_operand (operands[1], DImode)"
:}
instantiates.out set_set
{
    root (duplicate 2,duplicate 3,duplicate 4,duplicate 5);
}
cmd_spec.out
{:
  "split_double_mode (DImode, &operands[0], 2, &operands[2], &operands[4]);"
:}

concrete *movdi_internal.insn  overrides *pop<mode>1.insn
{
    root.1:=nonimmediate_operand:DI:"=r  ,o  ,*y,m*y,*y,*x,m ,*x,*x,*x,m ,*x,*x,?*x,?*Ym";
    root.2:=general_operand:DI:"riFo,riF,C ,*y ,m ,C ,*x,*x,m ,C ,*x,*x,m ,*Ym,*x";
}
{:
  "!TARGET_64BIT && !(MEM_P (operands[0]) && MEM_P (operands[1]))"
{
  switch (get_attr_type (insn))
    {
    case TYPE_SSECVT:
      if (SSE_REG_P (operands[0]))
    return "movq2dq\t{%1, %0|%0, %1}";
      else
    return "movdq2q\t{%1, %0|%0, %1}";

    case TYPE_SSEMOV:
      switch (get_attr_mode (insn))
    {
    case MODE_TI:
      return "%vmovdqa\t{%1, %0|%0, %1}";
    case MODE_DI:
       return "%vmovq\t{%1, %0|%0, %1}";
    case MODE_V4SF:
      return "movaps\t{%1, %0|%0, %1}";
    case MODE_V2SF:
      return "movlps\t{%1, %0|%0, %1}";
    default:
      gcc_unreachable ();
    }

    case TYPE_MMXMOV:
      return "movq\t{%1, %0|%0, %1}";

    case TYPE_SSELOG1:
      return standard_sse_constant_opcode (insn, operands[1]);

    case TYPE_MMX:
      return "pxor\t%0, %0";

    case TYPE_MULTI:
      return "#";
    default:
      gcc_unreachable ();
    }
}
  [(set (attr "isa")
     (cond [(eq_attr "alternative" "5,6,7,8,13,14")
          (const_string "sse2")
        (eq_attr "alternative" "9,10,11,12")
          (const_string "noavx")
       ]
           (const_string "*")))
   (set (attr "type")
     (cond [(eq_attr "alternative" "0,1")
          (const_string "multi")
        (eq_attr "alternative" "2")
          (const_string "mmx")
        (eq_attr "alternative" "3,4")
          (const_string "mmxmov")
        (eq_attr "alternative" "5,9")
          (const_string "sselog1")
        (eq_attr "alternative" "13,14")
          (const_string "ssecvt")
       ]
       (const_string "ssemov")))
   (set (attr "prefix")
     (if_then_else (eq_attr "alternative" "5,6,7,8")
       (const_string "maybe_vex")
       (const_string "orig")))
   (set_attr "mode" "DI,DI,DI,DI,DI,TI,DI,TI,DI,V4SF,V2SF,V4SF,V2SF,DI,DI")]
:}

concrete .split instantiates.in set
{
    root (0=nonimmediate_operand:DI:"",1=general_operand:DI:"");
}
cmd_spec.in
{:
  "!TARGET_64BIT && reload_completed
   && !(MMX_REG_P (operands[0]) || SSE_REG_P (operands[0]))
   && !(MMX_REG_P (operands[1]) || SSE_REG_P (operands[1]))"
:}
instantiates.out sequence
{
    root (const_int:0);
}
cmd_spec.out
{:
  "ix86_split_long_move (operands); DONE;"
:}

concrete *movsi_internal.insn  overrides *pop<mode>1.insn
{
    root.1:=nonimmediate_operand:SI:"=r,m ,*y,*y,?rm,?*y,*x,*x,?r ,m ,?*Yi,*x";
    root.2:=general_operand:SI:"g ,re,C ,*y,*y ,rm ,C ,*x,*Yi,*x,r   ,m ";
}
{:
  "!(MEM_P (operands[0]) && MEM_P (operands[1]))"
{
  switch (get_attr_type (insn))
    {
    case TYPE_SSELOG1:
      return standard_sse_constant_opcode (insn, operands[1]);

    case TYPE_SSEMOV:
      switch (get_attr_mode (insn))
    {
    case MODE_TI:
      return "%vmovdqa\t{%1, %0|%0, %1}";
    case MODE_V4SF:
      return "%vmovaps\t{%1, %0|%0, %1}";
    case MODE_SI:
          return "%vmovd\t{%1, %0|%0, %1}";
    case MODE_SF:
          return "%vmovss\t{%1, %0|%0, %1}";
    default:
      gcc_unreachable ();
    }

    case TYPE_MMX:
      return "pxor\t%0, %0";

    case TYPE_MMXMOV:
      if (get_attr_mode (insn) == MODE_DI)
    return "movq\t{%1, %0|%0, %1}";
      return "movd\t{%1, %0|%0, %1}";

    case TYPE_LEA:
      return "lea{l}\t{%E1, %0|%0, %E1}";
    default:
      gcc_assert (!flag_pic || LEGITIMATE_PIC_OPERAND_P (operands[1]));
      if (ix86_use_lea_for_mov (insn, operands))
    return "lea{l}\t{%E1, %0|%0, %E1}";
      else
    return "mov{l}\t{%1, %0|%0, %1}";
    }
}
  [(set (attr "type")
     (cond [(eq_attr "alternative" "2")
          (const_string "mmx")
        (eq_attr "alternative" "3,4,5")
          (const_string "mmxmov")
        (eq_attr "alternative" "6")
          (const_string "sselog1")
        (eq_attr "alternative" "7,8,9,10,11")
          (const_string "ssemov")
        (match_operand 1 "pic_32bit_operand" "")
          (const_string "lea")
       ]
       (const_string "imov")))
   (set (attr "prefix")
     (if_then_else (eq_attr "alternative" "0,1,2,3,4,5")
       (const_string "orig")
       (const_string "maybe_vex")))
   (set (attr "prefix_data16")
     (if_then_else (and (eq_attr "type" "ssemov") (eq_attr "mode" "SI"))
       (const_string "1")
       (const_string "*")))
   (set (attr "mode")
     (cond [(eq_attr "alternative" "2,3")
          (const_string "DI")
        (eq_attr "alternative" "6,7")
          (if_then_else
            (not (match_test "TARGET_SSE2"))
            (const_string "V4SF")
            (const_string "TI"))
        (and (eq_attr "alternative" "8,9,10,11")
             (not (match_test "TARGET_SSE2")))
          (const_string "SF")
       ]
       (const_string "SI")))]
:}

concrete *movhi_internal.insn  overrides *pop<mode>1.insn
{
    root.1:=nonimmediate_operand:HI:"=r,r,r,m";
    root.2:=general_operand:HI:"r,rn,rm,rn";
}
{:
  "!(MEM_P (operands[0]) && MEM_P (operands[1]))"
{
  switch (get_attr_type (insn))
    {
    case TYPE_IMOVX:
      /* movzwl is faster than movw on p2 due to partial word stalls,
     though not as fast as an aligned movl.  */
      return "movz{wl|x}\t{%1, %k0|%k0, %1}";
    default:
      if (get_attr_mode (insn) == MODE_SI)
        return "mov{l}\t{%k1, %k0|%k0, %k1}";
      else
        return "mov{w}\t{%1, %0|%0, %1}";
    }
}
  [(set (attr "type")
     (cond [(match_test "optimize_function_for_size_p (cfun)")
          (const_string "imov")
        (and (eq_attr "alternative" "0")
         (ior (not (match_test "TARGET_PARTIAL_REG_STALL"))
              (not (match_test "TARGET_HIMODE_MATH"))))
          (const_string "imov")
        (and (eq_attr "alternative" "1,2")
         (match_operand:HI 1 "aligned_operand" ""))
          (const_string "imov")
        (and (match_test "TARGET_MOVX")
         (eq_attr "alternative" "0,2"))
          (const_string "imovx")
       ]
       (const_string "imov")))
    (set (attr "mode")
      (cond [(eq_attr "type" "imovx")
           (const_string "SI")
         (and (eq_attr "alternative" "1,2")
          (match_operand:HI 1 "aligned_operand" ""))
           (const_string "SI")
         (and (eq_attr "alternative" "0")
          (ior (not (match_test "TARGET_PARTIAL_REG_STALL"))
               (not (match_test "TARGET_HIMODE_MATH"))))
           (const_string "SI")
        ]
        (const_string "HI")))]
:}

{:
;; Situation is quite tricky about when to choose full sized (SImode) move
;; over QImode moves.  For Q_REG -> Q_REG move we use full size only for
;; partial register dependency machines (such as AMD Athlon), where QImode
;; moves issue extra dependency and for partial register stalls machines
;; that don't use QImode patterns (and QImode move cause stall on the next
;; instruction).
;;
;; For loads of Q_REG to NONQ_REG we use full sized moves except for partial
;; register stall machines with, where we use QImode instructions, since
;; partial register stall can be caused there.  Then we use movzx
:}

concrete *movqi_internal.insn overrides *pop<mode>1.insn
{
    root.1:=nonimmediate_operand:QI:"=q,q ,q ,r,r ,?r,m";
    root.2:=general_operand:QI:" q,qn,qm,q,rn,qm,qn";
}
{:
  "!(MEM_P (operands[0]) && MEM_P (operands[1]))"
{
  switch (get_attr_type (insn))
    {
    case TYPE_IMOVX:
      gcc_assert (ANY_QI_REG_P (operands[1]) || MEM_P (operands[1]));
      return "movz{bl|x}\t{%1, %k0|%k0, %1}";
    default:
      if (get_attr_mode (insn) == MODE_SI)
        return "mov{l}\t{%k1, %k0|%k0, %k1}";
      else
        return "mov{b}\t{%1, %0|%0, %1}";
    }
}
  [(set (attr "type")
     (cond [(and (eq_attr "alternative" "5")
         (not (match_operand:QI 1 "aligned_operand" "")))
          (const_string "imovx")
        (match_test "optimize_function_for_size_p (cfun)")
          (const_string "imov")
        (and (eq_attr "alternative" "3")
         (ior (not (match_test "TARGET_PARTIAL_REG_STALL"))
              (not (match_test "TARGET_QIMODE_MATH"))))
          (const_string "imov")
        (eq_attr "alternative" "3,5")
          (const_string "imovx")
        (and (match_test "TARGET_MOVX")
         (eq_attr "alternative" "2"))
          (const_string "imovx")
       ]
       (const_string "imov")))
   (set (attr "mode")
      (cond [(eq_attr "alternative" "3,4,5")
           (const_string "SI")
         (eq_attr "alternative" "6")
           (const_string "QI")
         (eq_attr "type" "imovx")
           (const_string "SI")
         (and (eq_attr "type" "imov")
          (and (eq_attr "alternative" "0,1")
               (and (match_test "TARGET_PARTIAL_REG_DEPENDENCY")
                (and (not (match_test "optimize_function_for_size_p (cfun)"))
                 (not (match_test "TARGET_PARTIAL_REG_STALL"))))))
           (const_string "SI")
         ;; Avoid partial register stalls when not using QImode arithmetic
         (and (eq_attr "type" "imov")
          (and (eq_attr "alternative" "0,1")
               (and (match_test "TARGET_PARTIAL_REG_STALL")
                (not (match_test "TARGET_QIMODE_MATH")))))
           (const_string "SI")
       ]
       (const_string "QI")))]
:}

{:
;; Stores and loads of ax to arbitrary constant address.
;; We fake an second form of instruction to force reload to load address
;; into register when rax is not available
:}

concrete *movabs<mode>_1.insn instantiates set_mem
{
    root(0=x86_64_movabs_operand:DI:"i,r",1=nonmemory_operand:SWI1248x:"a,r<i>");
    root.1.mode:=SWI1248x;
}
{:
  "TARGET_LP64 && ix86_check_movabs (insn, 0)"
  "@
   movabs{<imodesuffix>}\t{%1, %P0|%P0, %1}
   mov{<imodesuffix>}\t{%1, %a0|%a0, %1}"
  [(set_attr "type" "imov")
   (set_attr "modrm" "0,*")
   (set_attr "length_address" "8,0")
   (set_attr "length_immediate" "0,*")
   (set_attr "memory" "store")
   (set_attr "mode" "<MODE>")]
:}

concrete *movabs<mode>_2.insn instantiates set_mem2
{
    root (0=register_operand:SWI1248x:"=a,r",1=x86_64_movabs_operand:DI:"i,r");
    root.2.mode:=SWI1248x;
}
{:
  "TARGET_LP64 && ix86_check_movabs (insn, 1)"
  "@
   movabs{<imodesuffix>}\t{%P1, %0|%0, %P1}
   mov{<imodesuffix>}\t{%a1, %0|%0, %a1}"
  [(set_attr "type" "imov")
   (set_attr "modrm" "0,*")
   (set_attr "length_address" "8,0")
   (set_attr "length_immediate" "0")
   (set_attr "memory" "load")
   (set_attr "mode" "<MODE>")]
:}

concrete *swap<mode>.insn instantiates set_set
{
    root (0=register_operand:SWI48:"+r",1=register_operand:SWI48:"+r",duplicate 1,duplicate 0);
}
{:
  ""
  "xchg{<imodesuffix>}\t%1, %0"
  [(set_attr "type" "imov")
   (set_attr "mode" "<MODE>")
   (set_attr "pent_pair" "np")
   (set_attr "athlon_decode" "vector")
   (set_attr "amdfam10_decode" "double")
   (set_attr "bdver1_decode" "double")]
:}

concrete *swap<mode>_1.insn overrides *swap<mode>.insn
{
    SWI48->SWI12;
}
{:
  "!TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun)"
  "xchg{l}\t%k1, %k0"
  [(set_attr "type" "imov")
   (set_attr "mode" "SI")
   (set_attr "pent_pair" "np")
   (set_attr "athlon_decode" "vector")
   (set_attr "amdfam10_decode" "double")
   (set_attr "bdver1_decode" "double")]
:}

{:
;; Not added amdfam10_decode since TARGET_PARTIAL_REG_STALL
;; is disabled for AMDFAM10
:}

concrete *swap<mode>_2.insn overrides *swap<mode>.insn
{
    SWI48->SWI12;
    allconstraints:= ("+<r>","+<r>");
}
{:
  "TARGET_PARTIAL_REG_STALL"
  "xchg{<imodesuffix>}\t%1, %0"
  [(set_attr "type" "imov")
   (set_attr "mode" "<MODE>")
   (set_attr "pent_pair" "np")
   (set_attr "athlon_decode" "vector")]
:}

concrete movstrict<mode>.exp instantiates set_strict_low_part1
{
    root (0=nonimmediate_operand:SWI12:"",1=general_operand:SWI12:"");
}
{:
  ""
{
  if (TARGET_PARTIAL_REG_STALL && optimize_function_for_speed_p (cfun))
    FAIL;
  if (GET_CODE (operands[0]) == SUBREG
      && GET_MODE_CLASS (GET_MODE (SUBREG_REG (operands[0]))) != MODE_INT)
    FAIL;
  /* Don't generate memory->memory moves, go through a register */
  if (MEM_P (operands[0]) && MEM_P (operands[1]))
    operands[1] = force_reg (<MODE>mode, operands[1]);
}
:}

concrete *movstrict<mode>_1.insn overrides movstrict<mode>.exp
{
    allconstraints:=("+<r>m,<r>","<r>n,m");
}
{:
  "(!TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun))
   && !(MEM_P (operands[0]) && MEM_P (operands[1]))"
  "mov{<imodesuffix>}\t{%1, %0|%0, %1}"
  [(set_attr "type" "imov")
   (set_attr "mode" "<MODE>")]
:}

abstract set_strict_low_part1_clobber extends sequence
{
    root.1:=set_strict_low_part1;
    root.2:=clobber;
}

concrete *movstrict<mode>_xor.insn instantiates set_strict_low_part1_clobber
{
    root (0=register_operand:SWI12:"+<r>",1=const0_operand:SWI12:"",reg(CC:FLAGS_REG));
}
{:
  "reload_completed"
  "xor{<imodesuffix>}\t%0, %0"
  [(set_attr "type" "alu1")
   (set_attr "mode" "<MODE>")
   (set_attr "length_immediate" "0")]
:}


concrete *mov<mode>_extv_1.insn instantiates set_sign_extract2
{
    root (0=register_operand:SWI24:"=R",1=ext_register_operand:NULL:"Q",const_int:8,const_int:8);
    root.2.mode:=SWI24;
}
{:
  ""
  "movs{bl|x}\t{%h1, %k0|%k0, %h1}"
  [(set_attr "type" "imovx")
   (set_attr "mode" "SI")]
:}

concrete *movqi_extv_1_rex64.insn overrides *mov<mode>_extv_1.insn
{
    SWI24->QI;
    root.2.mode:=QI;
    allconstraints:=("=Q,?R","Q,Q");
}
{:
  "TARGET_64BIT"
{
  switch (get_attr_type (insn))
    {
    case TYPE_IMOVX:
      return "movs{bl|x}\t{%h1, %k0|%k0, %h1}";
    default:
      return "mov{b}\t{%h1, %0|%0, %h1}";
    }
}
  [(set (attr "type")
     (if_then_else (ior (not (match_operand:QI 0 "QIreg_operand" ""))
            (match_test "TARGET_MOVX"))
    (const_string "imovx")
    (const_string "imov")))
   (set (attr "mode")
     (if_then_else (eq_attr "type" "imovx")
    (const_string "SI")
    (const_string "QI")))]
:}

concrete *movqi_extv_1.insn overrides *movqi_extv_1_rex64.insn
{
    root.1.predicate:=nonimmediate_operand;
    allconstraints:=("=Qm,?r","Q,Q");
}
{:
  "!TARGET_64BIT"
{
  switch (get_attr_type (insn))
    {
    case TYPE_IMOVX:
      return "movs{bl|x}\t{%h1, %k0|%k0, %h1}";
    default:
      return "mov{b}\t{%h1, %0|%0, %h1}";
    }
}
  [(set (attr "type")
     (if_then_else (and (match_operand:QI 0 "register_operand" "")
            (ior (not (match_operand:QI 0 "QIreg_operand" ""))
                 (match_test "TARGET_MOVX")))
    (const_string "imovx")
    (const_string "imov")))
   (set (attr "mode")
     (if_then_else (eq_attr "type" "imovx")
    (const_string "SI")
    (const_string "QI")))]
:}

concrete *mov<mode>_extzv_1.insn instantiates set_zero_extract2
{
    root (0=register_operand:SWI48:"=R",1=ext_register_operand:NULL:"Q",const_int:8,const_int:8);
    root.2.mode:=SWI48;
}
{:
  ""
  "movz{bl|x}\t{%h1, %k0|%k0, %h1}"
  [(set_attr "type" "imovx")
   (set_attr "mode" "SI")]
:}

abstract set_subreg2_zero_extract extends set
{
    root.2:=subreg;
    root.2.1:=zero_extract;
}

concrete *movqi_extzv_2_rex64.insn instantiates set_subreg2_zero_extract
{
    root(0=register_operand:QI:"=Q,?R",1=ext_register_operand:NULL:"Q,Q",const_int:8,const_int:8, 0);
    root.2.mode:=QI;
    root.2.1.mode:=SI;
}
{:
  "TARGET_64BIT"
{
  switch (get_attr_type (insn))
    {
    case TYPE_IMOVX:
      return "movz{bl|x}\t{%h1, %k0|%k0, %h1}";
    default:
      return "mov{b}\t{%h1, %0|%0, %h1}";
    }
}
  [(set (attr "type")
     (if_then_else (ior (not (match_operand:QI 0 "QIreg_operand" ""))
            (match_test "TARGET_MOVX"))
    (const_string "imovx")
    (const_string "imov")))
   (set (attr "mode")
     (if_then_else (eq_attr "type" "imovx")
    (const_string "SI")
    (const_string "QI")))]
:}

concrete *movqi_extzv_2.insn overrides *movqi_extzv_2_rex64.insn
{
    root.1:=nonimmediate_operand:QI:"=Qm,?R";
}
{:
  "!TARGET_64BIT"
{
  switch (get_attr_type (insn))
    {
    case TYPE_IMOVX:
      return "movz{bl|x}\t{%h1, %k0|%k0, %h1}";
    default:
      return "mov{b}\t{%h1, %0|%0, %h1}";
    }
}
  [(set (attr "type")
     (if_then_else (and (match_operand:QI 0 "register_operand" "")
            (ior (not (match_operand:QI 0 "QIreg_operand" ""))
                 (match_test "TARGET_MOVX")))
    (const_string "imovx")
    (const_string "imov")))
   (set (attr "mode")
     (if_then_else (eq_attr "type" "imovx")
    (const_string "SI")
    (const_string "QI")))]
:}

abstract set_zero_extract1 extends set
{
    root.1:=zero_extract;
}

concrete mov<mode>_insv_1.exp instantiates set_zero_extract1
{
    root (0=ext_register_operand:NULL:"",const_int:8,const_int:8,1=nonmemory_operand:SWI48:"");
    root.1.mode:=SWI48;
}
{:
:}

concrete *mov<mode>_insv_1_rex64.insn instantiates set_zero_extract1
{
    root (0=ext_register_operand:NULL:"+Q",const_int:8,const_int:8,1=nonmemory_operand:SWI48x:"Qn");
    root.1.mode:=SWI48x;
}
{:
  "TARGET_64BIT"
{
  if (CONST_INT_P (operands[1]))
    operands[1] = simplify_gen_subreg (QImode, operands[1], <MODE>mode, 0);
  return "mov{b}\t{%b1, %h0|%h0, %b1}";
}
  [(set_attr "type" "imov")
   (set_attr "mode" "QI")]
:}

concrete *movsi_insv_1.insn overrides *mov<mode>_insv_1_rex64.insn
{
    root.2:=general_operand:SI:"Qmn";
    root.1.mode:=SI;
}
{:
  "!TARGET_64BIT"
{
  if (CONST_INT_P (operands[1]))
    operands[1] = simplify_gen_subreg (QImode, operands[1], SImode, 0);
  return "mov{b}\t{%b1, %h0|%h0, %b1}";
}
  [(set_attr "type" "imov")
   (set_attr "mode" "QI")]
:}

abstract set_zero_extract1_lshiftrt2 extends set
{
    root.1:=zero_extract;
    root.2:=lshiftrt;
}

concrete *movqi_insv_2.insn instantiates set_zero_extract1_lshiftrt2
{
    root(0=ext_register_operand:NULL:"+Q",const_int:8,const_int:8,1=register_operand:SI:"Q",const_int:8);
    root.1.mode:=SI;
    root.2.mode:=SI;
}
{:
  ""
  "mov{b}\t{%h1, %h0|%h0, %h1}"
  [(set_attr "type" "imov")
   (set_attr "mode" "QI")]
:}

{:
;; Floating point push instructions.
:}

concrete *pushtf.insn overrides *pop<mode>1.insn
{
    root.1:=push_operand:TF:"=<,<,<"; root.2:=general_no_elim_operand:TF:"x,Fo,*r";
}
{:
  "TARGET_SSE2"
{
  /* This insn should be already split before reg-stack.  */
  gcc_unreachable ();
}
  [(set_attr "type" "multi")
   (set_attr "unit" "sse,*,*")
   (set_attr "mode" "TF,SI,SI")]
:}

{:
;; %%% Kill this when call knows how to work this out.
:}

abstract set_plus2_set_mem1 extends set_set
{
    root.1:=set;
    root.1.2:=plus;
    root.2:=set;
    root.2.1:=mem;
}


concrete .split instantiates.in set
{
    root (0=push_operand:TF:"",1=sse_reg_operand:TF:"");
}
cmd_spec.in
{:
  "TARGET_SSE2 && reload_completed"
:}
instantiates.out set_plus2_set_mem1
{
    root(reg(P:SP_REG),reg(P:SP_REG),const_int:-16,reg(P:SP_REG),duplicate 1);
    root.1.2.mode:=P;
    root.2.1.mode:=TF;
}

concrete *pushxf.insn overrides *pop<mode>1.insn
{
    root.1:=push_operand:XF:"=<,<";root.2:=general_no_elim_operand:XF:"f,ro";
}
{:
  "optimize_function_for_speed_p (cfun)"
{
  /* This insn should be already split before reg-stack.  */
  gcc_unreachable ();
}
  [(set_attr "type" "multi")
   (set_attr "unit" "i387,*")
   (set_attr "mode" "XF,SI")]
:}

{:
;; Size of pushxf is 3 (for sub) + 2 (for fstp) + memory operand size.
;; Size of pushxf using integer instructions is 3+3*memory operand size
;; Pushing using integer instructions is longer except for constants
;; and direct memory references (assuming that any given constant is pushed
;; only once, but this ought to be handled elsewhere).
:}

concrete *pushxf_nointeger.insn overrides *pop<mode>1.insn
{
    root.1:=push_operand:XF:"=<,<";root.2:=general_no_elim_operand:XF:"f,*rFo";
}
{:
  "optimize_function_for_size_p (cfun)"
{
  /* This insn should be already split before reg-stack.  */
  gcc_unreachable ();
}
  [(set_attr "type" "multi")
   (set_attr "unit" "i387,*")
   (set_attr "mode" "XF,SI")]
:}
{:
;; %%% Kill this when call knows how to work this out.
:}

concrete .split instantiates.in set
{
    root (0=push_operand:XF:"",1=fp_register_operand:XF:"");
}
cmd_spec.in
{:
  "reload_completed"
:}
instantiates.out set_plus2_set_mem1
{
    root (reg(P:SP_REG),reg(P:SP_REG),duplicate 2,reg(P:SP_REG),duplicate 1);
    root.1.2.mode:=P;
    root.2.1.mode:=XF;

}
cmd_spec.out
{:
  "operands[2] = GEN_INT (-GET_MODE_SIZE (XFmode));"
:}

concrete *pushdf_rex64.insn overrides *pop<mode>1.insn
{
    root.1:=push_operand:DF:"=<,<,<"; root.2:=general_no_elim_operand:DF:"f,Yd*rFm,x";
}
{:
  "TARGET_64BIT"
{
  /* This insn should be already split before reg-stack.  */
  gcc_unreachable ();
}
  [(set_attr "type" "multi")
   (set_attr "unit" "i387,*,*")
   (set_attr "mode" "DF,DI,DF")]
:}

{:
;; Size of pushdf is 3 (for sub) + 2 (for fstp) + memory operand size.
;; Size of pushdf using integer instructions is 2+2*memory operand size
;; On the average, pushdf using integers can be still shorter.
:}

concrete *pushdf.insn overrides *pop<mode>1.insn
{
    root.1:=push_operand:DF:"=<,<,<"; root.2:=general_no_elim_operand:DF:"f,Yd*rFo,x";
}
{:
  "!TARGET_64BIT"
{
  /* This insn should be already split before reg-stack.  */
  gcc_unreachable ();
}
  [(set_attr "isa" "*,*,sse2")
   (set_attr "type" "multi")
   (set_attr "unit" "i387,*,*")
   (set_attr "mode" "DF,DI,DF")]
:}

{:
;; %%% Kill this when call knows how to work this out.
:}

concrete .split instantiates.in set
{
    root (0=push_operand:DF:"",1=any_fp_register_operand:DF:"");
}
cmd_spec.in
{:
    "reload_completed"
:}
instantiates.out set_plus2_set_mem1
{
    root(reg(P:SP_REG),reg(P:SP_REG),const_int:-8,reg(P:SP_REG),duplicate 1);
    root.1.2.mode:=P;
    root.2.1.mode:=DF;
}

concrete *pushsf_rex64.insn overrides *pop<mode>1.insn
{
    root.1:=push_operand:SF:"=X,X,X";root.2:=nonmemory_no_elim_operand:SF:"f,rF,x";
}
{:
  "TARGET_64BIT"
{
  /* Anything else should be already split before reg-stack.  */
  gcc_assert (which_alternative == 1);
  return "push{q}\t%q1";
}
  [(set_attr "type" "multi,push,multi")
   (set_attr "unit" "i387,*,*")
   (set_attr "mode" "SF,DI,SF")]
:}

concrete *pushsf.insn overrides *pop<mode>1.insn
{
    root.1:=push_operand:SF:"=<,<,<"; root.2:=general_no_elim_operand:SF:"f,rFm,x";
}
{:
  "!TARGET_64BIT"
{
  /* Anything else should be already split before reg-stack.  */
  gcc_assert (which_alternative == 1);
  return "push{l}\t%1";
}
  [(set_attr "type" "multi,push,multi")
   (set_attr "unit" "i387,*,*")
   (set_attr "mode" "SF,SI,SF")]
:}

{:
;; %%% Kill this when call knows how to work this out.
:}

concrete .split instantiates.in set
{
    root(0=push_operand:SF:"",1=any_fp_register_operand:SF:"");
}
cmd_spec.in
{:
  "reload_completed"
:}
instantiates.out set_plus2_set_mem1
{
    root(reg(P:SP_REG),reg(P:SP_REG),duplicate 2,reg(P:SP_REG),duplicate 1);
    root.1.2.mode:=P;
    root.2.1.mode:=SF;
}
cmd_spec.out
{:
  "operands[2] = GEN_INT (-GET_MODE_SIZE (<P:MODE>mode));"
:}

concrete .split instantiates.in set
{
    root(0=push_operand:SF:"",1=memory_operand:SF:"");
}
cmd_spec.in
{:
  "reload_completed
   && (operands[2] = find_constant_src (insn))"
:}
instantiates.out set
{
    root(duplicate 0,duplicate 2);
}

concrete .split instantiates.in set
{
    root(0=push_operand:NULL:"",1=general_operand:NULL:"");
}
cmd_spec.in
{:
  "reload_completed
   && (GET_MODE (operands[0]) == TFmode
       || GET_MODE (operands[0]) == XFmode
       || GET_MODE (operands[0]) == DFmode)
   && !ANY_FP_REG_P (operands[1])"
:}
instantiates.out sequence
{
    root(const_int:0);
}
cmd_spec.out
{:
  "ix86_split_long_move (operands); DONE;"
:}

{:
;; Floating point move instructions.
:}

concrete movtf.exp overrides *pop<mode>1.insn
{
    root.1:=nonimmediate_operand:TF:""; root.2:=nonimmediate_operand:TF:"";
}
{:
  "TARGET_SSE2"
{
  ix86_expand_move (TFmode, operands);
  DONE;
}
:}

concrete mov<mode>.exp overrides *pop<mode>1.insn
{
    root.1:=nonimmediate_operand:X87MODEF:""; root.2:=general_operand:X87MODEF:"";
}
{:
  ""
  "ix86_expand_move (<MODE>mode, operands); DONE;"
:}

concrete *movtf_internal.insn overrides *pop<mode>1.insn
{
    root.1:=nonimmediate_operand:TF:"=x,m,x,?*r ,!o"; root.2:=general_operand:TF:"xm,x,C,*roF,F*r";
}
{:
  "TARGET_SSE2
   && !(MEM_P (operands[0]) && MEM_P (operands[1]))
   && (!can_create_pseudo_p ()
       || (ix86_cmodel == CM_MEDIUM || ix86_cmodel == CM_LARGE)
       || GET_CODE (operands[1]) != CONST_DOUBLE
       || (optimize_function_for_size_p (cfun)
       && standard_sse_constant_p (operands[1])
       && !memory_operand (operands[0], TFmode))
       || (!TARGET_MEMORY_MISMATCH_STALL
       && memory_operand (operands[0], TFmode)))"
{
  switch (which_alternative)
    {
    case 0:
    case 1:
      /* Handle misaligned load/store since we
         don't have movmisaligntf pattern. */
      if (misaligned_operand (operands[0], TFmode)
      || misaligned_operand (operands[1], TFmode))
    {
      if (get_attr_mode (insn) == MODE_V4SF)
        return "%vmovups\t{%1, %0|%0, %1}";
      else
        return "%vmovdqu\t{%1, %0|%0, %1}";
    }
      else
    {
      if (get_attr_mode (insn) == MODE_V4SF)
        return "%vmovaps\t{%1, %0|%0, %1}";
      else
        return "%vmovdqa\t{%1, %0|%0, %1}";
    }

    case 2:
      return standard_sse_constant_opcode (insn, operands[1]);

    case 3:
    case 4:
    return "#";

    default:
      gcc_unreachable ();
    }
}
  [(set_attr "type" "ssemov,ssemov,sselog1,*,*")
   (set_attr "prefix" "maybe_vex,maybe_vex,maybe_vex,*,*")
   (set (attr "mode")
        (cond [(eq_attr "alternative" "0,2")
         (if_then_else
           (match_test "optimize_function_for_size_p (cfun)")
           (const_string "V4SF")
           (const_string "TI"))
           (eq_attr "alternative" "1")
         (if_then_else
           (ior (match_test "TARGET_SSE_TYPELESS_STORES")
            (match_test "optimize_function_for_size_p (cfun)"))
           (const_string "V4SF")
           (const_string "TI"))]
           (const_string "DI")))]
:}

{:
;; Possible store forwarding (partial memory) stall in alternative 4.
:}

concrete *movxf_internal.insn overrides *pop<mode>1.insn
{
    root.1:=nonimmediate_operand:XF:"=f,m,f,?Yx*r ,!o"; root.2:=general_operand:XF:"fm,f,G,Yx*roF,FYx*r";
}
{:
  "!(MEM_P (operands[0]) && MEM_P (operands[1]))
   && (!can_create_pseudo_p ()
       || (ix86_cmodel == CM_MEDIUM || ix86_cmodel == CM_LARGE)
       || GET_CODE (operands[1]) != CONST_DOUBLE
       || (optimize_function_for_size_p (cfun)
       && standard_80387_constant_p (operands[1]) > 0
       && !memory_operand (operands[0], XFmode))
       || (!TARGET_MEMORY_MISMATCH_STALL
       && memory_operand (operands[0], XFmode)))"
{
  switch (which_alternative)
    {
    case 0:
    case 1:
      return output_387_reg_move (insn, operands);

    case 2:
      return standard_80387_constant_opcode (operands[1]);

    case 3:
    case 4:
      return "#";

    default:
      gcc_unreachable ();
    }
}
  [(set_attr "type" "fmov,fmov,fmov,multi,multi")
   (set_attr "mode" "XF,XF,XF,SI,SI")]
:}

concrete *movdf_internal_rex64.insn overrides *pop<mode>1.insn
{
    root.1:=nonimmediate_operand:DF:"=f,m,f,?r,?m,?r,!o,x,x,x,m,Yi,r "; root.2:=general_operand:DF:"fm,f,G,rm,r ,F ,F ,C,x,m,x,r ,Yi";
}
{:
  "TARGET_64BIT && !(MEM_P (operands[0]) && MEM_P (operands[1]))
   && (!can_create_pseudo_p ()
       || (ix86_cmodel == CM_MEDIUM || ix86_cmodel == CM_LARGE)
       || GET_CODE (operands[1]) != CONST_DOUBLE
       || (optimize_function_for_size_p (cfun)
       && ((!(TARGET_SSE2 && TARGET_SSE_MATH)
        && standard_80387_constant_p (operands[1]) > 0)
           || (TARGET_SSE2 && TARGET_SSE_MATH
           && standard_sse_constant_p (operands[1]))))
       || memory_operand (operands[0], DFmode))"
{
  switch (which_alternative)
    {
    case 0:
    case 1:
      return output_387_reg_move (insn, operands);

    case 2:
      return standard_80387_constant_opcode (operands[1]);

    case 3:
    case 4:
      return "mov{q}\t{%1, %0|%0, %1}";

    case 5:
      return "movabs{q}\t{%1, %0|%0, %1}";

    case 6:
      return "#";

    case 7:
      return standard_sse_constant_opcode (insn, operands[1]);

    case 8:
    case 9:
    case 10:
      switch (get_attr_mode (insn))
    {
    case MODE_V2DF:
      if (!TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL)
        return "%vmovapd\t{%1, %0|%0, %1}";
    case MODE_V4SF:
      return "%vmovaps\t{%1, %0|%0, %1}";

    case MODE_DI:
      return "%vmovq\t{%1, %0|%0, %1}";
    case MODE_DF:
      if (TARGET_AVX && REG_P (operands[0]) && REG_P (operands[1]))
        return "vmovsd\t{%1, %0, %0|%0, %0, %1}";
      return "%vmovsd\t{%1, %0|%0, %1}";
    case MODE_V1DF:
      return "%vmovlpd\t{%1, %d0|%d0, %1}";
    case MODE_V2SF:
      return "%vmovlps\t{%1, %d0|%d0, %1}";
    default:
      gcc_unreachable ();
    }

    case 11:
    case 12:
      /* Handle broken assemblers that require movd instead of movq.  */
      return "%vmovd\t{%1, %0|%0, %1}";

    default:
      gcc_unreachable();
    }
}
  [(set (attr "type")
    (cond [(eq_attr "alternative" "0,1,2")
         (const_string "fmov")
           (eq_attr "alternative" "3,4,5")
         (const_string "imov")
           (eq_attr "alternative" "6")
         (const_string "multi")
           (eq_attr "alternative" "7")
         (const_string "sselog1")
          ]
          (const_string "ssemov")))
   (set (attr "modrm")
     (if_then_else
       (and (eq_attr "alternative" "5") (eq_attr "type" "imov"))
     (const_string "0")
     (const_string "*")))
   (set (attr "length_immediate")
    (if_then_else
       (and (eq_attr "alternative" "5") (eq_attr "type" "imov"))
     (const_string "8")
     (const_string "*")))
   (set (attr "prefix")
     (if_then_else (eq_attr "alternative" "0,1,2,3,4,5,6")
       (const_string "orig")
       (const_string "maybe_vex")))
   (set (attr "prefix_data16")
     (if_then_else (eq_attr "mode" "V1DF")
       (const_string "1")
       (const_string "*")))
   (set (attr "mode")
        (cond [(eq_attr "alternative" "0,1,2")
         (const_string "DF")
           (eq_attr "alternative" "3,4,5,6,11,12")
         (const_string "DI")

           /* xorps is one byte shorter.  */
           (eq_attr "alternative" "7")
         (cond [(match_test "optimize_function_for_size_p (cfun)")
              (const_string "V4SF")
            (match_test "TARGET_SSE_LOAD0_BY_PXOR")
              (const_string "TI")
               ]
               (const_string "V2DF"))

           /* For architectures resolving dependencies on
          whole SSE registers use APD move to break dependency
          chains, otherwise use short move to avoid extra work.

          movaps encodes one byte shorter.  */
           (eq_attr "alternative" "8")
         (cond
           [(match_test "optimize_function_for_size_p (cfun)")
              (const_string "V4SF")
            (match_test "TARGET_SSE_PARTIAL_REG_DEPENDENCY")
              (const_string "V2DF")
           ]
           (const_string "DF"))
           /* For architectures resolving dependencies on register
          parts we may avoid extra work to zero out upper part
          of register.  */
           (eq_attr "alternative" "9")
         (if_then_else
           (match_test "TARGET_SSE_SPLIT_REGS")
           (const_string "V1DF")
           (const_string "DF"))
          ]
          (const_string "DF")))]
:}

{:
;; Possible store forwarding (partial memory) stall in alternative 4.
:}

concrete *movdf_internal.insn overrides *pop<mode>1.insn
{
    root.1:=nonimmediate_operand:DF:"=f,m,f,?Yd*r ,!o   ,x,x,x,m,*x,*x,*x,m"; 
    root.2:=general_operand:DF:"fm,f,G,Yd*roF,FYd*r,C,x,m,x,C ,*x,m ,*x";
}
{:
  "!TARGET_64BIT && !(MEM_P (operands[0]) && MEM_P (operands[1]))
   && (!can_create_pseudo_p ()
       || (ix86_cmodel == CM_MEDIUM || ix86_cmodel == CM_LARGE)
       || GET_CODE (operands[1]) != CONST_DOUBLE
       || (optimize_function_for_size_p (cfun)
       && ((!(TARGET_SSE2 && TARGET_SSE_MATH)
        && standard_80387_constant_p (operands[1]) > 0)
           || (TARGET_SSE2 && TARGET_SSE_MATH
           && standard_sse_constant_p (operands[1])))
       && !memory_operand (operands[0], DFmode))
       || (!TARGET_MEMORY_MISMATCH_STALL
       && memory_operand (operands[0], DFmode)))"
{
  switch (which_alternative)
    {
    case 0:
    case 1:
      return output_387_reg_move (insn, operands);

    case 2:
      return standard_80387_constant_opcode (operands[1]);

    case 3:
    case 4:
      return "#";

    case 5:
    case 9:
      return standard_sse_constant_opcode (insn, operands[1]);

    case 6:
    case 7:
    case 8:
    case 10:
    case 11:
    case 12:
      switch (get_attr_mode (insn))
    {
    case MODE_V2DF:
       if (!TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL)
        return "%vmovapd\t{%1, %0|%0, %1}";
    case MODE_V4SF:
      return "%vmovaps\t{%1, %0|%0, %1}";

    case MODE_DI:
      return "%vmovq\t{%1, %0|%0, %1}";
    case MODE_DF:
      if (TARGET_AVX && REG_P (operands[0]) && REG_P (operands[1]))
        return "vmovsd\t{%1, %0, %0|%0, %0, %1}";
      return "%vmovsd\t{%1, %0|%0, %1}";
    case MODE_V1DF:
      return "%vmovlpd\t{%1, %d0|%d0, %1}";
    case MODE_V2SF:
      return "%vmovlps\t{%1, %d0|%d0, %1}";
    default:
      gcc_unreachable ();
    }

    default:
      gcc_unreachable ();
    }
}
  [(set (attr "isa")
     (if_then_else (eq_attr "alternative" "5,6,7,8")
       (const_string "sse2")
       (const_string "*")))
   (set (attr "type")
    (cond [(eq_attr "alternative" "0,1,2")
         (const_string "fmov")
           (eq_attr "alternative" "3,4")
         (const_string "multi")
           (eq_attr "alternative" "5,9")
         (const_string "sselog1")
          ]
          (const_string "ssemov")))
   (set (attr "prefix")
     (if_then_else (eq_attr "alternative" "0,1,2,3,4")
       (const_string "orig")
       (const_string "maybe_vex")))
   (set (attr "prefix_data16")
     (if_then_else (eq_attr "mode" "V1DF")
       (const_string "1")
       (const_string "*")))
   (set (attr "mode")
        (cond [(eq_attr "alternative" "0,1,2")
         (const_string "DF")
           (eq_attr "alternative" "3,4")
         (const_string "SI")

           /* For SSE1, we have many fewer alternatives.  */
           (not (match_test "TARGET_SSE2"))
         (if_then_else
           (eq_attr "alternative" "5,6,9,10")
           (const_string "V4SF")
           (const_string "V2SF"))

           /* xorps is one byte shorter.  */
           (eq_attr "alternative" "5,9")
         (cond [(match_test "optimize_function_for_size_p (cfun)")
              (const_string "V4SF")
            (match_test "TARGET_SSE_LOAD0_BY_PXOR")
              (const_string "TI")
               ]
               (const_string "V2DF"))

           /* For architectures resolving dependencies on
          whole SSE registers use APD move to break dependency
          chains, otherwise use short move to avoid extra work.

          movaps encodes one byte shorter.  */
           (eq_attr "alternative" "6,10")
         (cond
           [(match_test "optimize_function_for_size_p (cfun)")
              (const_string "V4SF")
            (match_test "TARGET_SSE_PARTIAL_REG_DEPENDENCY")
              (const_string "V2DF")
           ]
           (const_string "DF"))
           /* For architectures resolving dependencies on register
          parts we may avoid extra work to zero out upper part
          of register.  */
           (eq_attr "alternative" "7,11")
         (if_then_else
           (match_test "TARGET_SSE_SPLIT_REGS")
           (const_string "V1DF")
           (const_string "DF"))
          ]
          (const_string "DF")))]
:}
 
concrete *movsf_internal.insn overrides *pop<mode>1.insn
{
    root.1:=nonimmediate_operand:SF:"=f,m,f,?r ,?m,x,x,x,m,!*y,!m,!*y,?Yi,?r,!*Ym,!r";
    root.2:=general_operand:SF:"fm,f,G,rmF,Fr,C,x,m,x,m  ,*y,*y ,r  ,Yi,r   ,*Ym";
}
{:
  "!(MEM_P (operands[0]) && MEM_P (operands[1]))
   && (!can_create_pseudo_p ()
       || (ix86_cmodel == CM_MEDIUM || ix86_cmodel == CM_LARGE)
       || GET_CODE (operands[1]) != CONST_DOUBLE
       || (optimize_function_for_size_p (cfun)
       && ((!TARGET_SSE_MATH
        && standard_80387_constant_p (operands[1]) > 0)
           || (TARGET_SSE_MATH
           && standard_sse_constant_p (operands[1]))))
       || memory_operand (operands[0], SFmode))"
{
  switch (which_alternative)
    {
    case 0:
    case 1:
      return output_387_reg_move (insn, operands);

    case 2:
      return standard_80387_constant_opcode (operands[1]);

    case 3:
    case 4:
      return "mov{l}\t{%1, %0|%0, %1}";

    case 5:
      return standard_sse_constant_opcode (insn, operands[1]);

    case 6:
      if (get_attr_mode (insn) == MODE_V4SF)
    return "%vmovaps\t{%1, %0|%0, %1}";
      if (TARGET_AVX)
    return "vmovss\t{%1, %0, %0|%0, %0, %1}";

    case 7:
    case 8:
      return "%vmovss\t{%1, %0|%0, %1}";

    case 9:
    case 10:
    case 14:
    case 15:
      return "movd\t{%1, %0|%0, %1}";

    case 11:
      return "movq\t{%1, %0|%0, %1}";

    case 12:
    case 13:
      return "%vmovd\t{%1, %0|%0, %1}";

    default:
      gcc_unreachable ();
    }
}
  [(set (attr "type")
    (cond [(eq_attr "alternative" "0,1,2")
         (const_string "fmov")
           (eq_attr "alternative" "3,4")
         (const_string "multi")
           (eq_attr "alternative" "5")
         (const_string "sselog1")
           (eq_attr "alternative" "9,10,11,14,15")
         (const_string "mmxmov")
          ]
          (const_string "ssemov")))
   (set (attr "prefix")
     (if_then_else (eq_attr "alternative" "5,6,7,8,12,13")
       (const_string "maybe_vex")
       (const_string "orig")))
   (set (attr "mode")
        (cond [(eq_attr "alternative" "3,4,9,10")
         (const_string "SI")
           (eq_attr "alternative" "5")
         (if_then_else
           (and (and (match_test "TARGET_SSE_LOAD0_BY_PXOR")
                 (match_test "TARGET_SSE2"))
            (not (match_test "optimize_function_for_size_p (cfun)")))
           (const_string "TI")
           (const_string "V4SF"))
           /* For architectures resolving dependencies on
          whole SSE registers use APS move to break dependency
          chains, otherwise use short move to avoid extra work.

          Do the same for architectures resolving dependencies on
          the parts.  While in DF mode it is better to always handle
          just register parts, the SF mode is different due to lack
          of instructions to load just part of the register.  It is
          better to maintain the whole registers in single format
          to avoid problems on using packed logical operations.  */
           (eq_attr "alternative" "6")
         (if_then_else
           (ior (match_test "TARGET_SSE_PARTIAL_REG_DEPENDENCY")
            (match_test "TARGET_SSE_SPLIT_REGS"))
           (const_string "V4SF")
           (const_string "SF"))
           (eq_attr "alternative" "11")
         (const_string "DI")]
           (const_string "SF")))]
:}

concrete .split instantiates.in set
{
    root(0=any_fp_register_operand:NULL:"",1=memory_operand:NULL:"");
}
cmd_spec.in
{:
  "reload_completed
    && (GET_MODE (operands[0]) == TFmode
       || GET_MODE (operands[0]) == XFmode
       || GET_MODE (operands[0]) == DFmode
       || GET_MODE (operands[0]) == SFmode)
   && (operands[2] = find_constant_src (insn))"
:}
instantiates.out set
{
    root (duplicate 0,duplicate 2);
}
cmd_spec.out
{:
{
  rtx c = operands[2];
  int r = REGNO (operands[0]);

  if ((SSE_REGNO_P (r) && !standard_sse_constant_p (c))
      || (FP_REGNO_P (r) && standard_80387_constant_p (c) < 1))
    FAIL;
}
:}

abstract set_float_extend2 extends set
{
    root.2:=float_extend;
}

concrete .split instantiates.in set_float_extend2
{
    root(0=any_fp_register_operand:NULL:"",1=memory_operand:NULL:"");
}
cmd_spec.in
{:
  "reload_completed
   && (GET_MODE (operands[0]) == TFmode
       || GET_MODE (operands[0]) == XFmode
       || GET_MODE (operands[0]) == DFmode)
   && (operands[2] = find_constant_src (insn))"
:}
instantiates.out set
{
    root(duplicate 0,duplicate 2);
}
cmd_spec.out
{:
{
  rtx c = operands[2];
  int r = REGNO (operands[0]);

  if ((SSE_REGNO_P (r) && !standard_sse_constant_p (c))
      || (FP_REGNO_P (r) && standard_80387_constant_p (c) < 1))
    FAIL;
}
:}

{:
;; Split the load of -0.0 or -1.0 into fldz;fchs or fld1;fchs sequence
:}

abstract set_set_neg2 extends set_set{
    root.2.2:=neg;
}

concrete .split instantiates.in set
{
    root (0=fp_register_operand:X87MODEF:"",1=immediate_operand:X87MODEF:"");
}
cmd_spec.in
{:
"reload_completed
   && (standard_80387_constant_p (operands[1]) == 8
       || standard_80387_constant_p (operands[1]) == 9)"
:}
instantiates.out set_set_neg2
{
    root (duplicate 0,duplicate 1,duplicate 0,duplicate 0);
    root.2.2.mode:=X87MODEF;
}
cmd_spec.out
{:
{
  REAL_VALUE_TYPE r;

  REAL_VALUE_FROM_CONST_DOUBLE (r, operands[1]);
  if (real_isnegzero (&r))
    operands[1] = CONST0_RTX (<MODE>mode);
  else
    operands[1] = CONST1_RTX (<MODE>mode);
}
:}

concrete .split instantiates.in set
{
    root(0=nonimmediate_operand:NULL:"",1=general_operand:NULL:"");
}
cmd_spec.in
{:

  "reload_completed
   && (GET_MODE (operands[0]) == TFmode
       || GET_MODE (operands[0]) == XFmode
       || GET_MODE (operands[0]) == DFmode)
   && !(ANY_FP_REG_P (operands[0]) || ANY_FP_REG_P (operands[1]))"
:}
instantiates.out sequence
{
    root (const_int:0);
}
cmd_spec.out
{:
  "ix86_split_long_move (operands); DONE;"
:}

concrete swapxf.insn instantiates set_set
{
    root(0=register_operand:XF:"+f",1=register_operand:XF:"+f",duplicate 1,duplicate 0);
}
{:
  "TARGET_80387"
{
  if (STACK_TOP_P (operands[0]))
    return "fxch\t%1";
  else
    return "fxch\t%0";
}
  [(set_attr "type" "fxch")
   (set_attr "mode" "XF")]
:}

concrete *swap<mode>.insn overrides swapxf.insn
{
    root.1.1:=fp_register_operand:MODEF:"+f"; root.1.2:=fp_register_operand:MODEF:"+f";
}
{:
  "TARGET_80387 || reload_completed"
{
  if (STACK_TOP_P (operands[0]))
    return "fxch\t%1";
  else
    return "fxch\t%0";
}
  [(set_attr "type" "fxch")
   (set_attr "mode" "<MODE>")]
:}

{:
;; Zero extension instructions
:}

abstract set_zero_extend2 extends set
{
    root.2:=zero_extend;
}

concrete zero_extendsidi2.exp instantiates set_zero_extend2
{
    root (0=nonimmediate_operand:DI:"",1=nonimmediate_operand:SI:"");
    root.2.mode:=DI;
}
{:
  ""
{
  if (!TARGET_64BIT)
    {
      emit_insn (gen_zero_extendsidi2_1 (operands[0], operands[1]));
      DONE;
    }
}
:}

concrete *zero_extendsidi2_rex64.insn overrides zero_extendsidi2.exp
{
    allconstraints:=("=r,o,?*Ym,?*y,?*Yi,*x","rm,0,r   ,m  ,r   ,m");
}
{:
  "TARGET_64BIT"
  "@
   mov{l}\t{%1, %k0|%k0, %1}
   #
   movd\t{%1, %0|%0, %1}
   movd\t{%1, %0|%0, %1}
   %vmovd\t{%1, %0|%0, %1}
   %vmovd\t{%1, %0|%0, %1}"
  [(set_attr "type" "imovx,imov,mmxmov,mmxmov,ssemov,ssemov")
   (set_attr "prefix" "orig,*,orig,orig,maybe_vex,maybe_vex")
   (set_attr "prefix_0f" "0,*,*,*,*,*")
   (set_attr "mode" "SI,DI,DI,DI,TI,TI")]
:}

concrete .split instantiates.in  set_zero_extend2
{
    root(0=memory_operand:DI:"",duplicate 0);
    root.2.mode:=DI;
}
cmd_spec.in
{:
  "TARGET_64BIT"
:}
instantiates.out set
{
    root (duplicate 4,const_int:0);
}
cmd_spec.out
{:
    "split_double_mode (DImode, &operands[0], 1, &operands[3], &operands[4]);"
:}

{:
;; %%% Kill me once multi-word ops are sane.
:}

abstract set_zero_extend2_clobber extends sequence
{
    root.1:=set_zero_extend2;
    root.2:=clobber;
}


concrete zero_extendsidi2_1.insn instantiates set_zero_extend2_clobber
{
    root (0=nonimmediate_operand:DI:"=r,?r,?o,?*Ym,?*y,?*Yi,*x",1=nonimmediate_operand:SI:"0,rm,r ,r   ,m  ,r   ,m",reg(CC:FLAGS_REG));
    root.1.2.mode:=DI;
}
{:
  "!TARGET_64BIT"
  "@
   #
   #
   #
   movd\t{%1, %0|%0, %1}
   movd\t{%1, %0|%0, %1}
   %vmovd\t{%1, %0|%0, %1}
   %vmovd\t{%1, %0|%0, %1}"
  [(set_attr "isa" "*,*,*,*,*,*,sse2")
   (set_attr "type" "multi,multi,multi,mmxmov,mmxmov,ssemov,ssemov")
   (set_attr "prefix" "*,*,*,orig,orig,maybe_vex,maybe_vex")
   (set_attr "mode" "SI,SI,SI,DI,DI,TI,TI")]
:}

concrete .split instantiates.in set_zero_extend2_clobber
{
    root (0=register_operand:DI:"",1=register_operand:SI:"",reg(CC:FLAGS_REG));
    root.1.2.mode:=DI;
}
cmd_spec.in
{:
  "!TARGET_64BIT && reload_completed
   && true_regnum (operands[0]) == true_regnum (operands[1])"
:}
instantiates.out set
{
    root (duplicate 4,const_int:0);
}
cmd_spec.out
{:
  "split_double_mode (DImode, &operands[0], 1, &operands[3], &operands[4]);"
:}

concrete .split instantiates.in set_zero_extend2_clobber
{
    root (0=nonimmediate_operand:DI:"",1=general_operand:SI:"",reg(CC:FLAGS_REG));
    root.1.2.mode:=DI;
}
cmd_spec.in
{:
  "!TARGET_64BIT && reload_completed
   && !(MMX_REG_P (operands[0]) || SSE_REG_P (operands[0]))"
:}
instantiates.out set_set
{
    root(duplicate 3,duplicate 1,duplicate 4, const_int:0);
}
cmd_spec.out
{:
  "split_double_mode (DImode, &operands[0], 1, &operands[3], &operands[4]);"
:}

concrete zero_extend<mode>di2.insn overrides zero_extendsidi2.exp
{
    root.1:=register_operand:DI:"=r"; root.2:=nonimmediate_operand:SWI12:"<r>m";
}
{:
    "TARGET_64BIT"
    "movz{<imodesuffix>l|x}\t{%1, %k0|%k0, %1}"
     [(set_attr "type" "imovx")
     (set_attr "mode" "SI")]
:}

concrete zero_extendhisi2.exp overrides zero_extendsidi2.exp
{
    root.1:=register_operand:SI:""; root.2:=nonimmediate_operand:HI:"";
    root.2.mode:=SI;
}
{:
    ""
    {
      if (TARGET_ZERO_EXTEND_WITH_AND && optimize_function_for_speed_p (cfun))
      {
            operands[1] = force_reg (HImode, operands[1]);
            emit_insn (gen_zero_extendhisi2_and (operands[0], operands[1]));
            DONE;
      }
}
:}

abstract set_and2 extends set
{
    root.2:=and;
}


abstract parallel_set_and2_clobber extends parallel
{
    root.1:=set_and2;
    root.2:=clobber;
}

concrete zero_extendhisi2_and.insn_and_split instantiates.in set_zero_extend2_clobber
{
    root (0=register_operand:SI:"=r", 1=register_operand:HI:"0",
        reg(CC:FLAGS_REG));
    root.1.2.mode:=SI;
}
cmd_spec.in
{:
  "TARGET_ZERO_EXTEND_WITH_AND && optimize_function_for_speed_p (cfun)"
  "#"
  "&& reload_completed"
:}
instantiates.out parallel_set_and2_clobber
{
    root (duplicate 0, duplicate 0, const_int:65535, reg(CC:FLAGS_REG));
    root.1.2.mode:=SI;
}
cmd_spec.out
{:
  ""
  [(set_attr "type" "alu1")
   (set_attr "mode" "SI")]
:}

concrete *zero_extendhisi2_movzwl.insn overrides zero_extendsidi2.exp
{
  root.1:=register_operand:SI:"=r"; root.2.1:=nonimmediate_operand:HI:"rm";
  root.2.mode:=SI;
}
{:
  "!TARGET_ZERO_EXTEND_WITH_AND
   || optimize_function_for_size_p (cfun)"
  "movz{wl|x}\t{%1, %0|%0, %1}"
  [(set_attr "type" "imovx")
   (set_attr "mode" "SI")]
:}

abstract parallel_set_zero_extend2_clobber extends parallel
{
    root.1:=set_zero_extend2;
    root.2:=clobber;
}


concrete zero_extendqi<mode>2.exp instantiates parallel_set_zero_extend2_clobber
{
    root (0=register_operand:SWI24:"",
        1=nonimmediate_operand:QI:"", reg(CC:FLAGS_REG));
    root.1.2.mode:=SWI24;
}
{:
:}

concrete *zero_extendqi<mode>2_and.insn instantiates set_zero_extend2_clobber
{
    root (0=register_operand:SWI24:"=r,?&q",
        1=nonimmediate_operand:QI:"0,qm", reg(CC:FLAGS_REG));
    root.1.2.mode:=SWI24;
}
{:
  "TARGET_ZERO_EXTEND_WITH_AND && optimize_function_for_speed_p (cfun)"
  "#"
  [(set_attr "type" "alu1")
   (set_attr "mode" "<MODE>")]
:}

{:
;; When source and destination does not overlap, clear destination
;; first and then do the movb
:}


concrete .split instantiates.in set_zero_extend2_clobber
{
	root (0=register_operand:SWI24:"",1=nonimmediate_operand:QI:"",reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI24;
}
cmd_spec.in
{:
  "reload_completed
   && (TARGET_ZERO_EXTEND_WITH_AND && optimize_function_for_speed_p (cfun))
   && ANY_QI_REG_P (operands[0])
   && (ANY_QI_REG_P (operands[1]) || MEM_P (operands[1]))
   && !reg_overlap_mentioned_p (operands[0], operands[1])"
:}
instantiates.out set_strict_low_part1
{
	root (duplicate 2,duplicate 1);
}
cmd_spec.out
{:
{
  operands[2] = gen_lowpart (QImode, operands[0]);
  ix86_expand_clear (operands[0]);
}
:}

concrete *zero_extendqi<mode>2_movzbl_and.insn overrides *zero_extendqi<mode>2_and.insn 
{
    allconstraints:=("=r,r", "qm,0");
}
{:
  "!TARGET_ZERO_EXTEND_WITH_AND || optimize_function_for_size_p (cfun)"
  "#"
  [(set_attr "type" "imovx,alu1")
   (set_attr "mode" "<MODE>")]
:}

{:
;; For the movzbl case strip only the clobber
:}

concrete .split instantiates.in set_zero_extend2_clobber
{
	root (0=register_operand:SWI24:"",1=nonimmediate_operand:QI:"",reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI24;
}
cmd_spec.in
{:
  "reload_completed
   && (!TARGET_ZERO_EXTEND_WITH_AND || optimize_function_for_size_p (cfun))
   && (!REG_P (operands[1]) || ANY_QI_REG_P (operands[1]))"
:}
instantiates.out set_zero_extend2
{
	root (duplicate 0, duplicate 1);
	root.2.mode:=SWI24;
}

{:
;; zero extend to SImode to avoid partial register stalls
:}

concrete *zero_extendqi<mode>2_movzbl.insn overrides zero_extendsidi2.exp
{
	root.1:=register_operand:SWI24:"=r"; root.2.1:=nonimmediate_operand:QI:"qm";
	root.2.mode:=SWI24;
}
{:
  "reload_completed
   && (!TARGET_ZERO_EXTEND_WITH_AND || optimize_function_for_size_p (cfun))"
  "movz{bl|x}\t{%1, %k0|%k0, %1}"
  [(set_attr "type" "imovx")
   (set_attr "mode" "SI")]
:}

{:
;; Rest is handled by single and.
:}

abstract parallel_set_and2_clobber extends parallel
{
	root.1:=set_and2;
	root.2:=clobber;
}

concrete .split instantiates.in set_zero_extend2_clobber
{
	root (0=register_operand:SWI24:"", 1=register_operand:QI:"",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI24;
}
cmd_spec.in
{:
  "reload_completed
   && true_regnum (operands[0]) == true_regnum (operands[1])"
:}
instantiates.out parallel_set_and2_clobber
{
	root (duplicate 0, duplicate 0, const_int:255,
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI24;
}
cmd_spec.out
{:
:}
{:

;; Sign extension instructions
:}

concrete extendsidi2.exp instantiates set_sign_extend2{
	root (0=register_operand:DI:"",1=register_operand:SI:"");
	root.2.mode:=DI;
}
{:
  ""
{
  if (!TARGET_64BIT)
    {
      emit_insn (gen_extendsidi2_1 (operands[0], operands[1]));
      DONE;
    }
}
:}

concrete *extendsidi2_rex64.insn overrides extendsidi2.exp
{
	root.1:=register_operand:DI:"=*a,r"; root.2:=nonimmediate_operand:SI:"*0,rm";
}
{:
  "TARGET_64BIT"
  "@
   {cltq|cdqe}
   movs{lq|x}\t{%1, %0|%0, %1}"
  [(set_attr "type" "imovx")
   (set_attr "mode" "DI")
   (set_attr "prefix_0f" "0")
   (set_attr "modrm" "0,1")]
:}

abstract set_sign_extend2_clobber_clobber extends sequence
{
	root.1:=set;
	root.1.2:=sign_extend;
	root.2:=clobber;
	root.3:=clobber;
}

concrete extendsidi2_1.insn instantiates set_sign_extend2_clobber_clobber
{
	root (0=nonimmediate_operand:DI:"=*A,r,?r,?*o",1=register_operand:SI:"0,0,r,r",reg(CC:FLAGS_REG),2=SI:"=X,X,X,&r");
	root.1.2.mode:=DI;
}
{:
  "!TARGET_64BIT"
  "#"
:}

{:
;; Extend to memory case when source register does die.
:}

abstract set_sign_extend2_clobber_x2 extends sequence
{
	root.1:=set_sign_extend2;
	root.2:=clobber;
	root.3:=clobber;
}

abstract parallel_set_ashiftrt2_clobber extends parallel
{
	root.1:=set_ashiftrt2;
	root.2:=clobber;
}

abstract set_parallel_set_ashiftrt2_clobber_set extends sequence
{
	root.1:=set;
	root.2:=parallel_set_ashiftrt2_clobber;
	root.3:=set;
}

concrete .split instantiates.in set_sign_extend2_clobber_x2
{
	root (0=memory_operand:DI:"", 1=register_operand:SI:"",
		reg(CC:FLAGS_REG), 2=register_operand:SI:"");
	root.1.2.mode:=DI;
}
cmd_spec.in
{:
  "(reload_completed
    && dead_or_set_p (insn, operands[1])
    && !reg_mentioned_p (operands[1], operands[0]))"
:}
instantiates.out set_parallel_set_ashiftrt2_clobber_set
{
	root (duplicate 3, duplicate 1,
		(duplicate 1, duplicate 1, const_int:31, reg(CC:FLAGS_REG)),
		duplicate 4, duplicate 1);
	root.2.1.2.mode:=SI;
}
cmd_spec.out
{:
  "split_double_mode (DImode, &operands[0], 1, &operands[3], &operands[4]);"
:}

{:
;; Extend to memory case when source register does not die.
:}

concrete .split instantiates.in set_sign_extend2_clobber_clobber
{
	root (0=memory_operand:DI:"",1=register_operand:SI:"",reg(CC:FLAGS_REG),2=register_operand:SI:"");
	root.1.2.mode:=DI;
}
cmd_spec.in
{:
	"reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  split_double_mode (DImode, &operands[0], 1, &operands[3], &operands[4]);

  emit_move_insn (operands[3], operands[1]);

  /* Generate a cltd if possible and doing so it profitable.  */
  if ((optimize_function_for_size_p (cfun) || TARGET_USE_CLTD)
      && true_regnum (operands[1]) == AX_REG
      && true_regnum (operands[2]) == DX_REG)
    {
      emit_insn (gen_ashrsi3_cvt (operands[2], operands[1], GEN_INT (31)));
    }
  else
    {
      emit_move_insn (operands[2], operands[1]);
      emit_insn (gen_ashrsi3_cvt (operands[2], operands[2], GEN_INT (31)));
    }
  emit_move_insn (operands[4], operands[2]);
  DONE;
}
:}

{:
;; Extend to register case.  Optimize case where source and destination
;; registers match and cases where we can use cltd.
:}

concrete .split instantiates.in set_sign_extend2_clobber_clobber
{
	root (0=register_operand:DI:"",1=register_operand:SI:"",reg(CC:FLAGS_REG),2=SI:"");
	root.1.2.mode:=DI;
}
cmd_spec.in
{:
  "reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  split_double_mode (DImode, &operands[0], 1, &operands[3], &operands[4]);

  if (true_regnum (operands[3]) != true_regnum (operands[1]))
    emit_move_insn (operands[3], operands[1]);

  /* Generate a cltd if possible and doing so it profitable.  */
  if ((optimize_function_for_size_p (cfun) || TARGET_USE_CLTD)
      && true_regnum (operands[3]) == AX_REG
      && true_regnum (operands[4]) == DX_REG)
    {
      emit_insn (gen_ashrsi3_cvt (operands[4], operands[3], GEN_INT (31)));
      DONE;
    }

  if (true_regnum (operands[4]) != true_regnum (operands[1]))
    emit_move_insn (operands[4], operands[1]);

  emit_insn (gen_ashrsi3_cvt (operands[4], operands[4], GEN_INT (31)));
  DONE;
}
:}

concrete extend<mode>di2.insn overrides extendsidi2.exp
{
	root.1:=register_operand:DI:"=r"; root.2.1:=nonimmediate_operand:SWI12:"<r>m";
}
{:
  "TARGET_64BIT"
  "movs{<imodesuffix>q|x}\t{%1, %0|%0, %1}"
  [(set_attr "type" "imovx")
   (set_attr "mode" "DI")]
:}

concrete extendhisi2.insn overrides extendsidi2.exp
{
	root.1:=register_operand:SI:"=*a,r"; root.2:=nonimmediate_operand:HI:"*0,rm";
	root.2.mode:=SI;
}
{:
  ""
{
  switch (get_attr_prefix_0f (insn))
    {
    case 0:
      return "{cwtl|cwde}";
    default:
      return "movs{wl|x}\t{%1, %0|%0, %1}";
    }
}
  [(set_attr "type" "imovx")
   (set_attr "mode" "SI")
   (set (attr "prefix_0f")
     ;; movsx is short decodable while cwtl is vector decoded.
     (if_then_else (and (eq_attr "cpu" "!k6")
			(eq_attr "alternative" "0"))
	(const_string "0")
	(const_string "1")))
   (set (attr "modrm")
     (if_then_else (eq_attr "prefix_0f" "0")
	(const_string "0")
	(const_string "1")))]
:}

concrete *extendhisi2_zext.insn instantiates set_zero_extend2_sign_extend
{
	root (0=register_operand:DI:"=*a,r",1=nonimmediate_operand:HI:"*0,rm");
	root.2.mode:=DI;
	root.2.1.mode:=SI;
}
{:
  "TARGET_64BIT"
{
  switch (get_attr_prefix_0f (insn))
    {
    case 0:
      return "{cwtl|cwde}";
    default:
      return "movs{wl|x}\t{%1, %k0|%k0, %1}";
    }
}
  [(set_attr "type" "imovx")
   (set_attr "mode" "SI")
   (set (attr "prefix_0f")
     ;; movsx is short decodable while cwtl is vector decoded.
     (if_then_else (and (eq_attr "cpu" "!k6")
			(eq_attr "alternative" "0"))
	(const_string "0")
	(const_string "1")))
   (set (attr "modrm")
     (if_then_else (eq_attr "prefix_0f" "0")
	(const_string "0")
	(const_string "1")))]
:}

concrete extendqisi2.insn overrides extendsidi2.exp
{
	root.1:=register_operand:SI:"=r"; root.2:=nonimmediate_operand:QI:"qm";
	root.2.mode:=SI;
}
{:
  ""
  "movs{bl|x}\t{%1, %0|%0, %1}"
   [(set_attr "type" "imovx")
    (set_attr "mode" "SI")]
:}

concrete *extendqisi2_zext.insn instantiates set_zero_extend2_sign_extend
{
	root (0=register_operand:DI:"=r",1=nonimmediate_operand:QI:"qm");
	root.2.mode:=DI;
	root.2.1.mode:=SI;
}
{:
  "TARGET_64BIT"
  "movs{bl|x}\t{%1, %k0|%k0, %1}"
   [(set_attr "type" "imovx")
    (set_attr "mode" "SI")]
:}

concrete extendqihi2.insn overrides extendsidi2.exp
{
	root.1:=register_operand:HI:"=*a,r"; root.2.1:=nonimmediate_operand:QI:"*0,qm";
	root.2.mode:=HI;
}
{:
  ""
{
  switch (get_attr_prefix_0f (insn))
    {
    case 0:
      return "{cbtw|cbw}";
    default:
      return "movs{bw|x}\t{%1, %0|%0, %1}";
    }
}
  	[(set_attr "type" "imovx")
   (set_attr "mode" "HI")
   (set (attr "prefix_0f")
     ;; movsx is short decodable while cwtl is vector decoded.
     (if_then_else (and (eq_attr "cpu" "!k6")
			(eq_attr "alternative" "0"))
	(const_string "0")
	(const_string "1")))
   (set (attr "modrm")
     (if_then_else (eq_attr "prefix_0f" "0")
	(const_string "0")
	(const_string "1")))]
:}
{:

;; Conversions between float and double.

;; These are all no-ops in the model used for the 80387.
;; So just emit moves.

;; %%% Kill these when call knows how to work out a DFmode push earlier.
:}

abstract set_plus2_set_mem1_float_extend2 extends set_plus2_set_mem1
{
	root.2.2:=float_extend;
}

concrete .split instantiates.in set_float_extend2
{
	root (0=push_operand:DF:"",1=fp_register_operand:SF:"");
	root.2.mode:=DF;
}
cmd_spec.in
{:
	"reload_completed"
:}
instantiates.out set_plus2_set_mem1_float_extend2
{
	root (reg(P:SP_REG),reg(P:SP_REG),const_int:-8,reg(P:SP_REG),duplicate 1);
	root.1.2.mode:=P;
	root.2.1.mode:=DF;
	root.2.2.mode:=DF;
}

concrete .split instantiates.in set_float_extend2
{
	root (0=push_operand:XF:"",1=fp_register_operand:MODEF:"");
	root.2.mode:=XF;
}
cmd_spec.in
{:
	"reload_completed"
:}
instantiates.out set_plus2_set_mem1_float_extend2
{
	root (reg(P:SP_REG),reg(P:SP_REG),duplicate 2, reg(P:SP_REG),duplicate 1);
	root.1.2.mode:=P;
	root.2.1.mode:=XF;
	root.2.2.mode:=XF;
}
cmd_spec.out
{:
  "operands[2] = GEN_INT (-GET_MODE_SIZE (XFmode));"
:}

concrete extendsfdf2.exp instantiates set_float_extend2
{
	root (0=nonimmediate_operand:DF:"",1=general_operand:SF:"");
	root.2.mode:=DF;
}
{:
  "TARGET_80387 || (TARGET_SSE2 && TARGET_SSE_MATH)"
{
  /* ??? Needed for compress_float_constant since all fp constants
     are TARGET_LEGITIMATE_CONSTANT_P.  */
  if (GET_CODE (operands[1]) == CONST_DOUBLE)
    {
      if ((!TARGET_SSE2 || TARGET_MIX_SSE_I387)
	  && standard_80387_constant_p (operands[1]) > 0)
	{
	  operands[1] = simplify_const_unary_operation
	    (FLOAT_EXTEND, DFmode, operands[1], SFmode);
	  emit_move_insn_1 (operands[0], operands[1]);
	  DONE;
	}
      operands[1] = validize_mem (force_const_mem (SFmode, operands[1]));
    }
}
:}

{:
/* For converting SF(xmm2) to DF(xmm1), use the following code instead of
   cvtss2sd:
      unpcklps xmm2,xmm2   ; packed conversion might crash on signaling NaNs
      cvtps2pd xmm2,xmm1
   We do the conversion post reload to avoid producing of 128bit spills
   that might lead to ICE on 32bit target.  The sequence unlikely combine
   anyway.  */
:}


abstract set_float_extend2_vec_select1_parallel2 extends set_float_extend2
{
	root.2.1:=vec_select;
	root.2.1.2:=parallel;
}

concrete .split instantiates.in set_float_extend2
{
	root (0=register_operand:DF:"", 
		1=nonimmediate_operand:SF:"");
	root.2.mode:=DF;
}
cmd_spec.in
{:
  "TARGET_USE_VECTOR_FP_CONVERTS
   && optimize_insn_for_speed_p ()
   && reload_completed && SSE_REG_P (operands[0])"
:}
instantiates.out set_float_extend2_vec_select1_parallel2
{
	root (duplicate 2, duplicate 3,
		(const_int:0, const_int:1));
	root.2.mode:=V2DF;
	root.2.1.mode:=V2SF;
}
cmd_spec.out
{:
{
  operands[2] = simplify_gen_subreg (V2DFmode, operands[0], DFmode, 0);
  operands[3] = simplify_gen_subreg (V4SFmode, operands[0], DFmode, 0);
  /* Use movss for loading from memory, unpcklps reg, reg for registers.
     Try to avoid move when unpacking can be done in source.  */
  if (REG_P (operands[1]))
    {
      /* If it is unsafe to overwrite upper half of source, we need
	 to move to destination and unpack there.  */
      if ((ORIGINAL_REGNO (operands[1]) < FIRST_PSEUDO_REGISTER
	   || PSEUDO_REGNO_BYTES (ORIGINAL_REGNO (operands[1])) > 4)
	  && true_regnum (operands[0]) != true_regnum (operands[1]))
	{
	  rtx tmp = gen_rtx_REG (SFmode, true_regnum (operands[0]));
	  emit_move_insn (tmp, operands[1]);
	}
      else
	operands[3] = simplify_gen_subreg (V4SFmode, operands[1], SFmode, 0);
      emit_insn (gen_vec_interleave_lowv4sf (operands[3], operands[3],
      		 			     operands[3]));
    }
  else
    emit_insn (gen_vec_setv4sf_0 (operands[3],
				  CONST0_RTX (V4SFmode), operands[1]));
}
:}

concrete *extendsfdf2_mixed.insn overrides extendsfdf2.exp
{
	root.1:=nonimmediate_operand:DF:"=f,m,x"; root.2.1:=nonimmediate_operand:SF:"fm,f,xm";
}
{:
  "TARGET_SSE2 && TARGET_MIX_SSE_I387"
{
  switch (which_alternative)
    {
    case 0:
    case 1:
      return output_387_reg_move (insn, operands);

    case 2:
      return "%vcvtss2sd\t{%1, %d0|%d0, %1}";

    default:
      gcc_unreachable ();
    }
}
  [(set_attr "type" "fmov,fmov,ssecvt")
   (set_attr "prefix" "orig,orig,maybe_vex")
   (set_attr "mode" "SF,XF,DF")]
:}

concrete *extendsfdf2_sse.insn overrides extendsfdf2.exp
{
	root.1:=nonimmediate_operand:DF:"=x"; root.2.1:=nonimmediate_operand:SF:"xm";
}
{:
  "TARGET_SSE2 && TARGET_SSE_MATH"
  "%vcvtss2sd\t{%1, %d0|%d0, %1}"
  [(set_attr "type" "ssecvt")
   (set_attr "prefix" "maybe_vex")
   (set_attr "mode" "DF")]
:}

concrete *extendsfdf2_i387.insn overrides extendsfdf2.exp
{
	root.1:=nonimmediate_operand:DF:"=f,m"; root.2.1:=nonimmediate_operand:SF:"fm,f";
}
{:
  "TARGET_80387"
  "* return output_387_reg_move (insn, operands);"
  [(set_attr "type" "fmov")
   (set_attr "mode" "SF,XF")]
:}

concrete extend<mode>xf2.exp overrides extendsfdf2.exp
{
	root.1.mode:=XF;	root.2.1.mode:=MODEF;	root.2.mode:=XF;
}
{:
  "TARGET_80387"
{
  /* ??? Needed for compress_float_constant since all fp constants
     are TARGET_LEGITIMATE_CONSTANT_P.  */
  if (GET_CODE (operands[1]) == CONST_DOUBLE)
    {
      if (standard_80387_constant_p (operands[1]) > 0)
	{
	  operands[1] = simplify_const_unary_operation
	    (FLOAT_EXTEND, XFmode, operands[1], <MODE>mode);
	  emit_move_insn_1 (operands[0], operands[1]);
	  DONE;
	}
      operands[1] = validize_mem (force_const_mem (<MODE>mode, operands[1]));
    }
}
:}

concrete *extend<mode>xf2_i387.insn overrides extendsfdf2.exp
{
	root.1:=nonimmediate_operand:XF:"=f,m"; root.2.1:=nonimmediate_operand:MODEF:"fm,f";
	root.2.mode:=XF;
}
{:
  "TARGET_80387"
  "* return output_387_reg_move (insn, operands);"
  [(set_attr "type" "fmov")
   (set_attr "mode" "<MODE>,XF")]
:}

{:
;; %%% This seems bad bad news.
;; This cannot output into an f-reg because there is no way to be sure
;; of truncating in that case.  Otherwise this is just like a simple move
;; insn.  So we pretend we can output to a reg in order to get better
;; register preferencing, but we really use a stack slot.

;; Conversion from DFmode to SFmode.
:}

concrete truncdfsf2.exp instantiates set_float_truncate2
{
	root(0=nonimmediate_operand:SF:"",1=nonimmediate_operand:DF:"");
	root.2.mode:=SF;
}
{:
  "TARGET_80387 || (TARGET_SSE2 && TARGET_SSE_MATH)"
{
  if (TARGET_SSE2 && TARGET_SSE_MATH && !TARGET_MIX_SSE_I387)
    ;
  else if (flag_unsafe_math_optimizations)
    ;
  else
    {
      enum ix86_stack_slot slot = (virtuals_instantiated
				   ? SLOT_TEMP
				   : SLOT_VIRTUAL);
      rtx temp = assign_386_stack_local (SFmode, slot);
      emit_insn (gen_truncdfsf2_with_temp (operands[0], operands[1], temp));
      DONE;
    }
}
:}

{:
/* For converting DF(xmm2) to SF(xmm1), use the following code instead of
   cvtsd2ss:
      unpcklpd xmm2,xmm2   ; packed conversion might crash on signaling NaNs
      cvtpd2ps xmm2,xmm1
   We do the conversion post reload to avoid producing of 128bit spills
   that might lead to ICE on 32bit target.  The sequence unlikely combine
   anyway.  */
:}

concrete .split instantiates.in set_float_truncate2
{
	root(0=register_operand:SF:"", 1=nonimmediate_operand:DF:"");
	root.2.mode:=SF;	
}
cmd_spec.in
{:
  "TARGET_USE_VECTOR_FP_CONVERTS
   && optimize_insn_for_speed_p ()
   && reload_completed && SSE_REG_P (operands[0])"
:}
instantiates.out set_vec_concat2_float_truncate1
{
	root(duplicate 2, duplicate 4, duplicate 3);
	root.2.mode:=V4SF;
	root.2.1.mode:=V2SF;
}
cmd_spec.out
{: 
{
  operands[2] = simplify_gen_subreg (V4SFmode, operands[0], SFmode, 0);
  operands[3] = CONST0_RTX (V2SFmode);
  operands[4] = simplify_gen_subreg (V2DFmode, operands[0], SFmode, 0);
  /* Use movsd for loading from memory, unpcklpd for registers.
     Try to avoid move when unpacking can be done in source, or SSE3
     movddup is available.  */
  if (REG_P (operands[1]))
    {
      if (!TARGET_SSE3
	  && true_regnum (operands[0]) != true_regnum (operands[1])
	  && (ORIGINAL_REGNO (operands[1]) < FIRST_PSEUDO_REGISTER
	      || PSEUDO_REGNO_BYTES (ORIGINAL_REGNO (operands[1])) > 8))
	{
	  rtx tmp = simplify_gen_subreg (DFmode, operands[0], SFmode, 0);
	  emit_move_insn (tmp, operands[1]);
	  operands[1] = tmp;
	}
      else if (!TARGET_SSE3)
	operands[4] = simplify_gen_subreg (V2DFmode, operands[1], DFmode, 0);
      emit_insn (gen_vec_dupv2df (operands[4], operands[1]));
    }
  else
    emit_insn (gen_sse2_loadlpd (operands[4],
				 CONST0_RTX (V2DFmode), operands[1]));
}
:}

abstract parallel_set_float_truncate2_clobber extends parallel
{
	root.1:=set_float_truncate2;
	root.2:=clobber;
}

concrete truncdfsf2_with_temp.exp instantiates parallel_set_float_truncate2_clobber
{
	root (0=NULL:SF:"", 1=NULL:DF:"",
		2=NULL:SF:"");
	root.1.2.mode:=SF;
}
{:
:}

concrete *truncdfsf_fast_mixed.insn overrides truncdfsf2.exp
{
	allconstraints:=("=fm,x","f  ,xm");
}
{:
  "TARGET_SSE2 && TARGET_MIX_SSE_I387 && flag_unsafe_math_optimizations"
{
  switch (which_alternative)
    {
    case 0:
      return output_387_reg_move (insn, operands);
    case 1:
      return "%vcvtsd2ss\t{%1, %d0|%d0, %1}";
    default:
      gcc_unreachable ();
    }
}
  [(set_attr "type" "fmov,ssecvt")
   (set_attr "prefix" "orig,maybe_vex")
   (set_attr "mode" "SF")]
:}

{:
;; Yes, this one doesn't depend on flag_unsafe_math_optimizations,
;; because nothing we do here is unsafe.
:}

concrete *truncdfsf_fast_sse.insn overrides truncdfsf2.exp
{
	allconstraints:=("=x","xm");
}
{:
  "TARGET_SSE2 && TARGET_SSE_MATH"
  "%vcvtsd2ss\t{%1, %d0|%d0, %1}"
  [(set_attr "type" "ssecvt")
   (set_attr "prefix" "maybe_vex")
   (set_attr "mode" "SF")]
:}

concrete *truncdfsf_fast_i387.insn overrides truncdfsf2.exp
{
	allconstraints:=("=fm", "f");
}
{:
  "TARGET_80387 && flag_unsafe_math_optimizations"
  "* return output_387_reg_move (insn, operands);"
  [(set_attr "type" "fmov")
   (set_attr "mode" "SF")]
:}

abstract set_float_truncate2_clobber extends sequence
{
	root.1:=set_float_truncate2;
	root.2:=clobber;
}

concrete *truncdfsf_mixed.insn instantiates set_float_truncate2_clobber
{
	root (0=nonimmediate_operand:SF:"=m,x ,?f,?x,?*r",1=nonimmediate_operand:DF:"f ,xm,f ,f ,f",2=memory_operand:SF:"=X,X ,m ,m ,m");
	root.1.2.mode:=SF;
}
{:
  "TARGET_MIX_SSE_I387"
{
  switch (which_alternative)
    {
    case 0:
      return output_387_reg_move (insn, operands);
    case 1:
      return "%vcvtsd2ss\t{%1, %d0|%d0, %1}";

    default:
      return "#";
    }
}
  [(set_attr "isa" "*,sse2,*,*,*")
   (set_attr "type" "fmov,ssecvt,multi,multi,multi")
   (set_attr "unit" "*,*,i387,i387,i387")
   (set_attr "prefix" "orig,maybe_vex,orig,orig,orig")
   (set_attr "mode" "SF")]
:}


concrete *truncdfsf_i387.insn overrides *truncdfsf_mixed.insn
{
	allconstraints:=("=m,?f,?x,?*r","f ,f ,f ,f","=X,m ,m ,m");
}
{:
  "TARGET_80387"
{
  switch (which_alternative)
    {
    case 0:
      return output_387_reg_move (insn, operands);

    default:
      return "#";
    }
}
  [(set_attr "type" "fmov,multi,multi,multi")
   (set_attr "unit" "*,i387,i387,i387")
   (set_attr "mode" "SF")]
:}

concrete *truncdfsf2_i387_1.insn overrides truncdfsf2.exp
{
	root.1:=memory_operand:SF:"=m"; root.2.1:=register_operand:DF:"f";
}
{:
  "TARGET_80387
   && !(TARGET_SSE2 && TARGET_SSE_MATH)
   && !TARGET_MIX_SSE_I387"
  "* return output_387_reg_move (insn, operands);"
  [(set_attr "type" "fmov")
   (set_attr "mode" "SF")]
:}

concrete .split instantiates.in set_float_truncate2_clobber
{
	root (0=register_operand:SF:"",1=fp_register_operand:DF:"",2=NULL:NULL:"");
	root.1.2.mode:=SF;
}
cmd_spec.in
{:
  "reload_completed"
:}
instantiates.out set_set
{
	root (duplicate 2,duplicate 1,duplicate 0,duplicate 2);
}
cmd_spec.out
{:
  "operands[1] = gen_rtx_REG (SFmode, true_regnum (operands[1]));"
:}

{:
;; Conversion from XFmode to {SF,DF}mode
:}

abstract parallel_set_float_truncate2_clobber extends parallel
{
	root.1:=set;
	root.1.2:=float_truncate;
	root.2:=clobber;
}

concrete truncxf<mode>2.exp instantiates parallel_set_float_truncate2_clobber
{
	root (0=nonimmediate_operand:MODEF:"",
		1=register_operand:XF:"", duplicate 2);
	root.1.2.mode:=MODEF;
}
{:
  "TARGET_80387"
{
  if (flag_unsafe_math_optimizations)
    {
      rtx reg = REG_P (operands[0]) ? operands[0] : gen_reg_rtx (<MODE>mode);
      emit_insn (gen_truncxf<mode>2_i387_noop (reg, operands[1]));
      if (reg != operands[0])
	emit_move_insn (operands[0], reg);
      DONE;
    }
  else
    {
      enum ix86_stack_slot slot = (virtuals_instantiated
				   ? SLOT_TEMP
				   : SLOT_VIRTUAL);
      operands[2] = assign_386_stack_local (<MODE>mode, slot);
    }
}
:}

concrete *truncxfsf2_mixed.insn instantiates set_float_truncate2_clobber
{
	root (0=nonimmediate_operand:SF:"=m,?f,?x,?*r",1=register_operand:XF:"f ,f ,f ,f",2=memory_operand:SF:"=X,m ,m ,m");
	root.1.2.mode:=SF;
}
{:
  "TARGET_80387"
{
  gcc_assert (!which_alternative);
  return output_387_reg_move (insn, operands);
}
  [(set_attr "type" "fmov,multi,multi,multi")
   (set_attr "unit" "*,i387,i387,i387")
   (set_attr "mode" "SF")]
:}

concrete *truncxfdf2_mixed.insn instantiates set_float_truncate2_clobber
{
	root (0=nonimmediate_operand:DF:"=m,?f,?x,?*r",1=register_operand:XF:"f ,f ,f  ,f",2=memory_operand:DF:"=X,m ,m  ,m");
	root.1.2.mode:=DF;
}
{:
  "TARGET_80387"
{
  gcc_assert (!which_alternative);
  return output_387_reg_move (insn, operands);
}
  [(set_attr "isa" "*,*,sse2,*")
   (set_attr "type" "fmov,multi,multi,multi")
   (set_attr "unit" "*,i387,i387,i387")
   (set_attr "mode" "DF")]
:}

concrete truncxf<mode>2_i387_noop.insn overrides truncdfsf2.exp
{
	root.1:=register_operand:MODEF:"=f"; root.2.1:=register_operand:XF:"f";
	root.2.mode:=MODEF;
}
{:
  "TARGET_80387 && flag_unsafe_math_optimizations"
  "* return output_387_reg_move (insn, operands);"
  [(set_attr "type" "fmov")
   (set_attr "mode" "<MODE>")]
:}

concrete *truncxf<mode>2_i387.insn overrides truncdfsf2.exp
{
	root.1:=memory_operand:MODEF:"=m"; root.2.1:=register_operand:XF:"f";
	root.2.mode:=MODEF;
}
{:
  "TARGET_80387"
  "* return output_387_reg_move (insn, operands);"
  [(set_attr "type" "fmov")
   (set_attr "mode" "<MODE>")]
:}

abstract set_float_truncate2_set extends set_set
{
	root.1.2:=float_truncate;
}

concrete .split instantiates.in set_float_truncate2_clobber
{
	root (0=register_operand:MODEF:"",1=register_operand:XF:"",2=memory_operand:MODEF:"");
	root.1.2.mode:=MODEF;
}
cmd_spec.in
{:
  "TARGET_80387 && reload_completed"
:}
instantiates.out set_float_truncate2_set
{
	root (duplicate 2,duplicate 1,duplicate 0,duplicate 2);
	root.1.2.mode:=MODEF;
}

concrete .split instantiates.in  set_float_truncate2_clobber
{
	root (0=memory_operand:MODEF:"",1=register_operand:XF:"",2=memory_operand:MODEF:"");
	root.1.2.mode:=MODEF;
}
cmd_spec.in
{:
  "TARGET_80387"
:}
instantiates.out set_float_truncate2
{
 	root (duplicate 0,duplicate 1);
	root.2.mode:=MODEF;
}

{:
;; Signed conversion to DImode.
:}

abstract parallel_set_fix2_clobber extends parallel
{
	root.1:=set_fix2;
	root.2:=clobber;
}

concrete fix_truncxfdi2.exp instantiates parallel_set_fix2_clobber
{
	root (0=nonimmediate_operand:DI:"", 1=register_operand:XF:"",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
}
{:
  "TARGET_80387"
{
  if (TARGET_FISTTP)
   {
     emit_insn (gen_fix_truncdi_fisttp_i387_1 (operands[0], operands[1]));
     DONE;
   }
}
:}

concrete fix_trunc<mode>di2.exp overrides fix_truncxfdi2.exp 
{
	root.1.2.1.mode:=MODEF;
}
{:
  "TARGET_80387 || (TARGET_64BIT && SSE_FLOAT_MODE_P (<MODE>mode))"
{
  if (TARGET_FISTTP
      && !(TARGET_64BIT && SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH))
   {
     emit_insn (gen_fix_truncdi_fisttp_i387_1 (operands[0], operands[1]));
     DONE;
   }
  if (TARGET_64BIT && SSE_FLOAT_MODE_P (<MODE>mode))
   {
     rtx out = REG_P (operands[0]) ? operands[0] : gen_reg_rtx (DImode);
     emit_insn (gen_fix_trunc<mode>di_sse (out, operands[1]));
     if (out != operands[0])
	emit_move_insn (operands[0], out);
     DONE;
   }
}
:}
{:
;; Signed conversion to SImode.
:}

concrete fix_truncxfsi2.exp instantiates parallel_set_fix2_clobber
{
	root (0=nonimmediate_operand:SI:"",
		1=register_operand:XF:"", reg(CC:FLAGS_REG));
	root.1.2.mode:=SI;
}
{:
  "TARGET_80387"
{
  if (TARGET_FISTTP)
   {
     emit_insn (gen_fix_truncsi_fisttp_i387_1 (operands[0], operands[1]));
     DONE;
   }
}
:}

concrete fix_trunc<mode>si2.exp overrides fix_truncxfsi2.exp
{
	root.1.2.1.mode:=MODEF;
}
{:
  "TARGET_80387 || SSE_FLOAT_MODE_P (<MODE>mode)"
{
  if (TARGET_FISTTP
      && !(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH))
   {
     emit_insn (gen_fix_truncsi_fisttp_i387_1 (operands[0], operands[1]));
     DONE;
   }
  if (SSE_FLOAT_MODE_P (<MODE>mode))
   {
     rtx out = REG_P (operands[0]) ? operands[0] : gen_reg_rtx (SImode);
     emit_insn (gen_fix_trunc<mode>si_sse (out, operands[1]));
     if (out != operands[0])
	emit_move_insn (operands[0], out);
     DONE;
   }
}
:}

{:
;; Signed conversion to HImode.
:}

concrete fix_trunc<mode>hi2.exp instantiates parallel_set_fix2_clobber
{
	root (0=nonimmediate_operand:HI:"", 
		1=register_operand:X87MODEF:"", reg(CC:FLAGS_REG));
	root.1.2.mode:=HI;
}
{:
  "TARGET_80387
   && !(SSE_FLOAT_MODE_P (<MODE>mode) && (!TARGET_FISTTP || TARGET_SSE_MATH))"
{
  if (TARGET_FISTTP)
   {
     emit_insn (gen_fix_trunchi_fisttp_i387_1 (operands[0], operands[1]));
     DONE;
   }
}
:}

{:
;; Unsigned conversion to SImode.
:}

abstract parallel_set_unsigned_fix2_use_clobber_x2 extends parallel
{
	root.1:=set_unsigned_fix2;
	root.2:=use;
	root.3:=clobber;
	root.4:=clobber;
}

concrete fixuns_trunc<mode>si2.exp instantiates parallel_set_unsigned_fix2_use_clobber_x2
{
	root (0=register_operand:SI:"",
		1=nonimmediate_operand:MODEF:"", duplicate 2, 
		3=<ssevecmode>:"", 4=<ssevecmode>:"");
	root.1.2.mode:=SI;
}
{:
  "!TARGET_64BIT && TARGET_SSE2 && TARGET_SSE_MATH"
{
  enum machine_mode mode = <MODE>mode;
  enum machine_mode vecmode = <ssevecmode>mode;
  REAL_VALUE_TYPE TWO31r;
  rtx two31;

  if (optimize_insn_for_size_p ())
    FAIL;

  real_ldexp (&TWO31r, &dconst1, 31);
  two31 = const_double_from_real_value (TWO31r, mode);
  two31 = ix86_build_const_vector (vecmode, true, two31);
  operands[2] = force_reg (vecmode, two31);
}
:}

abstract set_unsigned_fix2_use_clobber_clobber extends sequence
{
	root.1:=set;
	root.1.2:=unsigned_fix;
	root.2:=use;
	root.3:=clobber;
	root.4:=clobber;
}

concrete *fixuns_trunc<mode>_1.insn_and_split instantiates.in set_unsigned_fix2_use_clobber_clobber
{
	root (0=register_operand:SI:"=&x,&x",3=nonimmediate_operand:MODEF:"xm,xm",
        4=nonimmediate_operand:<ssevecmode>:"m,x",1=<ssevecmode>:"=x,&x",
        2=<ssevecmode>:"=x,x");
	root.1.2.mode:=SI;
}
cmd_spec.in
{:
  "!TARGET_64BIT && TARGET_SSE2 && TARGET_SSE_MATH
   && optimize_function_for_speed_p (cfun)"
  "#"
  "&& reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  ix86_split_convert_uns_si_sse (operands);
  DONE;
}
:}

{:
;; Unsigned conversion to HImode.
;; Without these patterns, we'll try the unsigned SI conversion which
;; is complex for SSE, rather than the signed SI conversion, which isn't.
:}

abstract set_fix_set_subreg extends set_set
{
	root.1.2:=fix;
	root.2.2:=subreg;
}

concrete fixuns_trunc<mode>hi2.exp instantiates set_fix_set_subreg
{
	root (duplicate 2,1=nonimmediate_operand:MODEF:"",0=nonimmediate_operand:HI:"",duplicate 2, 0);
	root.1.2.mode:=SI;
	root.2.2.mode:=HI;
}
{:
  "SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH"
  "operands[2] = gen_reg_rtx (SImode);"
:}

{:
;; When SSE is available, it is always faster to use it.
:}

concrete fix_trunc<mode>di_sse.insn instantiates set_fix2
{
	root (0=register_operand:DI:"=r,r",1=nonimmediate_operand:MODEF:"x,m");
	root.2.mode:=DI;
}
{:
  "TARGET_64BIT && SSE_FLOAT_MODE_P (<MODE>mode)
   && (!TARGET_FISTTP || TARGET_SSE_MATH)"
  "%vcvtt<ssemodesuffix>2si{q}\t{%1, %0|%0, %1}"
  [(set_attr "type" "sseicvt")
   (set_attr "prefix" "maybe_vex")
   (set_attr "prefix_rex" "1")
   (set_attr "mode" "<MODE>")
   (set_attr "athlon_decode" "double,vector")
   (set_attr "amdfam10_decode" "double,double")
   (set_attr "bdver1_decode" "double,double")]
:}

concrete fix_trunc<mode>si_sse.insn overrides fix_trunc<mode>di_sse.insn
{
	root.1.mode:=SI;
	root.2.mode:=SI;
}
{:
  "SSE_FLOAT_MODE_P (<MODE>mode)
   && (!TARGET_FISTTP || TARGET_SSE_MATH)"
  "%vcvtt<ssemodesuffix>2si\t{%1, %0|%0, %1}"
  [(set_attr "type" "sseicvt")
   (set_attr "prefix" "maybe_vex")
   (set_attr "mode" "<MODE>")
   (set_attr "athlon_decode" "double,vector")
   (set_attr "amdfam10_decode" "double,double")
   (set_attr "bdver1_decode" "double,double")]
:}

{:
;; Shorten x87->SSE reload sequences of fix_trunc?f?i_sse patterns.
:}

abstract set_set_fix2 extends set_set
{
	root.2.2:=fix;
}

concrete .peep2 instantiates.in set_set_fix2
{
	root (0=register_operand:MODEF:"",1=memory_operand:MODEF:"",2=register_operand:SWI48x:"",duplicate 0);
	root.2.2.mode:=SWI48x;
}
cmd_spec.in
{:
  "TARGET_SHORTEN_X87_SSE
   && !(TARGET_AVOID_VECTOR_DECODE && optimize_insn_for_speed_p ())
   && peep2_reg_dead_p (2, operands[0])"
:}
instantiates.out set_fix2
{
	root (duplicate 2,duplicate 1);
	root.2.mode:=SWI48x;
}
{:
;; Avoid vector decoded forms of the instruction.
:}

abstract match_scratch_set_fix2 extends sequence
{
	root.2:=set_fix2;
}

concrete .peep2 instantiates.in match_scratch_set_fix2
{
	root (2=DF:"x",0=register_operand:SWI48x:"",1=memory_operand:DF:"");
	root.2.2.mode:=SWI48x;
}
cmd_spec.in
{:
  "TARGET_SSE2 && TARGET_AVOID_VECTOR_DECODE && optimize_insn_for_speed_p ()"
:}
instantiates.out set_set_fix2
{
	root (duplicate 2,duplicate 1,duplicate 0, duplicate 2);
	root.2.2.mode:=SWI48x;
}

concrete .peep2 instantiates.in match_scratch_set_fix2
{
	root (2=SF:"x",0=register_operand:SWI48x:"",1=memory_operand:SF:"");
	root.2.2.mode:=SWI48x;
}
cmd_spec.in
{:
  "TARGET_AVOID_VECTOR_DECODE && optimize_insn_for_speed_p ()"
:}
instantiates.out set_set_fix2
{
	root (duplicate 2,duplicate 1,duplicate 0,duplicate 2);
	root.2.2.mode:=SWI48x;
}

concrete fix_trunc<mode>_fisttp_i387_1.insn_and_split instantiates.in set_fix2
{
	root (0=nonimmediate_operand:SWI248x:"",1=register_operand:NULL:"");
	root.2.mode:=SWI248x;
}
cmd_spec.in
{:
  "X87_FLOAT_MODE_P (GET_MODE (operands[1]))
   && TARGET_FISTTP
   && !((SSE_FLOAT_MODE_P (GET_MODE (operands[1]))
	 && (TARGET_64BIT || <MODE>mode != DImode))
	&& TARGET_SSE_MATH)
   && can_create_pseudo_p ()"
  "#"
  "&& 1"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  if (memory_operand (operands[0], VOIDmode))
    emit_insn (gen_fix_trunc<mode>_i387_fisttp (operands[0], operands[1]));
  else
    {
      operands[2] = assign_386_stack_local (<MODE>mode, SLOT_TEMP);
      emit_insn (gen_fix_trunc<mode>_i387_fisttp_with_temp (operands[0],
							    operands[1],
							    operands[2]));
    }
  DONE;
}
  [(set_attr "type" "fisttp")
   (set_attr "mode" "<MODE>")]
:}

abstract set_fix2_clobber extends sequence
{
	root.1:=set_fix2;
	root.2:=clobber;
}

concrete fix_trunc<mode>_i387_fisttp.insn instantiates set_fix2_clobber
{
	root (0=memory_operand:SWI248x:"=m",1=register_operand:NULL:"f",2=XF:"=&1f");
	root.1.2.mode:=SWI248x;
}
{:  
  "X87_FLOAT_MODE_P (GET_MODE (operands[1]))
   && TARGET_FISTTP
   && !((SSE_FLOAT_MODE_P (GET_MODE (operands[1]))
	 && (TARGET_64BIT || <MODE>mode != DImode))
	&& TARGET_SSE_MATH)"
  "* return output_fix_trunc (insn, operands, true);"
  [(set_attr "type" "fisttp")
   (set_attr "mode" "<MODE>")]
:}

abstract set_fix2_clobber_clobber extends sequence
{
	root.1:=set_fix2;
	root.2:=clobber;
	root.3:=clobber;
}

concrete fix_trunc<mode>_i387_fisttp_with_temp.insn instantiates set_fix2_clobber_clobber
{
	root (0=nonimmediate_operand:SWI248x:"=m,?r",1=register_operand:NULL:"f,f",2=memory_operand:SWI248x:"=X,m",3=XF:"=&1f,&1f");
	root.1.2.mode:=SWI248x;
}
{:
  "X87_FLOAT_MODE_P (GET_MODE (operands[1]))
   && TARGET_FISTTP
   && !((SSE_FLOAT_MODE_P (GET_MODE (operands[1]))
	&& (TARGET_64BIT || <MODE>mode != DImode))
	&& TARGET_SSE_MATH)"
  "#"
  [(set_attr "type" "fisttp")
   (set_attr "mode" "<MODE>")]
:}

abstract set_fix2_clobber_x2 extends sequence
{
	root.1:=set_fix2;
	root.2:=clobber;
	root.3:=clobber;
}

abstract parallel_set_fix2_clobber_set extends sequence
{
	root.1:=parallel_set_fix2_clobber;
	root.2:=set;
}

concrete .split instantiates.in set_fix2_clobber_x2
{
	root(0=register_operand:SWI248x:"", 1=register_operand:NULL:"",
		2=memory_operand:SWI248x:"", 3=NULL:"");
	root.1.2.mode:=SWI248x;
}
cmd_spec.in
{:
  "reload_completed"
:}
instantiates.out parallel_set_fix2_clobber_set
{
	root((duplicate 2, duplicate 1, duplicate 3), 
		duplicate 0, duplicate 2);
	root.1.1.2.mode:=SWI248x;
}
cmd_spec.out
{:
:}

{:
(define_split
  [(set (match_operand:SWI248x 0 "memory_operand" "")
	(fix:SWI248x (match_operand 1 "register_operand" "")))
   (clobber (match_operand:SWI248x 2 "memory_operand" ""))
   (clobber (match_scratch 3 ""))]
  "reload_completed"
  [(parallel [(set (match_dup 0) (fix:SWI248x (match_dup 1)))
	      (clobber (match_dup 3))])])

;; See the comments in i386.h near OPTIMIZE_MODE_SWITCHING for the description
;; of the machinery. Please note the clobber of FLAGS_REG. In i387 control
;; word calculation (inserted by LCM in mode switching pass) a FLAGS_REG
;; clobbering insns can be used. Look at emit_i387_cw_initialization ()
;; function in i386.c.
:}

concrete *fix_trunc<mode>_i387_1.insn_and_split instantiates.in set_fix2_clobber
{
	root (0=nonimmediate_operand:SWI248x:"",1=register_operand:NULL:"",reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI248x;
}
cmd_spec.in
{:
  "X87_FLOAT_MODE_P (GET_MODE (operands[1]))
   && !TARGET_FISTTP
   && !(SSE_FLOAT_MODE_P (GET_MODE (operands[1]))
	 && (TARGET_64BIT || <MODE>mode != DImode))
   && can_create_pseudo_p ()"
  "#"
  "&& 1"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  ix86_optimize_mode_switching[I387_TRUNC] = 1;

  operands[2] = assign_386_stack_local (HImode, SLOT_CW_STORED);
  operands[3] = assign_386_stack_local (HImode, SLOT_CW_TRUNC);
  if (memory_operand (operands[0], VOIDmode))
    emit_insn (gen_fix_trunc<mode>_i387 (operands[0], operands[1],
					 operands[2], operands[3]));
  else
    {
      operands[4] = assign_386_stack_local (<MODE>mode, SLOT_TEMP);
      emit_insn (gen_fix_trunc<mode>_i387_with_temp (operands[0], operands[1],
						     operands[2], operands[3],
						     operands[4]));
    }
  DONE;
}
  [(set_attr "type" "fistp")
   (set_attr "i387_cw" "trunc")
   (set_attr "mode" "<MODE>")]
:}

abstract set_fix2_use_use_clobber extends sequence
{	
	root.1:=set_fix2;

	root.2:=use;
	root.3:=use;
	root.4:=clobber;
}

concrete fix_truncdi_i387.insn instantiates set_fix2_use_use_clobber
{
	root (0=memory_operand:DI:"=m",1=register_operand:NULL:"f",2=memory_operand:HI:"m",3=memory_operand:HI:"m",4=XF:"=&1f");
	root.1.2.mode:=DI;
}
{:
  "X87_FLOAT_MODE_P (GET_MODE (operands[1]))
   && !TARGET_FISTTP
   && !(TARGET_64BIT && SSE_FLOAT_MODE_P (GET_MODE (operands[1])))"
  "* return output_fix_trunc (insn, operands, false);"
  [(set_attr "type" "fistp")
   (set_attr "i387_cw" "trunc")
   (set_attr "mode" "DI")]
:}

abstract set_fix2_use_use_clobber_clobber extends sequence
{
	    root.1:=set_fix2;
		root.2:=use;
		root.3:=use;
		root.4:=clobber;
		root.5:=clobber;
}

concrete fix_truncdi_i387_with_temp.insn instantiates set_fix2_use_use_clobber_clobber{
	root (0=nonimmediate_operand:DI:"=m,?r",1=register_operand:NULL:"f,f",2=memory_operand:HI:"m,m",3=memory_operand:HI:"m,m",4=memory_operand:DI:"=X,m",5=XF:"=&1f,&1f");
	root.1.2.mode:=DI;
}
{:
  "X87_FLOAT_MODE_P (GET_MODE (operands[1]))
   && !TARGET_FISTTP
   && !(TARGET_64BIT && SSE_FLOAT_MODE_P (GET_MODE (operands[1])))"
  "#"
  [(set_attr "type" "fistp")
   (set_attr "i387_cw" "trunc")
   (set_attr "mode" "DI")]
:}

{:
;; TODO Cause: matchScratch. empty required but NULL present.
(define_split
  [(set (match_operand:DI 0 "register_operand" "")
	(fix:DI (match_operand 1 "register_operand" "")))
   (use (match_operand:HI 2 "memory_operand" ""))
   (use (match_operand:HI 3 "memory_operand" ""))
   (clobber (match_operand:DI 4 "memory_operand" ""))
   (clobber (match_scratch 5 ""))]
  "reload_completed"
  [(parallel [(set (match_dup 4) (fix:DI (match_dup 1)))
	      (use (match_dup 2))
	      (use (match_dup 3))
	      (clobber (match_dup 5))])
   (set (match_dup 0) (match_dup 4))])

(define_split
  [(set (match_operand:DI 0 "memory_operand" "")
	(fix:DI (match_operand 1 "register_operand" "")))
   (use (match_operand:HI 2 "memory_operand" ""))
   (use (match_operand:HI 3 "memory_operand" ""))
   (clobber (match_operand:DI 4 "memory_operand" ""))
   (clobber (match_scratch 5 ""))]
  "reload_completed"
  [(parallel [(set (match_dup 0) (fix:DI (match_dup 1)))
	      (use (match_dup 2))
	      (use (match_dup 3))
	      (clobber (match_dup 5))])])
:}

abstract set_fix2_use_use extends sequence
{
	root.1:=set_fix2;
	root.2:=use;
	root.3:=use;
}

concrete fix_trunc<mode>_i387.insn instantiates set_fix2_use_use
{
	root  (0=memory_operand:SWI24:"=m",1=register_operand:NULL:"f",2=memory_operand:HI:"m",3=memory_operand:HI:"m");
	root.1.2.mode:=SWI24;
}
{:
  "X87_FLOAT_MODE_P (GET_MODE (operands[1]))
   && !TARGET_FISTTP
   && !SSE_FLOAT_MODE_P (GET_MODE (operands[1]))"
  "* return output_fix_trunc (insn, operands, false);"
  [(set_attr "type" "fistp")
   (set_attr "i387_cw" "trunc")
   (set_attr "mode" "<MODE>")]
:}

concrete fix_trunc<mode>_i387_with_temp.insn instantiates set_fix2_use_use_clobber
{
	root (0=nonimmediate_operand:SWI24:"=m,?r",1=register_operand:NULL:"f,f",2=memory_operand:HI:"m,m",3=memory_operand:HI:"m,m",4=memory_operand:SWI24:"=X,m");
	root.1.2.mode:=SWI24;
}
{:
  "X87_FLOAT_MODE_P (GET_MODE (operands[1]))
   && !TARGET_FISTTP
   && !SSE_FLOAT_MODE_P (GET_MODE (operands[1]))"
  "#"
  [(set_attr "type" "fistp")
   (set_attr "i387_cw" "trunc")
   (set_attr "mode" "<MODE>")]
:}

abstract set_fix2_use_x2_clobber extends sequence
{
	root.1:=set_fix2;
	root.2:=use;
	root.3:=use;
	root.4:=clobber;
}

abstract parallel_set_fix2_use_x2 extends parallel
{
    root.1:=set_fix2;
    root.2:=use;
    root.3:=use;
}

abstract parallel_set_fix2_use_x2_set extends sequence
{
	root.1:=parallel_set_fix2_use_x2;
	root.2:=set;
}

concrete .split instantiates.in set_fix2_use_x2_clobber
{
	root (0=register_operand:SWI24:"",
		1=register_operand:NULL:"", 2=memory_operand:HI:"",
		3=memory_operand:HI:"", 4=memory_operand:SWI24:"");
	root.1.2.mode:=SWI24;
}
cmd_spec.in
{:
  "reload_completed"
:}
instantiates.out parallel_set_fix2_use_x2_set
{
	root ((duplicate 4, duplicate 1, duplicate 2,
	duplicate 3), duplicate 0, duplicate 4);
	root.1.1.2.mode:=SWI24;
}
cmd_spec.out
{:
:}

abstract parallel_set_fix2_use_x2 extends parallel
{
	root.1:=set_fix2;
	root.2:=use;
	root.3:=use;
}

concrete .split instantiates.in set_fix2_use_x2_clobber
{
	root (0=memory_operand:SWI24:"", 1=register_operand:NULL:"",
		2=memory_operand:HI:"", 3=memory_operand:HI:"", 4=memory_operand:SWI24:"");
	root.1.2.mode:=SWI24;
}
cmd_spec.in
{:
  "reload_completed"
:}
instantiates.out parallel_set_fix2_use_x2
{
	root (duplicate 0, duplicate 1,
		duplicate 2, duplicate 3);
	root.1.2.mode:=SWI24;
}
cmd_spec.out
{:
:}

concrete x86_fnstcw_1.insn instantiates set_unspec2
{
	root (0=memory_operand:HI:"=m",(reg(HI:FPCR_REG), <UNSPEC_FSTCW>));
	root.2.mode:=HI;
}
{:
  "TARGET_80387"
  "fnstcw\t%0"
  [(set (attr "length")
	(symbol_ref "ix86_attr_length_address_default (insn) + 2"))
   (set_attr "mode" "HI")
   (set_attr "unit" "i387")
   (set_attr "bdver1_decode" "vector")]
:}

concrete x86_fldcw_1.insn instantiates set_unspec2
{
	root (reg(HI:FPCR_REG),(0=memory_operand:HI:"m",<UNSPEC_FLDCW>));
	root.2.mode:=HI;
}
{:
  "TARGET_80387"
  "fldcw\t%0"
  [(set (attr "length")
	(symbol_ref "ix86_attr_length_address_default (insn) + 2"))
   (set_attr "mode" "HI")
   (set_attr "unit" "i387")
   (set_attr "athlon_decode" "vector")
   (set_attr "amdfam10_decode" "vector")
   (set_attr "bdver1_decode" "vector")]
:}

{:
;; Conversion between fixed point and floating point.

;; Even though we only accept memory inputs, the backend _really_
;; wants to be able to do this between registers.
:}

concrete floathi<mode>2.exp instantiates set_float2
{
	root (0=register_operand:X87MODEF:"",1=nonimmediate_operand:HI:"");
	root.2.mode:=X87MODEF;
}
{:
  "TARGET_80387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)"
:}

{:
;; Pre-reload splitter to add memory clobber to the pattern.
:}

abstract parallel_set_float2_clobber extends parallel
{
	root.1:=set_float2;
	root.2:=clobber;
}

concrete *floathi<mode>2_1.insn_and_split instantiates.in set_float2
{
	root (0=register_operand:X87MODEF:"", 1=register_operand:HI:"");
	root.2.mode:=X87MODEF;
}
cmd_spec.in
{:
  "TARGET_80387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && can_create_pseudo_p ()"
  "#"
  "&& 1"
:}
instantiates.out parallel_set_float2_clobber
{
	root (duplicate 0, duplicate 1, duplicate 2);
	root.1.2.mode:=X87MODEF;
}
cmd_spec.out
{:
  "operands[2] = assign_386_stack_local (HImode, SLOT_TEMP);"
:}

abstract set_float2_clobber extends sequence
{
	root.1:=set_float2;
	root.2:=clobber;
}

concrete *floathi<mode>2_i387_with_temp.insn instantiates set_float2_clobber
{
	root (0=register_operand:X87MODEF:"=f,f",1=nonimmediate_operand:HI:"m,?r",2=memory_operand:HI:"=X,m");
	root.1.2.mode:=X87MODEF;
}
{:
  "TARGET_80387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)"
  "#"
  [(set_attr "type" "fmov,multi")
   (set_attr "mode" "<MODE>")
   (set_attr "unit" "*,i387")
   (set_attr "fp_int_src" "true")]
:}

concrete *floathi<mode>2_i387.insn overrides floathi<mode>2.exp
{
	allconstraints:=("=f","m");
	root.2.1.predicate:=memory_operand;
}
{:
  "TARGET_80387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)"
  "fild%Z1\t%1"
  [(set_attr "type" "fmov")
   (set_attr "mode" "<MODE>")
   (set_attr "fp_int_src" "true")]
:}


abstract set_set_float2 extends set_set
{
	root.2.2:=float;
}

concrete .split instantiates.in set_float2_clobber
{
	root (0=register_operand:X87MODEF:"",1=register_operand:HI:"",2=memory_operand:HI:"");
	root.1.2.mode:=X87MODEF;
}
cmd_spec.in
{:
  "TARGET_80387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && reload_completed"
:}
instantiates.out set_set_float2
{
	root (duplicate 2,duplicate 1,duplicate 0,duplicate 2);
	root.2.2.mode:=X87MODEF;
}

concrete .split instantiates.in set_float2_clobber
{
	root (0=register_operand:X87MODEF:"",1=memory_operand:HI:"",2=memory_operand:HI:"");
	root.1.2.mode:=X87MODEF;
}
cmd_spec.in
{:
   "TARGET_80387
    && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
        || TARGET_MIX_SSE_I387)
    && reload_completed"
:}
instantiates.out set_float2
{
	root (duplicate 0,duplicate 1);
	root.2.mode:=X87MODEF;
}


{:
;;TODO Cause : colon in Mode not allowed.
(define_expand "float<SWI48x:mode><X87MODEF:mode>2"
  [(set (match_operand:X87MODEF 0 "register_operand" "")
        (float:X87MODEF
          (match_operand:SWI48x 1 "nonimmediate_operand" "")))]
  "TARGET_80387
   || ((<SWI48x:MODE>mode != DImode || TARGET_64BIT)
       && SSE_FLOAT_MODE_P (<X87MODEF:MODE>mode) && TARGET_SSE_MATH)"
{
  if (!((<SWI48x:MODE>mode != DImode || TARGET_64BIT)
        && SSE_FLOAT_MODE_P (<X87MODEF:MODE>mode) && TARGET_SSE_MATH)
      && !X87_ENABLE_FLOAT (<X87MODEF:MODE>mode, <SWI48x:MODE>mode))
    {
      rtx reg = gen_reg_rtx (XFmode);
      rtx (*insn)(rtx, rtx);

      emit_insn (gen_float<SWI48x:mode>xf2 (reg, operands[1]));

      if (<X87MODEF:MODE>mode == SFmode)
        insn = gen_truncxfsf2;
      else if (<X87MODEF:MODE>mode == DFmode)
        insn = gen_truncxfdf2;
      else
        gcc_unreachable ();

      emit_insn (insn (operands[0], reg));
      DONE;
    }
})

;; Pre-reload splitter to add memory clobber to the pattern.
(define_insn_and_split "*float<SWI48x:mode><X87MODEF:mode>2_1"
  [(set (match_operand:X87MODEF 0 "register_operand" "")
	(float:X87MODEF (match_operand:SWI48x 1 "register_operand" "")))]
  "((TARGET_80387
     && X87_ENABLE_FLOAT (<X87MODEF:MODE>mode, <SWI48x:MODE>mode)
     && (!((<SWI48x:MODE>mode != DImode || TARGET_64BIT)
	   && SSE_FLOAT_MODE_P (<X87MODEF:MODE>mode) && TARGET_SSE_MATH)
	 || TARGET_MIX_SSE_I387))
    || ((<SWI48x:MODE>mode != DImode || TARGET_64BIT)
	&& SSE_FLOAT_MODE_P (<X87MODEF:MODE>mode) && TARGET_SSE_MATH
	&& ((<SWI48x:MODE>mode == SImode
	     && TARGET_SSE2 && TARGET_USE_VECTOR_CONVERTS
	     && optimize_function_for_speed_p (cfun)
	     && flag_trapping_math)
	    || !(TARGET_INTER_UNIT_CONVERSIONS
	         || optimize_function_for_size_p (cfun)))))
   && can_create_pseudo_p ()"
  "#"
  "&& 1"
  [(parallel [(set (match_dup 0) (float:X87MODEF (match_dup 1)))
	      (clobber (match_dup 2))])]
{
  operands[2] = assign_386_stack_local (<SWI48x:MODE>mode, SLOT_TEMP);

  /* Avoid store forwarding (partial memory) stall penalty
     by passing DImode value through XMM registers.  */
  if (<SWI48x:MODE>mode == DImode && !TARGET_64BIT
      && TARGET_80387 && TARGET_SSE2 && TARGET_INTER_UNIT_MOVES
      && optimize_function_for_speed_p (cfun))
    {
      emit_insn (gen_floatdi<X87MODEF:mode>2_i387_with_xmm (operands[0],
							    operands[1],
							    operands[2]));
      DONE;
    }
})
:}

concrete *floatsi<mode>2_vector_mixed_with_temp.insn instantiates set_float2_clobber
{
	root (0=register_operand:MODEF:"=f,f,x,x,x",1=nonimmediate_operand:SI:"m,?r,r,m,!x",2=memory_operand:SI:"=X,m,m,X,m");
	root.1.2.mode:=MODEF;
}
{:
  "TARGET_SSE2 && TARGET_MIX_SSE_I387
   && TARGET_USE_VECTOR_CONVERTS && optimize_function_for_speed_p (cfun)"
  "#"
  [(set_attr "type" "fmov,multi,sseicvt,sseicvt,sseicvt")
   (set_attr "mode" "<MODE>,<MODE>,<MODE>,<MODE>,<ssevecmode>")
   (set_attr "unit" "*,i387,*,*,*")
   (set_attr "athlon_decode" "*,*,double,direct,double")
   (set_attr "amdfam10_decode" "*,*,vector,double,double")
   (set_attr "bdver1_decode" "*,*,double,direct,double")
   (set_attr "fp_int_src" "true")]
:}


concrete *floatsi<mode>2_vector_mixed.insn instantiates set_float2
{
	root (0=register_operand:MODEF:"=f,x",1=memory_operand:SI:"m,m");
	root.2.mode:=MODEF;
}
{:
  "TARGET_SSE2 && TARGET_MIX_SSE_I387
   && TARGET_USE_VECTOR_CONVERTS && optimize_function_for_speed_p (cfun)"
  "@
   fild%Z1\t%1
   #"
  [(set_attr "type" "fmov,sseicvt")
   (set_attr "mode" "<MODE>,<ssevecmode>")
   (set_attr "unit" "i387,*")
   (set_attr "athlon_decode" "*,direct")
   (set_attr "amdfam10_decode" "*,double")
   (set_attr "bdver1_decode" "*,direct")
   (set_attr "fp_int_src" "true")]
:}

{:
(define_insn "*float<SWI48x:mode><MODEF:mode>2_mixed_with_temp"
  [(set (match_operand:MODEF 0 "register_operand" "=f,f,x,x")
        (float:MODEF
          (match_operand:SWI48x 1 "nonimmediate_operand" "m,?r,r,m")))
   (clobber (match_operand:SWI48x 2 "memory_operand" "=X,m,m,X"))]
  "(<SWI48x:MODE>mode != DImode || TARGET_64BIT)
   && SSE_FLOAT_MODE_P (<MODEF:MODE>mode) && TARGET_MIX_SSE_I387"
  "#"
  [(set_attr "type" "fmov,multi,sseicvt,sseicvt")
   (set_attr "mode" "<MODEF:MODE>")
   (set_attr "unit" "*,i387,*,*")
   (set_attr "athlon_decode" "*,*,double,direct")
   (set_attr "amdfam10_decode" "*,*,vector,double")
   (set_attr "bdver1_decode" "*,*,double,direct")
   (set_attr "fp_int_src" "true")])
:}

concrete .split instantiates.in set_float2_clobber
{
	root (0=register_operand:MODEF:"",1=register_operand:SWI48x:"",2=memory_operand:SWI48x:"");
	root.1.2.mode:=MODEF;
}
cmd_spec.in
{:
  "(<SWI48x:MODE>mode != DImode || TARGET_64BIT)
   && SSE_FLOAT_MODE_P (<MODEF:MODE>mode) && TARGET_MIX_SSE_I387
   && TARGET_INTER_UNIT_CONVERSIONS
   && reload_completed
   && (SSE_REG_P (operands[0])
       || (GET_CODE (operands[0]) == SUBREG
	   && SSE_REG_P (SUBREG_REG (operands[0]))))"
:}
instantiates.out set_float2
{
	root (duplicate 0,duplicate 1);
	root.2.mode:=MODEF;
}

concrete .split instantiates.in set_float2_clobber
{
	root (0=register_operand:MODEF:"",1=register_operand:SWI48x:"",2=memory_operand:SWI48x:"");
	root.1.2.mode:=MODEF;
}
cmd_spec.in
{:
  "(<SWI48x:MODE>mode != DImode || TARGET_64BIT)
   && SSE_FLOAT_MODE_P (<MODEF:MODE>mode) && TARGET_MIX_SSE_I387
   && !(TARGET_INTER_UNIT_CONVERSIONS || optimize_function_for_size_p (cfun))
   && reload_completed
   && (SSE_REG_P (operands[0])
       || (GET_CODE (operands[0]) == SUBREG
	   && SSE_REG_P (SUBREG_REG (operands[0]))))"
:}
instantiates.out set_set_float2
{
	root (duplicate 2,duplicate 1,duplicate 0,duplicate 2);
	root.2.2.mode:=MODEF;
}

{:

(define_insn "*float<SWI48x:mode><MODEF:mode>2_mixed_interunit"
  [(set (match_operand:MODEF 0 "register_operand" "=f,x,x")
        (float:MODEF
          (match_operand:SWI48x 1 "nonimmediate_operand" "m,r,m")))]
  "(<SWI48x:MODE>mode != DImode || TARGET_64BIT)
   && SSE_FLOAT_MODE_P (<MODEF:MODE>mode) && TARGET_MIX_SSE_I387
   && (TARGET_INTER_UNIT_CONVERSIONS || optimize_function_for_size_p (cfun))"
  "@
   fild%Z1\t%1
   %vcvtsi2<MODEF:ssemodesuffix><SWI48x:rex64suffix>\t{%1, %d0|%d0, %1}
   %vcvtsi2<MODEF:ssemodesuffix><SWI48x:rex64suffix>\t{%1, %d0|%d0, %1}"
  [(set_attr "type" "fmov,sseicvt,sseicvt")
   (set_attr "prefix" "orig,maybe_vex,maybe_vex")
   (set_attr "mode" "<MODEF:MODE>")
   (set (attr "prefix_rex")
     (if_then_else
       (and (eq_attr "prefix" "maybe_vex")
            (match_test "<SWI48x:MODE>mode == DImode"))
       (const_string "1")
       (const_string "*")))
   (set_attr "unit" "i387,*,*")
   (set_attr "athlon_decode" "*,double,direct")
   (set_attr "amdfam10_decode" "*,vector,double")
   (set_attr "bdver1_decode" "*,double,direct")
   (set_attr "fp_int_src" "true")])

(define_insn "*float<SWI48x:mode><MODEF:mode>2_mixed_nointerunit"
  [(set (match_operand:MODEF 0 "register_operand" "=f,x")
        (float:MODEF
          (match_operand:SWI48x 1 "memory_operand" "m,m")))]
  "(<SWI48x:MODE>mode != DImode || TARGET_64BIT)
   && SSE_FLOAT_MODE_P (<MODEF:MODE>mode) && TARGET_MIX_SSE_I387
   && !(TARGET_INTER_UNIT_CONVERSIONS || optimize_function_for_size_p (cfun))"
  "@
   fild%Z1\t%1
   %vcvtsi2<MODEF:ssemodesuffix><SWI48x:rex64suffix>\t{%1, %d0|%d0, %1}"
  [(set_attr "type" "fmov,sseicvt")
   (set_attr "prefix" "orig,maybe_vex")
   (set_attr "mode" "<MODEF:MODE>")
   (set (attr "prefix_rex")
     (if_then_else
       (and (eq_attr "prefix" "maybe_vex")
            (match_test "<SWI48x:MODE>mode == DImode"))
       (const_string "1")
       (const_string "*")))
   (set_attr "athlon_decode" "*,direct")
   (set_attr "amdfam10_decode" "*,double")
   (set_attr "bdver1_decode" "*,direct")
   (set_attr "fp_int_src" "true")])

:}

concrete *floatsi<mode>2_vector_sse_with_temp.insn overrides *floathi<mode>2_i387_with_temp.insn
{
	root.1.1:=register_operand:MODEF:"=x,x,x"; root.1.2.1:=nonimmediate_operand:SI:"r,m,!x";
	root.2.1:=memory_operand:SI:"=m,X,m";
	root.1.2.mode:=MODEF;
}
{:
  "TARGET_SSE2 && TARGET_SSE_MATH
   && TARGET_USE_VECTOR_CONVERTS && optimize_function_for_speed_p (cfun)"
  "#"
  [(set_attr "type" "sseicvt")
   (set_attr "mode" "<MODE>,<MODE>,<ssevecmode>")
   (set_attr "athlon_decode" "double,direct,double")
   (set_attr "amdfam10_decode" "vector,double,double")
   (set_attr "bdver1_decode" "double,direct,double")
   (set_attr "fp_int_src" "true")]
:}

concrete *floatsi<mode>2_vector_sse.insn overrides *floatsi<mode>2_vector_mixed.insn
{
	allconstraints:=("=x", "m");
}
{:
  "TARGET_SSE2 && TARGET_SSE_MATH
   && TARGET_USE_VECTOR_CONVERTS && optimize_function_for_speed_p (cfun)"
  "#"
  [(set_attr "type" "sseicvt")
   (set_attr "mode" "<MODE>")
   (set_attr "athlon_decode" "direct")
   (set_attr "amdfam10_decode" "double")
   (set_attr "bdver1_decode" "direct")
   (set_attr "fp_int_src" "true")]
:}

concrete .split instantiates.in set_float2_clobber
{
	root (0=register_operand:MODEF:"",1=register_operand:SI:"",2=memory_operand:SI:"");
	root.1.2.mode:=MODEF;
}
cmd_spec.in
{:
  "TARGET_SSE2 && TARGET_SSE_MATH
   && TARGET_USE_VECTOR_CONVERTS && optimize_function_for_speed_p (cfun)
   && reload_completed
   && (SSE_REG_P (operands[0])
       || (GET_CODE (operands[0]) == SUBREG
	   && SSE_REG_P (SUBREG_REG (operands[0]))))"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  rtx op1 = operands[1];

  operands[3] = simplify_gen_subreg (<ssevecmode>mode, operands[0],
				     <MODE>mode, 0);
  if (GET_CODE (op1) == SUBREG)
    op1 = SUBREG_REG (op1);

  if (GENERAL_REG_P (op1) && TARGET_INTER_UNIT_MOVES)
    {
      operands[4] = simplify_gen_subreg (V4SImode, operands[0], <MODE>mode, 0);
      emit_insn (gen_sse2_loadld (operands[4],
				  CONST0_RTX (V4SImode), operands[1]));
    }
  /* We can ignore possible trapping value in the
     high part of SSE register for non-trapping math. */
  else if (SSE_REG_P (op1) && !flag_trapping_math)
    operands[4] = simplify_gen_subreg (V4SImode, operands[1], SImode, 0);
  else
    {
      operands[4] = simplify_gen_subreg (V4SImode, operands[0], <MODE>mode, 0);
      emit_move_insn (operands[2], operands[1]);
      emit_insn (gen_sse2_loadld (operands[4],
				  CONST0_RTX (V4SImode), operands[2]));
    }
  if (<ssevecmode>mode == V4SFmode)
    emit_insn (gen_floatv4siv4sf2 (operands[3], operands[4]));
  else
    emit_insn (gen_sse2_cvtdq2pd (operands[3], operands[4]));
  DONE;
}
:}

concrete .split instantiates.in set_float2_clobber
{
	root (0=register_operand:MODEF:"",1=memory_operand:SI:"",2=memory_operand:SI:"");
	root.1.2.mode:=MODEF;
}
cmd_spec.in
{:
  "TARGET_SSE2 && TARGET_SSE_MATH
   && TARGET_USE_VECTOR_CONVERTS && optimize_function_for_speed_p (cfun)
   && reload_completed
   && (SSE_REG_P (operands[0])
       || (GET_CODE (operands[0]) == SUBREG
	   && SSE_REG_P (SUBREG_REG (operands[0]))))"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  operands[3] = simplify_gen_subreg (<ssevecmode>mode, operands[0],
				     <MODE>mode, 0);
  operands[4] = simplify_gen_subreg (V4SImode, operands[0], <MODE>mode, 0);

  emit_insn (gen_sse2_loadld (operands[4],
			      CONST0_RTX (V4SImode), operands[1]));
  if (<ssevecmode>mode == V4SFmode)
    emit_insn (gen_floatv4siv4sf2 (operands[3], operands[4]));
  else
    emit_insn (gen_sse2_cvtdq2pd (operands[3], operands[4]));
  DONE;
}
:}

concrete .split instantiates.in set_float2
{
	root (0=register_operand:MODEF:"",1=register_operand:SI:"");
	root.2.mode:=MODEF;
}
cmd_spec.in
{:
  "TARGET_SSE2 && TARGET_SSE_MATH
   && TARGET_USE_VECTOR_CONVERTS && optimize_function_for_speed_p (cfun)
   && reload_completed
   && (SSE_REG_P (operands[0])
       || (GET_CODE (operands[0]) == SUBREG
	   && SSE_REG_P (SUBREG_REG (operands[0]))))"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  rtx op1 = operands[1];

  operands[3] = simplify_gen_subreg (<ssevecmode>mode, operands[0],
				     <MODE>mode, 0);
  if (GET_CODE (op1) == SUBREG)
    op1 = SUBREG_REG (op1);

  if (GENERAL_REG_P (op1))
    {
      operands[4] = simplify_gen_subreg (V4SImode, operands[0], <MODE>mode, 0);
      if (TARGET_INTER_UNIT_MOVES)
	emit_insn (gen_sse2_loadld (operands[4],
				    CONST0_RTX (V4SImode), operands[1]));
      else
	{
	  operands[5] = ix86_force_to_memory (GET_MODE (operands[1]),
					      operands[1]);
	  emit_insn (gen_sse2_loadld (operands[4],
				      CONST0_RTX (V4SImode), operands[5]));
	  ix86_free_from_memory (GET_MODE (operands[1]));
	}
    }
  /* We can ignore possible trapping value in the
     high part of SSE register for non-trapping math. */
  else if (SSE_REG_P (op1) && !flag_trapping_math)
    operands[4] = simplify_gen_subreg (V4SImode, operands[1], SImode, 0);
  else
    gcc_unreachable ();
  if (<ssevecmode>mode == V4SFmode)
    emit_insn (gen_floatv4siv4sf2 (operands[3], operands[4]));
  else
    emit_insn (gen_sse2_cvtdq2pd (operands[3], operands[4]));
  DONE;
}
:}

concrete .split instantiates.in set_float2 
{
	root (0=register_operand:MODEF:"",1=memory_operand:SI:"");
	root.2.mode:=MODEF;
}
cmd_spec.in
{:
  "TARGET_SSE2 && TARGET_SSE_MATH
   && TARGET_USE_VECTOR_CONVERTS && optimize_function_for_speed_p (cfun)
   && reload_completed
   && (SSE_REG_P (operands[0])
       || (GET_CODE (operands[0]) == SUBREG
	   && SSE_REG_P (SUBREG_REG (operands[0]))))"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  operands[3] = simplify_gen_subreg (<ssevecmode>mode, operands[0],
				     <MODE>mode, 0);
  operands[4] = simplify_gen_subreg (V4SImode, operands[0], <MODE>mode, 0);

  emit_insn (gen_sse2_loadld (operands[4],
			      CONST0_RTX (V4SImode), operands[1]));
  if (<ssevecmode>mode == V4SFmode)
    emit_insn (gen_floatv4siv4sf2 (operands[3], operands[4]));
  else
    emit_insn (gen_sse2_cvtdq2pd (operands[3], operands[4]));
  DONE;
}
:}

{:

(define_insn "*float<SWI48x:mode><MODEF:mode>2_sse_with_temp"
  [(set (match_operand:MODEF 0 "register_operand" "=x,x")
        (float:MODEF
          (match_operand:SWI48x 1 "nonimmediate_operand" "r,m")))
  (clobber (match_operand:SWI48x 2 "memory_operand" "=m,X"))]
  "(<SWI48x:MODE>mode != DImode || TARGET_64BIT)
   && SSE_FLOAT_MODE_P (<MODEF:MODE>mode) && TARGET_SSE_MATH"
  "#"
  [(set_attr "type" "sseicvt")
   (set_attr "mode" "<MODEF:MODE>")
   (set_attr "athlon_decode" "double,direct")
   (set_attr "amdfam10_decode" "vector,double")
   (set_attr "bdver1_decode" "double,direct")
   (set_attr "fp_int_src" "true")])

(define_insn "*float<SWI48x:mode><MODEF:mode>2_sse_interunit"
  [(set (match_operand:MODEF 0 "register_operand" "=x,x")
        (float:MODEF
          (match_operand:SWI48x 1 "nonimmediate_operand" "r,m")))]
  "(<SWI48x:MODE>mode != DImode || TARGET_64BIT)
   && SSE_FLOAT_MODE_P (<MODEF:MODE>mode) && TARGET_SSE_MATH
   && (TARGET_INTER_UNIT_CONVERSIONS || optimize_function_for_size_p (cfun))"
  "%vcvtsi2<MODEF:ssemodesuffix><SWI48x:rex64suffix>\t{%1, %d0|%d0, %1}"
  [(set_attr "type" "sseicvt")
   (set_attr "prefix" "maybe_vex")
   (set_attr "mode" "<MODEF:MODE>")
   (set (attr "prefix_rex")
     (if_then_else
       (and (eq_attr "prefix" "maybe_vex")
            (match_test "<SWI48x:MODE>mode == DImode"))
       (const_string "1")
       (const_string "*")))
   (set_attr "athlon_decode" "double,direct")
   (set_attr "amdfam10_decode" "vector,double")
   (set_attr "bdver1_decode" "double,direct")
   (set_attr "fp_int_src" "true")])

:}

concrete .split instantiates.in set_float2_clobber
{
    root (0=register_operand:MODEF:"",1=nonimmediate_operand:SWI48x:"",2=memory_operand:SWI48x:"");
	root.1.2.mode:=MODEF;
}
cmd_spec.in
{:
  "(<SWI48x:MODE>mode != DImode || TARGET_64BIT)
   && SSE_FLOAT_MODE_P (<MODEF:MODE>mode) && TARGET_SSE_MATH
   && (TARGET_INTER_UNIT_CONVERSIONS || optimize_function_for_size_p (cfun))
   && reload_completed
   && (SSE_REG_P (operands[0])
       || (GET_CODE (operands[0]) == SUBREG
	   && SSE_REG_P (SUBREG_REG (operands[0]))))"
:}
instantiates.out set_float2
{
	root (duplicate 0,duplicate 1);
	root.2.mode:=MODEF;
}


{:

(define_insn "*float<SWI48x:mode><MODEF:mode>2_sse_nointerunit"
  [(set (match_operand:MODEF 0 "register_operand" "=x")
        (float:MODEF
          (match_operand:SWI48x 1 "memory_operand" "m")))]
  "(<SWI48x:MODE>mode != DImode || TARGET_64BIT)
   && SSE_FLOAT_MODE_P (<MODEF:MODE>mode) && TARGET_SSE_MATH
   && !(TARGET_INTER_UNIT_CONVERSIONS || optimize_function_for_size_p (cfun))"
  "%vcvtsi2<MODEF:ssemodesuffix><SWI48x:rex64suffix>\t{%1, %d0|%d0, %1}"
  [(set_attr "type" "sseicvt")
   (set_attr "prefix" "maybe_vex")
   (set_attr "mode" "<MODEF:MODE>")
   (set (attr "prefix_rex")
     (if_then_else
       (and (eq_attr "prefix" "maybe_vex")
            (match_test "<SWI48x:MODE>mode == DImode"))
       (const_string "1")
       (const_string "*")))
   (set_attr "athlon_decode" "direct")
   (set_attr "amdfam10_decode" "double")
   (set_attr "bdver1_decode" "direct")
   (set_attr "fp_int_src" "true")])

:}

concrete .split instantiates.in  set_float2_clobber
{
	root (0=register_operand:MODEF:"",1=register_operand:SWI48x:"",2=memory_operand:SWI48x:"");
	root.1.2.mode:=MODEF;
}
cmd_spec.in
{:
  "(<SWI48x:MODE>mode != DImode || TARGET_64BIT)
   && SSE_FLOAT_MODE_P (<MODEF:MODE>mode) && TARGET_SSE_MATH
   && !(TARGET_INTER_UNIT_CONVERSIONS || optimize_function_for_size_p (cfun))
   && reload_completed
   && (SSE_REG_P (operands[0])
       || (GET_CODE (operands[0]) == SUBREG
	   && SSE_REG_P (SUBREG_REG (operands[0]))))"
:}
instantiates.out set_set_float2
{
	root (duplicate 2,duplicate 1,duplicate 0,duplicate 2);
	root.2.2.mode:=MODEF;
}

concrete .split instantiates.in set_float2_clobber
{
	root (0=register_operand:MODEF:"",1=memory_operand:SWI48x:"",2=memory_operand:SWI48x:"");
	root.1.2.mode:=MODEF;
}
cmd_spec.in
{:
  "(<SWI48x:MODE>mode != DImode || TARGET_64BIT)
   && SSE_FLOAT_MODE_P (<MODEF:MODE>mode) && TARGET_SSE_MATH
   && reload_completed
   && (SSE_REG_P (operands[0])
       || (GET_CODE (operands[0]) == SUBREG
	   && SSE_REG_P (SUBREG_REG (operands[0]))))"
:}
instantiates.out set_float2
{
	root (duplicate 0,duplicate 1);
	root.2.mode:=MODEF;
}

{:

(define_insn "*float<SWI48x:mode><X87MODEF:mode>2_i387_with_temp"
  [(set (match_operand:X87MODEF 0 "register_operand" "=f,f")
        (float:X87MODEF
          (match_operand:SWI48x 1 "nonimmediate_operand" "m,?r")))
  (clobber (match_operand:SWI48x 2 "memory_operand" "=X,m"))]
  "TARGET_80387
   && X87_ENABLE_FLOAT (<X87MODEF:MODE>mode, <SWI48x:MODE>mode)"
  "@
   fild%Z1\t%1
   #"
  [(set_attr "type" "fmov,multi")
   (set_attr "mode" "<X87MODEF:MODE>")
   (set_attr "unit" "*,i387")
   (set_attr "fp_int_src" "true")])

(define_insn "*float<SWI48x:mode><X87MODEF:mode>2_i387"
  [(set (match_operand:X87MODEF 0 "register_operand" "=f")
        (float:X87MODEF
          (match_operand:SWI48x 1 "memory_operand" "m")))]
  "TARGET_80387
   && X87_ENABLE_FLOAT (<X87MODEF:MODE>mode, <SWI48x:MODE>mode)"
  "fild%Z1\t%1"
  [(set_attr "type" "fmov")
   (set_attr "mode" "<X87MODEF:MODE>")
   (set_attr "fp_int_src" "true")])


:}

concrete .split instantiates.in set_float2_clobber
{
	root (0=fp_register_operand:X87MODEF:"",1=register_operand:SWI48x:"",2=memory_operand:SWI48x:"");
	root.1.2.mode:=X87MODEF;
}
cmd_spec.in
{:
  "TARGET_80387
   && X87_ENABLE_FLOAT (<X87MODEF:MODE>mode, <SWI48x:MODE>mode)
   && reload_completed"
:}
instantiates.out set_set_float2
{
	root (duplicate 2,duplicate 1,duplicate 0,duplicate 2);
	root.2.2.mode:=X87MODEF;
}

concrete .split instantiates.in set_float2_clobber
{
	root (0=fp_register_operand:X87MODEF:"",1=memory_operand:SWI48x:"",2=memory_operand:SWI48x:"");
	root.1.2.mode:=X87MODEF;
}
cmd_spec.in
{:
  "TARGET_80387
   && X87_ENABLE_FLOAT (<X87MODEF:MODE>mode, <SWI48x:MODE>mode)
   && reload_completed"
:}
instantiates.out set_float2
{
	root (duplicate 0,duplicate 1);
	root.2.mode:=X87MODEF;
}

{:
;; Avoid store forwarding (partial memory) stall penalty
;; by passing DImode value through XMM registers.  */
:}

abstract set_float2_clobber_clobber_clobber extends sequence
{
	root.1:=set_float2;
	root.2:=clobber;
	root.3:=clobber;
	root.4:=clobber;
}

{:
(define_insn "floatdi<X87MODEF:mode>2_i387_with_xmm"
  [(set (match_operand:X87MODEF 0 "register_operand" "=f,f")
        (float:X87MODEF
          (match_operand:DI 1 "nonimmediate_operand" "m,?r")))
   (clobber (match_scratch:V4SI 3 "=X,x"))
   (clobber (match_scratch:V4SI 4 "=X,x"))
   (clobber (match_operand:DI 2 "memory_operand" "=X,m"))]
  "TARGET_80387 && X87_ENABLE_FLOAT (<X87MODEF:MODE>mode, DImode)
   && TARGET_SSE2 && TARGET_INTER_UNIT_MOVES
   && !TARGET_64BIT && optimize_function_for_speed_p (cfun)"
  "#"
  [(set_attr "type" "multi")
   (set_attr "mode" "<X87MODEF:MODE>")
   (set_attr "unit" "i387")
   (set_attr "fp_int_src" "true")])
:}

concrete .split instantiates.in set_float2_clobber_clobber_clobber
{
	root (0=fp_register_operand:X87MODEF:"",1=register_operand:DI:"",3=V4SI:"",4=V4SI:"",2=memory_operand:DI:"");
	root.1.2.mode:=X87MODEF;
}
cmd_spec.in
{:
  "TARGET_80387 && X87_ENABLE_FLOAT (<X87MODEF:MODE>mode, DImode)
   && TARGET_SSE2 && TARGET_INTER_UNIT_MOVES
   && !TARGET_64BIT && optimize_function_for_speed_p (cfun)
   && reload_completed"
:}
instantiates.out set_set_float2
{
	root (duplicate 2,duplicate 3,duplicate 0, duplicate 2);
	root.2.2.mode:=X87MODEF;
}
cmd_spec.out
{:
{
  /* The DImode arrived in a pair of integral registers (e.g. %edx:%eax).
     Assemble the 64-bit DImode value in an xmm register.  */
  emit_insn (gen_sse2_loadld (operands[3], CONST0_RTX (V4SImode),
			      gen_rtx_SUBREG (SImode, operands[1], 0)));
  emit_insn (gen_sse2_loadld (operands[4], CONST0_RTX (V4SImode),
			      gen_rtx_SUBREG (SImode, operands[1], 4)));
  emit_insn (gen_vec_interleave_lowv4si (operands[3], operands[3],
  	    				 operands[4]));

  operands[3] = gen_rtx_REG (DImode, REGNO (operands[3]));
}
:}

concrete .split instantiates.in set_float2_clobber_clobber_clobber
{
	root (0=fp_register_operand:X87MODEF:"",1=memory_operand:DI:"",3=V4SI:"",4=V4SI:"", 2=memory_operand:DI:"");
	root.1.2.mode:=X87MODEF;
}
cmd_spec.in
{:
  "TARGET_80387 && X87_ENABLE_FLOAT (<X87MODEF:MODE>mode, DImode)
   && TARGET_SSE2 && TARGET_INTER_UNIT_MOVES
   && !TARGET_64BIT && optimize_function_for_speed_p (cfun)
   && reload_completed"
:}
instantiates.out set_float2
{
	root (duplicate 0,duplicate 1);
	root.2.mode:=X87MODEF;
}

{:
;; Avoid store forwarding (partial memory) stall penalty by extending
;; SImode value to DImode through XMM register instead of pushing two
;; SImode values to stack. Note that even !TARGET_INTER_UNIT_MOVES
;; targets benefit from this optimization. Also note that fild
;; loads from memory only.
:}

abstract set_unsigned_float2_clobber_clobber extends sequence
{
	root.1:=set_unsigned_float2;
	root.2:=clobber;
	root.3:=clobber;
}

concrete *floatunssi<mode>2_1.insn instantiates set_unsigned_float2_clobber_clobber
{
	root (0=register_operand:X87MODEF:"=f,f",1=nonimmediate_operand:SI:"x,m",2=memory_operand:DI:"=m,m",3=SI:"=X,x");
	root.1.2.mode:=X87MODEF;
}
{:
  "!TARGET_64BIT
   && TARGET_80387 && X87_ENABLE_FLOAT (<X87MODEF:MODE>mode, DImode)
   && TARGET_SSE"
  "#"
  [(set_attr "type" "multi")
   (set_attr "mode" "<MODE>")]
:}

concrete .split instantiates.in set_unsigned_float2_clobber_clobber
{
	root (0=register_operand:X87MODEF:"",1=register_operand:SI:"",2=memory_operand:DI:"",3=SI:"");
	root.1.2.mode:=X87MODEF;
}
cmd_spec.in
{:
  "!TARGET_64BIT
   && TARGET_80387 && X87_ENABLE_FLOAT (<X87MODEF:MODE>mode, DImode)
   && TARGET_SSE
   && reload_completed"
:}
instantiates.out set_set_float2
{
	root (duplicate 2,duplicate 1,duplicate 0,duplicate 2);
	root.2.2.mode:=X87MODEF;
}
cmd_spec.out
{:
  "operands[1] = simplify_gen_subreg (DImode, operands[1], SImode, 0);"
:}

concrete .split instantiates.in set_unsigned_float2_clobber_clobber
{
	root (0=register_operand:X87MODEF:"",1=memory_operand:SI:"",2=memory_operand:DI:"",3=SI:"");
	root.1.2.mode:=X87MODEF;
}
cmd_spec.in
{:
  "!TARGET_64BIT
   && TARGET_80387 && X87_ENABLE_FLOAT (<X87MODEF:MODE>mode, DImode)
   && TARGET_SSE
   && reload_completed"
:}
instantiates.out set_set_float2
{
	root (duplicate 2,duplicate 3,duplicate 0,duplicate 2);
	root.2.2.mode:=X87MODEF;
}
cmd_spec.out
{:
{
  emit_move_insn (operands[3], operands[1]);
  operands[3] = simplify_gen_subreg (DImode, operands[3], SImode, 0);
}
:}

abstract parallel_set_unsigned_float2_clobber_x2 extends parallel
{
	root.1:=set_unsigned_float2;
	root.2:=clobber;
	root.3:=clobber;
}


concrete floatunssi<mode>2.exp instantiates parallel_set_unsigned_float2_clobber_x2
{
	root (0=register_operand:X87MODEF:"",
		1=nonimmediate_operand:SI:"", duplicate 2, 3=SI:"");
	root.1.2.mode:=X87MODEF;
}
{:
  "!TARGET_64BIT
   && ((TARGET_80387 && X87_ENABLE_FLOAT (<X87MODEF:MODE>mode, DImode)
	&& TARGET_SSE)
       || (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH))"
{
  if (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
    {
      ix86_expand_convert_uns_si<mode>_sse (operands[0], operands[1]);
      DONE;
    }
  else
    {
      enum ix86_stack_slot slot = (virtuals_instantiated
				   ? SLOT_TEMP
				   : SLOT_VIRTUAL);
      operands[2] = assign_386_stack_local (DImode, slot);
    }
}
:}

abstract use_use extends sequence
{
	root.1:=use;
	root.2:=use;
}

concrete floatunsdisf2.exp instantiates use_use
{
	root (0=register_operand:SF:"",1=nonimmediate_operand:DI:"");
}
{:
  "TARGET_64BIT && TARGET_SSE_MATH"
  "x86_emit_floatuns (operands); DONE;"
:}

concrete floatunsdidf2.exp overrides floatunsdisf2.exp
{
	root.1.1.mode:=DF;
}
{:
  "(TARGET_64BIT || TARGET_KEEPS_VECTOR_ALIGNED_STACK)
   && TARGET_SSE2 && TARGET_SSE_MATH"
{
  if (TARGET_64BIT)
    x86_emit_floatuns (operands);
  else
    ix86_expand_convert_uns_didf_sse (operands[0], operands[1]);
  DONE;
}
:}

{:

;; Load effective address instructions
:}

concrete *lea<mode>.insn_and_split instantiates.in set
{
	root (0=register_operand:SWI48:"=r",1=lea_address_operand:SWI48:"p");
}
cmd_spec.in
{:
  ""
{
  rtx addr = operands[1];

  if (GET_CODE (addr) == SUBREG)
    {
      gcc_assert (TARGET_64BIT);
      gcc_assert (<MODE>mode == SImode);
      gcc_assert (GET_MODE (SUBREG_REG (addr)) == DImode);
      return "lea{l}\t{%E1, %0|%0, %E1}";
    }
  else if (GET_CODE (addr) == ZERO_EXTEND
	   || GET_CODE (addr) == AND)
    {
      gcc_assert (TARGET_64BIT);
      	gcc_assert (<MODE>mode == DImode);
      return "lea{l}\t{%E1, %k0|%k0, %E1}";
    }
  else 
    return "lea{<imodesuffix>}\t{%E1, %0|%0, %E1}";
}
  "reload_completed && ix86_avoid_lea_for_addr (insn, operands)"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  ix86_split_lea_for_addr (operands, <MODE>mode);
  DONE;
}
  [(set_attr "type" "lea")
   (set_attr "mode" "<MODE>")]
:}

{:

;; Add instructions
:}

concrete add<mode>3.exp instantiates set_plus2
{
	root (0=nonimmediate_operand:SDWIM:"",1=nonimmediate_operand:SDWIM:"",2=<general_operand>:SDWIM:"");
	root.2.mode:=SDWIM;
}
{:
  ""
  "ix86_expand_binary_operator (PLUS, <MODE>mode, operands); DONE;"
:}

abstract set_plus2_clobber extends sequence
{
	root.1:=set_plus2;
	root.2:=clobber;
}

abstract parallel_set_unspec2_set_plus2 extends parallel
{
	root.1:=set_unspec2;
	root.2:=set_plus2;
}


abstract parallel_set_unspec2_set_plus2_parallel_set_plus2_plus2_ltu1_clobber extends sequence
{
	root.1:=parallel_set_unspec2_set_plus2;
	root.2:=parallel;
	root.2.1:=set_plus2;
	root.2.1.2.2:=plus;
	root.2.1.2.2.1:=ltu;
	root.2.2:=clobber;
}

concrete *add<dwi>3_doubleword.insn_and_split instantiates.in set_plus2_clobber
{
	root (0=nonimmediate_operand:<DWI>:"=r,o",
		1=nonimmediate_operand:<DWI>:"%0,0",
		2=<general_operand>:<DWI>:"ro<di>,r<di>", reg(CC:FLAGS_REG));
	root.1.2.mode:=<DWI>;
}
cmd_spec.in
{:
  "ix86_binary_operator_ok (PLUS, <DWI>mode, operands)"
  "#"
  "reload_completed"
:}
instantiates.out parallel_set_unspec2_set_plus2_parallel_set_plus2_plus2_ltu1_clobber
{
	root((
		reg(CC:FLAGS_REG), (duplicate 1, duplicate 2, <UNSPEC_ADD_CARRY>),
		duplicate 0, duplicate 1, duplicate 2),
		(duplicate 3, duplicate 4, reg(CC:FLAGS_REG), const_int:0, duplicate 5,
		reg(CC:FLAGS_REG)));
	root.1.1.2.mode:=CC;
	root.1.2.2.mode:=DWIH;

	root.2.1.2.mode:=DWIH;
	root.2.1.2.2.mode:=DWIH;
	root.2.1.2.2.1.mode:=DWIH;

}
cmd_spec.out
{:
  "split_double_mode (<DWI>mode, &operands[0], 3, &operands[0], &operands[3]);"
:}

abstract set_unspec2_set_plus2 extends sequence
{
	root.1:=set_unspec2;
	root.2:=set_plus2;
}

concrete *add<mode>3_cc.insn instantiates set_unspec2_set_plus2
{
	root(reg(CC:FLAGS_REG),(1=nonimmediate_operand:SWI48:"%0,0",2=<general_operand>:SWI48:"r<i>,rm",<UNSPEC_ADD_CARRY>),0=nonimmediate_operand:SWI48:"=rm,r",duplicate 1, duplicate 2);
	root.1.2.mode:=CC;
	root.2.2.mode:=SWI48;
}
{:
  "ix86_binary_operator_ok (PLUS, <MODE>mode, operands)"
  "add{<imodesuffix>}\t{%2, %0|%0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "<MODE>")]
:}

concrete addqi3_cc.insn instantiates set_unspec2_set_plus2
{
	root(reg(CC:FLAGS_REG),(1=nonimmediate_operand:QI:"%0,0",2=general_operand:QI:"qn,qm",<UNSPEC_ADD_CARRY>),0=nonimmediate_operand:QI:"=qm,q", duplicate 1, duplicate 2);
	root.1.2.mode:=CC;
	root.2.2.mode:=QI;
}

{:
  "ix86_binary_operator_ok (PLUS, QImode, operands)"
  "add{b}\t{%2, %0|%0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "QI")]
:}

concrete *add<mode>_1.insn instantiates set_plus2_clobber
{
	root(0=nonimmediate_operand:SWI48:"=r,rm,r,r",1=nonimmediate_operand:SWI48:"%0,0,r,r",2=x86_64_general_operand:SWI48:"rme,re,0,le",reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
}
{:  
	"ix86_binary_operator_ok (PLUS, <MODE>mode, operands)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_LEA:
      return "#";

    case TYPE_INCDEC:
      gcc_assert (rtx_equal_p (operands[0], operands[1]));
      if (operands[2] == const1_rtx)
        return "inc{<imodesuffix>}\t%0";
      else
        {
	  gcc_assert (operands[2] == constm1_rtx);
          return "dec{<imodesuffix>}\t%0";
	}

    default:
      /* For most processors, ADD is faster than LEA.  This alternative
	 was added to use ADD as much as possible.  */
      if (which_alternative == 2)
	{
	  rtx tmp;
	  tmp = operands[1], operands[1] = operands[2], operands[2] = tmp;
	}
        
      gcc_assert (rtx_equal_p (operands[0], operands[1]));
      if (x86_maybe_negate_const_int (&operands[2], <MODE>mode))
        return "sub{<imodesuffix>}\t{%2, %0|%0, %2}";

      return "add{<imodesuffix>}\t{%2, %0|%0, %2}";
    }
}
  [(set (attr "type")
     (cond [(eq_attr "alternative" "3")
              (const_string "lea")
	    (match_operand:SWI48 2 "incdec_operand" "")
	      (const_string "incdec")
	   ]
	   (const_string "alu")))
   (set (attr "length_immediate")
      (if_then_else
	(and (eq_attr "type" "alu") (match_operand 2 "const128_operand" ""))
	(const_string "1")
	(const_string "*")))
   (set_attr "mode" "<MODE>")]
:}

{:

;; It may seem that nonimmediate operand is proper one for operand 1.
;; The addsi_1 pattern allows nonimmediate operand at that place and
;; we take care in ix86_binary_operator_ok to not allow two memory
;; operands so proper swapping will be done in reload.  This allow
;; patterns constructed from addsi_1 to match.

:}

abstract set_zero_extend2_plus_clobber extends sequence
{
	root.1:=set_zero_extend2;
	root.1.2.1:=plus;
	root.2:=clobber;
}

concrete addsi_1_zext.insn instantiates set_zero_extend2_plus_clobber
{
	root(0=register_operand:DI:"=r,r,r",1=nonimmediate_operand:SI:"%0,r,r",2=x86_64_general_operand:SI:"rme,0,le",reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=SI;
}
{:
  "TARGET_64BIT && ix86_binary_operator_ok (PLUS, SImode, operands)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_LEA:
      return "#";

    case TYPE_INCDEC:
      if (operands[2] == const1_rtx)
        return "inc{l}\t%k0";
      else
        {
	  gcc_assert (operands[2] == constm1_rtx);
          return "dec{l}\t%k0";
	}

    default:
      /* For most processors, ADD is faster than LEA.  This alternative
	 was added to use ADD as much as possible.  */
      if (which_alternative == 1)
	{
	  rtx tmp;
	  tmp = operands[1], operands[1] = operands[2], operands[2] = tmp;
	}

      if (x86_maybe_negate_const_int (&operands[2], SImode))
        return "sub{l}\t{%2, %k0|%k0, %2}";

      return "add{l}\t{%2, %k0|%k0, %2}";
    }
}
  [(set (attr "type")
     (cond [(eq_attr "alternative" "2")
	      (const_string "lea")
	    (match_operand:SI 2 "incdec_operand" "")
	      (const_string "incdec")
	   ]
	   (const_string "alu")))
   (set (attr "length_immediate")
      (if_then_else
	(and (eq_attr "type" "alu") (match_operand 2 "const128_operand" ""))
	(const_string "1")
	(const_string "*")))
   (set_attr "mode" "SI")]
:}

concrete *addhi_1.insn overrides *add<mode>_1.insn
{
	root.1.1:=nonimmediate_operand:HI:"=rm,r,r,Yp"; root.1.2.1:=nonimmediate_operand:HI:"%0,0,r,Yp";
	root.1.2.2:=general_operand:HI:"rn,rm,0,ln";
	root.1.2.mode:=HI;
}
{:
  "ix86_binary_operator_ok (PLUS, HImode, operands)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_LEA:
      return "#";

    case TYPE_INCDEC:
      gcc_assert (rtx_equal_p (operands[0], operands[1]));
      if (operands[2] == const1_rtx)
	return "inc{w}\t%0";
      else
	{
	  gcc_assert (operands[2] == constm1_rtx);
	  return "dec{w}\t%0";
	}

    default:
      /* For most processors, ADD is faster than LEA.  This alternative
	 was added to use ADD as much as possible.  */
      if (which_alternative == 2)
	{
	  rtx tmp;
	  tmp = operands[1], operands[1] = operands[2], operands[2] = tmp;
	}

      gcc_assert (rtx_equal_p (operands[0], operands[1]));
      if (x86_maybe_negate_const_int (&operands[2], HImode))
	return "sub{w}\t{%2, %0|%0, %2}";

      return "add{w}\t{%2, %0|%0, %2}";
    }
}
  [(set (attr "type")
     (cond [(eq_attr "alternative" "3")
              (const_string "lea")
	    (match_operand:HI 2 "incdec_operand" "")
	      (const_string "incdec")
	   ]
	   (const_string "alu")))
   (set (attr "length_immediate")
      (if_then_else
	(and (eq_attr "type" "alu") (match_operand 2 "const128_operand" ""))
	(const_string "1")
	(const_string "*")))
   (set_attr "mode" "HI,HI,HI,SI")]
:}

{:
;; %%% Potential partial reg stall on alternatives 3 and 4.  What to do?
:}

concrete *addqi_1.insn overrides *add<mode>_1.insn
{
	root.1.1:=nonimmediate_operand:QI:"=qm,q,q,r,r,Yp"; root.1.2.1:=nonimmediate_operand:QI:"%0,0,q,0,r,Yp";
	root.1.2.2:=general_operand:QI:"qn,qm,0,rn,0,ln";
	root.1.2.mode:=QI;
}
{:
  "ix86_binary_operator_ok (PLUS, QImode, operands)"
{
  bool widen = (which_alternative == 3 || which_alternative == 4);

  switch (get_attr_type (insn))
    {
    case TYPE_LEA:
      return "#";

    case TYPE_INCDEC:
      gcc_assert (rtx_equal_p (operands[0], operands[1]));
      if (operands[2] == const1_rtx)
	return widen ? "inc{l}\t%k0" : "inc{b}\t%0";
      else
	{
	  gcc_assert (operands[2] == constm1_rtx);
	  return widen ? "dec{l}\t%k0" : "dec{b}\t%0";
	}

    default:
      /* For most processors, ADD is faster than LEA.  These alternatives
	 were added to use ADD as much as possible.  */
      if (which_alternative == 2 || which_alternative == 4)
	{
	  rtx tmp;
	  tmp = operands[1], operands[1] = operands[2], operands[2] = tmp;
	}

      gcc_assert (rtx_equal_p (operands[0], operands[1]));
      if (x86_maybe_negate_const_int (&operands[2], QImode))
	{
	  if (widen)
	    return "sub{l}\t{%2, %k0|%k0, %2}";
	  else
	    return "sub{b}\t{%2, %0|%0, %2}";
	}
      if (widen)
        return "add{l}\t{%k2, %k0|%k0, %k2}";
      else
        return "add{b}\t{%2, %0|%0, %2}";
    }
}
  [(set (attr "type")
     (cond [(eq_attr "alternative" "5")
              (const_string "lea")
	    (match_operand:QI 2 "incdec_operand" "")
	      (const_string "incdec")
	   ]
	   (const_string "alu")))
   (set (attr "length_immediate")
      (if_then_else
	(and (eq_attr "type" "alu") (match_operand 2 "const128_operand" ""))
	(const_string "1")
	(const_string "*")))
   (set_attr "mode" "QI,QI,QI,SI,SI,SI")]
:}

abstract set_strict_low_part1_plus2_clobber extends set_plus2_clobber
{
	root.1.1:=strict_low_part;
}

concrete *addqi_1_slp.insn instantiates  set_strict_low_part1_plus2_clobber
{
	root (0=nonimmediate_operand:QI:"+qm,q",duplicate 0,1=general_operand:QI:"qn,qm",reg(CC:FLAGS_REG));
	root.1.2.mode:=QI;
}
{:
  "(! TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun))
   && !(MEM_P (operands[0]) && MEM_P (operands[1]))"
{
  switch (get_attr_type (insn))
    {
    case TYPE_INCDEC:
      if (operands[1] == const1_rtx)
	return "inc{b}\t%0";
      else
	{
	  gcc_assert (operands[1] == constm1_rtx);
	  return "dec{b}\t%0";
	}

    default:
      if (x86_maybe_negate_const_int (&operands[1], QImode))
	return "sub{b}\t{%1, %0|%0, %1}";

      return "add{b}\t{%1, %0|%0, %1}";
    }
}
  [(set (attr "type")
     (if_then_else (match_operand:QI 1 "incdec_operand" "")
	(const_string "incdec")
	(const_string "alu1")))
   (set (attr "memory")
     (if_then_else (match_operand 1 "memory_operand" "")
        (const_string "load")
        (const_string "none")))
   (set_attr "mode" "QI")]
:}

{:
;; Split non destructive adds if we cannot use lea.
:}

abstract set_parallel_set_plus2_clobber extends sequence
{
	root.1:=set;
	root.2:=parallel;
	root.2.1:=set_plus2;
	root.2.2:=clobber;
}


concrete .split instantiates.in set_plus2_clobber
{
	root (0=register_operand:SWI48:"", 1=register_operand:SWI48:"",
		2=nonmemory_operand:SWI48:"", reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
}
cmd_spec.in
{:
  "reload_completed && ix86_avoid_lea_for_add (insn, operands)"
:}
instantiates.out set_parallel_set_plus2_clobber
{
	root (duplicate 0, duplicate 1,
		(duplicate 0, duplicate 0, duplicate 2, reg(CC:FLAGS_REG)));
root.2.1.2.mode:=<MODE>;
}
cmd_spec.out
{:
:}
{:
;; Convert add to the lea pattern to avoid flags dependency.
:}

concrete .split instantiates.in set_plus2_clobber
{
	root (0=register_operand:SWI:"",1=register_operand:SWI:"",2=<nonmemory_operand>:SWI:"",reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI;
}
cmd_spec.in
{:
  "reload_completed && ix86_lea_for_add_ok (insn, operands)" 
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  enum machine_mode mode = <MODE>mode;
  rtx pat;

  if (GET_MODE_SIZE (mode) < GET_MODE_SIZE (SImode))
    { 
      mode = SImode; 
      operands[0] = gen_lowpart (mode, operands[0]);
      operands[1] = gen_lowpart (mode, operands[1]);
      operands[2] = gen_lowpart (mode, operands[2]);
    }

  pat = gen_rtx_PLUS (mode, operands[1], operands[2]);

  emit_insn (gen_rtx_SET (VOIDmode, operands[0], pat));
  DONE;
}
:}

{:
;; Convert add to the lea pattern to avoid flags dependency.
:}


abstract set_zero_extend2_plus extends set_zero_extend2
{
	root.2.1:=plus;
}

concrete .split instantiates.in set_zero_extend2_plus_clobber
{
	root (0=register_operand:DI:"",1=register_operand:SI:"",2=x86_64_nonmemory_operand:SI:"",reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=SI;
}
cmd_spec.in
{:
  "TARGET_64BIT && reload_completed && ix86_lea_for_add_ok (insn, operands)"
:}
instantiates.out set_zero_extend2_plus
{
	root (duplicate 0, duplicate 1, duplicate 2);
	root.2.mode:=DI;
	root.2.1.mode:=SI;
}

abstract set_compare2_plus_set_plus2 extends sequence
{
	root.1:=set_compare2_plus;
	root.2:=set_plus2;
}

concrete *add<mode>_2.insn instantiates set_compare2_plus_set_plus2
{
	root (reg(NULL:FLAGS_REG),1=nonimmediate_operand:SWI:"%0,0,<r>",2=<general_operand>:SWI:"<g>,<r><i>,0",const_int:0,0=nonimmediate_operand:SWI:"=<r>,<r>m,<r>",duplicate 1,duplicate 2);
	root.1.2.1.mode:=SWI;
	root.2.2.mode:=SWI;
}
{:
  "ix86_match_ccmode (insn, CCGOCmode)
   && ix86_binary_operator_ok (PLUS, <MODE>mode, operands)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_INCDEC:
      if (operands[2] == const1_rtx)
        return "inc{<imodesuffix>}\t%0";
      else
        {
	  gcc_assert (operands[2] == constm1_rtx);
          return "dec{<imodesuffix>}\t%0";
	}

    default:
      if (which_alternative == 2)
	{
	  rtx tmp;
	  tmp = operands[1], operands[1] = operands[2], operands[2] = tmp;
	}
        
      gcc_assert (rtx_equal_p (operands[0], operands[1]));
      if (x86_maybe_negate_const_int (&operands[2], <MODE>mode))
        return "sub{<imodesuffix>}\t{%2, %0|%0, %2}";

      return "add{<imodesuffix>}\t{%2, %0|%0, %2}";
    }
}
  [(set (attr "type")
     (if_then_else (match_operand:SWI 2 "incdec_operand" "")
	(const_string "incdec")
	(const_string "alu")))
   (set (attr "length_immediate")
      (if_then_else
	(and (eq_attr "type" "alu") (match_operand 2 "const128_operand" ""))
	(const_string "1")
	(const_string "*")))
   (set_attr "mode" "<MODE>")]
:}

{:
;; See comment for addsi_1_zext why we do use nonimmediate_operand
:}

abstract set_compare2_plus_set_zero_extend2_plus extends sequence
{
	root.1:=set_compare2_plus;
	root.2:=set_zero_extend2;
	root.2.2.1:=plus;
}

concrete *addsi_2_zext.insn instantiates set_compare2_plus_set_zero_extend2_plus
{
	root (reg(NULL:FLAGS_REG),1=nonimmediate_operand:SI:"%0,r",2=x86_64_general_operand:SI:"rme,0",const_int:0,0=register_operand:DI:"=r,r",duplicate 1,duplicate 2);
	root.1.2.1.mode:=SI;
	root.2.2.mode:=DI;
	root.2.2.1.mode:=SI;
}
{:
  "TARGET_64BIT && ix86_match_ccmode (insn, CCGOCmode)
   && ix86_binary_operator_ok (PLUS, SImode, operands)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_INCDEC:
      if (operands[2] == const1_rtx)
        return "inc{l}\t%k0";
      else
	{
	  gcc_assert (operands[2] == constm1_rtx);
          return "dec{l}\t%k0";
	}

    default:
      if (which_alternative == 1)
	{
	  rtx tmp;
	  tmp = operands[1], operands[1] = operands[2], operands[2] = tmp;
	}

      if (x86_maybe_negate_const_int (&operands[2], SImode))
        return "sub{l}\t{%2, %k0|%k0, %2}";

      return "add{l}\t{%2, %k0|%k0, %2}";
    }
}
  [(set (attr "type")
     (if_then_else (match_operand:SI 2 "incdec_operand" "")
	(const_string "incdec")
	(const_string "alu")))
   (set (attr "length_immediate")
      (if_then_else
	(and (eq_attr "type" "alu") (match_operand 2 "const128_operand" ""))
	(const_string "1")
	(const_string "*")))
   (set_attr "mode" "SI")]
:}

abstract set_compare2_neg_clobber extends sequence
{
	root.1:=set_compare2_neg;
	root.2:=clobber;
}

concrete *add<mode>_3.insn instantiates set_compare2_neg_clobber
{
	root (reg(NULL:FLAGS_REG),2=<general_operand>:SWI:"<g>,0",1=nonimmediate_operand:SWI:"%0,<r>",0=SWI:"=<r>,<r>");
	root.1.2.1.mode:=SWI;
}
{:  
	"ix86_match_ccmode (insn, CCZmode)
   && !(MEM_P (operands[1]) && MEM_P (operands[2]))"
{
  switch (get_attr_type (insn))
    {
    case TYPE_INCDEC:
      if (operands[2] == const1_rtx)
        return "inc{<imodesuffix>}\t%0";
      else
        {
	  gcc_assert (operands[2] == constm1_rtx);
          return "dec{<imodesuffix>}\t%0";
	}

    default:
      if (which_alternative == 1)
	{
	  rtx tmp;
	  tmp = operands[1], operands[1] = operands[2], operands[2] = tmp;
	}

      gcc_assert (rtx_equal_p (operands[0], operands[1]));
      if (x86_maybe_negate_const_int (&operands[2], <MODE>mode))
        return "sub{<imodesuffix>}\t{%2, %0|%0, %2}";

      return "add{<imodesuffix>}\t{%2, %0|%0, %2}";
    }
}
  [(set (attr "type")
     (if_then_else (match_operand:SWI 2 "incdec_operand" "")
	(const_string "incdec")
	(const_string "alu")))
   (set (attr "length_immediate")
      (if_then_else
	(and (eq_attr "type" "alu") (match_operand 2 "const128_operand" ""))
	(const_string "1")
	(const_string "*")))
   (set_attr "mode" "<MODE>")]
:}

abstract set_compare2_neg_set_zero_extend2_plus extends sequence
{
	root.1:=set_compare2_neg;
	root.2:=set;
	root.2.2:=zero_extend;
	root.2.2.1:=plus;
}

concrete *addsi_3_zext.insn instantiates set_compare2_neg_set_zero_extend2_plus
{
	root (reg(NULL:FLAGS_REG),2=x86_64_general_operand:SI:"rme,0",1=nonimmediate_operand:SI:"%0,r",0=register_operand:DI:"=r,r",duplicate 1, duplicate 2);
	root.1.2.1.mode:=SI;
	root.2.2.mode:=DI;
	root.2.2.1.mode:=SI;
}
{:
  "TARGET_64BIT && ix86_match_ccmode (insn, CCZmode)
   && ix86_binary_operator_ok (PLUS, SImode, operands)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_INCDEC:
      if (operands[2] == const1_rtx)
        return "inc{l}\t%k0";
      else
        {
	  gcc_assert (operands[2] == constm1_rtx);
          return "dec{l}\t%k0";
	}

    default:
      if (which_alternative == 1)
	{
	  rtx tmp;
	  tmp = operands[1], operands[1] = operands[2], operands[2] = tmp;
	}

      if (x86_maybe_negate_const_int (&operands[2], SImode))
        return "sub{l}\t{%2, %k0|%k0, %2}";

      return "add{l}\t{%2, %k0|%k0, %2}";
    }
}
  [(set (attr "type")
     (if_then_else (match_operand:SI 2 "incdec_operand" "")
	(const_string "incdec")
	(const_string "alu")))
   (set (attr "length_immediate")
      (if_then_else
	(and (eq_attr "type" "alu") (match_operand 2 "const128_operand" ""))
	(const_string "1")
	(const_string "*")))
   (set_attr "mode" "SI")]
:}

{:
; For comparisons against 1, -1 and 128, we may generate better code
; by converting cmp to add, inc or dec as done by peephole2.  This pattern
; is matched then.  We can't accept general immediate, because for
; case of overflows,  the result is messed up.
; Also carry flag is reversed compared to cmp, so this conversion is valid
; only for comparisons not depending on it.
:}

abstract set_compare2_clobber extends sequence
{
	root.1:=set_compare2;
	root.2:=clobber;
}

concrete *adddi_4.insn instantiates set_compare2_clobber
{
	root (reg(NULL:FLAGS_REG),1=nonimmediate_operand:DI:"0",2=x86_64_immediate_operand:DI:"e",0=DI:"=rm");
}
 {: 
	"TARGET_64BIT
   && ix86_match_ccmode (insn, CCGCmode)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_INCDEC:
      if (operands[2] == constm1_rtx)
        return "inc{q}\t%0";
      else
        {
	  gcc_assert (operands[2] == const1_rtx);
          return "dec{q}\t%0";
	}

    default:
      if (x86_maybe_negate_const_int (&operands[2], DImode))
	return "add{q}\t{%2, %0|%0, %2}";

      return "sub{q}\t{%2, %0|%0, %2}";
    }
}
  [(set (attr "type")
     (if_then_else (match_operand:DI 2 "incdec_operand" "")
	(const_string "incdec")
	(const_string "alu")))
   (set (attr "length_immediate")
      (if_then_else
	(and (eq_attr "type" "alu") (match_operand 2 "const128_operand" ""))
	(const_string "1")
	(const_string "*")))
   (set_attr "mode" "DI")]
:}

{:
; For comparisons against 1, -1 and 128, we may generate better code
; by converting cmp to add, inc or dec as done by peephole2.  This pattern
; is matched then.  We can't accept general immediate, because for
; case of overflows,  the result is messed up.
; Also carry flag is reversed compared to cmp, so this conversion is valid
; only for comparisons not depending on it.
:}

concrete *add<mode>_4.insn instantiates set_compare2_clobber
{
	root (reg(NULL:FLAGS_REG),1=nonimmediate_operand:SWI124:"0",2=const_int_operand:SWI124:"n",0=SWI124:"=<r>m");
}
{:
  "ix86_match_ccmode (insn, CCGCmode)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_INCDEC:
      if (operands[2] == constm1_rtx)
        return "inc{<imodesuffix>}\t%0";
      else
        {
	  gcc_assert (operands[2] == const1_rtx);
          return "dec{<imodesuffix>}\t%0";
	}

    default:
      if (x86_maybe_negate_const_int (&operands[2], <MODE>mode))
	return "add{<imodesuffix>}\t{%2, %0|%0, %2}";

      return "sub{<imodesuffix>}\t{%2, %0|%0, %2}";
    }
}
  [(set (attr "type")
     (if_then_else (match_operand:<MODE> 2 "incdec_operand" "")
	(const_string "incdec")
	(const_string "alu")))
   (set (attr "length_immediate")
      (if_then_else
	(and (eq_attr "type" "alu") (match_operand 2 "const128_operand" ""))
	(const_string "1")
	(const_string "*")))
   (set_attr "mode" "<MODE>")]
:}

abstract set_compare2_plus_clobber extends sequence
{
	root.1:=set_compare2_plus;
	root.2:=clobber;
}

concrete *add<mode>_5.insn instantiates set_compare2_plus_clobber
{
	root (reg(NULL:FLAGS_REG),1=nonimmediate_operand:SWI:"%0,<r>",2=<general_operand>:SWI:"<g>,0",const_int:0,0=SWI:"=<r>,<r>");
	root.1.2.1.mode:=SWI;
}
{:
  "ix86_match_ccmode (insn, CCGOCmode)
   && !(MEM_P (operands[1]) && MEM_P (operands[2]))"
{
  switch (get_attr_type (insn))
    {
    case TYPE_INCDEC:
      if (operands[2] == const1_rtx)
        return "inc{<imodesuffix>}\t%0";
      else
        {
          gcc_assert (operands[2] == constm1_rtx);
          return "dec{<imodesuffix>}\t%0";
	}

    default:
      if (which_alternative == 1)
	{
	  rtx tmp;
	  tmp = operands[1], operands[1] = operands[2], operands[2] = tmp;
	}

      gcc_assert (rtx_equal_p (operands[0], operands[1]));
      if (x86_maybe_negate_const_int (&operands[2], <MODE>mode))
        return "sub{<imodesuffix>}\t{%2, %0|%0, %2}";

      return "add{<imodesuffix>}\t{%2, %0|%0, %2}";
    }
}
  [(set (attr "type")
     (if_then_else (match_operand:SWI 2 "incdec_operand" "")
	(const_string "incdec")
	(const_string "alu")))
   (set (attr "length_immediate")
      (if_then_else
	(and (eq_attr "type" "alu") (match_operand 2 "const128_operand" ""))
	(const_string "1")
	(const_string "*")))
   (set_attr "mode" "<MODE>")]
:}


abstract set_zero_extract1_plus2_zero_extract1 extends set
{
	root.1:=zero_extract;
	root.2:=plus;
	root.2.1:=zero_extract;
}

abstract set_zero_extract1_plus2_zero_extract1_clobber extends sequence
{
	root.1:=set_zero_extract1_plus2_zero_extract1;
	root.2:=clobber;
}

concrete *addqi_ext_1_rex64.insn instantiates set_zero_extract1_plus2_zero_extract1_clobber
{
	root (0=ext_register_operand:NULL:"=Q",const_int:8,const_int:8,1=ext_register_operand:NULL:"0",const_int:8,const_int:8,2=nonmemory_operand:QI:"Qn",reg(CC:FLAGS_REG));
	root.1.1.mode:=SI;
	root.1.2.mode:=SI;
	root.1.2.1.mode:=SI;
}
{:
  "TARGET_64BIT"
{
  switch (get_attr_type (insn))
    {
    case TYPE_INCDEC:
      if (operands[2] == const1_rtx)
	return "inc{b}\t%h0";
      else
        {
	  gcc_assert (operands[2] == constm1_rtx);
          return "dec{b}\t%h0";
        }

    default:
      return "add{b}\t{%2, %h0|%h0, %2}";
    }
}
  [(set (attr "type")
     (if_then_else (match_operand:QI 2 "incdec_operand" "")
	(const_string "incdec")
	(const_string "alu")))
   (set_attr "modrm" "1")
   (set_attr "mode" "QI")]
:}

concrete addqi_ext_1.insn overrides *addqi_ext_1_rex64.insn
{
	root.1.2.2:=general_operand:QI:"Qmn";
}
{:  
	"!TARGET_64BIT"
{
  switch (get_attr_type (insn))
    {
    case TYPE_INCDEC:
      if (operands[2] == const1_rtx)
	return "inc{b}\t%h0";
      else
        {
	  gcc_assert (operands[2] == constm1_rtx);
          return "dec{b}\t%h0";
	}

    default:
      return "add{b}\t{%2, %h0|%h0, %2}";
    }
}
  [(set (attr "type")
     (if_then_else (match_operand:QI 2 "incdec_operand" "")
	(const_string "incdec")
	(const_string "alu")))
   (set_attr "modrm" "1")
   (set_attr "mode" "QI")]
:}

abstract set_zero_extract1_plus2_zero_extract1_zero_extract2 extends set
{
	root.1:=zero_extract;
	root.2:=plus;
	root.2.1:=zero_extract;
	root.2.2:=zero_extract;
}

abstract set_zero_extract1_plus2_zero_extract1_zero_extract2_clobber extends sequence
{
	root.1:=set_zero_extract1_plus2_zero_extract1_zero_extract2;
	root.2:=clobber;
}

concrete *addqi_ext_2.insn instantiates set_zero_extract1_plus2_zero_extract1_zero_extract2_clobber
{
	root (0=ext_register_operand:NULL:"=Q",const_int:8,const_int:8,1=ext_register_operand:NULL:"%0",const_int:8,const_int:8,2=ext_register_operand:NULL:"Q",const_int:8,const_int:8,reg(CC:FLAGS_REG));
	root.1.1.mode:=SI;
	root.1.2.mode:=SI;
	root.1.2.1.mode:=SI;
	root.1.2.2.mode:=SI;
}
{:
  ""
  "add{b}\t{%h2, %h0|%h0, %h2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "QI")]
:}

{:
;; The lea patterns for modes less than 32 bits need to be matched by
;; several insns converted to real lea by splitters.
:}

abstract set_plus2_plus1 extends set_plus2
{
	root.2.1:=plus;
}

concrete *lea_general_1.insn_and_split instantiates.in set_plus2_plus1
{
	root (0=register_operand:NULL:"=r",1=index_register_operand:NULL:"l",2=register_operand:NULL:"r",3=immediate_operand:NULL:"i");
}
cmd_spec.in
{:
	"(GET_MODE (operands[0]) == QImode || GET_MODE (operands[0]) == HImode)
	&& (!TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun))
  	&& GET_MODE (operands[0]) == GET_MODE (operands[1])
   	&& GET_MODE (operands[0]) == GET_MODE (operands[2])
   	&& (GET_MODE (operands[0]) == GET_MODE (operands[3])
        || GET_MODE (operands[3]) == VOIDmode)"
	"#"
	"&& reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  enum machine_mode mode = SImode;
  rtx pat;

  operands[0] = gen_lowpart (mode, operands[0]);
  operands[1] = gen_lowpart (mode, operands[1]);
  operands[2] = gen_lowpart (mode, operands[2]);
  operands[3] = gen_lowpart (mode, operands[3]);

  pat = gen_rtx_PLUS (mode, gen_rtx_PLUS (mode, operands[1], operands[2]),
  		      operands[3]);

  emit_insn (gen_rtx_SET (VOIDmode, operands[0], pat));
  DONE;
}
  [(set_attr "type" "lea")
   (set_attr "mode" "SI")]

:}

abstract set_plus2_mult1 extends set_plus2
{
	root.2.1:=mult;
}

concrete *lea_general_2.insn_and_split instantiates.in set_plus2_mult1
{
	root (0=register_operand:NULL:"=r",1=index_register_operand:NULL:"l",2=const248_operand:NULL:"n",3=nonmemory_operand:NULL:"ri");
}
cmd_spec.in
{:
  "(GET_MODE (operands[0]) == QImode || GET_MODE (operands[0]) == HImode)
   && (!TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun))
   && GET_MODE (operands[0]) == GET_MODE (operands[1])
   && (GET_MODE (operands[0]) == GET_MODE (operands[3])
       || GET_MODE (operands[3]) == VOIDmode)"
  "#"
  "&& reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
} 
cmd_spec.out 
{:
{
  enum machine_mode mode = SImode;
  rtx pat;

  operands[0] = gen_lowpart (mode, operands[0]);
  operands[1] = gen_lowpart (mode, operands[1]);
  operands[3] = gen_lowpart (mode, operands[3]);

  pat = gen_rtx_PLUS (mode, gen_rtx_MULT (mode, operands[1], operands[2]),
		      operands[3]);

  emit_insn (gen_rtx_SET (VOIDmode, operands[0], pat));
  DONE;
}
  [(set_attr "type" "lea")
   (set_attr "mode" "SI")]
:}

abstract set_plus2_plus1_mult1 extends set_plus2
{
	root.2.1:=plus;
	root.2.1.1:=mult;
}

concrete *lea_general_3.insn_and_split instantiates.in set_plus2_plus1_mult1
{
	root (0=register_operand:NULL:"=r",1=index_register_operand:NULL:"l",2=const248_operand:NULL:"n",3=register_operand:NULL:"r",4=immediate_operand:NULL:"i");
}
cmd_spec.in
{:
  "(GET_MODE (operands[0]) == QImode || GET_MODE (operands[0]) == HImode)
   && (!TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun))
   && GET_MODE (operands[0]) == GET_MODE (operands[1])
   && GET_MODE (operands[0]) == GET_MODE (operands[3])"
  "#"
  "&& reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  enum machine_mode mode = SImode;
  rtx pat;

  operands[0] = gen_lowpart (mode, operands[0]);
  operands[1] = gen_lowpart (mode, operands[1]);
  operands[3] = gen_lowpart (mode, operands[3]);
  operands[4] = gen_lowpart (mode, operands[4]);

  pat = gen_rtx_PLUS (mode,
  		      gen_rtx_PLUS (mode,
				    gen_rtx_MULT (mode, operands[1],
		      					operands[2]),
				    operands[3]),
  		      operands[4]);

  emit_insn (gen_rtx_SET (VOIDmode, operands[0], pat));
  DONE;
}
  [(set_attr "type" "lea")
   (set_attr "mode" "SI")]
:}

abstract set_any_or2 extends set
{
	root.2:=any_or;
}


abstract set_any_or2_ashift1 extends set_any_or2
{
	root.2.1:=ashift;
}


concrete *lea_general_4.insn_and_split instantiates.in set_any_or2_ashift1
{
	root (0=register_operand:NULL:"=r", 
		1=index_register_operand:NULL:"l", 2=const_int_operand:NULL:"n",
		3=const_int_operand:NULL:"n");
}
cmd_spec.in
{:
  "(((GET_MODE (operands[0]) == QImode || GET_MODE (operands[0]) == HImode)
      && (!TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun)))
    || GET_MODE (operands[0]) == SImode
    || (TARGET_64BIT && GET_MODE (operands[0]) == DImode))
   && GET_MODE (operands[0]) == GET_MODE (operands[1])
   && ((unsigned HOST_WIDE_INT) INTVAL (operands[2])) - 1 < 3
   && ((unsigned HOST_WIDE_INT) INTVAL (operands[3])
       < ((unsigned HOST_WIDE_INT) 1 << INTVAL (operands[2])))"
  "#"
  "&& reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  enum machine_mode mode = GET_MODE (operands[0]);
  rtx pat;

  if (GET_MODE_SIZE (mode) < GET_MODE_SIZE (SImode))
    { 
      mode = SImode; 
      operands[0] = gen_lowpart (mode, operands[0]);
      operands[1] = gen_lowpart (mode, operands[1]);
    }

  operands[2] = GEN_INT (1 << INTVAL (operands[2]));

  pat = plus_constant (gen_rtx_MULT (mode, operands[1], operands[2]),
		       INTVAL (operands[3]));

  emit_insn (gen_rtx_SET (VOIDmode, operands[0], pat));
  DONE;
}
  [(set_attr "type" "lea")
   (set (attr "mode")
      (if_then_else (match_operand:DI 0 "" "")
	(const_string "DI")
	(const_string "SI")))]
:}

{:

;; Subtract instructions
:}

concrete sub<mode>3.exp instantiates set_minus2
{
	root (0=nonimmediate_operand:SDWIM:"",1=nonimmediate_operand:SDWIM:"",2=<general_operand>:SDWIM:"");
	root.2.mode:=SDWIM;
}
{:
  ""
  "ix86_expand_binary_operator (MINUS, <MODE>mode, operands); DONE;"
:}

abstract set_minus2_clobber extends sequence
{
	root.1:=set_minus2;
	root.2:=clobber;
}

abstract parallel_set_compare2_set_minus2_parallel_set_minus2_plus2_ltu1_clobber extends sequence
{
	root.1:=parallel;
	root.1.1:=set_compare2;
	root.1.2:=set_minus2;

	root.2:=parallel;
	root.2.1:=set_minus2;
	root.2.1.2.2:=plus;
	root.2.1.2.2.1:=ltu;
	root.2.2:=clobber;
}


concrete *sub<dwi>3_doubleword.insn_and_split instantiates.in set_minus2_clobber
{
	root (0=nonimmediate_operand:<DWI>:"=r,o",
		1=nonimmediate_operand:<DWI>:"0,0", 2=<general_operand>:<DWI>:"ro<di>,r<di>",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=<DWI>;
}
cmd_spec.in
{:
  "ix86_binary_operator_ok (MINUS, <MODE>mode, operands)"
  "#"
  "reload_completed"
:}
instantiates.out parallel_set_compare2_set_minus2_parallel_set_minus2_plus2_ltu1_clobber
{
	root (
		(reg(CC:FLAGS_REG), duplicate 1, duplicate 2, duplicate 0,
			duplicate 1, duplicate 2),
		(duplicate 3, duplicate 4, reg(CC:FLAGS_REG), const_int:0, duplicate 5,
			reg(CC:FLAGS_REG)));
	root.1.1.2.mode:=CC;
	root.1.2.2.mode:=DWIH;

	root.2.1.2.mode:=DWIH;
	root.2.1.2.2.mode:=DWIH;
	root.2.1.2.2.1.mode:=DWIH;
}
cmd_spec.out
{:
  "split_double_mode (<DWI>mode, &operands[0], 3, &operands[0], &operands[3]);"
:}

abstract set_minus2_clobber extends sequence
{
	root.1:=set_minus2;
	root.2:=clobber;
}

concrete *sub<mode>_1.insn instantiates set_minus2_clobber
{
	root (0=nonimmediate_operand:SWI:"=<r>m,<r>",1=nonimmediate_operand:SWI:"0,0",2=<general_operand>:SWI:"<r><i>,<r>m",reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI;
}
{:
  "ix86_binary_operator_ok (MINUS, <MODE>mode, operands)"
  "sub{<imodesuffix>}\t{%2, %0|%0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "<MODE>")]
:}

abstract set_zero_extend2_minus1_clobber extends sequence
{
	root.1:=set_zero_extend2_minus1;
	root.2:=clobber;
}

concrete *subsi_1_zext.insn instantiates set_zero_extend2_minus1_clobber
{
	root (0=register_operand:DI:"=r",1=register_operand:SI:"0",2=x86_64_general_operand:SI:"rme",reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=SI;
}
{:
  "TARGET_64BIT && ix86_binary_operator_ok (MINUS, SImode, operands)"
  "sub{l}\t{%2, %k0|%k0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "SI")]
:}

abstract set_strict_low_part1_minus2 extends set_minus2
{
	root.1:=strict_low_part;
}

abstract set_strict_low_part1_minus2_clobber extends sequence
{
	root.1:=set_strict_low_part1_minus2;
	root.2:=clobber;
}

concrete *subqi_1_slp.insn instantiates set_strict_low_part1_minus2_clobber
{
	root (0=nonimmediate_operand:QI:"+qm,q",duplicate 0,1=general_operand:QI:"qn,qm",reg(CC:FLAGS_REG));
	root.1.2.mode:=QI;
}
{:
  "(! TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun))
   && !(MEM_P (operands[0]) && MEM_P (operands[1]))"
  "sub{b}\t{%1, %0|%0, %1}"
  [(set_attr "type" "alu1")
   (set_attr "mode" "QI")]
:}

abstract set_compare2_minus_set_minus2 extends sequence
{
	root.1:=set_compare2_minus;
	root.2:=set_minus2;
}

concrete *sub<mode>_2.insn instantiates set_compare2_minus_set_minus2
{
	root (reg(NULL:FLAGS_REG),1=nonimmediate_operand:SWI:"0,0",2=<general_operand>:SWI:"<r><i>,<r>m",const_int:0,0=nonimmediate_operand:SWI:"=<r>m,<r>",duplicate 1,duplicate 2);
	root.1.2.1.mode:=SWI;
	root.2.2.mode:=SWI;
}
{:
  "ix86_match_ccmode (insn, CCGOCmode)
   && ix86_binary_operator_ok (MINUS, <MODE>mode, operands)"
  "sub{<imodesuffix>}\t{%2, %0|%0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "<MODE>")]
:}


abstract set_compare2_minus_set_zero_extend2_minus extends sequence
{
	root.1:=set_compare2_minus;
	root.2:=set_zero_extend2_minus;
}

concrete *subsi_2_zext.insn instantiates set_compare2_minus_set_zero_extend2_minus
{
	root (reg(NULL:FLAGS_REG),1=register_operand:SI:"0",2=x86_64_general_operand:SI:"rme",const_int:0,0=register_operand:DI:"=r",duplicate 1,duplicate 2);
	root.1.2.1.mode:=SI;
	root.2.2.mode:=DI;
	root.2.2.1.mode:=SI;
}
{:
  "TARGET_64BIT && ix86_match_ccmode (insn, CCGOCmode)
   && ix86_binary_operator_ok (MINUS, SImode, operands)"
  "sub{l}\t{%2, %k0|%k0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "SI")]
:}

abstract set_compare2_set_minus2 extends sequence
{
	root.1:=set_compare2;
	root.2:=set_minus2;
}

concrete *sub<mode>_3.insn instantiates set_compare2_set_minus2
{
	root (reg(NULL:FLAGS_REG),1=nonimmediate_operand:SWI:"0,0",2=<general_operand>:SWI:"<r><i>,<r>m",0=nonimmediate_operand:SWI:"=<r>m,<r>",duplicate 1,duplicate 2);
	root.2.2.mode:=SWI;
}
{:
  "ix86_match_ccmode (insn, CCmode)
   && ix86_binary_operator_ok (MINUS, <MODE>mode, operands)"
  "sub{<imodesuffix>}\t{%2, %0|%0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "<MODE>")]
:}

abstract set_compare2_set_zero_extend2_minus extends sequence
{
	root.1:=set_compare2;
	root.2:=set_zero_extend2_minus;
}


concrete *subsi_3_zext.insn instantiates set_compare2_set_zero_extend2_minus
{
	root (reg(NULL:FLAGS_REG),1=register_operand:SI:"0",2=x86_64_general_operand:SI:"rme",0=register_operand:DI:"=r",duplicate 1,duplicate 2);
	root.2.2.mode:=DI;
	root.2.2.1.mode:=SI;
}
{:
  "TARGET_64BIT && ix86_match_ccmode (insn, CCmode)
   && ix86_binary_operator_ok (MINUS, SImode, operands)"
  "sub{l}\t{%2, %1|%1, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "SI")]
:}

{:

;; Add with carry and subtract with borrow
:}

{:
;; TODO. Parallel and sequence subpatterns are same. Should be able to use the same
;; child patterns. e.g. See below two patterns.
:}

abstract set_plusminus2 extends set
{
	root.2:=plusminus;
}

abstract set_plusminus2_plus2_match_operator1_clobber extends sequence
{
	root.1:=set_plusminus2;
	root.1.2.2:=plus;
	root.1.2.2.1:=match_operator;
	root.2:=clobber;
}

abstract parallel_set_plusminus2_plus2_match_operator1_clobber extends parallel
{
	root.1:=set_plusminus2;
	root.1.2.2:=plus;
	root.1.2.2.1:=match_operator;
	root.2:=clobber;
}

concrete <plusminus_insn><mode>3_carry.exp instantiates parallel_set_plusminus2_plus2_match_operator1_clobber
{
	root (0=nonimmediate_operand:SWI:"",
		1=nonimmediate_operand:SWI:"", (4=ix86_carry_flag_operator, 
		3=flags_reg_operand:NULL:"", const_int:0), 2=<general_operand>:SWI:"",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI;
	root.1.2.2.mode:=SWI;
	root.1.2.2.1.mode:=SWI;
}
{:
  "ix86_binary_operator_ok (<CODE>, <MODE>mode, operands)"
:}

concrete *<plusminus_insn><mode>3_carry.insn instantiates set_plusminus2_plus2_match_operator1_clobber
{
	root (0=nonimmediate_operand:SWI:"=<r>m,<r>",
		1=nonimmediate_operand:SWI:"<comm>0,0", (3=ix86_carry_flag_operator, 
		reg(NULL:FLAGS_REG), const_int:0), 2=<general_operand>:SWI:"<r><i>,<r>m",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI;
	root.1.2.2.mode:=SWI;
}
{:
  "ix86_binary_operator_ok (PLUS, <MODE>mode, operands)"
  "<plusminus_carry_mnemonic>{<imodesuffix>}\t{%2, %0|%0, %2}"
  [(set_attr "type" "alu")
   (set_attr "use_carry" "1")
   (set_attr "pent_pair" "pu")
   (set_attr "mode" "<MODE>")]
:}

abstract set_zero_extend2_plus_plus2 extends set_zero_extend2
{
	root.2.1:=plus;
	root.2.1.2:=plus;
}

abstract set_zero_extend2_plus_plus2_clobber extends sequence
{
	root.1:=set_zero_extend2_plus_plus2;
	root.2:=clobber;
}

abstract set_zero_extend2_plus1_plus2_match_operator1_clobber extends set_zero_extend2_plus_plus2_clobber
{
	root.1.2.1.2.1:=match_operator;
}

concrete *addsi3_carry_zext.insn instantiates set_zero_extend2_plus1_plus2_match_operator1_clobber
{
	root (
		0=register_operand:DI:"=r", 1=nonimmediate_operand:SI:"%0",
		(3=ix86_carry_flag_operator, reg(NULL:FLAGS_REG), const_int:0),
		2=x86_64_general_operand:SI:"rme", reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=SI;
	root.1.2.1.2.mode:=SI;
}
{:
  "TARGET_64BIT && ix86_binary_operator_ok (PLUS, SImode, operands)"
  "adc{l}\t{%2, %k0|%k0, %2}"
  [(set_attr "type" "alu")
   (set_attr "use_carry" "1")
   (set_attr "pent_pair" "pu")
   (set_attr "mode" "SI")]
:}

abstract set_zero_extend2_minus_plus2_match_operator1_clobber extends set_zero_extend2_plus_plus2_clobber
{
	root.1.2.1:=minus;
	root.1.2.1.2:=plus;
	root.1.2.1.2.1:=match_operator;
}

concrete *subsi3_carry_zext.insn instantiates set_zero_extend2_minus_plus2_match_operator1_clobber 
{
	root (
		0=register_operand:DI:"=r", 1=register_operand:SI:"0", 
		(3=ix86_carry_flag_operator, reg(NULL:FLAGS_REG), const_int:0),
		2=x86_64_general_operand:SI:"rme", reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=SI;
	root.1.2.1.2.mode:=SI;
}
{:
	    "TARGET_64BIT && ix86_binary_operator_ok (MINUS, SImode, operands)"
	  "sbb{l}\t{%2, %k0|%k0, %2}"
    [(set_attr "type" "alu")
   (set_attr "pent_pair" "pu")
   (set_attr "mode" "SI")]
:}

{:

;; Overflow setting add and subtract instructions
:}

concrete *add<mode>3_cconly_overflow.insn instantiates set_compare2_plus_clobber
{
	root (reg(CCC:FLAGS_REG),1=nonimmediate_operand:SWI:"%0",2=<general_operand>:SWI:"<g>",duplicate 1,0=SWI:"=<r>");
	root.1.2.mode:=CCC;
	root.1.2.1.mode:=SWI;
}
{:
  "!(MEM_P (operands[1]) && MEM_P (operands[2]))"
  "add{<imodesuffix>}\t{%2, %0|%0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "<MODE>")]
:}

concrete *sub<mode>3_cconly_overflow.insn instantiates set_compare2_minus1
{
	root (reg(CCC:FLAGS_REG), 
		0=nonimmediate_operand:SWI:"<r>m,<r>",
		1=<general_operand>:SWI:"<r><i>,<r>m", duplicate 0);
	root.2.mode:=CCC;
	root.2.1.mode:=SWI;
}
{:
  ""
  "cmp{<imodesuffix>}\t{%1, %0|%0, %1}"
  [(set_attr "type" "icmp")
   (set_attr "mode" "<MODE>")]
:}
{:
;; TODO Cause: Instead of writing the entire patern again in conrete, we can something like root there.
:}

abstract set_compare2_plusminus1 extends set_compare2_minus1
{
	root.2.1:=plusminus;
}


abstract set_compare2_plusminus1_set_plusminus2 extends sequence
{
	root.1:=set_compare2_plusminus1;
	root.2:=set_plusminus2;
}


concrete *<plusminus_insn><mode>3_cc_overflow.insn instantiates set_compare2_plusminus1_set_plusminus2
{
	root (reg(CCC:FLAGS_REG),
		1=nonimmediate_operand:SWI:"<comm>0,0",2=<general_operand>:SWI:"<r><i>,<r>m",
		duplicate 1, 0=nonimmediate_operand:SWI:"=<r>m,<r>", duplicate 1, 
		duplicate 2);
	root.1.2.mode:=CCC;
	root.1.2.1.mode:=SWI;
	root.2.2.mode:=SWI;
}
{:
  "ix86_binary_operator_ok (<CODE>, <MODE>mode, operands)"
  "<plusminus_mnemonic>{<imodesuffix>}\t{%2, %0|%0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "<MODE>")]
:}

abstract set_compare2_plusminus1_set_zero_extend2_plusminus1 extends sequence
{
	root.1:=set_compare2_plusminus1;
	root.2:=set_zero_extend2;
	root.2.2.1:=plusminus;
}

concrete *<plusminus_insn>si3_zext_cc_overflow.insn instantiates set_compare2_plusminus1_set_zero_extend2_plusminus1
{
	root (reg(CCC:FLAGS_REG), 
		1=nonimmediate_operand:SI:"<comm>0", 2=x86_64_general_operand:SI:"rme",
		duplicate 1, 0=register_operand:DI:"=r", duplicate 1, duplicate 2);
	root.1.2.mode:=CCC;
	root.1.2.1.mode:=SI;
	root.2.2.mode:=DI;
	root.2.2.1.mode:=SI;
}
{:
  "TARGET_64BIT && ix86_binary_operator_ok (<CODE>, SImode, operands)"
  "<plusminus_mnemonic>{l}\t{%2, %k0|%k0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "SI")]
:}
{:
;; TODO Cause: We can have all the abstract patterns in a separate file. like a c header file.
:}
{:
;; The patterns that match these are at the end of this file.
:}
concrete <plusminus_insn>xf3.exp instantiates set_plusminus2
{
	root (0=register_operand:XF:"", 1=register_operand:XF:"",
		2=register_operand:XF:"");
	root.2.mode:=XF;
}
{:
  "TARGET_80387"
:}

concrete <plusminus_insn><mode>3.exp overrides <plusminus_insn>xf3.exp
{
	XF->MODEF;
	root.2.2.predicate:=nonimmediate_operand;
}
{:
  "(TARGET_80387 && X87_ENABLE_ARITH (<MODE>mode))
    || (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)"
:}
{:

;; Multiply instructions
:}
abstract parallel_set_mult2_clobber extends parallel
{
	root.1:=set_mult2;
	root.2:=clobber;
}

concrete mul<mode>3.exp instantiates parallel_set_mult2_clobber
{
	root (0=register_operand:SWIM248:"",
		1=register_operand:SWIM248:"", 2=<general_operand>:SWIM248:"",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWIM248;
}
{:
:}

concrete mulqi3.exp overrides mul<mode>3.exp
{
	SWIM248->QI;
	root.1.2.2.predicate:=nonimmediate_operand;
}
{:
  "TARGET_QIMODE_MATH"
:}

{:
;; On AMDFAM10
;; IMUL reg32/64, reg32/64, imm8 	Direct
;; IMUL reg32/64, mem32/64, imm8 	VectorPath
;; IMUL reg32/64, reg32/64, imm32 	Direct
;; IMUL reg32/64, mem32/64, imm32 	VectorPath
;; IMUL reg32/64, reg32/64 		Direct
;; IMUL reg32/64, mem32/64 		Direct
;;
;; On BDVER1, all above IMULs use DirectPath

:}

abstract set_mult2_clobber extends sequence
{
	root.1:=set_mult2;
	root.2:=clobber;
}

concrete *mul<mode>3_1.insn instantiates set_mult2_clobber
{
	root (0=register_operand:SWI48:"=r,r,r",1=nonimmediate_operand:SWI48:"%rm,rm,0",2=<general_operand>:SWI48:"K,<i>,mr",reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
}
{:
  "!(MEM_P (operands[1]) && MEM_P (operands[2]))"
  "@
   imul{<imodesuffix>}\t{%2, %1, %0|%0, %1, %2}
   imul{<imodesuffix>}\t{%2, %1, %0|%0, %1, %2}
   imul{<imodesuffix>}\t{%2, %0|%0, %2}"
  [(set_attr "type" "imul")
   (set_attr "prefix_0f" "0,0,1")
   (set (attr "athlon_decode")
	(cond [(eq_attr "cpu" "athlon")
		  (const_string "vector")
	       (eq_attr "alternative" "1")
		  (const_string "vector")
	       (and (eq_attr "alternative" "2")
		    (match_operand 1 "memory_operand" ""))
		  (const_string "vector")]
	      (const_string "direct")))
   (set (attr "amdfam10_decode")
	(cond [(and (eq_attr "alternative" "0,1")
		    (match_operand 1 "memory_operand" ""))
		  (const_string "vector")]
	      (const_string "direct")))
   (set_attr "bdver1_decode" "direct")
   (set_attr "mode" "<MODE>")]
:}

abstract set_zero_extend2_mult_clobber extends set_zero_extend2_plus_clobber
{
	root.1.2.1:=mult;
}

concrete *mulsi3_1_zext.insn instantiates set_zero_extend2_mult_clobber
{
	root (0=register_operand:DI:"=r,r,r",1=nonimmediate_operand:SI:"%rm,rm,0",2=x86_64_general_operand:SI:"K,e,mr",reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=SI;
}
{:
  "TARGET_64BIT
   && !(MEM_P (operands[1]) && MEM_P (operands[2]))"
  "@
   imul{l}\t{%2, %1, %k0|%k0, %1, %2}
   imul{l}\t{%2, %1, %k0|%k0, %1, %2}
   imul{l}\t{%2, %k0|%k0, %2}"
  [(set_attr "type" "imul")
   (set_attr "prefix_0f" "0,0,1")
   (set (attr "athlon_decode")
	(cond [(eq_attr "cpu" "athlon")
		  (const_string "vector")
	       (eq_attr "alternative" "1")
		  (const_string "vector")
	       (and (eq_attr "alternative" "2")
		    (match_operand 1 "memory_operand" ""))
		  (const_string "vector")]
	      (const_string "direct")))
   (set (attr "amdfam10_decode")
	(cond [(and (eq_attr "alternative" "0,1")
		    (match_operand 1 "memory_operand" ""))
		  (const_string "vector")]
	      (const_string "direct")))
   (set_attr "bdver1_decode" "direct")
   (set_attr "mode" "SI")]
:}

{:
;; On AMDFAM10
;; IMUL reg16, reg16, imm8 	VectorPath
;; IMUL reg16, mem16, imm8 	VectorPath
;; IMUL reg16, reg16, imm16 	VectorPath
;; IMUL reg16, mem16, imm16 	VectorPath
;; IMUL reg16, reg16 		Direct
;; IMUL reg16, mem16 		Direct
;;
;; On BDVER1, all HI MULs use DoublePath
:}
concrete *mulhi3_1.insn overrides *mul<mode>3_1.insn
{
	allconstraints:=("=r,r,r", "%rm,rm,0", "K,n,mr");
	SWI48->HI; 	root.1.2.2.predicate:=general_operand;
}
{:
  "TARGET_HIMODE_MATH
   && !(MEM_P (operands[1]) && MEM_P (operands[2]))"
  "@
   imul{w}\t{%2, %1, %0|%0, %1, %2}
   imul{w}\t{%2, %1, %0|%0, %1, %2}
   imul{w}\t{%2, %0|%0, %2}"
  [(set_attr "type" "imul")
   (set_attr "prefix_0f" "0,0,1")
   (set (attr "athlon_decode")
	(cond [(eq_attr "cpu" "athlon")
		  (const_string "vector")
	       (eq_attr "alternative" "1,2")
		  (const_string "vector")]
	      (const_string "direct")))
   (set (attr "amdfam10_decode")
	(cond [(eq_attr "alternative" "0,1")
		  (const_string "vector")]
	      (const_string "direct")))
   (set_attr "bdver1_decode" "double")
   (set_attr "mode" "HI")]
:}

{:
;;On AMDFAM10 and BDVER1
;; MUL reg8 	Direct
;; MUL mem8 	Direct
:}

concrete *mulqi3_1.insn overrides *mul<mode>3_1.insn
{
	allconstraints:=("=a", "%0", "qm");
	SWI48->QI;	root.1.2.2.predicate:=nonimmediate_operand;
}
{:
  "TARGET_QIMODE_MATH
   && !(MEM_P (operands[1]) && MEM_P (operands[2]))"
  "mul{b}\t%2"
  [(set_attr "type" "imul")
   (set_attr "length_immediate" "0")
   (set (attr "athlon_decode")
     (if_then_else (eq_attr "cpu" "athlon")
        (const_string "vector")
        (const_string "direct")))
   (set_attr "amdfam10_decode" "direct")
   (set_attr "bdver1_decode" "direct")
   (set_attr "mode" "QI")]
:}

abstract parallel_set_mult2_any_extend1_any_extend2_clobber extends parallel
{
	root.1:=set_mult2;
	root.1.2.1:=any_extend;
	root.1.2.2:=any_extend;
	root.2:=clobber;
}


concrete <u>mul<mode><dwi>3.exp instantiates parallel_set_mult2_any_extend1_any_extend2_clobber
{
	root (0=register_operand:<DWI>:"",
		1=nonimmediate_operand:DWIH:"", 2=register_operand:DWIH:"",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=<DWI>;
	root.1.2.1.mode:=<DWI>;
	root.1.2.2.mode:=<DWI>;
}
{:
:}

concrete <u>mulqihi3.exp overrides <u>mul<mode><dwi>3.exp
{
	root.1.1.mode:=HI;
	root.1.2.mode:=HI;
	root.1.2.1.mode:=HI;
	root.1.2.1.1.mode:=QI;
	root.1.2.2.mode:=HI;
	root.1.2.2.1.mode:=QI;
}
{:
  "TARGET_QIMODE_MATH"
:}

abstract set_truncate2_lshiftrt_mult extends set
{
	root.2:=truncate;
	root.2.1:=lshiftrt;
	root.2.1.1:=mult;
}

abstract set_mult2_set_truncate2_lshiftrt_mult extends sequence
{
	root.1:=set_mult2;
	root.2:=set_truncate2_lshiftrt_mult;
}

abstract set_mult2_set_truncate2_lshiftrt_mult_zero_extend1_zero_extend2 extends set_mult2_set_truncate2_lshiftrt_mult
{
        root.2.2.1.1.1:=zero_extend;
        root.2.2.1.1.2:=zero_extend;
}


concrete *bmi2_umulditi3_1.insn instantiates set_mult2_set_truncate2_lshiftrt_mult_zero_extend1_zero_extend2
{
	root (0=register_operand:DI:"=r",2=nonimmediate_operand:DI:"%d",3=nonimmediate_operand:DI:"rm",1=register_operand:DI:"=r",duplicate 2, duplicate 3,const_int:64);
	root.1.2.mode:=DI;
	root.2.2.mode:=DI;
	root.2.2.1.mode:=TI;
	root.2.2.1.1.mode:=TI;
	root.2.2.1.1.1.mode:=TI;
	root.2.2.1.1.2.mode:=TI;
}
{:
  "TARGET_64BIT && TARGET_BMI2
   && !(MEM_P (operands[1]) && MEM_P (operands[2]))"
  "mulx\t{%3, %0, %1|%1, %0, %3}"
  [(set_attr "type" "imulx")
   (set_attr "prefix" "vex")
   (set_attr "mode" "DI")]
:}


concrete *bmi2_umulsidi3_1.insn instantiates set_mult2_set_truncate2_lshiftrt_mult_zero_extend1_zero_extend2
{
	root (0=register_operand:SI:"=r",2=nonimmediate_operand:SI:"%d",3=nonimmediate_operand:SI:"rm",1=register_operand:SI:"=r",duplicate 2,duplicate 3,  const_int:32);
	root.1.2.mode:=SI;
	root.2.2.mode:=SI;
	root.2.2.1.mode:=DI;
	root.2.2.1.1.mode:=DI;
	root.2.2.1.1.1.mode:=DI;
	root.2.2.1.1.2.mode:=DI;
}
{:
  "!TARGET_64BIT && TARGET_BMI2
   && !(MEM_P (operands[1]) && MEM_P (operands[2]))"
  "mulx\t{%3, %0, %1|%1, %0, %3}"
  [(set_attr "type" "imulx")
   (set_attr "prefix" "vex")
   (set_attr "mode" "SI")]
:}

abstract set_mult2_zero_extend1_zero_extend2 extends set_mult2
{
	root.2.1:=zero_extend;
	root.2.2:=zero_extend;
}


abstract set_mult2_zero_extend1_zero_extend2_clobber extends sequence
{
	root.1:=set_mult2_zero_extend1_zero_extend2;
	root.2:=clobber;
}

concrete *umul<mode><dwi>3_1.insn instantiates set_mult2_zero_extend1_zero_extend2_clobber
{
	root (0=register_operand:<DWI>:"=A,r",
		1=nonimmediate_operand:DWIH:"%0,d", 2=nonimmediate_operand:DWIH:"rm,rm",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=<DWI>;
	root.1.2.1.mode:=<DWI>;
	root.1.2.2.mode:=<DWI>;
}
{:
  "!(MEM_P (operands[1]) && MEM_P (operands[2]))"
  "@
   mul{<imodesuffix>}\t%2
   #"
  [(set_attr "isa" "*,bmi2")
   (set_attr "type" "imul,imulx")
   (set_attr "length_immediate" "0,*")
   (set (attr "athlon_decode")
	(cond [(eq_attr "alternative" "0")
		 (if_then_else (eq_attr "cpu" "athlon")
		   (const_string "vector")
		   (const_string "double"))]
	      (const_string "*")))
   (set_attr "amdfam10_decode" "double,*")
   (set_attr "bdver1_decode" "direct,*")
   (set_attr "prefix" "orig,vex")
   (set_attr "mode" "<MODE>")]
:}

{:
;; Convert mul to the mulx pattern to avoid flags dependency.
:}

abstract set_truncate2_lshiftrt1_mult1_zero_extend1_zero_extend2 extends set
{
	root.2:=truncate;
	root.2.1:=lshiftrt;
	root.2.1.1:=mult;
	root.2.1.1.1:=zero_extend;
	root.2.1.1.2:=zero_extend;
}


abstract parallel_set_mult2_set_truncate2_lshiftrt1_mult1_zero_extend1_zero_extend2 extends parallel
{
	root.1:=set_mult2;
	root.2:=set_truncate2_lshiftrt1_mult1_zero_extend1_zero_extend2;
}


concrete .split instantiates.in set_mult2_zero_extend1_zero_extend2_clobber
{
	root (0=register_operand:<DWI>:"",
		1=register_operand:DWIH:"", 2=nonimmediate_operand:DWIH:"",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=<DWI>;
	root.1.2.1.mode:=<DWI>;
	root.1.2.2.mode:=<DWI>;
}
cmd_spec.in
{:
 "TARGET_BMI2 && reload_completed
 && true_regnum (operands[1]) == DX_REG"
:}
instantiates.out parallel_set_mult2_set_truncate2_lshiftrt1_mult1_zero_extend1_zero_extend2
{
	root (
		duplicate 3, duplicate 1, duplicate 2, duplicate 4,
		duplicate 1,duplicate 2, duplicate 5);
	root.1.2.mode:=DWIH;
	root.2.2.mode:=DWIH;
	root.2.2.1.mode:=<DWI>;
	root.2.2.1.1.mode:=<DWI>;
	root.2.2.1.1.1.mode:=<DWI>;
	root.2.2.1.1.2.mode:=<DWI>;
}
cmd_spec.out
{:
{
  split_double_mode (<DWI>mode, &operands[0], 1, &operands[3], &operands[4]);

  operands[5] = GEN_INT (GET_MODE_BITSIZE (<MODE>mode));
}
:}

abstract set_mult2_sign_extend1_sign_extend2 extends set_mult2
{
	root.2.1:=sign_extend;
	root.2.2:=sign_extend;
}

abstract set_mult2_sign_extend1_sign_extend2_clobber extends sequence
{
	root.1:=set_mult2_sign_extend1_sign_extend2;
	root.2:=clobber;
}


concrete *mul<mode><dwi>3_1.insn instantiates set_mult2_sign_extend1_sign_extend2_clobber
{
	root (0=register_operand:<DWI>:"=A",
		1=nonimmediate_operand:DWIH:"%0", 2=nonimmediate_operand:DWIH:"rm",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=<DWI>;
	root.1.2.1.mode:=<DWI>;
	root.1.2.2.mode:=<DWI>;
}
{:
  "!(MEM_P (operands[1]) && MEM_P (operands[2]))"
  "imul{<imodesuffix>}\t%2"
  [(set_attr "type" "imul")
   (set_attr "length_immediate" "0")
   (set (attr "athlon_decode")
     (if_then_else (eq_attr "cpu" "athlon")
        (const_string "vector")
        (const_string "double")))
   (set_attr "amdfam10_decode" "double")
   (set_attr "bdver1_decode" "direct")
   (set_attr "mode" "<MODE>")]
:}

abstract set_mult2_any_extend1_any_extend2_clobber extends set_mult2_sign_extend1_sign_extend2_clobber
{
	root.1.2.1:=any_extend;
	root.1.2.2:=any_extend;
}


concrete *<u>mulqihi3_1.insn instantiates set_mult2_any_extend1_any_extend2_clobber
{
	root (0=register_operand:HI:"=a",
		1=nonimmediate_operand:QI:"%0", 2=nonimmediate_operand:QI:"qm",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=HI;
	root.1.2.1.mode:=HI;
	root.1.2.2.mode:=HI;
}
{:
  "TARGET_QIMODE_MATH
   && !(MEM_P (operands[1]) && MEM_P (operands[2]))"
  "<sgnprefix>mul{b}\t%2"
  [(set_attr "type" "imul")
   (set_attr "length_immediate" "0")
   (set (attr "athlon_decode")
     (if_then_else (eq_attr "cpu" "athlon")
        (const_string "vector")
        (const_string "direct")))
   (set_attr "amdfam10_decode" "direct")
   (set_attr "bdver1_decode" "direct")
   (set_attr "mode" "QI")]
:}

abstract set_truncate2_lshiftrt1_mult1_any_extend1_any_extend2 extends set 
{
	root.2:=truncate;
	root.2.1:=lshiftrt;
	root.2.1.1:=mult;
	root.2.1.1.1:=any_extend;
	root.2.1.1.2:=any_extend;
}

abstract parallel_set_truncate2_lshiftrt1_mult1_any_extend1_any_extend2_clobber_clobber extends parallel
{
	root.1:=set_truncate2_lshiftrt1_mult1_any_extend1_any_extend2;
	root.2:=clobber;
	root.3:=clobber;
}


concrete <s>mul<mode>3_highpart.exp instantiates parallel_set_truncate2_lshiftrt1_mult1_any_extend1_any_extend2_clobber_clobber
{
	root (
		0=register_operand:SWI48:"", 1=nonimmediate_operand:SWI48:"", 
		2=register_operand:SWI48:"",duplicate 4, 3=SWI48:"", reg(CC:FLAGS_REG));
	
	root.1.2.mode:=SWI48;
	root.1.2.1.mode:=<DWI>;
	root.1.2.1.1.mode:=<DWI>;
	root.1.2.1.1.1.mode:=<DWI>;
	root.1.2.1.1.2.mode:=<DWI>;
}
{:
  ""
  "operands[4] = GEN_INT (GET_MODE_BITSIZE (<MODE>mode));"
:}

abstract set_truncate2_lshiftrt1_mult1_any_extend1_any_extend2_clobber_clobber extends sequence
{
    root.1:=set_truncate2_lshiftrt1_mult1_any_extend1_any_extend2;
	root.2:=clobber;
    root.3:=clobber;
}



concrete *<s>muldi3_highpart_1.insn instantiates set_truncate2_lshiftrt1_mult1_any_extend1_any_extend2_clobber_clobber
{
	root (
		0=register_operand:DI:"=d", 1=nonimmediate_operand:DI:"%a",
		2=nonimmediate_operand:DI:"rm",const_int:64,3=DI:"=1", reg(CC:FLAGS_REG));
	
	root.1.2.mode:=DI;
	root.1.2.1.mode:=TI;
	root.1.2.1.1.mode:=TI;
	root.1.2.1.1.1.mode:=TI;
	root.1.2.1.1.2.mode:=TI;
}
{:
  "TARGET_64BIT
   && !(MEM_P (operands[1]) && MEM_P (operands[2]))"
  "<sgnprefix>mul{q}\t%2"
  [(set_attr "type" "imul")
   (set_attr "length_immediate" "0")
   (set (attr "athlon_decode")
     (if_then_else (eq_attr "cpu" "athlon")
        (const_string "vector")
        (const_string "double")))
   (set_attr "amdfam10_decode" "double")
   (set_attr "bdver1_decode" "direct")
   (set_attr "mode" "DI")]
:}

concrete *<s>mulsi3_highpart_1.insn instantiates set_truncate2_lshiftrt1_mult1_any_extend1_any_extend2_clobber_clobber
{
	root (
		0=register_operand:SI:"=d", 1=nonimmediate_operand:SI:"%a",
		2=nonimmediate_operand:SI:"rm",const_int:32, 3=SI:"=1", reg(CC:FLAGS_REG));
	root.1.2.mode:=SI;
	root.1.2.1.mode:=DI;
	root.1.2.1.1.mode:=DI;
	root.1.2.1.1.1.mode:=DI;
	root.1.2.1.1.2.mode:=DI;
}
{:
  "!(MEM_P (operands[1]) && MEM_P (operands[2]))"
  "<sgnprefix>mul{l}\t%2"
  [(set_attr "type" "imul")
   (set_attr "length_immediate" "0")
   (set (attr "athlon_decode")
     (if_then_else (eq_attr "cpu" "athlon")
        (const_string "vector")
        (const_string "double")))
   (set_attr "amdfam10_decode" "double")
   (set_attr "bdver1_decode" "direct")
   (set_attr "mode" "SI")]
:}

abstract set_zero_extend2_truncate1_lshiftrt1_mult1_any_extend1_any_extend2 extends set
{
    root.2:=zero_extend;
    root.2.1:=truncate;
    root.2.1.1:=lshiftrt;
    root.2.1.1.1:=mult;
	root.2.1.1.1.1:=any_extend;
    root.2.1.1.1.2:=any_extend;
}

abstract set_zero_extend2_truncate1_lshiftrt1_mult1_any_extend1_any_extend2_clobber_clobber extends sequence
{
    root.1:=set_zero_extend2_truncate1_lshiftrt1_mult1_any_extend1_any_extend2;
    root.2:=clobber;
    root.3:=clobber;
}



concrete *<s>mulsi3_highpart_zext.insn instantiates set_zero_extend2_truncate1_lshiftrt1_mult1_any_extend1_any_extend2_clobber_clobber
{
	root (
		0=register_operand:DI:"=d", 1=nonimmediate_operand:SI:"%a",
		2=nonimmediate_operand:SI:"rm", const_int:32, 3=SI:"=1",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=SI;
	root.1.2.1.1.mode:=DI;
	root.1.2.1.1.1.mode:=DI;
	root.1.2.1.1.1.1.mode:=DI;
	root.1.2.1.1.1.2.mode:=DI;
}
{:
  "TARGET_64BIT
   && !(MEM_P (operands[1]) && MEM_P (operands[2]))"
  "<sgnprefix>mul{l}\t%2"
  [(set_attr "type" "imul")
   (set_attr "length_immediate" "0")
   (set (attr "athlon_decode")
     (if_then_else (eq_attr "cpu" "athlon")
        (const_string "vector")
        (const_string "double")))
   (set_attr "amdfam10_decode" "double")
   (set_attr "bdver1_decode" "direct")
   (set_attr "mode" "SI")]
:}

{:
;; The patterns that match these are at the end of this file.
:}

concrete mulxf3.exp instantiates set_mult2
{
	root (0=register_operand:XF:"",1=register_operand:XF:"",2=register_operand:XF:"");
	root.2.mode:=XF;
}
{:
  "TARGET_80387"
:}

concrete mul<mode>3.exp overrides mulxf3.exp
{
	root.2.2.predicate:=nonimmediate_operand;
	XF->MODEF;
}
{:
  "(TARGET_80387 && X87_ENABLE_ARITH (<MODE>mode))
    || (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)"
:}

{:

;; Divide instructions

;; The patterns that match these are at the end of this file.
:}

concrete divxf3.exp instantiates set_div2
{
	root (0=register_operand:XF:"",1=register_operand:XF:"",2=register_operand:XF:"");
	root.2.mode:=XF;
}
{:
	"TARGET_80387"
:}

concrete divdf3.exp overrides divxf3.exp
{
	root.2.2.predicate:=nonimmediate_operand;	XF->DF;
}
{:
   "(TARGET_80387 && X87_ENABLE_ARITH (DFmode))
    || (TARGET_SSE2 && TARGET_SSE_MATH)"
:}

concrete divsf3.exp overrides divxf3.exp
{
	root.2.2.predicate:=nonimmediate_operand;	XF->SF;
}
{:
  "(TARGET_80387 && X87_ENABLE_ARITH (SFmode))
    || TARGET_SSE_MATH"
{
  if (TARGET_SSE_MATH
      && TARGET_RECIP_DIV
      && optimize_insn_for_speed_p ()
      && flag_finite_math_only && !flag_trapping_math
      && flag_unsafe_math_optimizations)
    {
      ix86_emit_swdivsf (operands[0], operands[1],
			 operands[2], SFmode);
      DONE;
    }
}
:}
{:

;; Divmod instructions.
:}

abstract parallel_set_div2_set_mod2_clobber extends parallel
{
	root.1:=set_div2;
	root.2:=set_mod2;
	root.3:=clobber;
}

concrete divmod<mode>4.exp instantiates parallel_set_div2_set_mod2_clobber
{
	root (0=register_operand:SWIM248:"", 
		1=register_operand:SWIM248:"",  2=nonimmediate_operand:SWIM248:"",
		3=register_operand:SWIM248:"", duplicate 1, duplicate 2, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWIM248;
	root.2.2.mode:=SWIM248;
}
{:
:}
{:
;; Split with 8bit unsigned divide:
;; 	if (dividend an divisor are in [0-255])
;;	   use 8bit unsigned integer divide
;;	 else
;;	   use original integer divide
:}

abstract set_div2_set_mod2_clobber extends sequence
{
	root.1:=set_div2;
	root.2:=set_mod2;
	root.3:=clobber;
}

concrete .split instantiates.in set_div2_set_mod2_clobber
{
	root (0=register_operand:SWI48:"",2=register_operand:SWI48:"",3=nonimmediate_operand:SWI48:"",1=register_operand:SWI48:"",duplicate 2,duplicate 3, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
	root.2.2.mode:=SWI48;
}
cmd_spec.in
{:
  "TARGET_USE_8BIT_IDIV
   && TARGET_QIMODE_MATH
   && can_create_pseudo_p ()
   && !optimize_insn_for_size_p ()"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
  "ix86_split_idivmod (<MODE>mode, operands, true); DONE;"
:}

abstract set_div2_set_mod2_unspec_clobber extends sequence
{
	root.1:=set_div2;
	root.2:=set_mod2;
	root.3:=unspec;
	root.4:=clobber;
}

abstract parallel_set_ashiftrt2_clobber extends parallel
{
	root.1:=set_ashiftrt2;
	root.2:=clobber;
}

abstract parallel_set_div2_set_mod2_use_clobber extends parallel
{
	root.1:=set_div2;
	root.2:=set_mod2;
	root.3:=use;
	root.4:=clobber;
}

abstract parallel_set_ashiftrt2_clobber_parallel_set_div2_set_mod2_use_clobber extends sequence
{
	root.1:=parallel_set_ashiftrt2_clobber;
	root.2:=parallel_set_div2_set_mod2_use_clobber;
}


concrete divmod<mode>4_1.insn_and_split instantiates.in set_div2_set_mod2_unspec_clobber
{
	root (0=register_operand:SWI48:"=a", 
		2=register_operand:SWI48:"0", 3=nonimmediate_operand:SWI48:"rm",
		1=register_operand:SWI48:"=&d", duplicate 2, duplicate 3,
		(const_int:0, <UNSPEC_DIV_ALREADY_SPLIT>), reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
	root.2.2.mode:=SWI48;
}
cmd_spec.in
{:
  ""
  "#"
  "reload_completed"
:}
instantiates.out parallel_set_ashiftrt2_clobber_parallel_set_div2_set_mod2_use_clobber
{
	root (
		(duplicate 1, duplicate 4, duplicate 5, reg(CC:FLAGS_REG)),
		(duplicate 0, duplicate 2, duplicate 3, duplicate 1, duplicate 2, 
		duplicate 3, duplicate 1, reg(CC:FLAGS_REG)));
	root.1.1.2.mode:=SWI48;
	root.2.1.2.mode:=SWI48;
	root.2.2.2.mode:=SWI48;
}
cmd_spec.out
{:
{
  operands[5] = GEN_INT (GET_MODE_BITSIZE (<MODE>mode)-1);

  if (optimize_function_for_size_p (cfun) || TARGET_USE_CLTD)
    operands[4] = operands[2];
  else
    {
      /* Avoid use of cltd in favor of a mov+shift.  */
      emit_move_insn (operands[1], operands[2]);
      operands[4] = operands[1];
    }
}
  [(set_attr "type" "multi")
   (set_attr "mode" "<MODE>")]
:}

concrete *divmod<mode>4.insn_and_split instantiates.in set_div2_set_mod2_clobber
{
	root (0=register_operand:SWIM248:"=a", 
		2=register_operand:SWIM248:"0", 3=nonimmediate_operand:SWIM248:"rm",
		1=register_operand:SWIM248:"=&d", duplicate 2, duplicate 3,
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWIM248;
	root.2.2.mode:=SWIM248;
}
cmd_spec.in
{:
  ""
  "#"
  "reload_completed"
:}
instantiates.out parallel_set_ashiftrt2_clobber_parallel_set_div2_set_mod2_use_clobber 
{
	root (
		(duplicate 1, duplicate 4, duplicate 5, reg(CC:FLAGS_REG)),
		duplicate 0, duplicate 2, duplicate 3, duplicate 1, duplicate 2,
		duplicate 3, duplicate 1, reg(CC:FLAGS_REG));
	root.1.1.2.mode:=SWIM248;
	root.2.1.2.mode:=SWIM248;
	root.2.2.2.mode:=SWIM248;
}
cmd_spec.out
{:
{
  operands[5] = GEN_INT (GET_MODE_BITSIZE (<MODE>mode)-1);

  if (<MODE>mode != HImode
      && (optimize_function_for_size_p (cfun) || TARGET_USE_CLTD))
    operands[4] = operands[2];
  else
    {
      /* Avoid use of cltd in favor of a mov+shift.  */
      emit_move_insn (operands[1], operands[2]);
      operands[4] = operands[1];
    }
}
  [(set_attr "type" "multi")
   (set_attr "mode" "<MODE>")]
:}


abstract set_div2_set_mod2_use_clobber extends set_div2_set_mod2_clobber
{
	root.3:=use;
	root.4:=clobber;
}

concrete *divmod<mode>4_noext.insn instantiates set_div2_set_mod2_use_clobber
{
	root (0=register_operand:SWIM248:"=a",2=register_operand:SWIM248:"0",3=nonimmediate_operand:SWIM248:"rm",1=register_operand:SWIM248:"=d",duplicate 2,duplicate 3,4=register_operand:SWIM248:"1",reg(CC:FLAGS_REG));
	root.1.2.mode:=SWIM248;
	root.2.2.mode:=SWIM248;
}
{:
  ""
  "idiv{<imodesuffix>}\t%3"
  [(set_attr "type" "idiv")
   (set_attr "mode" "<MODE>")]
:}

{:
(define_expand "divmodqi4"
  [(parallel [(set (match_operand:QI 0 "register_operand" "")
		   (div:QI
		     (match_operand:QI 1 "register_operand" "")
		     (match_operand:QI 2 "nonimmediate_operand" "")))
	      (set (match_operand:QI 3 "register_operand" "")
		   (mod:QI (match_dup 1) (match_dup 2)))
	      (clobber (reg:CC FLAGS_REG))])]
  "TARGET_QIMODE_MATH"
{
  rtx div, mod, insn;
  rtx tmp0, tmp1;
  
  tmp0 = gen_reg_rtx (HImode);
  tmp1 = gen_reg_rtx (HImode);

  /* Extend operands[1] to HImode.  Generate 8bit divide.  Result is
     in AX.  */
  emit_insn (gen_extendqihi2 (tmp1, operands[1]));
  emit_insn (gen_divmodhiqi3 (tmp0, tmp1, operands[2]));

  /* Extract remainder from AH.  */
  tmp1 = gen_rtx_SIGN_EXTRACT (QImode, tmp0, GEN_INT (8), GEN_INT (8));
  insn = emit_move_insn (operands[3], tmp1);

  mod = gen_rtx_MOD (QImode, operands[1], operands[2]);
  set_unique_reg_note (insn, REG_EQUAL, mod);

  /* Extract quotient from AL.  */
  insn = emit_move_insn (operands[0], gen_lowpart (QImode, tmp0));

  div = gen_rtx_DIV (QImode, operands[1], operands[2]);
  set_unique_reg_note (insn, REG_EQUAL, div);

  DONE;
})

;; Divide AX by r/m8, with result stored in
;; AL <- Quotient
;; AH <- Remainder
;; Change div/mod to HImode and extend the second argument to HImode
;; so that mode of div/mod matches with mode of arguments.  Otherwise
;; combine may fail.

:}

abstract set_ior2_ashift1_zero_extend_truncate_mod_sign_extend2_zero_extend2_truncate_div1_sign_extend2 extends set
{
	root.2:=ior;
	root.2.1:=ashift;
	root.2.1.1:=zero_extend;
	root.2.1.1.1:=truncate;
	root.2.1.1.1.1:=mod;
	root.2.1.1.1.1.2:=sign_extend;
	root.2.2:=zero_extend;
	root.2.2.1:=truncate;
	root.2.2.1.1:=div;
	root.2.2.1.1.2:=sign_extend;
}

abstract set_ior2_ashift1_zero_extend_truncate_mod_sign_extend2_zero_extend2_truncate_div1_sign_extend2_clobber extends sequence
{
	root.1:=set_ior2_ashift1_zero_extend_truncate_mod_sign_extend2_zero_extend2_truncate_div1_sign_extend2;
	root.2:=clobber;
}

concrete divmodhiqi3.insn instantiates set_ior2_ashift1_zero_extend_truncate_mod_sign_extend2_zero_extend2_truncate_div1_sign_extend2_clobber
{
	root (0=register_operand:HI:"=a",1=register_operand:HI:"0",2=nonimmediate_operand:QI:"qm",const_int:8,duplicate 1, duplicate 2, reg(CC:FLAGS_REG));
	root.1.2.mode:=HI;
	root.1.2.1.mode:=HI;
	root.1.2.1.1.mode:=HI;
	root.1.2.1.1.1.mode:=QI;
	root.1.2.1.1.1.1.mode:=HI;
	root.1.2.1.1.1.1.2.mode:=HI;
	root.1.2.2.mode:=HI;
	root.1.2.2.1.mode:=QI;
	root.1.2.2.1.1.mode:=HI;
	root.1.2.2.1.1.2.mode:=HI;
}
{:
;; Nepal Flag ^^ :P
  "TARGET_QIMODE_MATH"
  "idiv{b}\t%2"
  [(set_attr "type" "idiv")
   (set_attr "mode" "QI")]
:}

{:
;; TODO Cause: Return as many possible errors from srtl as possible.
:}

abstract parallel_set_udiv2_set_umod2_clobber extends parallel
{
	root.1:=set_udiv2;
	root.2:=set_umod2;
	root.3:=clobber;
}

concrete udivmod<mode>4.exp instantiates parallel_set_udiv2_set_umod2_clobber
{
	root (0=register_operand:SWIM248:"", 
		1=register_operand:SWIM248:"", 2=nonimmediate_operand:SWIM248:"",
		3=register_operand:SWIM248:"", duplicate 1, duplicate 2,
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWIM248;
	root.2.2.mode:=SWIM248;
}
{:
:}

{:
;; Split with 8bit unsigned divide:
;; 	if (dividend an divisor are in [0-255])
;;	   use 8bit unsigned integer divide
;;	 else
;;	   use original integer divide
:}

abstract set_udiv2_set_umod2_clobber extends sequence
{
	root.1:=set;
	root.1.2:=udiv;
	root.2:=set;
	root.2.2:=umod;
	root.3:=clobber;
}

concrete .split instantiates.in set_udiv2_set_umod2_clobber
{
	root (0=register_operand:SWI48:"",2=register_operand:SWI48:"",3=nonimmediate_operand:SWI48:"",1=register_operand:SWI48:"", duplicate 2, duplicate 3, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
	root.2.2.mode:=SWI48;
}
cmd_spec.in
{:
  "TARGET_USE_8BIT_IDIV
   && TARGET_QIMODE_MATH
   && can_create_pseudo_p ()
   && !optimize_insn_for_size_p ()"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
  "ix86_split_idivmod (<MODE>mode, operands, false); DONE;"
:}

abstract set_udiv2_set_umod2_unspec_clobber extends sequence
{
	root.1:=set_udiv2;
	root.2:=set_umod2;
	root.3:=unspec;
	root.4:=clobber;
}

abstract set_parallel_set_udiv2_set_umod2_use_clobber extends sequence
{
	root.1:=set;
	root.2:=parallel;
	root.2.1:=set_udiv2;
	root.2.2:=set_umod2;
	root.2.3:=use;
	root.2.4:=clobber;
}
concrete udivmod<mode>4_1.insn_and_split instantiates.in set_udiv2_set_umod2_unspec_clobber
{
	root (0=register_operand:SWI48:"=a",
		2=register_operand:SWI48:"0", 3=nonimmediate_operand:SWI48:"rm",
		1=register_operand:SWI48:"=&d", duplicate 2, duplicate 3,
		(const_int:0, <UNSPEC_DIV_ALREADY_SPLIT>), reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
	root.2.2.mode:=SWI48;
}
cmd_spec.in
{:
  ""
  "#"
  "reload_completed"
:}
instantiates.out set_parallel_set_udiv2_set_umod2_use_clobber
{
	root (duplicate 1, const_int:0,
		(duplicate 0, duplicate 2, duplicate 3, duplicate 1, duplicate 2,
		duplicate 3, duplicate 1, reg(CC:FLAGS_REG)));
	root.2.1.2.mode:=SWI48;
	root.2.2.2.mode:=SWI48;
}
cmd_spec.out
{:
  ""
  [(set_attr "type" "multi")
   (set_attr "mode" "<MODE>")]
:}

concrete *udivmod<mode>4.insn_and_split instantiates.in set_udiv2_set_umod2_clobber
{
	root (0=register_operand:SWIM248:"=a",
		2=register_operand:SWIM248:"0", 3=nonimmediate_operand:SWIM248:"rm",
		1=register_operand:SWIM248:"=&d", duplicate 2, duplicate 3,
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWIM248;
	root.2.2.mode:=SWIM248;
}
cmd_spec.in
{:
  ""
  "#"
  "reload_completed"
:}
instantiates.out set_parallel_set_udiv2_set_umod2_use_clobber
{
	root (duplicate 1, const_int:0,
        (duplicate 0, duplicate 2, duplicate 3, duplicate 1, duplicate 2,
        duplicate 3, duplicate 1, reg(CC:FLAGS_REG)));
    root.2.1.2.mode:=SWIM248;
    root.2.2.2.mode:=SWIM248;
}
cmd_spec.out
{:
  ""
  [(set_attr "type" "multi")
   (set_attr "mode" "<MODE>")]
:}

abstract set_udiv2_set_umod2_use_clobber extends set_udiv2_set_umod2_clobber
{
	root.3:=use;
	root.4:=clobber;
}

concrete *udivmod<mode>4_noext.insn instantiates set_udiv2_set_umod2_use_clobber
{
	root (0=register_operand:SWIM248:"=a",2=register_operand:SWIM248:"0",3=nonimmediate_operand:SWIM248:"rm",1=register_operand:SWIM248:"=d",duplicate 2,duplicate 3,4=register_operand:SWIM248:"1",reg(CC:FLAGS_REG));
	root.1.2.mode:=SWIM248;
	root.2.2.mode:=SWIM248;
}
{:
  ""
  "div{<imodesuffix>}\t%3"
  [(set_attr "type" "idiv")
   (set_attr "mode" "<MODE>")]
:}

concrete udivmodqi4.exp instantiates parallel_set_udiv2_set_umod2_clobber
{
	root (0=register_operand:QI:"",
		1=register_operand:QI:"", 2=nonimmediate_operand:QI:"",
		3=register_operand:QI:"", duplicate 1, duplicate 2,
		reg(CC:FLAGS_REG));
	root.1.2.mode:=QI;
	root.2.2.mode:=QI;
}
{:
  "TARGET_QIMODE_MATH"
{
  rtx div, mod, insn;
  rtx tmp0, tmp1;
  
  tmp0 = gen_reg_rtx (HImode);
  tmp1 = gen_reg_rtx (HImode);

  /* Extend operands[1] to HImode.  Generate 8bit divide.  Result is
     in AX.  */
  emit_insn (gen_zero_extendqihi2 (tmp1, operands[1]));
  emit_insn (gen_udivmodhiqi3 (tmp0, tmp1, operands[2]));

  /* Extract remainder from AH.  */
  tmp1 = gen_rtx_ZERO_EXTRACT (SImode, tmp0, GEN_INT (8), GEN_INT (8));
  tmp1 = simplify_gen_subreg (QImode, tmp1, SImode, 0);
  insn = emit_move_insn (operands[3], tmp1);

  mod = gen_rtx_UMOD (QImode, operands[1], operands[2]);
  set_unique_reg_note (insn, REG_EQUAL, mod);

  /* Extract quotient from AL.  */
  insn = emit_move_insn (operands[0], gen_lowpart (QImode, tmp0));

  div = gen_rtx_UDIV (QImode, operands[1], operands[2]);
  set_unique_reg_note (insn, REG_EQUAL, div);

  DONE;
}
:}

abstract set_ior2_ashift1_zero_extend1_truncate_mod_zero_extend2_zero_extend2_truncate_div_zero_extend2_clobber  extends set_ior2_ashift1_zero_extend_truncate_mod_sign_extend2_zero_extend2_truncate_div1_sign_extend2_clobber
{
	root.1.2.1.1.1.1.2:=zero_extend;
	root.1.2.2.1.1.2:=zero_extend;
	
}

concrete udivmodhiqi3.insn instantiates set_ior2_ashift1_zero_extend1_truncate_mod_zero_extend2_zero_extend2_truncate_div_zero_extend2_clobber
{
	root (0=register_operand:HI:"=a",1=register_operand:HI:"0",2=nonimmediate_operand:QI:"qm",const_int:8,duplicate 1, duplicate 2,reg(CC:FLAGS_REG));
	root.1.2.mode:=HI;
	root.1.2.1.mode:=HI;
	root.1.2.1.1.mode:=HI;
	root.1.2.1.1.1.mode:=QI;
	root.1.2.1.1.1.1.mode:=HI;
	root.1.2.1.1.1.1.2.mode:=HI;
	root.1.2.2.mode:=HI;
	root.1.2.2.1.mode:=QI;
	root.1.2.2.1.1.mode:=HI;
	root.1.2.2.1.1.2.mode:=HI;
}
{:
  "TARGET_QIMODE_MATH"
  "div{b}\t%2"
  [(set_attr "type" "idiv")
   (set_attr "mode" "QI")]
:}

{:

;; We cannot use div/idiv for double division, because it causes
;; "division by zero" on the overflow and that's not what we expect
;; from truncate.  Because true (non truncating) double division is
;; never generated, we can't create this insn anyway.
;
;(define_insn ""
;  [(set (match_operand:SI 0 "register_operand" "=a")
;	(truncate:SI
;	  (udiv:DI (match_operand:DI 1 "register_operand" "A")
;		   (zero_extend:DI
;		     (match_operand:SI 2 "nonimmediate_operand" "rm")))))
;   (set (match_operand:SI 3 "register_operand" "=d")
;	(truncate:SI
;	  (umod:DI (match_dup 1) (zero_extend:DI (match_dup 2)))))
;   (clobber (reg:CC FLAGS_REG))]
;  ""
;  "div{l}\t{%2, %0|%0, %2}"
;  [(set_attr "type" "idiv")])

;;- Logical AND instructions

;; On Pentium, "test imm, reg" is pairable only with eax, ax, and al.
;; Note that this excludes ah.

:}

concrete testsi_ccno_1.exp instantiates set_compare2_and
{
	root (reg(CCNO:FLAGS_REG),0=nonimmediate_operand:SI:"",1=x86_64_nonmemory_operand:SI:"",const_int:0);
	root.2.mode:=CCNO;
	root.2.1.mode:=SI;
}
{:
:}

concrete testqi_ccz_1.exp instantiates set_compare2_and
{
	root (reg(CCZ:FLAGS_REG),0=nonimmediate_operand:QI:"",1=nonmemory_operand:QI:"",const_int:0);
	root.2.mode:=CCZ;
	root.2.1.mode:=QI;
}
{:
:}

concrete testdi_ccno_1.exp instantiates set_compare2_and
{
	root (reg(CCNO:FLAGS_REG),0=nonimmediate_operand:DI:"",1=x86_64_szext_general_operand:DI:"",const_int:0);
	root.2.mode:=CCNO;
	root.2.1.mode:=DI;
}
{:
  "TARGET_64BIT && !(MEM_P (operands[0]) && MEM_P (operands[1]))"
:}

concrete *testdi_1.insn instantiates set_compare2_and
{
root (reg(NULL:FLAGS_REG),0=nonimmediate_operand:DI:"%!*a,r,!*a,r,rm",1=x86_64_szext_general_operand:DI:"Z,Z,e,e,re",const_int:0);
	root.2.1.mode:=DI;
}
{:
  "TARGET_64BIT && ix86_match_ccmode (insn, CCNOmode)
   && !(MEM_P (operands[0]) && MEM_P (operands[1]))"
  "@
   test{l}\t{%k1, %k0|%k0, %k1}
   test{l}\t{%k1, %k0|%k0, %k1}
   test{q}\t{%1, %0|%0, %1}
   test{q}\t{%1, %0|%0, %1}
   test{q}\t{%1, %0|%0, %1}"
  [(set_attr "type" "test")
   (set_attr "modrm" "0,1,0,1,1")
   (set_attr "mode" "SI,SI,DI,DI,DI")]
:}

concrete *testqi_1_maybe_si.insn instantiates set_compare2_and
{
	root (reg(NULL:FLAGS_REG),0=nonimmediate_operand:QI:"%!*a,q,qm,r",1=general_operand:QI:"n,n,qn,n",const_int:0);
	root.2.1.mode:=QI;
}
{:
	"!(MEM_P (operands[0]) && MEM_P (operands[1]))
    && ix86_match_ccmode (insn,
 			 CONST_INT_P (operands[1])
 			 && INTVAL (operands[1]) >= 0 ? CCNOmode : CCZmode)"
{
  if (which_alternative == 3)
    {
      if (CONST_INT_P (operands[1]) && INTVAL (operands[1]) < 0)
	operands[1] = GEN_INT (INTVAL (operands[1]) & 0xff);
      return "test{l}\t{%1, %k0|%k0, %1}";
    }
  return "test{b}\t{%1, %0|%0, %1}";
}
  [(set_attr "type" "test")
   (set_attr "modrm" "0,1,1,1")
   (set_attr "mode" "QI,QI,QI,SI")
   (set_attr "pent_pair" "uv,np,uv,np")]
:}

concrete *test<mode>_1.insn instantiates set_compare2_and
{
	root (reg(NULL:FLAGS_REG),0=nonimmediate_operand:SWI124:"%!*a,<r>,<r>m",1=<general_operand>:SWI124:"<i>,<i>,<r><i>",const_int:0);
	root.2.1.mode:=SWI124;
}
{:
  "ix86_match_ccmode (insn, CCNOmode)
   && !(MEM_P (operands[0]) && MEM_P (operands[1]))"
  "test{<imodesuffix>}\t{%1, %0|%0, %1}"
  [(set_attr "type" "test")
   (set_attr "modrm" "0,1,1")
   (set_attr "mode" "<MODE>")
   (set_attr "pent_pair" "uv,np,uv")]
:}

abstract set_compare2_and_zero_extract1 extends set_compare2_and
{
	root.2.1.1:=zero_extract;
}

concrete testqi_ext_ccno_0.exp instantiates set_compare2_and_zero_extract1
{
	root (reg(CCNO:FLAGS_REG),0=ext_register_operand:NULL:"",const_int:8,const_int:8,1=const_int_operand:NULL:"",const_int:0);
	root.2.mode:=CCNO;
	root.2.1.mode:=SI;
	root.2.1.1.mode:=SI;
}
{:
:}

concrete *testqi_ext_0.insn instantiates set_compare2_and_zero_extract1
{
	root (reg(NULL:FLAGS_REG),0=ext_register_operand:NULL:"Q",const_int:8,const_int:8,1=const_int_operand:NULL:"n",const_int:0);
	root.2.1.mode:=SI;
	root.2.1.1.mode:=SI;
}
{:
  "ix86_match_ccmode (insn, CCNOmode)"
  "test{b}\t{%1, %h0|%h0, %1}"
  [(set_attr "type" "test")
   (set_attr "mode" "QI")
   (set_attr "length_immediate" "1")
   (set_attr "modrm" "1")
   (set_attr "pent_pair" "np")]
:}

abstract set_compare2_and_zero_extract1_zero_extend2 extends set_compare2_and_zero_extract1
{
	root.2.1.2:=zero_extend;
}

concrete *testqi_ext_1_rex64.insn instantiates set_compare2_and_zero_extract1_zero_extend2
{
	root (reg(NULL:FLAGS_REG),0=ext_register_operand:NULL:"Q",const_int:8,const_int:8,1=register_operand:QI:"Q",const_int:0);
	root.2.1.mode:=SI;
	root.2.1.1.mode:=SI;
	root.2.1.2.mode:=SI;
}
{:
  "TARGET_64BIT && ix86_match_ccmode (insn, CCNOmode)"
  "test{b}\t{%1, %h0|%h0, %1}"
  [(set_attr "type" "test")
   (set_attr "mode" "QI")]
:}

concrete *testqi_ext_1.insn instantiates set_compare2_and_zero_extract1_zero_extend2
{
	root (reg(NULL:FLAGS_REG),0=ext_register_operand:NULL:"Q",const_int:8,const_int:8,1=general_operand:QI:"Qm",const_int:0);
	root.2.1.mode:=SI;
	root.2.1.1.mode:=SI;
	root.2.1.2.mode:=SI;
}
{:
  "!TARGET_64BIT && ix86_match_ccmode (insn, CCNOmode)"
  "test{b}\t{%1, %h0|%h0, %1}"
  [(set_attr "type" "test")
   (set_attr "mode" "QI")]
:}

abstract set_compare2_and_zero_extract1_zero_extract2 extends set_compare2_and_zero_extract1_zero_extend2
{
	root.2.1.2:=zero_extract;
}

concrete *testqi_ext_2.insn instantiates set_compare2_and_zero_extract1_zero_extract2
{
	root (reg(NULL:FLAGS_REG),0=ext_register_operand:NULL:"Q",const_int:8,const_int:8,1=ext_register_operand:NULL:"Q",const_int:8,const_int:8,const_int:0);
	root.2.1.mode:=SI;
	root.2.1.1.mode:=SI;
	root.2.1.2.mode:=SI;
}
{:
  "ix86_match_ccmode (insn, CCNOmode)"
  "test{b}\t{%h1, %h0|%h0, %h1}"
  [(set_attr "type" "test")
   (set_attr "mode" "QI")]
:}


abstract set_compare2_zero_extract1 extends set_compare2
{
	root.2.1:=zero_extract;
}

concrete *testqi_ext_3_rex64.insn instantiates set_compare2_zero_extract1
{
	root (reg(NULL:FLAGS_REG),0=nonimmediate_operand:NULL:"rm",1=const_int_operand:DI:"",2=const_int_operand:DI:"",const_int:0);
	root.2.1.mode:=DI;
}
{:
  "TARGET_64BIT
   && ix86_match_ccmode (insn, CCNOmode)
   && INTVAL (operands[1]) > 0
   && INTVAL (operands[2]) >= 0
   /* Ensure that resulting mask is zero or sign extended operand.  */
   && (INTVAL (operands[1]) + INTVAL (operands[2]) <= 32
       || (INTVAL (operands[1]) + INTVAL (operands[2]) == 64
	   && INTVAL (operands[1]) > 32))
   && (GET_MODE (operands[0]) == SImode
       || GET_MODE (operands[0]) == DImode
       || GET_MODE (operands[0]) == HImode
       || GET_MODE (operands[0]) == QImode)"
  "#"
:}

{:
;; Combine likes to form bit extractions for some tests.  Humor it.
:}

concrete *testqi_ext_3.insn instantiates set_compare2_zero_extract1
{
	root (reg(NULL:FLAGS_REG), 0=nonimmediate_operand:NULL:"rm",1=const_int_operand:SI:"",2=const_int_operand:SI:"",const_int:0);
	root.2.1.mode:=SI;
}
{:
  "ix86_match_ccmode (insn, CCNOmode)
   && INTVAL (operands[1]) > 0
   && INTVAL (operands[2]) >= 0
   && INTVAL (operands[1]) + INTVAL (operands[2]) <= 32
   && (GET_MODE (operands[0]) == SImode
       || (TARGET_64BIT && GET_MODE (operands[0]) == DImode)
       || GET_MODE (operands[0]) == HImode
       || GET_MODE (operands[0]) == QImode)"
  "#"
:}

abstract set_match_operator_zero_extract extends set
{
    root.2:=match_operator;
    root.2.2:=zero_extract;
}

concrete .split
instantiates.in set_match_operator_zero_extract
{
    root (flags_reg_operand:NULL:"",(1=compare_operator,nonimmediate_operand:NULL:"",const_int_operand:NULL:"",const_int_operand:NULL:"",const_int:0));
}
cmd_spec.in
{:
 "ix86_match_ccmode (insn, CCNOmode)"
:}
instantiates.out set_match_op_dup
{
    root (duplicate 0,(<1>,duplicate 2,const_int:0));
}
cmd_spec.out
{:
{
  rtx val = operands[2];
  HOST_WIDE_INT len = INTVAL (operands[3]);
  HOST_WIDE_INT pos = INTVAL (operands[4]);
  HOST_WIDE_INT mask;
  enum machine_mode mode, submode;

  mode = GET_MODE (val);
  if (MEM_P (val))
    {
      /* ??? Combine likes to put non-volatile mem extractions in QImode
	 no matter the size of the test.  So find a mode that works.  */
      if (! MEM_VOLATILE_P (val))
	{
	  mode = smallest_mode_for_size (pos + len, MODE_INT);
	  val = adjust_address (val, mode, 0);
	}
    }
  else if (GET_CODE (val) == SUBREG
	   && (submode = GET_MODE (SUBREG_REG (val)),
	       GET_MODE_BITSIZE (mode) > GET_MODE_BITSIZE (submode))
	   && pos + len <= GET_MODE_BITSIZE (submode)
	   && GET_MODE_CLASS (submode) == MODE_INT)
    {
      /* Narrow a paradoxical subreg to prevent partial register stalls.  */
      mode = submode;
      val = SUBREG_REG (val);
    }
  else if (mode == HImode && pos + len <= 8)
    {
      /* Small HImode tests can be converted to QImode.  */
      mode = QImode;
      val = gen_lowpart (QImode, val);
    }

  if (len == HOST_BITS_PER_WIDE_INT)
    mask = -1;
  else
    mask = ((HOST_WIDE_INT)1 << len) - 1;
  mask <<= pos;

  operands[2] = gen_rtx_AND (mode, val, gen_int_mode (mask, mode));
}
:}
{:
;; Convert HImode/SImode test instructions with immediate to QImode ones.
;; i386 does not allow to encode test with 8bit sign extended immediate, so
;; this is relatively important trick.
;; Do the conversion only post-reload to avoid limiting of the register class
;; to QI regs.
:}

abstract set_match_op_dup2_and1_zero_extract1 extends set_match_op_dup2_and1
{
	root.2.1.1:=zero_extract;
}

concrete .split instantiates.in set_match_operator2_and1
{
	root (0=flags_reg_operand:NULL:"", 
		(1=compare_operator, 2=register_operand:NULL:"",
		3=const_int_operand:NULL:"", const_int:0));
}
cmd_spec.in
{:
   "reload_completed
    && QI_REG_P (operands[2])
    && GET_MODE (operands[2]) != QImode
    && ((ix86_match_ccmode (insn, CCZmode)
    	 && !(INTVAL (operands[3]) & ~(255 << 8)))
	|| (ix86_match_ccmode (insn, CCNOmode)
	    && !(INTVAL (operands[3]) & ~(127 << 8))))"
:}
instantiates.out set_match_op_dup2_and1_zero_extract1
{
	root (duplicate 0, (<1>,
		duplicate 2, const_int:8, const_int:8, duplicate 3, const_int:0));
	root.2.1.mode:=SI;
	root.2.1.1.mode:=SI;
}
cmd_spec.out
{:
{
  operands[2] = gen_lowpart (SImode, operands[2]);
  operands[3] = gen_int_mode (INTVAL (operands[3]) >> 8, SImode);
}
:}

concrete .split instantiates.in set_match_operator2_and1
{
	root (0=flags_reg_operand:NULL:"", (1=compare_operator,
		2=nonimmediate_operand:NULL:"", 3=const_int_operand:NULL:"", const_int:0));
}
cmd_spec.in
{:
   "reload_completed
    && GET_MODE (operands[2]) != QImode
    && (!REG_P (operands[2]) || ANY_QI_REG_P (operands[2]))
    && ((ix86_match_ccmode (insn, CCZmode)
	 && !(INTVAL (operands[3]) & ~255))
	|| (ix86_match_ccmode (insn, CCNOmode)
	    && !(INTVAL (operands[3]) & ~127)))"
:}
instantiates.out set_match_op_dup2_and1
{
	root (duplicate 0, (<1>, duplicate 2, duplicate 3,
		const_int:0));
	root.2.1.mode:=QI;
}
cmd_spec.out
{:
{
  operands[2] = gen_lowpart (QImode, operands[2]);
  operands[3] = gen_lowpart (QImode, operands[3]);
}
:}

{:
;; %%% This used to optimize known byte-wide and operations to memory,
;; and sometimes to QImode registers.  If this is considered useful,
;; it should be done with splitters.
:}

concrete and<mode>3.exp instantiates set_and2
{
	root (0=nonimmediate_operand:SWIM:"",1=nonimmediate_operand:SWIM:"",2=<general_szext_operand>:SWIM:"");
	root.2.mode:=SWIM;
}
{:
  ""
{
  if (<MODE>mode == DImode
      && GET_CODE (operands[2]) == CONST_INT
      && INTVAL (operands[2]) == (HOST_WIDE_INT) 0xffffffff
      && REG_P (operands[1]))
    emit_insn (gen_zero_extendsidi2 (operands[0],
				     gen_lowpart (SImode, operands[1])));
  else
    ix86_expand_binary_operator (AND, <MODE>mode, operands);
  DONE;
}
:}

abstract set_and2_clobber extends sequence
{
	root.1:=set_and2;
	root.2:=clobber;
}

concrete *anddi_1.insn instantiates set_and2_clobber
{
	root (0=nonimmediate_operand:DI:"=r,rm,r,r",1=nonimmediate_operand:DI:"%0,0,0,qm",2=x86_64_szext_general_operand:DI:"Z,re,rm,L",reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
}
{:
  "TARGET_64BIT && ix86_binary_operator_ok (AND, DImode, operands)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_IMOVX:
      {
	enum machine_mode mode;

	gcc_assert (CONST_INT_P (operands[2]));
	if (INTVAL (operands[2]) == (HOST_WIDE_INT) 0xffffffff)
	  mode = SImode;
	else if (INTVAL (operands[2]) == 0xffff)
	  mode = HImode;
	else
	  {
	    gcc_assert (INTVAL (operands[2]) == 0xff);
	    mode = QImode;
	  }

	operands[1] = gen_lowpart (mode, operands[1]);
	if (mode == SImode)
	  return "mov{l}\t{%1, %k0|%k0, %1}";
	else if (mode == HImode)
	  return "movz{wl|x}\t{%1, %k0|%k0, %1}";
	else
	  return "movz{bl|x}\t{%1, %k0|%k0, %1}";
      }

    default:
      gcc_assert (rtx_equal_p (operands[0], operands[1]));
      if (get_attr_mode (insn) == MODE_SI)
	return "and{l}\t{%k2, %k0|%k0, %k2}";
      else
	return "and{q}\t{%2, %0|%0, %2}";
    }
}
  [(set_attr "type" "alu,alu,alu,imovx")
   (set_attr "length_immediate" "*,*,*,0")
   (set (attr "prefix_rex")
     (if_then_else
       (and (eq_attr "type" "imovx")
	    (and (match_test "INTVAL (operands[2]) == 0xff")
		 (match_operand 1 "ext_QIreg_operand" "")))
       (const_string "1")
       (const_string "*")))
   (set_attr "mode" "SI,DI,DI,SI")]
:}

concrete *andsi_1.insn overrides *anddi_1.insn
{
	DI->SI;	allconstraints:=("=rm,r,r","%0,0,qm","re,rm,L");
	root.1.2.2.predicate:=x86_64_general_operand;
}
{:
  "ix86_binary_operator_ok (AND, SImode, operands)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_IMOVX:
      {
	enum machine_mode mode;

	gcc_assert (CONST_INT_P (operands[2]));
        if (INTVAL (operands[2]) == 0xffff)
	  mode = HImode;
	else
	  {
	    gcc_assert (INTVAL (operands[2]) == 0xff);
	    mode = QImode;
	  }

	operands[1] = gen_lowpart (mode, operands[1]);
	if (mode == HImode)
	  return "movz{wl|x}\t{%1, %0|%0, %1}";
	else
	  return "movz{bl|x}\t{%1, %0|%0, %1}";
      }

    default:
      gcc_assert (rtx_equal_p (operands[0], operands[1]));
      return "and{l}\t{%2, %0|%0, %2}";
    }
}
  [(set_attr "type" "alu,alu,imovx")
   (set (attr "prefix_rex")
     (if_then_else
       (and (eq_attr "type" "imovx")
	    (and (match_test "INTVAL (operands[2]) == 0xff")
		 (match_operand 1 "ext_QIreg_operand" "")))
       (const_string "1")
       (const_string "*")))
   (set_attr "length_immediate" "*,*,0")
   (set_attr "mode" "SI")]
:}

{:
;; See comment for addsi_1_zext why we do use nonimmediate_operand
:}

abstract set_zero_extend2_and extends set_zero_extend2
{
	root.2.1:=and;
}

abstract set_zero_extend2_and_clobber extends sequence
{
	root.1:=set_zero_extend2_and;
	root.2:=clobber;
}

concrete *andsi_1_zext.insn instantiates set_zero_extend2_and_clobber
{
	root (0=register_operand:DI:"=r",1=nonimmediate_operand:SI:"%0",2=x86_64_general_operand:SI:"rme",reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;	root.1.2.1.mode:=SI;
}
{:
  "TARGET_64BIT && ix86_binary_operator_ok (AND, SImode, operands)"
  "and{l}\t{%2, %k0|%k0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "SI")]
:}

concrete *andhi_1.insn overrides *anddi_1.insn
{
	allconstraints:=("=rm,r,r", "%0,0,qm", "rn,rm,L");	DI->HI;
	root.1.2.2.predicate:=general_operand;
}
{:
  "ix86_binary_operator_ok (AND, HImode, operands)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_IMOVX:
      gcc_assert (CONST_INT_P (operands[2]));
      gcc_assert (INTVAL (operands[2]) == 0xff);
      return "movz{bl|x}\t{%b1, %k0|%k0, %b1}";

    default:
      gcc_assert (rtx_equal_p (operands[0], operands[1]));

      return "and{w}\t{%2, %0|%0, %2}";
    }
}
  [(set_attr "type" "alu,alu,imovx")
   (set_attr "length_immediate" "*,*,0")
   (set (attr "prefix_rex")
     (if_then_else
       (and (eq_attr "type" "imovx")
	    (match_operand 1 "ext_QIreg_operand" ""))
       (const_string "1")
       (const_string "*")))
   (set_attr "mode" "HI,HI,SI")]
:}
{:
;; %%% Potential partial reg stall on alternative 2.  What to do?
:}

concrete *andqi_1.insn overrides *anddi_1.insn
{
	DI->QI; allconstraints:=("=qm,q,r","%0,0,0","qn,qmn,rn");
	root.1.2.2.predicate:=general_operand;
}	
{:
  "ix86_binary_operator_ok (AND, QImode, operands)"
  "@
   and{b}\t{%2, %0|%0, %2}
   and{b}\t{%2, %0|%0, %2}
   and{l}\t{%k2, %k0|%k0, %k2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "QI,QI,SI")]
:}

abstract set_strict_low_part_and2_clobber extends sequence
{
	root.1:=set_strict_low_part_and2;
	root.2:=clobber;
}

concrete *andqi_1_slp.insn instantiates set_strict_low_part_and2_clobber
{
	root (0=nonimmediate_operand:QI:"+qm,q",duplicate 0, 1=general_operand:QI:"qn,qmn",reg(CC:FLAGS_REG));
	root.1.2.mode:=QI;
}
{:
  "(!TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun))
   && !(MEM_P (operands[0]) && MEM_P (operands[1]))"
  "and{b}\t{%1, %0|%0, %1}"
  [(set_attr "type" "alu1")
   (set_attr "mode" "QI")]
:}

concrete .split instantiates.in set_and2_clobber
{
	root (0=register_operand:NULL:"",duplicate 0,const_int:-65536,reg(CC:FLAGS_REG));
}
cmd_spec.in
{:
  "(TARGET_FAST_PREFIX && !TARGET_PARTIAL_REG_STALL)
    || optimize_function_for_size_p (cfun)"
:}
instantiates.out set_strict_low_part1
{
	root (duplicate 1, const_int:0);
}
cmd_spec.out
{:
	"operands[1] = gen_lowpart (HImode, operands[0]);"
:}

concrete .split instantiates.in set_and2_clobber
{
	root (0=ext_register_operand:NULL:"",duplicate 0, const_int:-256, reg(CC:FLAGS_REG));
}
cmd_spec.in
{:
  "(!TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun))
   && reload_completed"
:}
instantiates.out set_strict_low_part1
{
	root (duplicate 1, const_int:0);
}
cmd_spec.out
{:
  "operands[1] = gen_lowpart (QImode, operands[0]);"
:}



abstract parallel_set_zero_extract_xor_zero_extract_zero_extract_clobber extends parallel
{
    root.1:=set;
    root.1.1:=zero_extract;
    root.1.2:=xor;
    root.1.2.1:=zero_extract;
    root.1.2.2:=zero_extract;
    root.2:=clobber;
}

abstract parallel_set_zero_extract_any_or_zero_extract_clobber extends parallel_set_zero_extract_xor_zero_extract_zero_extract_clobber
{
    root.1.2:=any_or;
    root.1.2.1:=zero_extract;
}

abstract parallel_set_zero_extract_and_zero_extract_clobber extends parallel_set_zero_extract_xor_zero_extract_zero_extract_clobber
{
    root.1.2:=and;
    root.1.2.1:=zero_extract;
}

abstract parallel_set_strict_low_part_and_clobber extends parallel
{
    root.1:=set;
    root.1.1:=strict_low_part;
    root.1.2:=and;
    root.2:=clobber;
}

abstract parallel_set_strict_low_part_any_or_clobber extends parallel_set_strict_low_part_and_clobber
{
    root.1.2:=any_or;
}

concrete .split
instantiates.in set_and2_clobber
{
    root (ext_register_operand:NULL:"",duplicate 0,const_int:-65281,reg(CC:FLAGS_REG));
}
cmd_spec.in
{:
  "(!TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun))
   && reload_completed"
:}
instantiates.out parallel_set_zero_extract_xor_zero_extract_zero_extract_clobber
{
    root (duplicate 0,const_int:8,const_int:8,duplicate 0,const_int:8,const_int:8,duplicate 0,const_int:8,const_int:8,reg(CC:FLAGS_REG));
    root.1.1.mode:=SI;
    root.1.2.mode:=SI;
    root.1.2.1.mode:=SI;
    root.1.2.2.mode:=SI;
}
cmd_spec.out
{:
 "operands[0] = gen_lowpart (SImode, operands[0]);"
:}

abstract set_compare2_and1_set_and2 extends sequence
{
	root.1:=set_compare2_and1;
	root.2:=set_and2;
}

concrete *anddi_2.insn instantiates set_compare2_and1_set_and2
{
	root (reg(NULL:FLAGS_REG),1=nonimmediate_operand:DI:"%0,0,0",2=x86_64_szext_general_operand:DI:"Z,rem,re",const_int:0,0=nonimmediate_operand:DI:"=r,r,rm",duplicate 1, duplicate 2);
	root.1.2.1.mode:=DI;
	root.2.2.mode:=DI;
}
{:
  "TARGET_64BIT && ix86_match_ccmode (insn, CCNOmode)
   && ix86_binary_operator_ok (AND, DImode, operands)"
  "@
   and{l}\t{%k2, %k0|%k0, %k2}
   and{q}\t{%2, %0|%0, %2}
   and{q}\t{%2, %0|%0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "SI,DI,DI")]
:}

abstract set_compare2_set_and2 extends sequence
{
	root.1:=set_compare2;
	root.1.2.1:=and;
	root.2:=set_and2;
}



concrete *andqi_2_maybe_si.insn instantiates set_compare2_and1_set_and2
{
	root (reg(NULL:FLAGS_REG), 1=nonimmediate_operand:QI:"%0,0,0",2=general_operand:QI:"qmn,qn,n",const_int:0,0=nonimmediate_operand:QI:"=q,qm,*r",duplicate 1, duplicate 2);
	root.1.2.1.mode:=QI;
	root.2.2.mode:=QI;
}
{:
  "ix86_binary_operator_ok (AND, QImode, operands)
   && ix86_match_ccmode (insn,
			 CONST_INT_P (operands[2])
			 && INTVAL (operands[2]) >= 0 ? CCNOmode : CCZmode)"
{
  if (which_alternative == 2)
    {
      if (CONST_INT_P (operands[2]) && INTVAL (operands[2]) < 0)
        operands[2] = GEN_INT (INTVAL (operands[2]) & 0xff);
      return "and{l}\t{%2, %k0|%k0, %2}";
    }
  return "and{b}\t{%2, %0|%0, %2}";
}
  [(set_attr "type" "alu")
   (set_attr "mode" "QI,QI,SI")]
:}

abstract set_compare2_and_set_and2 extends set_compare2_set_and2
{
	root.1.2.1:=and;
}

concrete *and<mode>_2.insn instantiates set_compare2_and_set_and2
{
	root (reg(NULL:FLAGS_REG),1=nonimmediate_operand:SWI124:"%0,0",2=<general_operand>:SWI124:"<g>,<r><i>", const_int:0,0=nonimmediate_operand:SWI124:"=<r>,<r>m",duplicate 1,duplicate 2);
	root.1.2.1.mode:=SWI124;
	root.2.2.mode:=SWI124;
}
{:  
  "ix86_match_ccmode (insn, CCNOmode)
   && ix86_binary_operator_ok (AND, <MODE>mode, operands)"
  "and{<imodesuffix>}\t{%2, %0|%0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "<MODE>")]
:}
{:
;; See comment for addsi_1_zext why we do use nonimmediate_operand
:}

abstract set_compare2_and_set_zero_extend2 extends set_compare2_and_set_and2
{
	root.2.2:=zero_extend;
}

abstract set_compare2_and_set_zero_extend2_and extends set_compare2_and_set_zero_extend2
{
	root.2.2.1:=and;
}

concrete *andsi_2_zext.insn instantiates set_compare2_and_set_zero_extend2_and
{
	root (reg(NULL:FLAGS_REG),1=nonimmediate_operand:SI:"%0",2=x86_64_general_operand:SI:"rme",const_int:0,0=register_operand:DI:"=r",duplicate 1,duplicate 2);
	root.1.2.1.mode:=SI;
	root.2.2.mode:=DI;
	root.2.2.1.mode:=SI;
}
{:
  "TARGET_64BIT && ix86_match_ccmode (insn, CCNOmode)
   && ix86_binary_operator_ok (AND, SImode, operands)"
  "and{l}\t{%2, %k0|%k0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "SI")]
:}

abstract set_strict_low_part1_and2 extends set_and2
{
	root.1:=strict_low_part;
}

abstract set_compare2_and_set_strict_low_part1_and2 extends sequence
{
	root.1:=set_compare2_and;
	root.2:=set_strict_low_part1_and2;
}

concrete *andqi_2_slp.insn instantiates set_compare2_and_set_strict_low_part1_and2
{
	root (reg(NULL:FLAGS_REG),0=nonimmediate_operand:QI:"+q,qm",1=nonimmediate_operand:QI:"qmn,qn",const_int:0,duplicate 0,duplicate 0,duplicate 1);
	root.1.2.1.mode:=QI;
	root.2.2.mode:=QI;
}
{:
  "(!TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun))
   && ix86_match_ccmode (insn, CCNOmode)
   && !(MEM_P (operands[0]) && MEM_P (operands[1]))"
  "and{b}\t{%1, %0|%0, %1}"
  [(set_attr "type" "alu1")
   (set_attr "mode" "QI")]
:}

{:
;; ??? A bug in recog prevents it from recognizing a const_int as an
;; operand to zero_extend in andqi_ext_1.  It was checking explicitly
;; for a QImode operand, which of course failed.
:}

abstract set_zero_extract1_and2_zero_extract1 extends set_and2
{
	root.1:=zero_extract;
	root.2.1:=zero_extract;
}

abstract set_zero_extract1_and2_zero_extract1_clobber extends sequence
{
	root.1:=set_zero_extract1_and2_zero_extract1;
	root.2:=clobber;
}

concrete andqi_ext_0.insn instantiates set_zero_extract1_and2_zero_extract1_clobber
{
	root (0=ext_register_operand:NULL:"=Q",const_int:8,const_int:8,1=ext_register_operand:NULL:"0",const_int:8,const_int:8,2=const_int_operand:NULL:"n",reg(CC:FLAGS_REG));
	root.1.1.mode:=SI;
	root.1.2.mode:=SI;
	root.1.2.1.mode:=SI;
}
{:
  ""
  "and{b}\t{%2, %h0|%h0, %2}"
  [(set_attr "type" "alu")
   (set_attr "length_immediate" "1")
   (set_attr "modrm" "1")
    (set_attr "mode" "QI")]
:}

{:
;; Generated by peephole translating test to and.  This shows up
;; often in fp comparisons.
:}

abstract set_compare2_and1_zero_extract1 extends set_compare2_and1
{
	root.2.1.1:=zero_extract;
}

abstract set_zero_extract1_and2_zero_extract1 extends set_zero_extract1_and2
{
	root.2.1:=zero_extract;
}

abstract set_compare2_and1_zero_extract1_set_zero_extract1_and2_zero_extract1 extends sequence
{
	root.1:=set_compare2_and1_zero_extract1;
	root.2:=set_zero_extract1_and2_zero_extract1;
}

concrete *andqi_ext_0_cc.insn instantiates set_compare2_and1_zero_extract1_set_zero_extract1_and2_zero_extract1
{
	root (reg(NULL:FLAGS_REG),1=ext_register_operand:NULL:"0",const_int:8,const_int:8,2=const_int_operand:NULL:"n",const_int:0,0=ext_register_operand:NULL:"=Q",const_int:8,const_int:8,duplicate 1, const_int:8,const_int:8, duplicate 2);
	root.1.2.1.mode:=SI;
	root.1.2.1.1.mode:=SI;
	root.2.1.mode:=SI;
	root.2.2.mode:=SI;
	root.2.2.1.mode:=SI;
}
{:  
  "ix86_match_ccmode (insn, CCNOmode)"
  "and{b}\t{%2, %h0|%h0, %2}"
  [(set_attr "type" "alu")
   (set_attr "length_immediate" "1")
   (set_attr "modrm" "1")
   (set_attr "mode" "QI")]
:}

abstract set_zero_extract1_and2_zero_extract1_zero_extend2 extends set_zero_extract1_and2
{
	root.2.1:=zero_extract;
	root.2.2:=zero_extend;
}

abstract set_zero_extract1_and2_zero_extract1_zero_extend2_clobber extends sequence
{
	root.1:=set_zero_extract1_and2_zero_extract1_zero_extend2;
	root.2:=clobber;
}

concrete *andqi_ext_1_rex64.insn instantiates set_zero_extract1_and2_zero_extract1_zero_extend2_clobber{
	root (0=ext_register_operand:NULL:"=Q",const_int:8,const_int:8,1=ext_register_operand:NULL:"0",const_int:8,const_int:8,2=ext_register_operand:NULL:"Q",reg(CC:FLAGS_REG));
	root.1.1.mode:=SI;
	root.1.2.mode:=SI;
	root.1.2.1.mode:=SI;
	root.1.2.2.mode:=SI;
}
{:
  "TARGET_64BIT"
  "and{b}\t{%2, %h0|%h0, %2}"
  [(set_attr "type" "alu")
   (set_attr "length_immediate" "0")
   (set_attr "mode" "QI")]
:}

concrete *andqi_ext_1.insn instantiates set_zero_extract1_and2_zero_extract1_zero_extend2_clobber
{
	root (0=ext_register_operand:NULL:"=Q",const_int:8,const_int:8,1=ext_register_operand:NULL:"0",const_int:8,const_int:8,2=general_operand:QI:"Qm",reg(CC:FLAGS_REG));
	root.1.1.mode:=SI;
	root.1.2.mode:=SI;
	root.1.2.1.mode:=SI;
	root.1.2.2.mode:=SI;
}
{:
  "!TARGET_64BIT"
  "and{b}\t{%2, %h0|%h0, %2}"
  [(set_attr "type" "alu")
   (set_attr "length_immediate" "0")
   (set_attr "mode" "QI")]
:}

abstract set_zero_extract1_and2_zero_extract1_zero_extract2_clobber extends set_zero_extract1_and2_zero_extract1_zero_extend2_clobber
{
	root.1.2.2:=zero_extract;
}

concrete *andqi_ext_2.insn instantiates set_zero_extract1_and2_zero_extract1_zero_extract2_clobber
{
        root (0=ext_register_operand:NULL:"=Q",const_int:8,const_int:8,1=ext_register_operand:NULL:"%0",const_int:8,const_int:8,2=ext_register_operand:NULL:"Q",const_int:8,const_int:8,reg(CC:FLAGS_REG));
        root.1.1.mode:=SI;
        root.1.2.mode:=SI;
        root.1.2.1.mode:=SI;
        root.1.2.2.mode:=SI;
}
{:
        ""
  "and{b}\t{%h2, %h0|%h0, %h2}"
  [(set_attr "type" "alu")
   (set_attr "length_immediate" "0")
   (set_attr "mode" "QI")]
:}

{:
;; Convert wide AND instructions with immediate operand to shorter QImode
;; equivalents when possible.
;; Don't do the splitting with memory operands, since it introduces risk
;; of memory mismatch stalls.  We may want to do the splitting for optimizing
;; for size, but that can (should?) be handled by generic code instead.
:}

abstract parallel_set_zero_extract1_and2_zero_extract1_clobber extends parallel
{
	root.1:=set_and2_zero_extract;
	root.1.1:=zero_extract;
	root.2:=clobber;
}


concrete .split instantiates.in set_and2_clobber
{
	root (0=register_operand:NULL:"", 1=register_operand:NULL:"",
		2=const_int_operand:NULL:"", reg(CC:FLAGS_REG));
}
cmd_spec.in
{:
   "reload_completed
    && QI_REG_P (operands[0])
    && (!TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun))
    && !(~INTVAL (operands[2]) & ~(255 << 8))
    && GET_MODE (operands[0]) != QImode"
:}
instantiates.out parallel_set_zero_extract1_and2_zero_extract1_clobber
{
	root (duplicate 0,  const_int:8,
		const_int:8, duplicate 1, const_int:8, const_int:8, duplicate 2,
		reg(CC:FLAGS_REG));
	root.1.1.mode:=SI;
	root.1.2.mode:=SI;
	root.1.2.1.mode:=SI;
}
cmd_spec.out
{:
{
  operands[0] = gen_lowpart (SImode, operands[0]);
  operands[1] = gen_lowpart (SImode, operands[1]);
  operands[2] = gen_int_mode ((INTVAL (operands[2]) >> 8) & 0xff, SImode);
}
:}
{:
;; Since AND can be encoded with sign extended immediate, this is only
;; profitable when 7th bit is not set.
:}

abstract parallel_set_strict_low_part1_and2_clobber extends parallel
{
	root.1:=set_strict_low_part1;
	root.1.2:=and;
	root.2:=clobber;
}


concrete .split instantiates.in set_and2_clobber
{
	root (0=register_operand:NULL:"", 1=general_operand:NULL:"",
		2=const_int_operand:NULL:"", reg(CC:FLAGS_REG));
}
cmd_spec.in
{:
   "reload_completed
    && ANY_QI_REG_P (operands[0])
    && (!TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun))
    && !(~INTVAL (operands[2]) & ~255)
    && !(INTVAL (operands[2]) & 128)
    && GET_MODE (operands[0]) != QImode"
:}
instantiates.out parallel_set_strict_low_part1_and2_clobber
{
	root (duplicate 0, duplicate 1, duplicate 2,
		reg(CC:FLAGS_REG));
	root.1.2.mode:=QI;
}
cmd_spec.out
{:
{
  operands[0] = gen_lowpart (QImode, operands[0]);
  operands[1] = gen_lowpart (QImode, operands[1]);
  operands[2] = gen_lowpart (QImode, operands[2]);
}
:}
{:

;; Logical inclusive and exclusive OR instructions

;; %%% This used to optimize known byte-wide and operations to memory.
;; If this is considered useful, it should be done with splitters.
:}

abstract set_any_or2_clobber extends sequence
{
	root.1:=set_any_or2;
	root.2:=clobber;
}

concrete <code><mode>3.exp instantiates set_any_or2
{
	root (0=nonimmediate_operand:SWIM:"", 1=nonimmediate_operand:SWIM:"",
		2=<general_operand>:SWIM:"");
	root.2.mode:=SWIM;
}
{:
  ""
  "ix86_expand_binary_operator (<CODE>, <MODE>mode, operands); DONE;"
:}

concrete *<code><mode>_1.insn instantiates set_any_or2_clobber
{
	root (0=nonimmediate_operand:SWI248:"=r,rm",
		1=nonimmediate_operand:SWI248:"%0,0", 2=<general_operand>:SWI248:"<g>,r<i>",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI248;
}
{:
  "ix86_binary_operator_ok (<CODE>, <MODE>mode, operands)"
  "<logic>{<imodesuffix>}\t{%2, %0|%0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "<MODE>")]
:}

{:
;; %%% Potential partial reg stall on alternative 2.  What to do?
:}

concrete *<code>qi_1.insn instantiates set_any_or2_clobber
{
	root (0=nonimmediate_operand:QI:"=q,m,r",
		1=nonimmediate_operand:QI:"%0,0,0", 2=general_operand:QI:"qmn,qn,rn",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=QI;
}
{:
  "ix86_binary_operator_ok (<CODE>, QImode, operands)"
  "@
   <logic>{b}\t{%2, %0|%0, %2}
   <logic>{b}\t{%2, %0|%0, %2}
   <logic>{l}\t{%k2, %k0|%k0, %k2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "QI,QI,SI")]
:}

{:
;; See comment for addsi_1_zext why we do use nonimmediate_operand
:}

abstract set_zero_extend2_any_or1_clobber extends sequence
{
	root.1:=set_zero_extend2;
	root.1.2.1:=any_or;
	root.2:=clobber;
}


concrete *<code>si_1_zext.insn instantiates set_zero_extend2_any_or1_clobber
{
	root (0=register_operand:DI:"=r", 
		1=nonimmediate_operand:SI:"%0", 2=x86_64_general_operand:SI:"rme",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=SI;
}
{:
  "TARGET_64BIT && ix86_binary_operator_ok (<CODE>, SImode, operands)"
  "<logic>{l}\t{%2, %k0|%k0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "SI")]
:}

abstract set_any_or2_zero_extend1 extends set_any_or2
{
	root.2.1:=zero_extend;
}

abstract set_any_or2_zero_extend1_clobber extends sequence
{
	root.1:=set_any_or2_zero_extend1;
	root.2:=clobber;
}


concrete *<code>si_1_zext_imm.insn instantiates set_any_or2_zero_extend1_clobber
{
	root (0=register_operand:DI:"=r",
		1=register_operand:SI:"%0", 2=x86_64_zext_immediate_operand:DI:"Z",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=DI;
}
{:
  "TARGET_64BIT && ix86_binary_operator_ok (<CODE>, SImode, operands)"
  "<logic>{l}\t{%2, %k0|%k0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "SI")]
:}

abstract set_strict_low_part1_any_or2_clobber extends sequence
{
	root.1:=set_strict_low_part1;
	root.1.2:=any_or;
	root.2:=clobber;
}


concrete *<code>qi_1_slp.insn instantiates set_strict_low_part1_any_or2_clobber
{
	root (0=nonimmediate_operand:QI:"+q,m",
		duplicate 0, 1=general_operand:QI:"qmn,qn", reg(CC:FLAGS_REG));
	root.1.2.mode:=QI;
}
{:
  "(!TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun))
   && !(MEM_P (operands[0]) && MEM_P (operands[1]))"
  "<logic>{b}\t{%1, %0|%0, %1}"
  [(set_attr "type" "alu1")
   (set_attr "mode" "QI")]
:}

abstract set_compare2_any_or1 extends set_compare2
{
	root.2.1:=any_or;
}


abstract set_compare2_any_or1_set_any_or2 extends sequence
{
	root.1:=set_compare2_any_or1;
	root.2:=set_any_or2;
}


concrete *<code><mode>_2.insn instantiates set_compare2_any_or1_set_any_or2
{
	root (reg(NULL:FLAGS_REG),
		1=nonimmediate_operand:SWI:"%0,0", 2=<general_operand>:SWI:"<g>,<r><i>",
		const_int:0,  0=nonimmediate_operand:SWI:"=<r>,<r>m", duplicate 1, duplicate 2);
	root.1.2.1.mode:=SWI;
	root.2.2.mode:=SWI;
}	
{:
  "ix86_match_ccmode (insn, CCNOmode)
   && ix86_binary_operator_ok (<CODE>, <MODE>mode, operands)"
  "<logic>{<imodesuffix>}\t{%2, %0|%0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "<MODE>")]
:}

{:
;; See comment for addsi_1_zext why we do use nonimmediate_operand
;; ??? Special case for immediate operand is missing - it is tricky.
:}

abstract set_compare2_any_or1 extends set_compare2
{
	root.2.1:=any_or;
}

abstract set_zero_extend2_any_or1 extends set_zero_extend2
{
	root.2.1:=any_or;
}

abstract set_compare2_any_or1_set_zero_extend2_any_or1 extends sequence
{
	root.1:=set_compare2_any_or1;
	root.2:=set_zero_extend2_any_or1;
}


concrete *<code>si_2_zext.insn instantiates set_compare2_any_or1_set_zero_extend2_any_or1
{
	root (reg(NULL:FLAGS_REG),
		1=nonimmediate_operand:SI:"%0", 2=x86_64_general_operand:SI:"rme",
		const_int:0, 0=register_operand:DI:"=r", duplicate 1, duplicate 2);
	root.1.2.1.mode:=SI;
	root.2.2.mode:=DI;
	root.2.2.1.mode:=SI;
}
{:
  "TARGET_64BIT && ix86_match_ccmode (insn, CCNOmode)
   && ix86_binary_operator_ok (<CODE>, SImode, operands)"
  "<logic>{l}\t{%2, %k0|%k0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "SI")]
:}

abstract set_compare2_any_or1_set_any_or2_zero_extend1 extends sequence
{
	root.1:=set_compare2_any_or1;
	root.2:=set_any_or2_zero_extend1;
}


concrete *<code>si_2_zext_imm.insn instantiates set_compare2_any_or1_set_any_or2_zero_extend1
{
	root (reg(NULL:FLAGS_REG),
		1=nonimmediate_operand:SI:"%0", 2=x86_64_zext_immediate_operand:SI:"Z",
		const_int:0, 0=register_operand:DI:"=r", duplicate 1, duplicate 2);
	root.1.2.1.mode:=SI;
	root.2.2.mode:=DI;
	root.2.2.1.mode:=DI;
}
{:
  "TARGET_64BIT && ix86_match_ccmode (insn, CCNOmode)
   && ix86_binary_operator_ok (<CODE>, SImode, operands)"
  "<logic>{l}\t{%2, %k0|%k0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "SI")]
:}

abstract set_strict_low_part1_any_or2 extends set_strict_low_part1
{
	root.2:=any_or;
}


abstract set_compare2_any_or1_set_strict_low_part1_any_or2 extends  sequence
{
	root.1:=set_compare2_any_or1;
	root.2:=set_strict_low_part1_any_or2;
}

concrete *<code>qi_2_slp.insn instantiates set_compare2_any_or1_set_strict_low_part1_any_or2
{
	root ( reg(NULL:FLAGS_REG),
		0=nonimmediate_operand:QI:"+q,qm", 1=general_operand:QI:"qmn,qn",
		const_int:0, duplicate 0, duplicate 0, duplicate 1);
	root.1.2.1.mode:=QI;
	root.2.2.mode:=QI;
}
{:
  "(!TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun))
   && ix86_match_ccmode (insn, CCNOmode)
   && !(MEM_P (operands[0]) && MEM_P (operands[1]))"
  "<logic>{b}\t{%1, %0|%0, %1}"
  [(set_attr "type" "alu1")
   (set_attr "mode" "QI")]
:}

abstract set_compare2_any_or1_clobber extends sequence
{
	root.1:=set_compare2_any_or1;
	root.2:=clobber;
}

concrete *<code><mode>_3.insn instantiates set_compare2_any_or1_clobber
{
	root (reg(NULL:FLAGS_REG), 1=nonimmediate_operand:SWI:"%0",
		2=<general_operand>:SWI:"<g>", const_int:0, 0=SWI:"=<r>");
	root.1.2.1.mode:=SWI;
}
{:
  "ix86_match_ccmode (insn, CCNOmode)
   && !(MEM_P (operands[1]) && MEM_P (operands[2]))"
  "<logic>{<imodesuffix>}\t{%2, %0|%0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "<MODE>")]
:}

abstract set_zero_extract1_any_or2_zero_extract1_clobber extends sequence
{
	root.1:=set_zero_extract1;
	root.1.2:=any_or;
	root.1.2.1:=zero_extract;
	root.2:=clobber;
}

concrete *<code>qi_ext_0.insn instantiates set_zero_extract1_any_or2_zero_extract1_clobber
{
	root (0=ext_register_operand:NULL:"=Q",
		const_int:8, const_int:8, 1=ext_register_operand:NULL:"0", const_int:8,
		const_int:8, 2=const_int_operand:NULL:"n", reg(CC:FLAGS_REG));
	root.1.1.mode:=SI;
	root.1.2.mode:=SI;
	root.1.2.1.mode:=SI;
}
{:
  "!TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun)"
  "<logic>{b}\t{%2, %h0|%h0, %2}"
  [(set_attr "type" "alu")
   (set_attr "length_immediate" "1")
   (set_attr "modrm" "1")
   (set_attr "mode" "QI")]
:}
abstract set_zero_extract1_any_or2_zero_extract1_zero_extend2_clobber extends set_zero_extract1_any_or2_zero_extract1_clobber 
{
	root.1.2.2:=zero_extend;
}


concrete *<code>qi_ext_1_rex64.insn instantiates set_zero_extract1_any_or2_zero_extract1_zero_extend2_clobber
{
	root (
		0=ext_register_operand:NULL:"=Q", const_int:8, const_int:8,
		1=ext_register_operand:NULL:"0", const_int:8, const_int:8,
		2=ext_register_operand:NULL:"Q", reg(CC:FLAGS_REG));
	root.1.1.mode:=SI;
	root.1.2.mode:=SI;
	root.1.2.1.mode:=SI;
	root.1.2.2.mode:=SI;
}
{:
  "TARGET_64BIT
   && (!TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun))"
  "<logic>{b}\t{%2, %h0|%h0, %2}"
  [(set_attr "type" "alu")
   (set_attr "length_immediate" "0")
   (set_attr "mode" "QI")]
:}

concrete *<code>qi_ext_1.insn instantiates set_zero_extract1_any_or2_zero_extract1_zero_extend2_clobber
{
	root (
		0=ext_register_operand:NULL:"=Q", const_int:8, const_int:8,
		1=ext_register_operand:NULL:"0", const_int:8, const_int:8,
		2=general_operand:QI:"Qm", reg(CC:FLAGS_REG));
	root.1.1.mode:=SI;
	root.1.2.mode:=SI;
	root.1.2.1.mode:=SI;
	root.1.2.2.mode:=SI;
}
{:
  "!TARGET_64BIT
   && (!TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun))"
  "<logic>{b}\t{%2, %h0|%h0, %2}"
  [(set_attr "type" "alu")
   (set_attr "length_immediate" "0")
   (set_attr "mode" "QI")]
:}

abstract set_zero_extract1_any_or2_zero_extract1_zero_extract2_clobber extends set_zero_extract1_any_or2_zero_extract1_zero_extend2_clobber
{
	root.1.2.2:=zero_extract;
}


concrete *<code>qi_ext_2.insn instantiates set_zero_extract1_any_or2_zero_extract1_zero_extract2_clobber
{
	root (
		0=ext_register_operand:NULL:"=Q", const_int:8, const_int:8,
		1=ext_register_operand:NULL:"0", const_int:8, const_int:8,
		2=ext_register_operand:NULL:"Q", const_int:8, const_int:8,
		reg(CC:FLAGS_REG));
	root.1.1.mode:=SI;
	root.1.2.mode:=SI;
	root.1.2.1.mode:=SI;
	root.1.2.2.mode:=SI;
}
{:
  "!TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun)"
  "<logic>{b}\t{%h2, %h0|%h0, %h2}"
  [(set_attr "type" "alu")
   (set_attr "length_immediate" "0")
   (set_attr "mode" "QI")]
:}

abstract parallel_set_zero_extract1_any_or2_zero_extract1_clobber extends parallel
{
	root.1:=set_zero_extract1;
	root.1.2:=any_or;
	root.1.2.1:=zero_extract;
	root.2:=clobber;
}


concrete .split instantiates.in set_any_or2_clobber 
{
	root (0=register_operand:NULL:"", 1=register_operand:NULL:"",
		2=const_int_operand:NULL:"", reg(CC:FLAGS_REG));
}
cmd_spec.in
{:
   "reload_completed
    && QI_REG_P (operands[0])
    && (!TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun))
    && !(INTVAL (operands[2]) & ~(255 << 8))
    && GET_MODE (operands[0]) != QImode"
:}
instantiates.out parallel_set_zero_extract1_any_or2_zero_extract1_clobber
{
	root (
		duplicate 0, const_int:8, const_int:8, duplicate 1, const_int:8,
		const_int:8, duplicate 2, reg(CC:FLAGS_REG));
	root.1.1.mode:=SI;
	root.1.2.mode:=SI;
	root.1.2.1.mode:=SI;
}
cmd_spec.out
{:
{
  operands[0] = gen_lowpart (SImode, operands[0]);
  operands[1] = gen_lowpart (SImode, operands[1]);
  operands[2] = gen_int_mode ((INTVAL (operands[2]) >> 8) & 0xff, SImode);
}
:}
{:
;; Since OR can be encoded with sign extended immediate, this is only
;; profitable when 7th bit is set.
:}

abstract parallel_set_strict_low_part1_any_or2_clobber extends parallel
{
	root.1:=set_strict_low_part1_any_or2;
	root.2:=clobber;
}


concrete .split instantiates.in set_any_or2_clobber
{
	root (0=register_operand:NULL:"", 1=general_operand:NULL:"",
		2=const_int_operand:NULL:"", reg(CC:FLAGS_REG));
}
cmd_spec.in
{:
   "reload_completed
    && ANY_QI_REG_P (operands[0])
    && (!TARGET_PARTIAL_REG_STALL || optimize_function_for_size_p (cfun))
    && !(INTVAL (operands[2]) & ~255)
    && (INTVAL (operands[2]) & 128)
    && GET_MODE (operands[0]) != QImode"
:}
instantiates.out parallel_set_strict_low_part1_any_or2_clobber
{
	root (duplicate 0, duplicate 1,
		duplicate 2, reg(CC:FLAGS_REG));
	root.1.2.mode:=QI;
}
cmd_spec.out
{:
{
  operands[0] = gen_lowpart (QImode, operands[0]);
  operands[1] = gen_lowpart (QImode, operands[1]);
  operands[2] = gen_lowpart (QImode, operands[2]);
}
:}

abstract set_compare2_xor1_zero_extract1 extends set_compare2
{
	root.2.1:=xor;
	root.2.1.1:=zero_extract;
}

abstract set_zero_extract1_xor2_zero_extract1 extends set
{
	root.1:=zero_extract;
	root.2:=xor;
	root.2.1:=zero_extract;
}

abstract parallel_set_compare2_xor1_zero_extract1_set_zero_extract1_xor2_zero_extract1 extends parallel
{
	root.1:=set_compare2_xor1_zero_extract1;
	root.2:=set_zero_extract1_xor2_zero_extract1;
}

concrete xorqi_cc_ext_1.exp instantiates parallel_set_compare2_xor1_zero_extract1_set_zero_extract1_xor2_zero_extract1
{
	root (
		reg(CCNO:FLAGS_REG), 1=ext_register_operand:NULL:"", const_int:8,const_int:8,
		2=general_operand:QI:"", const_int:0, 0=ext_register_operand:NULL:"",
		const_int:8, const_int:8, duplicate 1, const_int:8, const_int:8,
		duplicate 2);
	root.1.2.mode:=CCNO;
	root.1.2.1.mode:=SI;
	root.1.2.1.1.mode:=SI;
	root.2.1.mode:=SI;
	root.2.2.mode:=SI;
	root.2.2.1.mode:=SI;
}
{:
:}

abstract set_compare2_xor1_zero_extract1 extends set_compare2
{
    root.2.1:=xor;
    root.2.1.1:=zero_extract;
}

abstract set_zero_extract1_xor2_zero_extract1 extends set
{
    root.1:=zero_extract;
    root.2:=xor;
    root.2.1:=zero_extract;
}

abstract set_compare2_xor1_zero_extract1_set_zero_extract1_xor2_zero_extract1 extends sequence
{
    root.1:=set_compare2_xor1_zero_extract1;
    root.2:=set_zero_extract1_xor2_zero_extract1;
}

concrete *xorqi_cc_ext_1_rex64.insn instantiates set_compare2_xor1_zero_extract1_set_zero_extract1_xor2_zero_extract1
{
	root (reg(NULL:FLAGS_REG), 1=ext_register_operand:NULL:"0", const_int:8, const_int:8, 2=nonmemory_operand:QI:"Qn",const_int:0, 0=ext_register_operand:NULL:"=Q",const_int:8, const_int:8, duplicate 1, const_int:8, const_int:8, duplicate 2);
	root.1.2.1.mode:=SI;
	root.1.2.1.1.mode:=SI;
	root.2.1.mode:=SI;
	root.2.2.mode:=SI;
	root.2.2.1.mode:=SI;
}
{:
  "TARGET_64BIT && ix86_match_ccmode (insn, CCNOmode)"
  "xor{b}\t{%2, %h0|%h0, %2}"
  [(set_attr "type" "alu")
   (set_attr "modrm" "1")
   (set_attr "mode" "QI")]
:}

concrete *xorqi_cc_ext_1.insn instantiates set_compare2_xor1_zero_extract1_set_zero_extract1_xor2_zero_extract1
{
	root (reg(NULL:FLAGS_REG), 1=ext_register_operand:NULL:"0",const_int:8, const_int:8, 2=general_operand:QI:"qmn",const_int:0,0=ext_register_operand:NULL:"=q",const_int:8,const_int:8,duplicate 1,const_int:8,const_int:8,duplicate 2);
	root.1.2.1.mode:=SI;
	root.1.2.1.1.mode:=SI;
	root.2.1.mode:=SI;
	root.2.2.mode:=SI;
	root.2.2.1.mode:=SI;
}
{:
  "!TARGET_64BIT && ix86_match_ccmode (insn, CCNOmode)"
  "xor{b}\t{%2, %h0|%h0, %2}"
  [(set_attr "type" "alu")
   (set_attr "modrm" "1")
   (set_attr "mode" "QI")]
:}

{:

;; Negation instructions
:}
concrete neg<mode>2.exp instantiates set_neg2
{
	root (0=nonimmediate_operand:SDWIM:"", 1=nonimmediate_operand:SDWIM:"");
	root.2.mode:=SDWIM;
}
{:

  ""
  "ix86_expand_unary_operator (NEG, <MODE>mode, operands); DONE;"
:}

abstract set_neg2_clobber extends sequence
{
	root.1:=set_neg2;
	root.2:=clobber;
}

abstract parallel_set_compare2_neg1_set extends parallel
{
	root.1:=set_compare2;
	root.1.2.1:=neg;
	root.2:=set;
	root.2.2:=neg;
}

abstract parallel_set_plus2_plus2_ltu1_clobber extends parallel
{
	root.1:=set_plus2;
	root.1.2.2:=plus;
	root.1.2.2.1:=ltu;
	root.2:=clobber;
}

abstract parallel_set_neg2_clobber extends parallel
{
	root.1:=set_neg2;
	root.2:=clobber;
}

abstract parallel_set_compare2_neg1_set_parallel_set_plus2_plus2_ltu1_clobber_parallel_set_neg2_clobber extends sequence
{
	root.1:=parallel_set_compare2_neg1_set;
	root.2:=parallel_set_plus2_plus2_ltu1_clobber;
	root.3:=parallel_set_neg2_clobber;
}

concrete *neg<dwi>2_doubleword.insn_and_split instantiates.in set_neg2_clobber
{
	root (0=nonimmediate_operand:<DWI>:"=ro", 1=nonimmediate_operand:<DWI>:"0",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=<DWI>;
}
cmd_spec.in
{:
	
  "ix86_unary_operator_ok (NEG, <DWI>mode, operands)"
  "#"
  "reload_completed"
:}
instantiates.out parallel_set_compare2_neg1_set_parallel_set_plus2_plus2_ltu1_clobber_parallel_set_neg2_clobber
{
	root (
		(reg(CCZ:FLAGS_REG),duplicate 1, const_int:0,duplicate 0, duplicate 1),
		(duplicate 2, duplicate 3, reg(CC:FLAGS_REG), const_int:0, const_int:0, reg(CC:FLAGS_REG)),
		(duplicate 2, duplicate 2, reg(CC:FLAGS_REG)));
	root.1.1.2.mode:=CCZ;
	root.1.1.2.1.mode:=DWIH;
	root.1.2.2.mode:=DWIH;
	root.2.1.2.mode:=DWIH;
	root.2.1.2.2.mode:=DWIH;
	root.2.1.2.2.1.mode:=DWIH;

	root.3.1.2.mode:=DWIH;
		
}
cmd_spec.out
{:
  "split_double_mode (<DWI>mode, &operands[0], 2, &operands[0], &operands[2]);"
:}

abstract set_neg2_clobber extends sequence
{
	root.1:=set_neg2;
	root.2:=clobber;
}

concrete *neg<mode>2_1.insn instantiates set_neg2_clobber
{
	root (0=nonimmediate_operand:SWI:"=<r>m",1=nonimmediate_operand:SWI:"0",reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI;
}
{:
  "ix86_unary_operator_ok (NEG, <MODE>mode, operands)"
  "neg{<imodesuffix>}\t%0"
  [(set_attr "type" "negnot")
   (set_attr "mode" "<MODE>")]
:}

{:
;; Combine is quite creative about this pattern.
:}

abstract set_lshiftrt2_neg1_ashift1 extends set
{
	root.2:=lshiftrt;
	root.2.1:=neg;
	root.2.1.1:=ashift;
}

abstract set_lshiftrt2_neg1_ashift1_clobber extends sequence
{
	root.1:=set_lshiftrt2_neg1_ashift1;
	root.2:=clobber;
}

concrete *negsi2_1_zext.insn instantiates set_lshiftrt2_neg1_ashift1_clobber
{
	root (0=register_operand:DI:"=r",1=register_operand:DI:"0",const_int:32,const_int:32,reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=DI;
	root.1.2.1.1.mode:=DI;
}
{:
  "TARGET_64BIT && ix86_unary_operator_ok (NEG, SImode, operands)"
  "neg{l}\t%k0"
  [(set_attr "type" "negnot")
   (set_attr "mode" "SI")]
:}

{:
;; The problem with neg is that it does not perform (compare x 0),
;; it really performs (compare 0 x), which leaves us with the zero
;; flag being the only useful item.
:}

abstract set_compare2_neg1_set_neg2 extends sequence
{
	root.1:=set_compare2_neg1;
	root.2:=set_neg2;
}

concrete *neg<mode>2_cmpz.insn instantiates set_compare2_neg1_set_neg2
{
	root (reg(CCZ:FLAGS_REG), 1=nonimmediate_operand:SWI:"0", const_int:0,0=nonimmediate_operand:SWI:"=<r>m",duplicate 1);
	root.1.2.mode:=CCZ;
	root.1.2.1.mode:=SWI;
	root.2.2.mode:=SWI;
}
{:
  "ix86_unary_operator_ok (NEG, <MODE>mode, operands)"
  "neg{<imodesuffix>}\t%0"
  [(set_attr "type" "negnot")
   (set_attr "mode" "<MODE>")]
:}

abstract set_compare2_lshiftrt1_neg1_ashift1 extends set_compare2
{
	root.2.1:=lshiftrt;
	root.2.1.1:=neg;
	root.2.1.1.1:=ashift;
}

abstract set_lshiftrt2_neg1 extends set
{
	root.2:=lshiftrt;
	root.2.1:=neg;
}

abstract set_compare2_lshiftrt1_neg1_ashift1_set_lshiftrt2_neg1_ashift1 extends sequence
{
	root.1:=set_compare2_lshiftrt1_neg1_ashift1;
	root.2:=set_lshiftrt2_neg1;
	root.2.2.1.1:=ashift;
}

concrete *negsi2_cmpz_zext.insn instantiates set_compare2_lshiftrt1_neg1_ashift1_set_lshiftrt2_neg1_ashift1
{
	root (reg(CCZ:FLAGS_REG), 1=register_operand:DI:"0", const_int:32, const_int:32, const_int:0, 0=register_operand:DI:"=r", duplicate 1, const_int:32, const_int:32);
	root.1.2.mode:=CCZ;
	root.1.2.1.mode:=DI;
	root.1.2.1.1.mode:=DI;
	root.1.2.1.1.1.mode:=DI;

	root.2.2.mode:=DI;
	root.2.2.1.mode:=DI;
	root.2.2.1.1.mode:=DI;
}
{:
  "TARGET_64BIT && ix86_unary_operator_ok (NEG, SImode, operands)"
  "neg{l}\t%k0"
  [(set_attr "type" "negnot")
   (set_attr "mode" "SI")]
:}

{:
;; Changing of sign for FP values is doable using integer unit too.
:}


abstract set_absneg extends set
{
        root.2:=absneg;
}

concrete <code><mode>2.exp instantiates set_absneg
{
	root (register_operand:X87MODEF:"",1=register_operand:X87MODEF:"");
        root.2.mode:=X87MODEF;
}
{:
          "TARGET_80387 || (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)"
  "ix86_expand_fp_absneg_operator (<CODE>, <MODE>mode, operands); DONE;"
:}

abstract set_match_operator_use_clobber extends sequence
{
        root.1:=set;
        root.1.2:=match_operator;
        root.2:=use;
        root.3:=clobber;
}

concrete *absneg<mode>2_mixed.insn instantiates set_match_operator_use_clobber
{
        root (0=register_operand:MODEF:"=x,x,f,!r",(3=absneg_operator,1=register_operand:MODEF:"0,x,0,0"),2=nonimmediate_operand:<ssevecmode>:"xm,0,X,X",reg(CC:FLAGS_REG));
        root.1.2.mode:=MODEF;
}
{:
"TARGET_MIX_SSE_I387 && SSE_FLOAT_MODE_P (<MODE>mode)"
  "#"
:}

concrete *absneg<mode>2_sse.insn overrides *absneg<mode>2_mixed.insn
{
        allconstraints:=("=x,x,!r","0,x,0","xm,0,X");
        root.2.1.predicate:=register_operand;
}
{:
"SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH"
  "#"
:}

concrete *absneg<mode>2_i387.insn overrides *absneg<mode>2_mixed.insn
{       
		allconstraints:=("=f,!r","0,0",""); root.2.1.predicate:=NULL;
        root.2.1.mode:=NULL; MODEF->X87MODEF;
}
{:
  "TARGET_80387 && !(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)"
  "#"
:}

concrete <code>tf2.exp overrides <code><mode>2.exp
{
        X87MODEF->TF;
}
{:
        "TARGET_SSE2"
  "ix86_expand_fp_absneg_operator (<CODE>, TFmode, operands); DONE;"

:}

concrete *absnegtf2_sse.insn overrides *absneg<mode>2_mixed.insn
{
        MODEF->TF;
        root.2.1.mode:=TF;
        allconstraints:=("=x,x","0,x","xm,0");
}
{:
"TARGET_SSE2"
  "#"
:}

concrete .split
instantiates.in set_match_operator_use_clobber
{
        root (fp_register_operand:NULL:"",(1=absneg_operator,duplicate 0),NULL:NULL:"",
reg(CC:FLAGS_REG));
}
cmd_spec.in
{:
 "reload_completed"
:}
instantiates.out set_match_op_dup
{
        root (duplicate 0,(<1>,duplicate 0));
}

concrete .split
instantiates.in set_match_operator_use_clobber
{
	root (0=register_operand:NULL:"",(3=absneg_operator,1=register_operand:NULL:""),
2=nonimmediate_operand:NULL:"",reg(CC:FLAGS_REG));
}
cmd_spec.in
{:
 "reload_completed && SSE_REG_P (operands[0])"
:}
instantiates.out set
{
	root (duplicate 0,duplicate 3);
}
cmd_spec.out
{:
{
  enum machine_mode mode = GET_MODE (operands[0]);
  enum machine_mode vmode = GET_MODE (operands[2]);
  rtx tmp;

  operands[0] = simplify_gen_subreg (vmode, operands[0], mode, 0);
  operands[1] = simplify_gen_subreg (vmode, operands[1], mode, 0);
  if (operands_match_p (operands[0], operands[2]))
    {
      tmp = operands[1];
      operands[1] = operands[2];
      operands[2] = tmp;
    }
  if (GET_CODE (operands[3]) == ABS)
    tmp = gen_rtx_AND (vmode, operands[1], operands[2]);
  else
    tmp = gen_rtx_XOR (vmode, operands[1], operands[2]);
  operands[3] = tmp;
}
:}

abstract parallel_set_clobber extends parallel
{
        root.1:=set;
        root.2:=clobber;
}

concrete .split
instantiates.in set_match_operator_use_clobber
{
        root (register_operand:SF:"",(1=absneg_operator,duplicate 0),NULL:V4SF:"",
reg(CC:FLAGS_REG));
        root.1.2.mode:=SF;
}
cmd_spec.in
{:
 "reload_completed"
:}
instantiates.out parallel_set_clobber
{
        root (duplicate 0,duplicate 1,reg(CC:FLAGS_REG));
}
cmd_spec.out
{:
{
  rtx tmp;
  operands[0] = gen_lowpart (SImode, operands[0]);
  if (GET_CODE (operands[1]) == ABS)
    {
      tmp = gen_int_mode (0x7fffffff, SImode);
      tmp = gen_rtx_AND (SImode, operands[0], tmp);
    }
  else
    {
      tmp = gen_int_mode (0x80000000, SImode);
      tmp = gen_rtx_XOR (SImode, operands[0], tmp);
    }
  operands[1] = tmp;
}
:}

concrete .split
instantiates.in set_match_operator_use_clobber
{
        root (register_operand:DF:"",(1=absneg_operator,duplicate 0),NULL:NULL:"",
reg(CC:FLAGS_REG));
        root.1.2.mode:=DF;
}
cmd_spec.in
{:
 "reload_completed"
:}
instantiates.out parallel_set_clobber
{
        root (duplicate 0,duplicate 1,reg(CC:FLAGS_REG));
}
cmd_spec.out
{:
{
  rtx tmp;
  if (TARGET_64BIT)
    {
      tmp = gen_lowpart (DImode, operands[0]);
      tmp = gen_rtx_ZERO_EXTRACT (DImode, tmp, const1_rtx, GEN_INT (63));
      operands[0] = tmp;

      if (GET_CODE (operands[1]) == ABS)
        tmp = const0_rtx;
      else
        tmp = gen_rtx_NOT (DImode, tmp);
    }
  else
    {
      operands[0] = gen_highpart (SImode, operands[0]);
      if (GET_CODE (operands[1]) == ABS)
        {
          tmp = gen_int_mode (0x7fffffff, SImode);
          tmp = gen_rtx_AND (SImode, operands[0], tmp);
        }
      else
        {
          tmp = gen_int_mode (0x80000000, SImode);
          tmp = gen_rtx_XOR (SImode, operands[0], tmp);
        }
    }
  operands[1] = tmp;
}
:}

concrete .split
instantiates.in set_match_operator_use_clobber
{
        root (register_operand:XF:"",(1=absneg_operator,duplicate 0),NULL:NULL:"",
reg(CC:FLAGS_REG));
        root.1.2.mode:=XF;
}
cmd_spec.in
{:
 "reload_completed"
:}
instantiates.out parallel_set_clobber
{
        root (duplicate 0,duplicate 1,reg(CC:FLAGS_REG));
}
cmd_spec.out
{:
{
  rtx tmp;
  operands[0] = gen_rtx_REG (SImode,
                             true_regnum (operands[0])
                             + (TARGET_64BIT ? 1 : 2));
  if (GET_CODE (operands[1]) == ABS)
    {
      tmp = GEN_INT (0x7fff);
      tmp = gen_rtx_AND (SImode, operands[0], tmp);
    }
  else
    {
      tmp = GEN_INT (0x8000);
      tmp = gen_rtx_XOR (SImode, operands[0], tmp);
    }
  operands[1] = tmp;
}
:}
{:
;; Conditionalize these after reload. If they match before reload, we
;; lose the clobber and ability to use integer instructions.
:}

concrete *<code><mode>2_1.insn overrides <code><mode>2.exp
{
        allconstraints:=("=f","0");
}
{:
        "TARGET_80387
   && (reload_completed
       || !(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH))"
  "f<absneg_mnemonic>"
  [(set_attr "type" "fsgn")
   (set_attr "mode" "<MODE>")]
:}

abstract set_absneg_float_extend extends set_absneg
{
        root.2.1:=float_extend;
}

concrete *<code>extendsfdf2.insn instantiates set_absneg_float_extend
{
	root (register_operand:DF:"=f",register_operand:SF:"0");
        root.2.mode:=DF;
        root.2.1.mode:=DF;
}
{:
"TARGET_80387 && (!TARGET_SSE_MATH || TARGET_MIX_SSE_I387)"
  "f<absneg_mnemonic>"
  [(set_attr "type" "fsgn")
   (set_attr "mode" "DF")]
:}

concrete *<code>extendsfxf2.insn overrides *<code>extendsfdf2.insn
{
        DF->XF;
}
{:
"TARGET_80387"
  "f<absneg_mnemonic>"
  [(set_attr "type" "fsgn")
   (set_attr "mode" "XF")]
:}

concrete *<code>extenddfxf2.insn instantiates set_absneg_float_extend
{
    root (register_operand:XF:"=f",register_operand:DF:"0");
    root.2.mode:=XF;
    root.2.1.mode:=XF;
}
{:
        "TARGET_80387"
  "f<absneg_mnemonic>"
  [(set_attr "type" "fsgn")
   (set_attr "mode" "XF")]
:}

{:

;; Copysign instructions

(define_mode_iterator CSGNMODE [SF DF TF])
(define_mode_attr CSGNVMODE [(SF "V4SF") (DF "V2DF") (TF "TF")])
:}

concrete copysign<mode>3.exp instantiates sequence
{
	root (0=register_operand:CSGNMODE:"", 1=nonmemory_operand:CSGNMODE:"",
		2=register_operand:CSGNMODE:"");
}
{:
  "(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
   || (TARGET_SSE2 && (<MODE>mode == TFmode))"
  "ix86_expand_copysign (operands); DONE;"
:}

concrete copysign<mode>3_const.insn_and_split instantiates.in set_unspec2
{
	root (0=register_operand:CSGNMODE:"=x",(1=vector_move_operand:<CSGNVMODE>:"xmC",
		2=register_operand:CSGNMODE:"0",3=nonimmediate_operand:<CSGNVMODE>:"xm",<UNSPEC_COPYSIGN>));
	root.2.mode:=CSGNMODE;
}
cmd_spec.in
{:
  "(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
   || (TARGET_SSE2 && (<MODE>mode == TFmode))"
  "#"
  "&& reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
  "ix86_split_copysign_const (operands); DONE;"
:}

abstract set_unspec2_clobber extends sequence
{
    root.1:=set_unspec2;
    root.2:=clobber;
}

concrete copysign<mode>3_var.insn instantiates set_unspec2_clobber
{
	root (0=register_operand:CSGNMODE:"=x,x,x,x,x", 
		(2=register_operand:CSGNMODE:"x,0,0,x,x", 3=register_operand:CSGNMODE:"1,1,x,1,x",
		4=nonimmediate_operand:<CSGNVMODE>:"X,xm,xm,0,0",
		5=nonimmediate_operand:<CSGNVMODE>:"0,xm,1,xm,1",<UNSPEC_COPYSIGN>),
		1=<CSGNVMODE>:"=x,x,x,x,x");
	root.1.2.mode:=CSGNMODE;
}
{:
  "(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
   || (TARGET_SSE2 && (<MODE>mode == TFmode))"
  "#"
:}

concrete .split instantiates.in set_unspec2_clobber
{
	root (0=register_operand:CSGNMODE:"",
		(2=register_operand:CSGNMODE:"", 
		3=register_operand:CSGNMODE:"",
		4=NULL:<CSGNVMODE>:"",
		5=NULL:<CSGNVMODE>:"",<UNSPEC_COPYSIGN>),
		1=<CSGNVMODE>:"");
	root.1.2.mode:=CSGNMODE;
}
cmd_spec.in
{:
  "((SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
    || (TARGET_SSE2 && (<MODE>mode == TFmode)))
   && reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
  "ix86_split_copysign_var (operands); DONE;"
:}

{:

;; One complement instructions
:}

concrete one_cmpl<mode>2.exp instantiates set_not2
{
	root (nonimmediate_operand:SWIM:"",nonimmediate_operand:SWIM:"");
        root.2.mode:=SWIM;
}
{:
""
  "ix86_expand_unary_operator (NOT, <MODE>mode, operands); DONE;"
:}

concrete *one_cmpl<mode>2_1.insn overrides one_cmpl<mode>2.exp
{
        SWIM->SWI248;
        allconstraints:=("=rm","0");
}
{:
"ix86_unary_operator_ok (NOT, <MODE>mode, operands)"
  "not{<imodesuffix>}\t%0"
  [(set_attr "type" "negnot")
   (set_attr "mode" "<MODE>")]
:}

concrete *one_cmplqi2_1.insn overrides one_cmpl<mode>2.exp
{
        SWIM->QI;
        allconstraints:=("=qm,r","0,0");
}
{:
"ix86_unary_operator_ok (NOT, QImode, operands)"
  "@
   not{b}\t%0
   not{l}\t%k0"
  [(set_attr "type" "negnot")
   (set_attr "mode" "QI,SI")]
:}

concrete *one_cmplsi2_1_zext.insn instantiates  set_zero_extend_not
{
	root (register_operand:DI:"=r",register_operand:SI:"0");
        root.2.mode:=DI;
        root.2.1.mode:=SI;
}
{:
"TARGET_64BIT && ix86_unary_operator_ok (NOT, SImode, operands)"
  "not{l}\t%k0"
  [(set_attr "type" "negnot")
   (set_attr "mode" "SI")]
:}

abstract set_compare_not_set_not2 extends sequence
{
        root.1:=set_compare_not;
        root.2:=set_not2;
}

concrete *one_cmpl<mode>2_2.insn instantiates set_compare_not_set_not2
{
	root (reg (NULL:FLAGS_REG),1=nonimmediate_operand:SWI:"0",const_int:0,0=nonimmediate_operand:SWI:"=<r>m",duplicate 1);
        root.1.2.1.mode:=SWI;
        root.2.2.mode:=SWI;
}
{:
"ix86_match_ccmode (insn, CCNOmode)
   && ix86_unary_operator_ok (NOT, <MODE>mode, operands)"
  "#"
  [(set_attr "type" "alu1")
   (set_attr "mode" "<MODE>")]
:}


abstract set_match_operator_not_set_not2 extends sequence
{
        root.1:=set;
        root.1.2:=match_operator;
        root.1.2.2:=not;
        root.2:=set;
        root.2.2:=not;
}


abstract parallel_set_match_op_dup_xor_set_xor extends parallel
{
        root.1:=set_match_op_dup;
        root.1.2.1:=xor;
        root.2:=set;
        root.2.2:=xor;
}

DDDD

concrete .split
instantiates.in set_match_operator_not_set_not2
{
        root (0=flags_reg_operand:NULL:"",(2=compare_operator,3=nonimmediate_operand:SWI:"",const_int:0),1=nonimmediate_operand:SWI:"",duplicate 3);
        root.1.2.2.mode:=SWI;
        root.2.2.mode:=SWI;
}
cmd_spec.in
{:
 "ix86_match_ccmode (insn, CCNOmode)"
:}
instantiates.out parallel_set_match_op_dup_xor_set_xor
{
        root (duplicate 0,(<2>,duplicate 3,const_int:-1,const_int:0),duplicate 1,duplicate 3,const_int:-1);
        root.1.2.1.mode:=SWI;
        root.2.2.mode:=SWI;
}


abstract set_compare_not_set_zero_extend_not extends sequence
{
        root.1:=set_compare_not;
        root.2:=set_zero_extend_not;
}

concrete *one_cmplsi2_2_zext.insn instantiates set_compare_not_set_zero_extend_not
{
	root (reg(NULL:FLAGS_REG),1=register_operand:SI:"0",const_int:0,0=register_operand:DI:"=r",duplicate 1);
        root.1.2.1.mode:=SI;
        root.2.2.mode:=DI;
        root.2.2.1.mode:=SI;
}
{:
"TARGET_64BIT && ix86_match_ccmode (insn, CCNOmode)
   && ix86_unary_operator_ok (NOT, SImode, operands)"
  "#"
  [(set_attr "type" "alu1")
   (set_attr "mode" "SI")]
:}


abstract parallel_set_match_op_dup_xor_set_zero_extend_xor extends parallel
{
        root.1:=set_match_op_dup;
        root.1.2.1:=xor;
        root.2:=set;
        root.2.2:=zero_extend;
        root.2.2.1:=xor;
}



abstract set_match_operator_not_set_zero_extend_not extends  set_match_operator_not_set_not2
{
        root.2:=set_zero_extend2;
        root.2.2.1:=not;
}

concrete .split instantiates.in set_match_operator_not_set_zero_extend_not
{
        root (0=flags_reg_operand:NULL:"",(2=compare_operator,3=register_operand:SI:"",const_int:0),1=register_operand:DI:"",duplicate 3);
root.1.2.2.mode:=SI;
root.2.2.mode:=DI;
root.2.2.1.mode:=SI;
}
cmd_spec.in
{:
  "ix86_match_ccmode (insn, CCNOmode)"
:}
instantiates.out parallel_set_match_op_dup_xor_set_zero_extend_xor
{
        root (duplicate 0,(<2>,duplicate 3,const_int:-1,const_int:0),duplicate 1,duplicate 3,const_int:-1);
root.1.2.1.mode:=SI;
root.2.2.mode:=DI;
root.2.2.1.mode:=SI;
}

{:

;; Shift instructions

;; DImode shifts are implemented using the i386 "shift double" opcode,
;; which is written as "sh[lr]d[lw] imm,reg,reg/mem".  If the shift count
;; is variable, then the count is in %cl and the "imm" operand is dropped
;; from the assembler input.
;;
;; This instruction shifts the target reg/mem as usual, but instead of
;; shifting in zeros, bits are shifted in from reg operand.  If the insn
;; is a left shift double, bits are taken from the high order bits of
;; reg, else if the insn is a shift right double, bits are taken from the
;; low order bits of reg.  So if %eax is "1234" and %edx is "5678",
;; "shldl $8,%edx,%eax" leaves %edx unchanged and sets %eax to "2345".
;;
;; Since sh[lr]d does not change the `reg' operand, that is done
;; separately, making all shifts emit pairs of shift double and normal
;; shift.  Since sh[lr]d does not shift more than 31 bits, and we wish to
;; support a 63 bit shift, each shift where the count is in a reg expands
;; to a pair of shifts, a branch, a shift by 32 and a label.
;;
;; If the shift count is a constant, we need never emit more than one
;; shift pair, instead using moves and sign extension for counts greater
;; than 31.
:}
concrete ashl<mode>3.exp instantiates set_ashift2
{
	root (0=<shift_operand>:SDWIM:"", 1=<ashl_input_operand>:SDWIM:"",
		2=nonmemory_operand:QI:"");
	root.2.mode:=SDWIM;
}
{:
  ""
  "ix86_expand_binary_operator (ASHIFT, <MODE>mode, operands); DONE;"
:}

abstract set_ashift2_clobber extends sequence
{
	root.1:=set_ashift2;
	root.2:=clobber;
}


concrete *ashl<mode>3_doubleword.insn instantiates set_ashift2_clobber
{
	root (0=register_operand:DWI:"=&r,r", 1=reg_or_pm1_operand:DWI:"n,0",
		2=nonmemory_operand:QI:"<S>c,<S>c", reg(CC:FLAGS_REG));
	root.1.2.mode:=DWI;
}
{:
  ""
  "#"
  [(set_attr "type" "multi")]
:}

concrete .split instantiates.in set_ashift2_clobber
{
	root (0=register_operand:DWI:"", 1=nonmemory_operand:DWI:"",
		2=nonmemory_operand:QI:"", reg(CC:FLAGS_REG));
	root.1.2.mode:=DWI;	
}
cmd_spec.in
{:
  "(optimize && flag_peephole2) ? epilogue_completed : reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
  "ix86_split_ashl (operands, NULL_RTX, <MODE>mode); DONE;"
:}

{:
;; By default we don't ask for a scratch register, because when DWImode
;; values are manipulated, registers are already at a premium.  But if
;; we have one handy, we won't turn it away.
:}

abstract parallel_set_ashift2_clobber extends parallel
{
	root.1:=set_ashift2;
	root.2:=clobber;
}

abstract sequence_parallel_set_ashift2_clobber_sequence extends sequence
{
	root.1:=sequence;
	root.2:=parallel_set_ashift2_clobber;
	root.3:=sequence;
}

{:
(define_peephole2
  [(match_scratch:DWIH 3 "r")
   (parallel [(set (match_operand:<DWI> 0 "register_operand" "")
           (ashift:<DWI>
             (match_operand:<DWI> 1 "nonmemory_operand" "")
             (match_operand:QI 2 "nonmemory_operand" "")))
          (clobber (reg:CC FLAGS_REG))])
   (match_dup 3)]
  "TARGET_CMOVE"
  [(const_int 0)]
  "ix86_split_ashl (operands, operands[3], <DWI>mode); DONE;")
:}

abstract set_ior2_match_ashift1_lshiftrt2_minus2 extends set
{
	root.2:=ior;
	root.2.1:=ashift;
	root.2.2:=lshiftrt;
	root.2.2.2:=minus;
}

abstract set_ior2_ashift1_lshiftrt2_minus2_clobber extends sequence
{
	root.1:=set_ior2_match_ashift1_lshiftrt2_minus2;
	root.2:=clobber;
}

concrete x86_64_shld.insn instantiates set_ior2_ashift1_lshiftrt2_minus2_clobber
{
	root (0=nonimmediate_operand:DI:"+r*m",
		duplicate 0, 2=nonmemory_operand:QI:"Jc", 1=register_operand:DI:"r",
		const_int:64, duplicate 2, reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=DI;
	root.1.2.2.mode:=DI;
	root.1.2.2.2.mode:=QI;
}
{:
  "TARGET_64BIT"
  "shld{q}\t{%s2%1, %0|%0, %1, %2}"
  [(set_attr "type" "ishift")
   (set_attr "prefix_0f" "1")
   (set_attr "mode" "DI")
   (set_attr "athlon_decode" "vector")
   (set_attr "amdfam10_decode" "vector")
   (set_attr "bdver1_decode" "vector")]
:}

concrete x86_shld.insn instantiates set_ior2_ashift1_lshiftrt2_minus2_clobber
{
	root (0=nonimmediate_operand:SI:"+r*m",
		duplicate 0, 2=nonmemory_operand:QI:"Ic", 1=register_operand:SI:"r",
		const_int:32, duplicate 2, reg(CC:FLAGS_REG));
	root.1.2.mode:=SI;
	root.1.2.1.mode:=SI;
	root.1.2.2.mode:=SI;
	root.1.2.2.2.mode:=QI;
}
{:
 ""
  "shld{l}\t{%s2%1, %0|%0, %1, %2}"
  [(set_attr "type" "ishift")
   (set_attr "prefix_0f" "1")
   (set_attr "mode" "SI")
   (set_attr "pent_pair" "np")
   (set_attr "athlon_decode" "vector")
   (set_attr "amdfam10_decode" "vector")
   (set_attr "bdver1_decode" "vector")]
:}

abstract set_compare2_and1_set_if_then_else2_ne1_set_if_then_else2_ne1 extends sequence
{
	root.1:=set_compare2_and1;
	root.2:=set_if_then_else2_ne1;
	root.3:=set_if_then_else2_ne1;
}

concrete x86_shift<mode>_adj_1.exp instantiates set_compare2_and1_set_if_then_else2_ne1_set_if_then_else2_ne1
{
	root (
		reg(CCZ:FLAGS_REG), 2=register_operand:QI:"", duplicate 4, const_int:0,
		0=register_operand:SWI48:"", reg(CCZ:FLAGS_REG), const_int:0,
		1=register_operand:SWI48:"", duplicate 0, duplicate 1,
		reg(CCZ:FLAGS_REG), const_int:0, 3=register_operand:SWI48:"",
		duplicate 1);
	root.1.2.mode:=CCZ;
	root.1.2.1.mode:=QI;
	root.2.2.mode:=SWI48;
	root.3.2.mode:=SWI48;
}
{:
  "TARGET_CMOVE"
  "operands[4] = GEN_INT (GET_MODE_BITSIZE (<MODE>mode));"
:}

abstract use_x3 extends sequence
{
	root.1:=use;
	root.2:=use;
	root.3:=use;
}


concrete x86_shift<mode>_adj_2.exp instantiates use_x3
{
	root (0=register_operand:SWI48:"", 1=register_operand:SWI48:"",
		2=register_operand:QI:"");
}
{:
  ""
{
  rtx label = gen_label_rtx ();
  rtx tmp;

  emit_insn (gen_testqi_ccz_1 (operands[2],
			       GEN_INT (GET_MODE_BITSIZE (<MODE>mode))));

  tmp = gen_rtx_REG (CCZmode, FLAGS_REG);
  tmp = gen_rtx_EQ (VOIDmode, tmp, const0_rtx);
  tmp = gen_rtx_IF_THEN_ELSE (VOIDmode, tmp,
			      gen_rtx_LABEL_REF (VOIDmode, label),
			      pc_rtx);
  tmp = emit_jump_insn (gen_rtx_SET (VOIDmode, pc_rtx, tmp));
  JUMP_LABEL (tmp) = label;

  emit_move_insn (operands[0], operands[1]);
  ix86_expand_clear (operands[1]);

  emit_label (label);
  LABEL_NUSES (label) = 1;

  DONE;
}
:}

{:
;; Avoid useless masking of count operand.
:}

abstract set_ashift2_subreg2_and1_clobber extends sequence
{
	root.1:=set_ashift2;
	root.1.2.2:=subreg;
	root.1.2.2.1:=and;
	root.2:=clobber;
}

abstract parallel_set_ashift2_clobber extends parallel
{
	root.1:=set_ashift2;
	root.2:=clobber;
}


concrete *ashl<mode>3_mask.insn_and_split instantiates.in set_ashift2_subreg2_and1_clobber
{
	root (0=nonimmediate_operand:SWI48:"=rm",
		1=nonimmediate_operand:SWI48:"0",2=nonimmediate_operand:SI:"c",
		3=const_int_operand:SI:"n", <0>, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
	root.1.2.2.mode:=QI;
	root.1.2.2.1.mode:=SI;
}
cmd_spec.in
{:  
  "ix86_binary_operator_ok (ASHIFT, <MODE>mode, operands)
   && (INTVAL (operands[3]) & (GET_MODE_BITSIZE (<MODE>mode)-1))
      == GET_MODE_BITSIZE (<MODE>mode)-1"
  "#"
  "&& 1"
:}
instantiates.out parallel_set_ashift2_clobber
{
	root (duplicate 0, duplicate 1,
		duplicate 2, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
}
cmd_spec.out
{:
{
  if (can_create_pseudo_p ())
    operands [2] = force_reg (SImode, operands[2]);

  operands[2] = simplify_gen_subreg (QImode, operands[2], SImode, 0);
}
  [(set_attr "type" "ishift")
   (set_attr "mode" "<MODE>")]
:}

concrete *bmi2_ashl<mode>3_1.insn instantiates set_ashift2
{
	root (0=register_operand:SWI48:"=r", 1=nonimmediate_operand:SWI48:"rm",
		2=register_operand:SWI48:"r");
	root.2.mode:=SWI48;
}
{:
  "TARGET_BMI2"
  "shlx\t{%2, %1, %0|%0, %1, %2}"
  [(set_attr "type" "ishiftx")
   (set_attr "mode" "<MODE>")]
:}

concrete *ashl<mode>3_1.insn instantiates set_ashift2_clobber
{
	root (0=nonimmediate_operand:SWI48:"=rm,r,r",
		1=nonimmediate_operand:SWI48:"0,l,rm", 2=nonmemory_operand:QI:"c<S>,M,r",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
}
{:
  "ix86_binary_operator_ok (ASHIFT, <MODE>mode, operands)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_LEA:
    case TYPE_ISHIFTX:
      return "#";

    case TYPE_ALU:
      gcc_assert (operands[2] == const1_rtx);
      gcc_assert (rtx_equal_p (operands[0], operands[1]));
      return "add{<imodesuffix>}\t%0, %0";

    default:
      if (operands[2] == const1_rtx
	  && (TARGET_SHIFT1 || optimize_function_for_size_p (cfun)))
	return "sal{<imodesuffix>}\t%0";
      else
	return "sal{<imodesuffix>}\t{%2, %0|%0, %2}";
    }
}
  [(set_attr "isa" "*,*,bmi2")
   (set (attr "type")
     (cond [(eq_attr "alternative" "1")
	      (const_string "lea")
	    (eq_attr "alternative" "2")
	      (const_string "ishiftx")
            (and (and (match_test "TARGET_DOUBLE_WITH_ADD")
		      (match_operand 0 "register_operand" ""))
		 (match_operand 2 "const1_operand" ""))
	      (const_string "alu")
	   ]
	   (const_string "ishift")))
   (set (attr "length_immediate")
     (if_then_else
       (ior (eq_attr "type" "alu")
	    (and (eq_attr "type" "ishift")
		 (and (match_operand 2 "const1_operand" "")
		      (ior (match_test "TARGET_SHIFT1")
			   (match_test "optimize_function_for_size_p (cfun)")))))
       (const_string "0")
       (const_string "*")))
   (set_attr "mode" "<MODE>")]
:}

{:
;; Convert shift to the shiftx pattern to avoid flags dependency.
:}

concrete .split instantiates.in set_ashift2_clobber
{
	root (0=register_operand:SWI48:"", 1=nonimmediate_operand:SWI48:"",
		2=register_operand:QI:"", reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
}
cmd_spec.in
{:
  "TARGET_BMI2 && reload_completed"
:}
instantiates.out set_ashift2
{
	root (duplicate 0, duplicate 1, duplicate 2);
	root.2.mode:=SWI48;
}
cmd_spec.out
{:
  "operands[2] = gen_lowpart (<MODE>mode, operands[2]);"
:}

concrete *bmi2_ashlsi3_1_zext.insn instantiates set_zero_extend2_ashift1
{
	root (0=register_operand:DI:"=r",
		1=nonimmediate_operand:SI:"rm", 2=register_operand:SI:"r");
	root.2.mode:=DI;
	root.2.1.mode:=SI;
}
{:
  "TARGET_64BIT && TARGET_BMI2"
  "shlx\t{%2, %1, %k0|%k0, %1, %2}"
  [(set_attr "type" "ishiftx")
   (set_attr "mode" "SI")]
:}

abstract set_zero_extend2_ashift1_clobber extends sequence
{
	root.1:=set_zero_extend2_ashift1;
	root.2:=clobber;
}

concrete *ashlsi3_1_zext.insn instantiates set_zero_extend2_ashift1_clobber
{
	root (0=register_operand:DI:"=r,r,r", 
		1=nonimmediate_operand:SI:"0,l,rm", 2=nonmemory_operand:QI:"cI,M,r",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=SI;
}
{:
  "TARGET_64BIT && ix86_binary_operator_ok (ASHIFT, SImode, operands)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_LEA:
    case TYPE_ISHIFTX:
      return "#";

    case TYPE_ALU:
      gcc_assert (operands[2] == const1_rtx);
      return "add{l}\t%k0, %k0";

    default:
      if (operands[2] == const1_rtx
	  && (TARGET_SHIFT1 || optimize_function_for_size_p (cfun)))
	return "sal{l}\t%k0";
      else
	return "sal{l}\t{%2, %k0|%k0, %2}";
    }
}
  [(set_attr "isa" "*,*,bmi2")
   (set (attr "type")
     (cond [(eq_attr "alternative" "1")
	      (const_string "lea")
	    (eq_attr "alternative" "2")
	      (const_string "ishiftx")
            (and (match_test "TARGET_DOUBLE_WITH_ADD")
		 (match_operand 2 "const1_operand" ""))
	      (const_string "alu")
	   ]
	   (const_string "ishift")))
   (set (attr "length_immediate")
     (if_then_else
       (ior (eq_attr "type" "alu")
	    (and (eq_attr "type" "ishift")
		 (and (match_operand 2 "const1_operand" "")
		      (ior (match_test "TARGET_SHIFT1")
			   (match_test "optimize_function_for_size_p (cfun)")))))
       (const_string "0")
       (const_string "*")))
   (set_attr "mode" "SI")]
:}
{:
;; Convert shift to the shiftx pattern to avoid flags dependency.
:}

abstract set_zero_extend2_ashift1_clobber extends sequence
{
	root.1:=set_zero_extend2_ashift1;
	root.2:=clobber;
}

concrete .split instantiates.in set_zero_extend2_ashift1_clobber
{
	root (0=register_operand:DI:"",
		1=nonimmediate_operand:SI:"", 2=register_operand:QI:"",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=SI;
}
cmd_spec.in
{:
  "TARGET_64BIT && TARGET_BMI2 && reload_completed"
:}
instantiates.out set_zero_extend2_ashift1
{
	root (duplicate 0, duplicate 1, duplicate 2);
	root.2.mode:=DI;
	root.2.1.mode:=SI;
}
cmd_spec.out
{:
  "operands[2] = gen_lowpart (SImode, operands[2]);"
:}

concrete *ashlhi3_1.insn instantiates set_ashift2_clobber
{
	root (0=nonimmediate_operand:HI:"=rm,Yp",
		1=nonimmediate_operand:HI:"0,l", 2=nonmemory_operand:QI:"cI,M",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=HI;
}
{:
  "ix86_binary_operator_ok (ASHIFT, HImode, operands)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_LEA:
      return "#";

    case TYPE_ALU:
      gcc_assert (operands[2] == const1_rtx);
      return "add{w}\t%0, %0";

    default:
      if (operands[2] == const1_rtx
	  && (TARGET_SHIFT1 || optimize_function_for_size_p (cfun)))
	return "sal{w}\t%0";
      else
	return "sal{w}\t{%2, %0|%0, %2}";
    }
}
  [(set (attr "type")
     (cond [(eq_attr "alternative" "1")
	      (const_string "lea")
            (and (and (match_test "TARGET_DOUBLE_WITH_ADD")
		      (match_operand 0 "register_operand" ""))
		 (match_operand 2 "const1_operand" ""))
	      (const_string "alu")
	   ]
	   (const_string "ishift")))
   (set (attr "length_immediate")
     (if_then_else
       (ior (eq_attr "type" "alu")
	    (and (eq_attr "type" "ishift")
		 (and (match_operand 2 "const1_operand" "")
		      (ior (match_test "TARGET_SHIFT1")
			   (match_test "optimize_function_for_size_p (cfun)")))))
       (const_string "0")
       (const_string "*")))
   (set_attr "mode" "HI,SI")]
:}

{:
;; %%% Potential partial reg stall on alternative 1.  What to do?
:}

concrete *ashlqi3_1.insn instantiates set_ashift2_clobber
{
	root (0=nonimmediate_operand:QI:"=qm,r,Yp",
		1=nonimmediate_operand:QI:"0,0,l", 2=nonmemory_operand:QI:"cI,cI,M",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=QI;
}
{:
  "ix86_binary_operator_ok (ASHIFT, QImode, operands)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_LEA:
      return "#";

    case TYPE_ALU:
      gcc_assert (operands[2] == const1_rtx);
      if (REG_P (operands[1]) && !ANY_QI_REG_P (operands[1]))
        return "add{l}\t%k0, %k0";
      else
        return "add{b}\t%0, %0";

    default:
      if (operands[2] == const1_rtx
	  && (TARGET_SHIFT1 || optimize_function_for_size_p (cfun)))
	{
	  if (get_attr_mode (insn) == MODE_SI)
	    return "sal{l}\t%k0";
	  else
	    return "sal{b}\t%0";
	}
      else
	{
	  if (get_attr_mode (insn) == MODE_SI)
	    return "sal{l}\t{%2, %k0|%k0, %2}";
	  else
	    return "sal{b}\t{%2, %0|%0, %2}";
	}
    }
}
  [(set (attr "type")
     (cond [(eq_attr "alternative" "2")
	      (const_string "lea")
            (and (and (match_test "TARGET_DOUBLE_WITH_ADD")
		      (match_operand 0 "register_operand" ""))
		 (match_operand 2 "const1_operand" ""))
	      (const_string "alu")
	   ]
	   (const_string "ishift")))
   (set (attr "length_immediate")
     (if_then_else
       (ior (eq_attr "type" "alu")
	    (and (eq_attr "type" "ishift")
		 (and (match_operand 2 "const1_operand" "")
		      (ior (match_test "TARGET_SHIFT1")
			   (match_test "optimize_function_for_size_p (cfun)")))))
       (const_string "0")
       (const_string "*")))
   (set_attr "mode" "QI,SI,SI")]
:}

abstract set_strict_low_part1_ashift2 extends set_ashift2
{
	root.1:=strict_low_part;
}


abstract set_strict_low_part1_ashift2_clobber extends sequence
{
	root.1:=set_strict_low_part1_ashift2;
	root.2:=clobber;
}


concrete *ashlqi3_1_slp.insn instantiates set_strict_low_part1_ashift2_clobber
{
	root (0=nonimmediate_operand:QI:"+qm",
		duplicate 0, 1=nonmemory_operand:QI:"cI", reg(CC:FLAGS_REG));
	root.1.2.mode:=QI;
}
{:
  "(optimize_function_for_size_p (cfun)
    || !TARGET_PARTIAL_FLAG_REG_STALL
    || (operands[1] == const1_rtx
	&& (TARGET_SHIFT1
	    || (TARGET_DOUBLE_WITH_ADD && REG_P (operands[0])))))"
{
  switch (get_attr_type (insn))
    {
    case TYPE_ALU:
      gcc_assert (operands[1] == const1_rtx);
      return "add{b}\t%0, %0";

    default:
      if (operands[1] == const1_rtx
	  && (TARGET_SHIFT1 || optimize_function_for_size_p (cfun)))
	return "sal{b}\t%0";
      else
	return "sal{b}\t{%1, %0|%0, %1}";
    }
}
  [(set (attr "type")
     (cond [(and (and (match_test "TARGET_DOUBLE_WITH_ADD")
		      (match_operand 0 "register_operand" ""))
		 (match_operand 1 "const1_operand" ""))
	      (const_string "alu")
	   ]
	   (const_string "ishift1")))
   (set (attr "length_immediate")
     (if_then_else
       (ior (eq_attr "type" "alu")
	    (and (eq_attr "type" "ishift1")
		 (and (match_operand 1 "const1_operand" "")
		      (ior (match_test "TARGET_SHIFT1")
			   (match_test "optimize_function_for_size_p (cfun)")))))
       (const_string "0")
       (const_string "*")))
   (set_attr "mode" "QI")]
:}

{:
;; Convert ashift to the lea pattern to avoid flags dependency.
:}

concrete .split instantiates.in set_ashift2_clobber
{
	root (0=register_operand:NULL:"",
		1=index_register_operand:NULL:"", 
		2=const_int_operand:QI:"", reg(CC:FLAGS_REG));
}
cmd_spec.in
{:
  "GET_MODE (operands[0]) == GET_MODE (operands[1])
   && reload_completed
   && true_regnum (operands[0]) != true_regnum (operands[1])"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  enum machine_mode mode = GET_MODE (operands[0]);
  rtx pat;

  if (GET_MODE_SIZE (mode) < GET_MODE_SIZE (SImode))
    { 
      mode = SImode; 
      operands[0] = gen_lowpart (mode, operands[0]);
      operands[1] = gen_lowpart (mode, operands[1]);
    }

  operands[2] = gen_int_mode (1 << INTVAL (operands[2]), mode);

  pat = gen_rtx_MULT (mode, operands[1], operands[2]);

  emit_insn (gen_rtx_SET (VOIDmode, operands[0], pat));
  DONE;
}
:}

{:
;; Convert ashift to the lea pattern to avoid flags dependency.
:}

abstract set_zero_extend2_subreg1_mult1 extends set_zero_extend2
{
	root.2.1:=subreg;
	root.2.1.1:=mult;
}


concrete .split instantiates.in set_zero_extend2_ashift1_clobber
{
	root (0=register_operand:DI:"",
		1=index_register_operand:SI:"", 2=const_int_operand:QI:"",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=SI;
}
cmd_spec.in
{:
  "TARGET_64BIT && reload_completed
   && true_regnum (operands[0]) != true_regnum (operands[1])"
:}
instantiates.out set_zero_extend2_subreg1_mult1
{
	root (duplicate 0, duplicate 1, duplicate 2, <0>);
	root.2.mode:=DI;
	root.2.1.mode:=SI;
	root.2.1.1.mode:=DI;
}
cmd_spec.out
{:
{
  operands[1] = gen_lowpart (DImode, operands[1]);
  operands[2] = gen_int_mode (1 << INTVAL (operands[2]), DImode);
}
:}
{:
;; This pattern can't accept a variable shift count, since shifts by
;; zero don't affect the flags.  We assume that shifts by constant
;; zero are optimized away.
:}
abstract set_compare2_ashift1_set_ashift2 extends sequence
{
	root.1:=set_compare2_ashift1;
	root.2:=set_ashift2;
}

concrete *ashl<mode>3_cmp.insn instantiates set_compare2_ashift1_set_ashift2
{
	root (reg(NULL:FLAGS_REG), 1=nonimmediate_operand:SWI:"0",
		2=<shift_immediate_operand>:QI:"<S>", const_int:0,
		0=nonimmediate_operand:SWI:"=<r>m", duplicate 1, duplicate 2);
	root.1.2.1.mode:=SWI;
	root.2.2.mode:=SWI;
}
{:
  "(optimize_function_for_size_p (cfun)
    || !TARGET_PARTIAL_FLAG_REG_STALL
    || (operands[2] == const1_rtx
	&& (TARGET_SHIFT1
	    || (TARGET_DOUBLE_WITH_ADD && REG_P (operands[0])))))
   && ix86_match_ccmode (insn, CCGOCmode)
   && ix86_binary_operator_ok (ASHIFT, <MODE>mode, operands)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_ALU:
      gcc_assert (operands[2] == const1_rtx);
      return "add{<imodesuffix>}\t%0, %0";

    default:
      if (operands[2] == const1_rtx
	  && (TARGET_SHIFT1 || optimize_function_for_size_p (cfun)))
	return "sal{<imodesuffix>}\t%0";
      else
	return "sal{<imodesuffix>}\t{%2, %0|%0, %2}";
    }
}
  [(set (attr "type")
     (cond [(and (and (match_test "TARGET_DOUBLE_WITH_ADD")
		      (match_operand 0 "register_operand" ""))
		 (match_operand 2 "const1_operand" ""))
	      (const_string "alu")
	   ]
	   (const_string "ishift")))
   (set (attr "length_immediate")
     (if_then_else
       (ior (eq_attr "type" "alu")
	    (and (eq_attr "type" "ishift")
		 (and (match_operand 2 "const1_operand" "")
		      (ior (match_test "TARGET_SHIFT1")
			   (match_test "optimize_function_for_size_p (cfun)")))))
       (const_string "0")
       (const_string "*")))
   (set_attr "mode" "<MODE>")]
:}

abstract set_compare2_ashift1_set_zero_extend2_ashift1 extends sequence
{
	root.1:=set_compare2_ashift1;
	root.2:=set_zero_extend2_ashift1;
}



concrete *ashlsi3_cmp_zext.insn instantiates set_compare2_ashift1_set_zero_extend2_ashift1
{
	root (reg(NULL:FLAGS_REG),
		1=register_operand:SI:"0", 2=const_1_to_31_operand:QI:"I",
		const_int:0, 0=register_operand:DI:"=r", duplicate 1, duplicate 2);
	root.1.2.1.mode:=SI;
	root.2.2.mode:=DI;
	root.2.2.1.mode:=SI;
}
{:
  "TARGET_64BIT
   && (optimize_function_for_size_p (cfun)
       || !TARGET_PARTIAL_FLAG_REG_STALL
       || (operands[2] == const1_rtx
	   && (TARGET_SHIFT1
	       || TARGET_DOUBLE_WITH_ADD)))
   && ix86_match_ccmode (insn, CCGOCmode)
   && ix86_binary_operator_ok (ASHIFT, SImode, operands)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_ALU:
      gcc_assert (operands[2] == const1_rtx);
      return "add{l}\t%k0, %k0";

    default:
      if (operands[2] == const1_rtx
	  && (TARGET_SHIFT1 || optimize_function_for_size_p (cfun)))
	return "sal{l}\t%k0";
      else
	return "sal{l}\t{%2, %k0|%k0, %2}";
    }
}
  [(set (attr "type")
     (cond [(and (match_test "TARGET_DOUBLE_WITH_ADD")
		 (match_operand 2 "const1_operand" ""))
	      (const_string "alu")
	   ]
	   (const_string "ishift")))
   (set (attr "length_immediate")
     (if_then_else
       (ior (eq_attr "type" "alu")
	    (and (eq_attr "type" "ishift")
		 (and (match_operand 2 "const1_operand" "")
		      (ior (match_test "TARGET_SHIFT1")
			   (match_test "optimize_function_for_size_p (cfun)")))))
       (const_string "0")
       (const_string "*")))
   (set_attr "mode" "SI")]
:}

abstract set_compare2_ashift1_clobber extends sequence
{
	root.1:=set_compare2_ashift1;
	root.2:=clobber;
}

concrete *ashl<mode>3_cconly.insn instantiates set_compare2_ashift1_clobber
{
	root (reg(NULL:FLAGS_REG), 1=register_operand:SWI:"0",
		2=<shift_immediate_operand>:QI:"<S>", const_int:0, 0=SWI:"=<r>");
	root.1.2.1.mode:=SWI;
}
{:
  "(optimize_function_for_size_p (cfun)
    || !TARGET_PARTIAL_FLAG_REG_STALL
    || (operands[2] == const1_rtx
	&& (TARGET_SHIFT1
	    || TARGET_DOUBLE_WITH_ADD)))
   && ix86_match_ccmode (insn, CCGOCmode)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_ALU:
      gcc_assert (operands[2] == const1_rtx);
      return "add{<imodesuffix>}\t%0, %0";

    default:
      if (operands[2] == const1_rtx
	  && (TARGET_SHIFT1 || optimize_function_for_size_p (cfun)))
	return "sal{<imodesuffix>}\t%0";
      else
	return "sal{<imodesuffix>}\t{%2, %0|%0, %2}";
    }
}
  [(set (attr "type")
     (cond [(and (and (match_test "TARGET_DOUBLE_WITH_ADD")
		      (match_operand 0 "register_operand" ""))
		 (match_operand 2 "const1_operand" ""))
	      (const_string "alu")
	   ]
	   (const_string "ishift")))
   (set (attr "length_immediate")
     (if_then_else
       (ior (eq_attr "type" "alu")
	    (and (eq_attr "type" "ishift")
		 (and (match_operand 2 "const1_operand" "")
		      (ior (match_test "TARGET_SHIFT1")
			   (match_test "optimize_function_for_size_p (cfun)")))))
       (const_string "0")
       (const_string "*")))
   (set_attr "mode" "<MODE>")]
:}
{:
;; See comment above `ashl<mode>3' about how this works.
:}

abstract set_any_shiftrt2 extends set
{
	root.2:=any_shiftrt;
}

concrete <shift_insn><mode>3.exp instantiates set_any_shiftrt2
{
	root (0=<shift_operand>:SDWIM:"", 
		1=<shift_operand>:SDWIM:"", 2=nonmemory_operand:QI:"");
	root.2.mode:=SDWIM;
}
{:
  ""
  "ix86_expand_binary_operator (<CODE>, <MODE>mode, operands); DONE;"
:}
{:
;; Avoid useless masking of count operand.
:}

abstract set_any_shiftrt2_subreg2_and1 extends set_any_shiftrt2
{
	root.2.2:=subreg;
	root.2.2.1:=and;
}

abstract set_any_shiftrt2_subreg2_and1_clobber extends sequence
{
	root.1:=set_any_shiftrt2_subreg2_and1;
	root.2:=clobber;
}


abstract parallel_set_any_shiftrt2_clobber extends parallel
{
	root.1:=set_any_shiftrt2;
	root.2:=clobber;
}

concrete *<shift_insn><mode>3_mask.insn_and_split instantiates.in set_any_shiftrt2_subreg2_and1_clobber
{
	root (0=nonimmediate_operand:SWI48:"=rm",
		1=nonimmediate_operand:SWI48:"0", 2=nonimmediate_operand:SI:"c",
		3=const_int_operand:SI:"n", 0, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
	root.1.2.2.mode:=QI;
	root.1.2.2.1.mode:=SI;
}
cmd_spec.in
{:
  "ix86_binary_operator_ok (<CODE>, <MODE>mode, operands)
   && (INTVAL (operands[3]) & (GET_MODE_BITSIZE (<MODE>mode)-1))
      == GET_MODE_BITSIZE (<MODE>mode)-1"
  "#"
  "&& 1"
:}
instantiates.out parallel_set_any_shiftrt2_clobber
{
	root (duplicate 0, duplicate 1, duplicate 2, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
}
cmd_spec.out
{:
{
  if (can_create_pseudo_p ())
    operands [2] = force_reg (SImode, operands[2]);

  operands[2] = simplify_gen_subreg (QImode, operands[2], SImode, 0);
}
  [(set_attr "type" "ishift")
   (set_attr "mode" "<MODE>")]
:}

abstract set_any_shiftrt2_clobber extends sequence
{
	root.1:=set_any_shiftrt2;
	root.2:=clobber;
}

concrete *<shift_insn><mode>3_doubleword.insn_and_split instantiates.in set_any_shiftrt2_clobber
{
	root (0=register_operand:DWI:"=r", 1=register_operand:DWI:"0",
		2=nonmemory_operand:QI:"<S>c", reg(CC:FLAGS_REG));
	root.1.2.mode:=DWI;
}
cmd_spec.in
{:
  ""
  "#"
  "(optimize && flag_peephole2) ? epilogue_completed : reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
  "ix86_split_<shift_insn> (operands, NULL_RTX, <MODE>mode); DONE;"
  [(set_attr "type" "multi")]
:}

{:
;; By default we don't ask for a scratch register, because when DWImode
;; values are manipulated, registers are already at a premium.  But if
;; we have one handy, we won't turn it away.
:}

abstract parallel_set_any_shiftrt2_clobber extends parallel_set_ashift2_clobber
{
	root.1.2:=any_shiftrt;
}

abstract sequence_parallel_set_any_shiftrt2_clobber_sequence extends sequence_parallel_set_ashift2_clobber_sequence
{
	root.2:=parallel_set_any_shiftrt2_clobber;
}

{:
(define_peephole2
  [(match_scratch:DWIH 3 "r")
   (parallel [(set (match_operand:<DWI> 0 "register_operand" "")
           (any_shiftrt:<DWI>
             (match_operand:<DWI> 1 "register_operand" "")
             (match_operand:QI 2 "nonmemory_operand" "")))
          (clobber (reg:CC FLAGS_REG))])
   (match_dup 3)]
  "TARGET_CMOVE"
  [(const_int 0)]
  "ix86_split_<shift_insn> (operands, operands[3], <DWI>mode); DONE;")
:}

abstract set_ior2_ashiftrt1_ashift2_minus2 extends set_ior2
{
	root.2.1:=ashiftrt;
	root.2.2:=ashift;
	root.2.2.2:=minus;

}

abstract set_ior2_ashiftrt1_ashift2_minus2_clobber extends sequence
{
	root.1:=set_ior2_ashiftrt1_ashift2_minus2;
	root.2:=clobber;
}

concrete x86_64_shrd.insn instantiates set_ior2_ashiftrt1_ashift2_minus2_clobber
{
	root (0=nonimmediate_operand:DI:"+r*m",
		duplicate 0 ,2=nonmemory_operand:QI:"Jc", 1=register_operand:DI:"r",
		const_int:64, duplicate 2, reg(CC:FLAGS_REG));
root.1.2.mode:=DI;
	root.1.2.1.mode:=DI;
	root.1.2.2.mode:=DI;
	root.1.2.2.2.mode:=QI;
}
{:
  "TARGET_64BIT"
  "shrd{q}\t{%s2%1, %0|%0, %1, %2}"
  [(set_attr "type" "ishift")
   (set_attr "prefix_0f" "1")
   (set_attr "mode" "DI")
   (set_attr "athlon_decode" "vector")
   (set_attr "amdfam10_decode" "vector")
   (set_attr "bdver1_decode" "vector")]
:}

concrete x86_shrd.insn instantiates set_ior2_ashiftrt1_ashift2_minus2_clobber
{
	root (0=nonimmediate_operand:SI:"+r*m",
		duplicate 0, 2=nonmemory_operand:QI:"Ic", 1=register_operand:SI:"r",
		const_int:32, duplicate 2, reg(CC:FLAGS_REG));
	root.1.2.mode:=SI;
	root.1.2.1.mode:=SI;
	root.1.2.2.mode:=SI;
	root.1.2.2.2.mode:=QI;
}
{:
  ""
  "shrd{l}\t{%s2%1, %0|%0, %1, %2}"
  [(set_attr "type" "ishift")
   (set_attr "prefix_0f" "1")
   (set_attr "mode" "SI")
   (set_attr "pent_pair" "np")
   (set_attr "athlon_decode" "vector")
   (set_attr "amdfam10_decode" "vector")
   (set_attr "bdver1_decode" "vector")]
:}


abstract set_ashiftrt2_clobber extends sequence
{
	root.1:=set_ashiftrt2;
	root.2:=clobber;
}

concrete ashrdi3_cvt.insn instantiates set_ashiftrt2_clobber
{
	root (0=nonimmediate_operand:DI:"=*d,rm",
		1=nonimmediate_operand:DI:"*a,0", 2=const_int_operand:QI:"",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
}
{:
  "TARGET_64BIT && INTVAL (operands[2]) == 63
   && (TARGET_USE_CLTD || optimize_function_for_size_p (cfun))
   && ix86_binary_operator_ok (ASHIFTRT, DImode, operands)"
  "@
   {cqto|cqo}
   sar{q}\t{%2, %0|%0, %2}"
  [(set_attr "type" "imovx,ishift")
   (set_attr "prefix_0f" "0,*")
   (set_attr "length_immediate" "0,*")
   (set_attr "modrm" "0,1")
   (set_attr "mode" "DI")]
:}

concrete ashrsi3_cvt.insn instantiates set_ashiftrt2_clobber
{
	root (0=nonimmediate_operand:SI:"=*d,rm",
		1=nonimmediate_operand:SI:"*a,0", 2=const_int_operand:QI:"",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SI;
}
{:
  "INTVAL (operands[2]) == 31
   && (TARGET_USE_CLTD || optimize_function_for_size_p (cfun))
   && ix86_binary_operator_ok (ASHIFTRT, SImode, operands)"
  "@
   {cltd|cdq}
   sar{l}\t{%2, %0|%0, %2}"
  [(set_attr "type" "imovx,ishift")
   (set_attr "prefix_0f" "0,*")
   (set_attr "length_immediate" "0,*")
   (set_attr "modrm" "0,1")
   (set_attr "mode" "SI")]
:}

abstract set_zero_extend2_ashiftrt1 extends set_zero_extend2
{
	root.2.1:=ashiftrt;
}


abstract set_zero_extend2_ashiftrt1_clobber extends sequence
{
	root.1:=set_zero_extend2_ashiftrt1;
	root.2:=clobber;
}

concrete *ashrsi3_cvt_zext.insn instantiates set_zero_extend2_ashiftrt1_clobber
{
	root (0=register_operand:DI:"=*d,r",
		1=register_operand:SI:"*a,0", 2=const_int_operand:QI:"",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=SI;
}
{:
  "TARGET_64BIT && INTVAL (operands[2]) == 31
   && (TARGET_USE_CLTD || optimize_function_for_size_p (cfun))
   && ix86_binary_operator_ok (ASHIFTRT, SImode, operands)"
  "@
   {cltd|cdq}
   sar{l}\t{%2, %k0|%k0, %2}"
  [(set_attr "type" "imovx,ishift")
   (set_attr "prefix_0f" "0,*")
   (set_attr "length_immediate" "0,*")
   (set_attr "modrm" "0,1")
   (set_attr "mode" "SI")]
:}

concrete x86_shift<mode>_adj_3.exp instantiates use_x3
{
	root (0=register_operand:SWI48:"", 1=register_operand:SWI48:"",
		2=register_operand:QI:"");
}
{:
  ""
{
  rtx label = gen_label_rtx ();
  rtx tmp;

  emit_insn (gen_testqi_ccz_1 (operands[2],
			       GEN_INT (GET_MODE_BITSIZE (<MODE>mode))));

  tmp = gen_rtx_REG (CCZmode, FLAGS_REG);
  tmp = gen_rtx_EQ (VOIDmode, tmp, const0_rtx);
  tmp = gen_rtx_IF_THEN_ELSE (VOIDmode, tmp,
			      gen_rtx_LABEL_REF (VOIDmode, label),
			      pc_rtx);
  tmp = emit_jump_insn (gen_rtx_SET (VOIDmode, pc_rtx, tmp));
  JUMP_LABEL (tmp) = label;

  emit_move_insn (operands[0], operands[1]);
  emit_insn (gen_ashr<mode>3_cvt (operands[1], operands[1],
				  GEN_INT (GET_MODE_BITSIZE (<MODE>mode)-1)));
  emit_label (label);
  LABEL_NUSES (label) = 1;

  DONE;
}
:}

concrete *bmi2_<shift_insn><mode>3_1.insn instantiates set_any_shiftrt2
{
	root (0=register_operand:SWI48:"=r", 1=nonimmediate_operand:SWI48:"rm",
		2=register_operand:SWI48:"r");
	root.2.mode:=SWI48;
}
{:
  "TARGET_BMI2"
  "<shift>x\t{%2, %1, %0|%0, %1, %2}"
  [(set_attr "type" "ishiftx")
   (set_attr "mode" "<MODE>")]
:}

concrete *<shift_insn><mode>3_1.insn instantiates set_any_shiftrt2_clobber
{
	root (0=nonimmediate_operand:SWI48:"=rm,r",
		1=nonimmediate_operand:SWI48:"0,rm", 2=nonmemory_operand:QI:"c<S>,r",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
}
{:
  "ix86_binary_operator_ok (<CODE>, <MODE>mode, operands)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_ISHIFTX:
      return "#";

    default:
      if (operands[2] == const1_rtx
	  && (TARGET_SHIFT1 || optimize_function_for_size_p (cfun)))
	return "<shift>{<imodesuffix>}\t%0";
      else
	return "<shift>{<imodesuffix>}\t{%2, %0|%0, %2}";
    }
}
  [(set_attr "isa" "*,bmi2")
   (set_attr "type" "ishift,ishiftx")
   (set (attr "length_immediate")
     (if_then_else
       (and (match_operand 2 "const1_operand" "")
	    (ior (match_test "TARGET_SHIFT1")
		 (match_test "optimize_function_for_size_p (cfun)")))
       (const_string "0")
       (const_string "*")))
   (set_attr "mode" "<MODE>")]
:}

{:
;; Convert shift to the shiftx pattern to avoid flags dependency.
:}

abstract set_zero_extend2_any_shiftrt1 extends set_zero_extend2
{
    root.2.1:=any_shiftrt;
}
	

concrete .split instantiates.in set_any_shiftrt2_clobber
{
	root (0=register_operand:SWI48:"",
		1=nonimmediate_operand:SWI48:"", 2=register_operand:QI:"",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
}
cmd_spec.in
{:
  "TARGET_BMI2 && reload_completed"
:}
instantiates.out set_any_shiftrt2
{
	root (duplicate 0, duplicate 1, duplicate 2);
	root.2.mode:=SWI48;
}
cmd_spec.out
{:
  "operands[2] = gen_lowpart (<MODE>mode, operands[2]);"
:}


concrete *bmi2_<shift_insn>si3_1_zext.insn instantiates set_zero_extend2_any_shiftrt1
{
	root (0=register_operand:DI:"=r",
		1=nonimmediate_operand:SI:"rm", 2=register_operand:SI:"r");
	root.2.mode:=DI;
	root.2.1.mode:=SI;
}
{:
  "TARGET_64BIT && TARGET_BMI2"
  "<shift>x\t{%2, %1, %k0|%k0, %1, %2}"
  [(set_attr "type" "ishiftx")
   (set_attr "mode" "SI")]
:}

abstract set_zero_extend2_any_shiftrt1_clobber extends sequence
{
	root.1:=set_zero_extend2_any_shiftrt1;
	root.2:=clobber;
}

concrete *<shift_insn>si3_1_zext.insn instantiates set_zero_extend2_any_shiftrt1_clobber
{
	root (0=register_operand:DI:"=r,r",
		1=nonimmediate_operand:SI:"0,rm", 2=nonmemory_operand:QI:"cI,r",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=SI;
}
{:
  "TARGET_64BIT && ix86_binary_operator_ok (<CODE>, SImode, operands)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_ISHIFTX:
      return "#";

    default:
      if (operands[2] == const1_rtx
	  && (TARGET_SHIFT1 || optimize_function_for_size_p (cfun)))
	return "<shift>{l}\t%k0";
      else
	return "<shift>{l}\t{%2, %k0|%k0, %2}";
    }
}
  [(set_attr "isa" "*,bmi2")
   (set_attr "type" "ishift,ishiftx")
   (set (attr "length_immediate")
     (if_then_else
       (and (match_operand 2 "const1_operand" "")
	    (ior (match_test "TARGET_SHIFT1")
		 (match_test "optimize_function_for_size_p (cfun)")))
       (const_string "0")
       (const_string "*")))
   (set_attr "mode" "SI")]
:}


{:
;; Convert shift to the shiftx pattern to avoid flags dependency.
:}

concrete .split instantiates.in set_zero_extend2_any_shiftrt1_clobber
{
	root (0=register_operand:DI:"",
		1=nonimmediate_operand:SI:"", 2=register_operand:QI:"",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=SI;
}
cmd_spec.in
{:
  "TARGET_64BIT && TARGET_BMI2 && reload_completed"
:}
instantiates.out set_zero_extend2_any_shiftrt1
{
	root (duplicate 0, duplicate 1, duplicate 2);
	root.2.mode:=DI;
	root.2.1.mode:=SI;
}
cmd_spec.out
{:
	"operands[2] = gen_lowpart (SImode, operands[2]);"
:}


concrete *<shift_insn><mode>3_1.insn instantiates set_any_shiftrt2_clobber
{
	root (0=nonimmediate_operand:SWI12:"=<r>m",
		1=nonimmediate_operand:SWI12:"0", 2=nonmemory_operand:QI:"c<S>",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI12;
}
{:
  "ix86_binary_operator_ok (<CODE>, <MODE>mode, operands)"
{
  if (operands[2] == const1_rtx
      && (TARGET_SHIFT1 || optimize_function_for_size_p (cfun)))
    return "<shift>{<imodesuffix>}\t%0";
  else
    return "<shift>{<imodesuffix>}\t{%2, %0|%0, %2}";
}
  [(set_attr "type" "ishift")
   (set (attr "length_immediate")
     (if_then_else
       (and (match_operand 2 "const1_operand" "")
	    (ior (match_test "TARGET_SHIFT1")
		 (match_test "optimize_function_for_size_p (cfun)")))
       (const_string "0")
       (const_string "*")))
   (set_attr "mode" "<MODE>")]
:}

abstract set_strict_low_part1_any_shiftrt2 extends set_any_shiftrt2
{
	root.1:=strict_low_part;
}

abstract set_strict_low_part1_any_shiftrt2_clobber extends sequence
{
	root.1:=set_strict_low_part1_any_shiftrt2;
	root.2:=clobber;
}


concrete *<shift_insn>qi3_1_slp.insn instantiates set_strict_low_part1_any_shiftrt2_clobber
{
	root (0=nonimmediate_operand:QI:"+qm",
		duplicate 0, 1=nonmemory_operand:QI:"cI",reg(CC:FLAGS_REG));
	root.1.2.mode:=QI;
}
{:
  "(optimize_function_for_size_p (cfun)
    || !TARGET_PARTIAL_REG_STALL
    || (operands[1] == const1_rtx
	&& TARGET_SHIFT1))"
{
  if (operands[1] == const1_rtx
      && (TARGET_SHIFT1 || optimize_function_for_size_p (cfun)))
    return "<shift>{b}\t%0";
  else
    return "<shift>{b}\t{%1, %0|%0, %1}";
}
  [(set_attr "type" "ishift1")
   (set (attr "length_immediate")
     (if_then_else
       (and (match_operand 1 "const1_operand" "")
	    (ior (match_test "TARGET_SHIFT1")
		 (match_test "optimize_function_for_size_p (cfun)")))
       (const_string "0")
       (const_string "*")))
   (set_attr "mode" "QI")]
:}

{:
;; This pattern can't accept a variable shift count, since shifts by
;; zero don't affect the flags.  We assume that shifts by constant
;; zero are optimized away.
:}

abstract set_compare2_any_shiftrt1 extends set_compare2
{
	root.2.1:=any_shiftrt;
}

abstract set_compare2_any_shiftrt1_set_any_shiftrt2 extends sequence
{
	root.1:=set_compare2_any_shiftrt1;
	root.2:=set_any_shiftrt2;
}

concrete *<shift_insn><mode>3_cmp.insn instantiates set_compare2_any_shiftrt1_set_any_shiftrt2
{
	root (reg(NULL:FLAGS_REG), 1=nonimmediate_operand:SWI:"0",
		2=<shift_immediate_operand>:QI:"<S>", const_int:0, 0=nonimmediate_operand:SWI:"=<r>m",
		duplicate 1, duplicate 2);
	root.1.2.1.mode:=SWI;
	root.2.2.mode:=SWI;
}
{:
  "(optimize_function_for_size_p (cfun)
    || !TARGET_PARTIAL_FLAG_REG_STALL
    || (operands[2] == const1_rtx
	&& TARGET_SHIFT1))
   && ix86_match_ccmode (insn, CCGOCmode)
   && ix86_binary_operator_ok (<CODE>, <MODE>mode, operands)"
{
  if (operands[2] == const1_rtx
      && (TARGET_SHIFT1 || optimize_function_for_size_p (cfun)))
    return "<shift>{<imodesuffix>}\t%0";
  else
    return "<shift>{<imodesuffix>}\t{%2, %0|%0, %2}";
}
  [(set_attr "type" "ishift")
   (set (attr "length_immediate")
     (if_then_else
       (and (match_operand 2 "const1_operand" "")
	    (ior (match_test "TARGET_SHIFT1")
		 (match_test "optimize_function_for_size_p (cfun)")))
       (const_string "0")
       (const_string "*")))
   (set_attr "mode" "<MODE>")]
:}

abstract set_compare2_any_shiftrt1_set_zero_extend2_any_shiftrt1 extends sequence
{
	root.1:=set_compare2_any_shiftrt1;
	root.2:=set_zero_extend2_any_shiftrt1;
}

concrete *<shift_insn>si3_cmp_zext.insn instantiates set_compare2_any_shiftrt1_set_zero_extend2_any_shiftrt1
{
	root (reg(NULL:FLAGS_REG),
		1=register_operand:SI:"0", 2=const_1_to_31_operand:QI:"I", const_int:0,
		0=register_operand:DI:"=r", duplicate 1, duplicate 2);
	root.1.2.1.mode:=SI;
	root.2.2.mode:=DI;
	root.2.2.1.mode:=SI;
}
{:
  "TARGET_64BIT
   && (optimize_function_for_size_p (cfun)
       || !TARGET_PARTIAL_FLAG_REG_STALL
       || (operands[2] == const1_rtx
	   && TARGET_SHIFT1))
   && ix86_match_ccmode (insn, CCGOCmode)
   && ix86_binary_operator_ok (<CODE>, SImode, operands)"
{
  if (operands[2] == const1_rtx
      && (TARGET_SHIFT1 || optimize_function_for_size_p (cfun)))
    return "<shift>{l}\t%k0";
  else
    return "<shift>{l}\t{%2, %k0|%k0, %2}";
}
  [(set_attr "type" "ishift")
   (set (attr "length_immediate")
     (if_then_else
       (and (match_operand 2 "const1_operand" "")
	    (ior (match_test "TARGET_SHIFT1")
		 (match_test "optimize_function_for_size_p (cfun)")))
       (const_string "0")
       (const_string "*")))
   (set_attr "mode" "SI")]
:}

abstract set_compare2_any_shiftrt1_clobber extends sequence
{
	root.1:=set_compare2_any_shiftrt1;
	root.2:=clobber;
}

concrete *<shift_insn><mode>3_cconly.insn instantiates set_compare2_any_shiftrt1_clobber
{
	root (reg(NULL:FLAGS_REG), 
		1=register_operand:SWI:"0", 2=<shift_immediate_operand>:QI:"<S>",
		const_int:0, 0=SWI:"=<r>");
	root.1.2.1.mode:=SWI;
}
{:
  "(optimize_function_for_size_p (cfun)
    || !TARGET_PARTIAL_FLAG_REG_STALL
    || (operands[2] == const1_rtx
	&& TARGET_SHIFT1))
   && ix86_match_ccmode (insn, CCGOCmode)"
{
  if (operands[2] == const1_rtx
      && (TARGET_SHIFT1 || optimize_function_for_size_p (cfun)))
    return "<shift>{<imodesuffix>}\t%0";
  else
    return "<shift>{<imodesuffix>}\t{%2, %0|%0, %2}";
}
  [(set_attr "type" "ishift")
   (set (attr "length_immediate")
     (if_then_else
       (and (match_operand 2 "const1_operand" "")
	    (ior (match_test "TARGET_SHIFT1")
		 (match_test "optimize_function_for_size_p (cfun)")))
       (const_string "0")
       (const_string "*")))
   (set_attr "mode" "<MODE>")]
:}
{:

;; Rotate instructions
:}

abstract set_any_rotate2 extends set
{
	root.2:=any_rotate;
}

concrete <rotate_insn>ti3.exp instantiates set_any_rotate2
{
	root (0=register_operand:TI:"", 1=register_operand:TI:"",
		2=nonmemory_operand:QI:"");
	root.2.mode:=TI;
}
{:
  "TARGET_64BIT"
{
  if (const_1_to_63_operand (operands[2], VOIDmode))
    emit_insn (gen_ix86_<rotate_insn>ti3_doubleword
		(operands[0], operands[1], operands[2]));
  else
    FAIL;

  DONE;
}
:}

concrete <rotate_insn>di3.exp overrides <rotate_insn>ti3.exp
{
	root.1.predicate:=shiftdi_operand; root.2.1.predicate:=shiftdi_operand;
	TI->DI;
}
{:
 ""
{
  if (TARGET_64BIT)
    ix86_expand_binary_operator (<CODE>, DImode, operands);
  else if (const_1_to_31_operand (operands[2], VOIDmode))
    emit_insn (gen_ix86_<rotate_insn>di3_doubleword
		(operands[0], operands[1], operands[2]));
  else
    FAIL;

  DONE;
}
:}

concrete <rotate_insn><mode>3.exp overrides <rotate_insn>ti3.exp
{
	root.1.predicate:=nonimmediate_operand; root.2.1.predicate:=nonimmediate_operand;
	TI->SWIM124;
}
{:
  ""
  "ix86_expand_binary_operator (<CODE>, <MODE>mode, operands); DONE;"
:}

{:
;; Avoid useless masking of count operand.
:}

abstract set_any_rotate2_subreg2_and1 extends set_any_rotate2
{
	root.2.2:=subreg;
	root.2.2.1:=and;
}

abstract set_any_rotate2_subreg2_and1_clobber extends sequence
{
	root.1:=set_any_rotate2_subreg2_and1;
	root.2:=clobber;
}

abstract parallel_set_any_rotate2_clobber extends parallel
{
	root.1:=set_any_rotate2;
	root.2:=clobber;
}

concrete *<rotate_insn><mode>3_mask.insn_and_split instantiates.in set_any_rotate2_subreg2_and1_clobber
{
	root (0=nonimmediate_operand:SWI48:"=rm",
		1=nonimmediate_operand:SWI48:"0", 2=nonimmediate_operand:SI:"c",
		3=const_int_operand:SI:"n",0, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
	root.1.2.2.mode:=QI;
	root.1.2.2.1.mode:=SI;
}
cmd_spec.in
{:
  "ix86_binary_operator_ok (<CODE>, <MODE>mode, operands)
   && (INTVAL (operands[3]) & (GET_MODE_BITSIZE (<MODE>mode)-1))
      == GET_MODE_BITSIZE (<MODE>mode)-1"
  "#"
  "&& 1"
:}
instantiates.out parallel_set_any_rotate2_clobber
{
	root (duplicate 0, duplicate 1,
		duplicate 2, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;	
}
cmd_spec.out
{:
{
  if (can_create_pseudo_p ())
    operands [2] = force_reg (SImode, operands[2]);

  operands[2] = simplify_gen_subreg (QImode, operands[2], SImode, 0);
}
  [(set_attr "type" "rotate")
   (set_attr "mode" "<MODE>")]
:}

{:
;; Implement rotation using two double-precision
;; shift instructions and a scratch register.
:}
{:
(define_insn_and_split "ix86_rotl<dwi>3_doubleword"
 [(set (match_operand:<DWI> 0 "register_operand" "=r")
       (rotate:<DWI> (match_operand:<DWI> 1 "register_operand" "0")
		     (match_operand:QI 2 "<shift_immediate_operand>" "<S>")))
  (clobber (reg:CC FLAGS_REG))
  (clobber (match_scratch:DWIH 3 "=&r"))]
 ""
 "#"
 "reload_completed"
 [(set (match_dup 3) (match_dup 4))
  (parallel
   [(set (match_dup 4)
	 (ior:DWIH (ashift:DWIH (match_dup 4) (match_dup 2))
		   (lshiftrt:DWIH (match_dup 5)
				  (minus:QI (match_dup 6) (match_dup 2)))))
    (clobber (reg:CC FLAGS_REG))])
  (parallel
   [(set (match_dup 5)
	 (ior:DWIH (ashift:DWIH (match_dup 5) (match_dup 2))
		   (lshiftrt:DWIH (match_dup 3)
				  (minus:QI (match_dup 6) (match_dup 2)))))
    (clobber (reg:CC FLAGS_REG))])]
{
  operands[6] = GEN_INT (GET_MODE_BITSIZE (<MODE>mode));

  split_double_mode (<DWI>mode, &operands[0], 1, &operands[4], &operands[5]);
})

(define_insn_and_split "ix86_rotr<dwi>3_doubleword"
 [(set (match_operand:<DWI> 0 "register_operand" "=r")
       (rotatert:<DWI> (match_operand:<DWI> 1 "register_operand" "0")
		       (match_operand:QI 2 "<shift_immediate_operand>" "<S>")))
  (clobber (reg:CC FLAGS_REG))
  (clobber (match_scratch:DWIH 3 "=&r"))]
 ""
 "#"
 "reload_completed"
 [(set (match_dup 3) (match_dup 4))
  (parallel
   [(set (match_dup 4)
	 (ior:DWIH (ashiftrt:DWIH (match_dup 4) (match_dup 2))
		   (ashift:DWIH (match_dup 5)
				(minus:QI (match_dup 6) (match_dup 2)))))
    (clobber (reg:CC FLAGS_REG))])
  (parallel
   [(set (match_dup 5)
	 (ior:DWIH (ashiftrt:DWIH (match_dup 5) (match_dup 2))
		   (ashift:DWIH (match_dup 3)
				(minus:QI (match_dup 6) (match_dup 2)))))
    (clobber (reg:CC FLAGS_REG))])]
{
  operands[6] = GEN_INT (GET_MODE_BITSIZE (<MODE>mode));

  split_double_mode (<DWI>mode, &operands[0], 1, &operands[4], &operands[5]);
})
:}

abstract set_rotatert2 extends set
{
	root.2:=rotatert;
}

concrete *bmi2_rorx<mode>3_1.insn instantiates set_rotatert2
{
	root (0=register_operand:SWI48:"=r",1=nonimmediate_operand:SWI48:"rm",
		2=immediate_operand:QI:"<S>");
	root.2.mode:=SWI48;
}
{:
  "TARGET_BMI2"
  "rorx\t{%2, %1, %0|%0, %1, %2}"
  [(set_attr "type" "rotatex")
   (set_attr "mode" "<MODE>")]
:}


abstract set_any_rotate2_clobber extends sequence
{
	root.1:=set_any_rotate2;
	root.2:=clobber;
}

concrete *<rotate_insn><mode>3_1.insn instantiates set_any_rotate2_clobber
{
	root (0=nonimmediate_operand:SWI48:"=rm,r", 
		1=nonimmediate_operand:SWI48:"0,rm", 2=nonmemory_operand:QI:"c<S>,<S>",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
}
{:
  "ix86_binary_operator_ok (<CODE>, <MODE>mode, operands)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_ROTATEX:
      return "#";

    default:
      if (operands[2] == const1_rtx
	  && (TARGET_SHIFT1 || optimize_function_for_size_p (cfun)))
	return "<rotate>{<imodesuffix>}\t%0";
      else
	return "<rotate>{<imodesuffix>}\t{%2, %0|%0, %2}";
    }
}
  [(set_attr "isa" "*,bmi2")
   (set_attr "type" "rotate,rotatex")
   (set (attr "length_immediate")
     (if_then_else
       (and (eq_attr "type" "rotate")
	    (and (match_operand 2 "const1_operand" "")
		 (ior (match_test "TARGET_SHIFT1")
		      (match_test "optimize_function_for_size_p (cfun)"))))
       (const_string "0")
       (const_string "*")))
   (set_attr "mode" "<MODE>")]
:}

{:
;; Convert rotate to the rotatex pattern to avoid flags dependency.
:}

abstract set_rotate2 extends set
{
	root.2:=rotate;
}

abstract set_rotate2_clobber extends sequence
{
	root.1:=set_rotate2;
	root.2:=clobber;
}

concrete .split instantiates.in set_rotate2_clobber
{
	root (0=register_operand:SWI48:"", 1=nonimmediate_operand:SWI48:"",
		2=immediate_operand:QI:"",reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
}
cmd_spec.in
{:
  "TARGET_BMI2 && reload_completed"
:}
instantiates.out set_rotatert2
{
	root (duplicate 0, duplicate 1, duplicate 2);
	root.2.mode:=SWI48;
}
cmd_spec.out
{:
{
  operands[2]
    = GEN_INT (GET_MODE_BITSIZE (<MODE>mode) - INTVAL (operands[2]));
}
:}

abstract set_rotatert2_clobber extends sequence
{
	root.1:=set_rotatert2;
	root.2:=clobber;
}

concrete .split instantiates.in set_rotatert2_clobber
{
	root (0=register_operand:SWI48:"", 
		1=nonimmediate_operand:SWI48:"", 2=immediate_operand:QI:"",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
}
cmd_spec.in
{:
  "TARGET_BMI2 && reload_completed"
:}
instantiates.out set_rotatert2
{
	root (duplicate 0, duplicate 1,duplicate 2);
	root.2.mode:=SWI48;
}
cmd_spec.out
{:
:}

abstract set_zero_extend2_rotatert1 extends set_zero_extend2
{
	root.2.1:=rotatert;
}

concrete *bmi2_rorxsi3_1_zext.insn instantiates set_zero_extend2_rotatert1
{
	root (0=register_operand:DI:"=r",
		1=nonimmediate_operand:SI:"rm", 2=immediate_operand:QI:"I");
	root.2.mode:=DI;
	root.2.1.mode:=SI;
}
{:
  "TARGET_64BIT && TARGET_BMI2"
  "rorx\t{%2, %1, %k0|%k0, %1, %2}"
  [(set_attr "type" "rotatex")
   (set_attr "mode" "SI")]
:}

abstract set_zero_extend2_any_rotate1 extends set_zero_extend2
{
	root.2.1:=any_rotate;
}

abstract set_zero_extend2_any_rotate1_clobber extends sequence
{
	root.1:=set_zero_extend2_any_rotate1;
	root.2:=clobber;
}

concrete *<rotate_insn>si3_1_zext.insn instantiates set_zero_extend2_any_rotate1_clobber
{
	root (0=register_operand:DI:"=r,r",
		1=nonimmediate_operand:SI:"0,rm", 2=nonmemory_operand:QI:"cI,I",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=SI;
}
{:
  "TARGET_64BIT && ix86_binary_operator_ok (<CODE>, SImode, operands)"
{
  switch (get_attr_type (insn))
    {
    case TYPE_ROTATEX:
      return "#";

    default:
      if (operands[2] == const1_rtx
	  && (TARGET_SHIFT1 || optimize_function_for_size_p (cfun)))
	return "<rotate>{l}\t%k0";
      else
	return "<rotate>{l}\t{%2, %k0|%k0, %2}";
    }
}
  [(set_attr "isa" "*,bmi2")
   (set_attr "type" "rotate,rotatex")
   (set (attr "length_immediate")
     (if_then_else
       (and (eq_attr "type" "rotate")
	    (and (match_operand 2 "const1_operand" "")
		 (ior (match_test "TARGET_SHIFT1")
		      (match_test "optimize_function_for_size_p (cfun)"))))
       (const_string "0")
       (const_string "*")))
   (set_attr "mode" "SI")]
:}

{:
;; Convert rotate to the rotatex pattern to avoid flags dependency.
;; TODO Implement Comments for the specRTL file, not the md file.
;; TODO Devise a name creation scheme for abstract patterns.
;; TODO VIM Color patterns already created for specRTL.
;; TODO Issue with removing the round bracket for each end of the pattern.
:}


abstract set_zero_extend2_rotate1_clobber extends sequence
{
	root.1:=set_zero_extend2;
	root.1.2.1:=rotate;
	root.2:=clobber;
}

abstract set_zero_extend2_rotatert1 extends set_zero_extend2
{
	root.2.1:=rotatert;
}

concrete .split instantiates.in set_zero_extend2_rotate1_clobber
{
	root (0=register_operand:DI:"",
		1=nonimmediate_operand:SI:"", 2=immediate_operand:QI:"",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=SI;
}
cmd_spec.in
{:
  "TARGET_64BIT && TARGET_BMI2 && reload_completed"
:}
instantiates.out set_zero_extend2_rotatert1
{
	root (duplicate 0, duplicate 1,
		duplicate 2);
	root.2.mode:=DI;
	root.2.1.mode:=SI;
}
cmd_spec.out
{:
{
  operands[2]
    = GEN_INT (GET_MODE_BITSIZE (SImode) - INTVAL (operands[2]));
}
:}

{:
;; TODO How does overriding work in case of splits/peepholes.
:}

abstract set_zero_extend2_rotatert1_clobber extends set_zero_extend2_rotate1_clobber
{
	root.1.2.1:=rotatert;
}

concrete .split instantiates.in set_zero_extend2_rotatert1_clobber
{
	root (0=register_operand:DI:"", 
		1=nonimmediate_operand:SI:"", 2=immediate_operand:QI:"",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=SI;
}
cmd_spec.in
{:
  "TARGET_64BIT && TARGET_BMI2 && reload_completed"
:}
instantiates.out set_zero_extend2_rotatert1
{
	root (duplicate 0,  duplicate 1, duplicate 2);
	root.2.mode:=DI;
	root.2.1.mode:=SI;
}
cmd_spec.out
{:
:}

concrete *<rotate_insn><mode>3_1.insn instantiates set_any_rotate2_clobber
{
	root (0=nonimmediate_operand:SWI12:"=<r>m",
		1=nonimmediate_operand:SWI12:"0", 2=nonmemory_operand:QI:"c<S>",
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI12;
}
{:
  "ix86_binary_operator_ok (<CODE>, <MODE>mode, operands)"
{
  if (operands[2] == const1_rtx
      && (TARGET_SHIFT1 || optimize_function_for_size_p (cfun)))
    return "<rotate>{<imodesuffix>}\t%0";
  else
    return "<rotate>{<imodesuffix>}\t{%2, %0|%0, %2}";
}
  [(set_attr "type" "rotate")
   (set (attr "length_immediate")
     (if_then_else
       (and (match_operand 2 "const1_operand" "")
	    (ior (match_test "TARGET_SHIFT1")
		 (match_test "optimize_function_for_size_p (cfun)")))
       (const_string "0")
       (const_string "*")))
   (set_attr "mode" "<MODE>")]
:}


abstract set_strict_low_part1_any_rotate2_clobber extends set_any_rotate2_clobber
{
	root.1.1:=strict_low_part;
}

concrete *<rotate_insn>qi3_1_slp.insn instantiates set_strict_low_part1_any_rotate2_clobber
{
	root (0=nonimmediate_operand:QI:"+qm",
		duplicate 0, 1=nonmemory_operand:QI:"cI", reg(CC:FLAGS_REG));
	root.1.2.mode:=QI;
}
{:
  "(optimize_function_for_size_p (cfun)
    || !TARGET_PARTIAL_REG_STALL
    || (operands[1] == const1_rtx
	&& TARGET_SHIFT1))"
{
  if (operands[1] == const1_rtx
      && (TARGET_SHIFT1 || optimize_function_for_size_p (cfun)))
    return "<rotate>{b}\t%0";
  else
    return "<rotate>{b}\t{%1, %0|%0, %1}";
}
  [(set_attr "type" "rotate1")
   (set (attr "length_immediate")
     (if_then_else
       (and (match_operand 1 "const1_operand" "")
	    (ior (match_test "TARGET_SHIFT1")
		 (match_test "optimize_function_for_size_p (cfun)")))
       (const_string "0")
       (const_string "*")))
   (set_attr "mode" "QI")]
:}

abstract set_bswap2 extends set
{
	root.2:=bswap;
}

abstract parallel_set_strict_low_part_bswap2_clobber extends parallel
{
	root.1:=set_bswap2;
	root.1.1:=strict_low_part;
	root.2:=clobber;
}

concrete .split instantiates.in set_any_rotate2_clobber
{
	root (0=register_operand:HI:"", 
		duplicate 0, const_int:8, reg(CC:FLAGS_REG));
	root.1.2.mode:=HI;
}
cmd_spec.in
{:
 "reload_completed
  && (TARGET_USE_XCHGB || optimize_function_for_size_p (cfun))"
:}
instantiates.out parallel_set_strict_low_part_bswap2_clobber
{
	root (duplicate 0, duplicate 0,
		reg(CC:FLAGS_REG));
	root.1.2.mode:=HI;
}
cmd_spec.out
{:
:}

{:

;; Bit set / bit test instructions
:}

concrete extv.exp instantiates set_sign_extract2
{
	root (0=register_operand:SI:"",
		1=register_operand:SI:"", 2=const8_operand:SI:"",
		3=const8_operand:SI:"");
	root.2.mode:=SI;
}
{:
  ""
{
  /* Handle extractions from %ah et al.  */
  if (INTVAL (operands[2]) != 8 || INTVAL (operands[3]) != 8)
    FAIL;

  /* From mips.md: extract_bit_field doesn't verify that our source
     matches the predicate, so check it again here.  */
  if (! ext_register_operand (operands[1], VOIDmode))
    FAIL;
}
:}

{:
;; TODO Case of hybrid use for override & instantiates.
:}

concrete extzv.exp instantiates set_zero_extract2
{
	root (0=register_operand:SI:"",
                1=ext_register_operand:NULL:"", 2=const8_operand:SI:"",
                3=const8_operand:SI:"");
        root.2.mode:=SI;
}
{:
  ""
{
  /* Handle extractions from %ah et al.  */
  if (INTVAL (operands[2]) != 8 || INTVAL (operands[3]) != 8)
    FAIL;

  /* From mips.md: extract_bit_field doesn't verify that our source
     matches the predicate, so check it again here.  */
  if (! ext_register_operand (operands[1], VOIDmode))
    FAIL;
}
:}

concrete insv.exp instantiates set_zero_extract1
{
	root (0=register_operand:NULL:"", 
		1=const_int_operand:NULL:"", 2=const_int_operand:NULL:"",
		3=register_operand:NULL:"");
}
{:
  ""
{
  rtx (*gen_mov_insv_1) (rtx, rtx);

  if (ix86_expand_pinsr (operands))
    DONE;

  /* Handle insertions to %ah et al.  */
  if (INTVAL (operands[1]) != 8 || INTVAL (operands[2]) != 8)
    FAIL;

  /* From mips.md: insert_bit_field doesn't verify that our source
     matches the predicate, so check it again here.  */
  if (! ext_register_operand (operands[0], VOIDmode))
    FAIL;

  gen_mov_insv_1 = (TARGET_64BIT
		    ? gen_movdi_insv_1 : gen_movsi_insv_1);

  emit_insn (gen_mov_insv_1 (operands[0], operands[3]));
  DONE;
}
:}

{:
;; %%% bts, btr, btc, bt.
;; In general these instructions are *slow* when applied to memory,
;; since they enforce atomic operation.  When applied to registers,
;; it depends on the cpu implementation.  They're never faster than
;; the corresponding and/ior/xor operations, so with 32-bit there's
;; no point.  But in 64-bit, we can't hold the relevant immediates
;; within the instruction itself, so operating on bits in the high
;; 32-bits of a register becomes easier.
;;
;; These are slow on Nocona, but fast on Athlon64.  We do require the use
;; of btrq and btcq for corner cases of post-reload expansion of absdf and
;; negdf respectively, so they can never be disabled entirely.
:}

abstract set_zero_extract1_clobber extends sequence
{
	root.1:=set;
	root.1.1:=zero_extract;
	root.2:=clobber;
}

concrete *btsq.insn instantiates set_zero_extract1_clobber
{
	root (0=register_operand:DI:"+r",
		const_int:1, 1=const_0_to_63_operand:DI:"", const_int:1,
		reg(CC:FLAGS_REG));
	root.1.1.mode:=DI;
}
{:
  "TARGET_64BIT && (TARGET_USE_BT || reload_completed)"
  "bts{q}\t{%1, %0|%0, %1}"
  [(set_attr "type" "alu1")
   (set_attr "prefix_0f" "1")
   (set_attr "mode" "DI")]
:}

concrete *btrq.insn overrides *btsq.insn
{
	root.1.2.operand:=const_int:0;
}
{:
  "TARGET_64BIT && (TARGET_USE_BT || reload_completed)"
  "btr{q}\t{%1, %0|%0, %1}"
  [(set_attr "type" "alu1")
   (set_attr "prefix_0f" "1")
   (set_attr "mode" "DI")]
:}

abstract set_zero_extract1_not2_zero_extract1_clobber extends set_zero_extract1_clobber
{
	root.1.2:=not;
	root.1.2.1:=zero_extract;
}

concrete *btcq.insn instantiates set_zero_extract1_not2_zero_extract1_clobber
{
	root (0=register_operand:DI:"+r",
		const_int:1, 1=const_0_to_63_operand:DI:"", duplicate 0, const_int:1,
		duplicate 1, reg(CC:FLAGS_REG));
	root.1.1.mode:=DI;
	root.1.2.mode:=DI;
	root.1.2.1.mode:=DI;
}
{:
  "TARGET_64BIT && (TARGET_USE_BT || reload_completed)"
  "btc{q}\t{%1, %0|%0, %1}"
  [(set_attr "type" "alu1")
   (set_attr "prefix_0f" "1")
   (set_attr "mode" "DI")]
:}

{:
;; Allow Nocona to avoid these instructions if a register is available.
:}

abstract parallel_set_zero_extract1_clobber extends parallel
{
	root.1:=set_zero_extract1;
	root.2:=clobber;
}

abstract sequence_parallel_set_zero_extract1_clobber extends sequence
{
	root.1:=sequence;
	root.2:=parallel_set_zero_extract1_clobber;
}

{:
(define_peephole2
  [(match_scratch:DI 2 "r")
   (parallel [(set (zero_extract:DI
             (match_operand:DI 0 "register_operand" "")
             (const_int 1)
             (match_operand:DI 1 "const_0_to_63_operand" ""))
           (const_int 1))
          (clobber (reg:CC FLAGS_REG))])]
  "TARGET_64BIT && !TARGET_USE_BT"
  [(const_int 0)]
{
  HOST_WIDE_INT i = INTVAL (operands[1]), hi, lo;
  rtx op1;

  if (HOST_BITS_PER_WIDE_INT >= 64)
    lo = (HOST_WIDE_INT)1 << i, hi = 0;
  else if (i < HOST_BITS_PER_WIDE_INT)
    lo = (HOST_WIDE_INT)1 << i, hi = 0;
  else
    lo = 0, hi = (HOST_WIDE_INT)1 << (i - HOST_BITS_PER_WIDE_INT);

  op1 = immed_double_const (lo, hi, DImode);
  if (i >= 31)
    {
      emit_move_insn (operands[2], op1);
      op1 = operands[2];
    }

  emit_insn (gen_iordi3 (operands[0], operands[0], op1));
  DONE;
})

(define_peephole2
  [(match_scratch:DI 2 "r")
   (parallel [(set (zero_extract:DI
             (match_operand:DI 0 "register_operand" "")
             (const_int 1)
             (match_operand:DI 1 "const_0_to_63_operand" ""))
           (const_int 0))
          (clobber (reg:CC FLAGS_REG))])]
  "TARGET_64BIT && !TARGET_USE_BT"
  [(const_int 0)]
{
  HOST_WIDE_INT i = INTVAL (operands[1]), hi, lo;
  rtx op1;

  if (HOST_BITS_PER_WIDE_INT >= 64)
    lo = (HOST_WIDE_INT)1 << i, hi = 0;
  else if (i < HOST_BITS_PER_WIDE_INT)
    lo = (HOST_WIDE_INT)1 << i, hi = 0;
  else
    lo = 0, hi = (HOST_WIDE_INT)1 << (i - HOST_BITS_PER_WIDE_INT);

  op1 = immed_double_const (~lo, ~hi, DImode);
  if (i >= 32)
    {
      emit_move_insn (operands[2], op1);
      op1 = operands[2];
    }

  emit_insn (gen_anddi3 (operands[0], operands[0], op1));
  DONE;
})

(define_peephole2
  [(match_scratch:DI 2 "r")
   (parallel [(set (zero_extract:DI
             (match_operand:DI 0 "register_operand" "")
             (const_int 1)
             (match_operand:DI 1 "const_0_to_63_operand" ""))
          (not:DI (zero_extract:DI
            (match_dup 0) (const_int 1) (match_dup 1))))
          (clobber (reg:CC FLAGS_REG))])]
  "TARGET_64BIT && !TARGET_USE_BT"
  [(const_int 0)]
{
  HOST_WIDE_INT i = INTVAL (operands[1]), hi, lo;
  rtx op1;

  if (HOST_BITS_PER_WIDE_INT >= 64)
    lo = (HOST_WIDE_INT)1 << i, hi = 0;
  else if (i < HOST_BITS_PER_WIDE_INT)
    lo = (HOST_WIDE_INT)1 << i, hi = 0;
  else
    lo = 0, hi = (HOST_WIDE_INT)1 << (i - HOST_BITS_PER_WIDE_INT);

  op1 = immed_double_const (lo, hi, DImode);
  if (i >= 31)
    {
      emit_move_insn (operands[2], op1);
      op1 = operands[2];
    }

  emit_insn (gen_xordi3 (operands[0], operands[0], op1));
  DONE;
})
:}

abstract parallel_set_zero_extract1_not2_zero_extract1_clobber extends parallel
{
	root.1:=set_zero_extract1;
	root.1.2:=not;
	root.1.2.1:=zero_extract;
	root.2:=clobber;
}

abstract sequence_parallel_set_zero_extract1_not2_zero_extract1_clobber extends  sequence
{
	root.1:=sequence;
	root.2:=parallel_set_zero_extract1_not2_zero_extract1_clobber;
}

concrete *bt<mode>.insn instantiates set_compare2_zero_extract1
{
	root (reg(CCC:FLAGS_REG), 0=register_operand:SWI48:"r",
		const_int:1, 1=x86_64_nonmemory_operand:SWI48:"rN", const_int:0);
	root.2.mode:=CCC;
	root.2.1.mode:=SWI48;
}
{:
  "TARGET_USE_BT || optimize_function_for_size_p (cfun)"
  "bt{<imodesuffix>}\t{%1, %0|%0, %1}"
  [(set_attr "type" "alu1")
   (set_attr "prefix_0f" "1")
   (set_attr "mode" "<MODE>")]
:}
{:

;; Store-flag instructions.

;; For all sCOND expanders, also expand the compare or test insn that
;; generates cc0.  Generate an equality comparison if `seq' or `sne'.
:}

abstract set_set_neg extends sequence
{
        root.1:=set;
        root.2:=set;
        root.2.2:=neg;
}

abstract set_set_zero_extend extends set_set_neg
{
        root.2.2:=zero_extend;
}

abstract set_match_operator_clobber extends sequence
{
        root.1:=set_match_operator;
        root.2:=clobber;
}

abstract set_parallel_set_zero_extend_clobber extends sequence
{
        root.1:=set;
        root.2:=parallel;
        root.2.1:=set;
        root.2.2:=clobber;
        root.2.1.2:=zero_extend;
}

concrete *setcc_di_1.insn_and_split
instantiates.in set_match_operator
{
        root (register_operand:DI:"=q",(1=ix86_comparison_operator,reg(NULL:FLAGS_REG),const_int:0));
        root.2.mode:=DI;
}
cmd_spec.in
{:
"TARGET_64BIT && !TARGET_PARTIAL_REG_STALL"
  "#"
  "&& reload_completed"
:}
instantiates.out set_set_zero_extend
{
	root (duplicate 2,duplicate 1,duplicate 0,duplicate 2);
        root.2.2.mode:=DI;
}
cmd_spec.out
{:
{
  PUT_MODE (operands[1], QImode);
  operands[2] = gen_lowpart (QImode, operands[0]);
}
:}

concrete *setcc_si_1_and.insn_and_split
instantiates.in set_match_operator_clobber
{
        root (register_operand:SI:"=q",(1=ix86_comparison_operator,reg(NULL:FLAGS_REG),const_int:0),reg(CC:FLAGS_REG));
        root.1.2.mode:=SI;
}
cmd_spec.in
{:
"!TARGET_PARTIAL_REG_STALL
   && TARGET_ZERO_EXTEND_WITH_AND && optimize_function_for_speed_p (cfun)"
  "#"
  "&& reload_completed"
:}
instantiates.out set_parallel_set_zero_extend_clobber
{
        root (duplicate 2,duplicate 1,(duplicate 0,duplicate 2,reg(CC:FLAGS_REG)));
        root.2.1.2.mode:=SI;
}
cmd_spec.out
{:
{
  PUT_MODE (operands[1], QImode);
  operands[2] = gen_lowpart (QImode, operands[0]);
}
:}




concrete *setcc_si_1_movzbl.insn_and_split
instantiates.in set_match_operator
{
        root (register_operand:SI:"=q",(1=ix86_comparison_operator,reg(NULL:FLAGS_REG),const_int:0));
        root.2.mode:=SI;
}
cmd_spec.in
{:
"!TARGET_PARTIAL_REG_STALL
   && (!TARGET_ZERO_EXTEND_WITH_AND || optimize_function_for_size_p (cfun))"
  "#"
  "&& reload_completed"
:}
instantiates.out set_set_zero_extend
{
	root (duplicate 2,duplicate 1,duplicate 0,duplicate 2);
        root.2.2.mode:=SI;
}
cmd_spec.out
{:
{
   PUT_MODE (operands[1], QImode);
  operands[2] = gen_lowpart (QImode, operands[0]);
}
:}

concrete *setcc_qi.insn instantiates set_match_operator
{
         root (nonimmediate_operand:QI:"=qm",(1=ix86_comparison_operator,reg(NULL:FLAGS_REG),const_int:0));
         root.2.mode:=QI;
}
{:
  ""
  "set%C1\t%0"
  [(set_attr "type" "setcc")
   (set_attr "mode" "QI")]
:}

abstract set_strict_low_part_match_operator extends set_strict_low_part1
{
        root.2:=match_operator;
}

concrete *setcc_qi_slp.insn instantiates set_strict_low_part_match_operator
{
        root (nonimmediate_operand:QI:"+qm",(1=ix86_comparison_operator,reg(NULL:FLAGS_REG),const_int:0));
        root.2.mode:=QI;
}
{:
  ""
  "set%C1\t%0"
  [(set_attr "type" "setcc")
   (set_attr "mode" "QI")]
:}

abstract set_ne_match_operator extends set
{
        root.2:=ne;
        root.2.1:=match_operator;
}


abstract set_strict_low_part_ne_match_operator extends set_ne_match_operator
{
        root.1:=strict_low_part;
}

{:
;; In general it is not safe to assume too much about CCmode registers,
;; so simplify-rtx stops when it sees a second one.  Under certain
;; conditions this is safe on x86, so help combine not create
;;
;;	seta	%al
;;	testb	%al, %al
;;	sete	%al
:}

concrete .split instantiates.in set_ne_match_operator
{
        root (nonimmediate_operand:QI:"",(1=ix86_comparison_operator,reg(NULL:FLAGS_REG),const_int:0),const_int:0);
root.2.mode:=QI;
}
cmd_spec.in
{:
  ""
:}
instantiates.out set
{
        root (duplicate 0,duplicate 1);
}
cmd_spec.out
{:
  "PUT_MODE (operands[1], QImode);"
:}

concrete .split instantiates.in set_strict_low_part_ne_match_operator
{
        root (nonimmediate_operand:QI:"",(1=ix86_comparison_operator,reg(NULL:FLAGS_REG),const_int:0),const_int:0);
root.2.mode:=QI;
}
cmd_spec.in
{:
  ""
:}
instantiates.out set
{
	root (duplicate 0,duplicate 1);
}
cmd_spec.out
{:
  "PUT_MODE (operands[1], QImode);"
:}

abstract set_eq_match_operator extends set
{
        root.2:=eq;
        root.2.1:=match_operator;
}

abstract set_strict_low_part_eq_match_operator extends set_eq_match_operator
{
        root.1:=strict_low_part;
}

concrete .split instantiates.in set_eq_match_operator
{
        root (nonimmediate_operand:QI:"",(1=ix86_comparison_operator,reg(NULL:FLAGS_REG),const_int:0),const_int:0);
root.2.mode:=QI;
}
cmd_spec.in
{:
  ""
:}
instantiates.out set
{
	root (duplicate 0,duplicate 1);
}
cmd_spec.out
{:
  {
  rtx new_op1 = copy_rtx (operands[1]);
  operands[1] = new_op1;
  PUT_MODE (new_op1, QImode);
  PUT_CODE (new_op1, ix86_reverse_condition (GET_CODE (new_op1),
                                             GET_MODE (XEXP (new_op1, 0))));

  /* Make sure that (a) the CCmode we have for the flags is strong
     enough for the reversed compare or (b) we have a valid FP compare.  */
  if (! ix86_comparison_operator (new_op1, VOIDmode))
    FAIL;
}
:}

concrete .split instantiates.in set_strict_low_part_eq_match_operator
{
        root (nonimmediate_operand:QI:"",(1=ix86_comparison_operator,reg(NULL:FLAGS_REG),const_int:0),const_int:0);
    root.2.mode:=QI;
}
cmd_spec.in
{:
  ""
:}
instantiates.out set
{
	root (duplicate 0,duplicate 1);
}
cmd_spec.out
{:
  {
  rtx new_op1 = copy_rtx (operands[1]);
  operands[1] = new_op1;
  PUT_MODE (new_op1, QImode);
  PUT_CODE (new_op1, ix86_reverse_condition (GET_CODE (new_op1),
                                             GET_MODE (XEXP (new_op1, 0))));

  /* Make sure that (a) the CCmode we have for the flags is strong
     enough for the reversed compare or (b) we have a valid FP compare.  */
  if (! ix86_comparison_operator (new_op1, VOIDmode))
    FAIL;
}
:}


{:
;; The SSE store flag instructions saves 0 or 0xffffffff to the result.
;; subsequent logical operations are used to imitate conditional moves.
;; 0xffffffff is NaN, but not in normalized form, so we can't represent
;; it directly.
:}

concrete setcc_<mode>_sse.insn instantiates set_match_operator
{
        root (0=register_operand:MODEF:"=x,x",(3=sse_comparison_operator,1=register_operand:MODEF:"0,x",2=nonimmediate_operand:MODEF:"xm,xm"));
        root.2.mode:=MODEF;
}
{:
  "SSE_FLOAT_MODE_P (<MODE>mode)"
  "@
   cmp%D3<ssemodesuffix>\t{%2, %0|%0, %2}
   vcmp%D3<ssemodesuffix>\t{%2, %1, %0|%0, %1, %2}"
  [(set_attr "isa" "noavx,avx")
   (set_attr "type" "ssecmp")
   (set_attr "length_immediate" "1")
   (set_attr "prefix" "orig,vex")
   (set_attr "mode" "<MODE>")]
:}

{:

;; Basic conditional jump instructions.
;; We ignore the overflow flag for signed branch instructions.
:}

concrete *jcc_1.insn instantiates set_if_then_else_match_operator_label_ref
{
        root (pc,(1=ix86_comparison_operator,reg(NULL:FLAGS_REG),const_int:0),0=NULL:NULL:"",pc);
}
{:
  ""
  "%+j%C1\t%l0"
  [(set_attr "type" "ibr")
   (set_attr "modrm" "0")
   (set (attr "length")
           (if_then_else (and (ge (minus (match_dup 0) (pc))
                                  (const_int -126))
                              (lt (minus (match_dup 0) (pc))
                                  (const_int 128)))
             (const_int 2)
             (const_int 6)))]
:}

abstract set_if_then_else_ne_match_operator_label_ref extends set_if_then_else_match_operator_label_ref
{
        root.2.1:=ne;
        root.2.1.1:=match_operator;
}


abstract set_if_then_else_match_operator_label_ref2 extends set
{
        root.2:=if_then_else;
        root.2.1:=match_operator;
        root.2.3:=label_ref;
}


concrete  *jcc_2.insn instantiates set_if_then_else_match_operator_label_ref2
{
        root (pc,(1=ix86_comparison_operator,reg(NULL:FLAGS_REG),const_int:0),pc,0=NULL:NULL:"");
}
{:
  ""
  "%+j%c1\t%l0"
  [(set_attr "type" "ibr")
   (set_attr "modrm" "0")
   (set (attr "length")
           (if_then_else (and (ge (minus (match_dup 0) (pc))
                                  (const_int -126))
                              (lt (minus (match_dup 0) (pc))
                                  (const_int 128)))
             (const_int 2)
             (const_int 6)))]
:}

abstract set_if_then_else_label_ref extends set_if_then_else
{
        root.2.2:=label_ref;
}


{:
;; In general it is not safe to assume too much about CCmode registers,
;; so simplify-rtx stops when it sees a second one.  Under certain
;; conditions this is safe on x86, so help combine not create
;;
;;	seta	%al
;;	testb	%al, %al
;;	je	Lfoo
:}

concrete .split instantiates.in set_if_then_else_ne_match_operator_label_ref
{
        root (pc,(0=ix86_comparison_operator,reg(NULL:FLAGS_REG),const_int:0),const_int:0,NULL:NULL:"",pc);
}
cmd_spec.in
{:
  ""
:}
instantiates.out set_if_then_else_label_ref
{
	root (pc,duplicate 0,duplicate 1,pc);
}
cmd_spec.out
{:
  "PUT_MODE (operands[0], VOIDmode);"
:}

abstract set_if_then_else_eq_match_operator_label_ref extends set_if_then_else_match_operator_label_ref
{
        root.2.1:=eq;
        root.2.1.1:=match_operator;
}

concrete .split instantiates.in set_if_then_else_eq_match_operator_label_ref
{
        root (pc,(0=ix86_comparison_operator,reg(NULL:FLAGS_REG),const_int:0),const_int:0,NULL:NULL:"",pc);
}
cmd_spec.in
{:
  ""
:}
instantiates.out set_if_then_else_label_ref
{
	root (pc,duplicate 0,duplicate 1,pc);
}
cmd_spec.out
{:
  {
  rtx new_op0 = copy_rtx (operands[0]);
  operands[0] = new_op0;
  PUT_MODE (new_op0, VOIDmode);
  PUT_CODE (new_op0, ix86_reverse_condition (GET_CODE (new_op0),
                                             GET_MODE (XEXP (new_op0, 0))));

  /* Make sure that (a) the CCmode we have for the flags is strong
     enough for the reversed compare or (b) we have a valid FP compare.  */
  if (! ix86_comparison_operator (new_op0, VOIDmode))
    FAIL;
}
:}

{:
;; zero_extend in SImode is correct also for DImode, since this is what combine
;; pass generates from shift insn with QImode operand.  Actually, the mode
;; of operand 2 (bit offset operand) doesn't matter since bt insn takes
;; appropriate modulo of the bit offset value.
:}


abstract set_if_then_else_match_operator_zero_extract_zero_extend_label_ref_clobber extends sequence
{
        root.1:=set_if_then_else_match_operator_label_ref;
        root.1.2.1.1:=zero_extract;
        root.1.2.1.1.3:=zero_extend;
        root.2:=clobber;
}


abstract set_if_then_else_match_operator_zero_extract_and_label_ref_clobber extends set_if_then_else_match_operator_zero_extract_zero_extend_label_ref_clobber
{
        root.1.2.1.1.3:=and;
}

abstract set_compare_zero_extract_set_if_then_else_match_op_dup_label_ref extends set_compare_set_if_then_else_match_operator_label_ref
{
        root.1.2.1:=zero_extract;
        root.2.2.1:=match_op_dup;
}



concrete *jcc_bt<mode>.insn_and_split instantiates.in set_if_then_else_match_operator_zero_extract_zero_extend_label_ref_clobber
{
        root (pc,(0=bt_comparison_operator,register_operand:SWI48:"r",const_int:1,register_operand:QI:"r",const_int:0),NULL:NULL:"",pc,reg(CC:FLAGS_REG));
root.1.2.1.1.mode:=SWI48;
root.1.2.1.1.3.mode:=SI;
}
cmd_spec.in
{:
  "TARGET_USE_BT || optimize_function_for_size_p (cfun)"
  "#"
  "&& 1"
:}
instantiates.out set_compare_zero_extract_set_if_then_else_match_op_dup_label_ref
{
    root (reg(CCC:FLAGS_REG),duplicate 1,const_int:1,duplicate 2,const_int:0,pc,(<0>,reg(CCC:FLAGS_REG),const_int:0),duplicate 3,pc);
	root.1.2.mode:=CCC;
	root.1.2.1.mode:=SWI48;
}
cmd_spec.out
{:
  {
  operands[2] = simplify_gen_subreg (<MODE>mode, operands[2], QImode, 0);

  PUT_CODE (operands[0], reverse_condition (GET_CODE (operands[0])));
}
:}
{:
;; Avoid useless masking of bit offset operand.  "and" in SImode is correct
;; also for DImode, this is what combine produces.

(define_insn_and_split "*jcc_bt<mode>_mask"
  [(set (pc)
    (if_then_else (match_operator 0 "bt_comparison_operator"
            [(zero_extract:SWI48
               (match_operand:SWI48 1 "register_operand" "r")
               (const_int 1)
               (and:SI
                 (match_operand:SI 2 "register_operand" "r")
                 (match_operand:SI 3 "const_int_operand" "n")))])
              (label_ref (match_operand 4 "" ""))
              (pc)))
   (clobber (reg:CC FLAGS_REG))]
  "(TARGET_USE_BT || optimize_function_for_size_p (cfun))
   && (INTVAL (operands[3]) & (GET_MODE_BITSIZE (<MODE>mode)-1))
      == GET_MODE_BITSIZE (<MODE>mode)-1"
  "#"
  "&& 1"
  [(set (reg:CCC FLAGS_REG)
    (compare:CCC
      (zero_extract:SWI48
        (match_dup 1)
        (const_int 1)
        (match_dup 2))
      (const_int 0)))
   (set (pc)
    (if_then_else (match_op_dup 0 [(reg:CCC FLAGS_REG) (const_int 0)])
              (label_ref (match_dup 4))
              (pc)))]
{
  operands[2] = simplify_gen_subreg (<MODE>mode, operands[2], SImode, 0);

  PUT_CODE (operands[0], reverse_condition (GET_CODE (operands[0])));
})

:}

abstract set_if_then_else_match_operator_and_lshiftrt_label_ref_clobber extends set_if_then_else_match_operator_zero_extract_zero_extend_label_ref_clobber
{
        root.1.2.1:=match_operator;
        root.1.2.1.1:=and;
        root.1.2.1.1.1:=lshiftrt;

}

concrete *jcc_btsi_1.insn_and_split instantiates.in set_if_then_else_match_operator_and_lshiftrt_label_ref_clobber
{
        root (pc,(0=bt_comparison_operator,register_operand:SI:"r",register_operand:QI:"r",const_int:1,const_int:0),NULL:NULL:"",pc,reg(CC:FLAGS_REG));
root.1.2.1.1.mode:=SI;
root.1.2.1.1.1.mode:=SI;
}
cmd_spec.in
{:
  "TARGET_USE_BT || optimize_function_for_size_p (cfun)"
  "#"
  "&& 1"
:}
instantiates.out set_compare_zero_extract_set_if_then_else_match_op_dup_label_ref
{
        root (reg(CCC:FLAGS_REG),duplicate 1,const_int:1,duplicate 2,const_int:0,pc,(<0>,reg(CCC:FLAGS_REG),const_int:0),duplicate 3,pc);
root.1.2.mode:=CCC;
root.1.2.1.mode:=SI;
}
cmd_spec.out
{:
 {
  operands[2] = simplify_gen_subreg (SImode, operands[2], QImode, 0);

  PUT_CODE (operands[0], reverse_condition (GET_CODE (operands[0])));
}
:}

{:
;; avoid useless masking of bit offset operand
:}

abstract set_if_then_else_match_operator_and_lshiftrt_subreg_and_label_ref_clobber extends set_if_then_else_match_operator_and_lshiftrt_label_ref_clobber
{
        root.1.2.1.1.1.2:=subreg;
        root.1.2.1.1.1.2.1:=and;
}

concrete *jcc_btsi_mask_1.insn_and_split instantiates.in set_if_then_else_match_operator_and_lshiftrt_subreg_and_label_ref_clobber
{
        root (pc,(0=bt_comparison_operator,register_operand:SI:"r",register_operand:SI:"r",const_int_operand:SI:"n" ,<0>,const_int:1,const_int:0),NULL:NULL:"",pc,reg(CC:FLAGS_REG));
root.1.2.1.1.mode:=SI;
root.1.2.1.1.1.mode:=SI;
root.1.2.1.1.1.2.1.mode:=SI;
root.1.2.1.1.1.2.mode:=QI;
}
cmd_spec.in
{:
  "(TARGET_USE_BT || optimize_function_for_size_p (cfun))
   && (INTVAL (operands[3]) & 0x1f) == 0x1f"
  "#"
  "&& 1"
:}
instantiates.out set_compare_zero_extract_set_if_then_else_match_op_dup_label_ref
{
        root (reg(CCC:FLAGS_REG),duplicate 1,const_int:1,duplicate 2,const_int:0,pc,(<0>,reg(CCC:FLAGS_REG),const_int:0),duplicate 4,pc);
root.1.2.mode:=CCC;
root.1.2.1.mode:=SI;
}
cmd_spec.out
{:
  "PUT_CODE (operands[0], reverse_condition (GET_CODE (operands[0])));"
:}

{:
;; Define combination compare-and-branch fp compare instructions to help
;; combine.
:}


abstract set_if_then_else_match_operator_clobber_clobber extends sequence
{
        root.1:=set_if_then_else_match_operator;
        root.2:=clobber;
        root.3:=clobber;
}

abstract set_if_then_else_match_operator_clobber_clobber_clobber extends set_if_then_else_match_operator_clobber_clobber
{
        root.4:=clobber;
}

abstract set_if_then_else_match_operator_label_ref_clobber_clobber_clobber extends sequence
{
        root.1:=set_if_then_else_match_operator_label_ref;
        root.2:=clobber;
        root.3:=clobber;
        root.4:=clobber;
}

abstract set_if_then_else_match_operator_label_ref2_clobber_clobber_clobber extends sequence
{
        root.1:=set_if_then_else_match_operator_label_ref2;
        root.2:=clobber;
        root.3:=clobber;
        root.4:=clobber;
}


concrete *fp_jcc_1_387.insn instantiates set_if_then_else_match_operator_label_ref_clobber_clobber_clobber
{
        root (pc,(0=ix86_fp_comparison_operator,register_operand:NULL:"f",nonimmediate_operand:NULL:"fm"),NULL:NULL:"",pc,reg(CCFP:FPSR_REG),reg(CCFP:FLAGS_REG),4=HI:"=a");
}
{:
     "TARGET_80387
   && (GET_MODE (operands[1]) == SFmode || GET_MODE (operands[1]) == DFmode)
   && GET_MODE (operands[1]) == GET_MODE (operands[2])
   && SELECT_CC_MODE (GET_CODE (operands[0]),
                      operands[1], operands[2]) == CCFPmode
   && !TARGET_CMOVE"
  "#"
:}

concrete *fp_jcc_1r_387.insn instantiates set_if_then_else_match_operator_label_ref2_clobber_clobber_clobber
{
  root (pc,(0=ix86_fp_comparison_operator,register_operand:NULL:"f",nonimmediate_operand:NULL:"fm"),pc,NULL:NULL:"",reg(CCFP:FPSR_REG),reg(CCFP:FLAGS_REG),4=HI:"=a");
}
{:
  "TARGET_80387
   && (GET_MODE (operands[1]) == SFmode || GET_MODE (operands[1]) == DFmode)
   && GET_MODE (operands[1]) == GET_MODE (operands[2])
   && SELECT_CC_MODE (GET_CODE (operands[0]),
                      operands[1], operands[2]) == CCFPmode
   && !TARGET_CMOVE"
  "#"
:}

{:
(define_insn "*fp_jcc_2_387"
  [(set (pc)
    (if_then_else (match_operator 0 "ix86_fp_comparison_operator"
            [(match_operand 1 "register_operand" "f")
             (match_operand 2 "register_operand" "f")])
      (label_ref (match_operand 3 "" ""))
      (pc)))
   (clobber (reg:CCFP FPSR_REG))
   (clobber (reg:CCFP FLAGS_REG))
   (clobber (match_scratch:HI 4 "=a"))]
  "X87_FLOAT_MODE_P (GET_MODE (operands[1]))
   && GET_MODE (operands[1]) == GET_MODE (operands[2])
   && !TARGET_CMOVE"
  "#")

(define_insn "*fp_jcc_2r_387"
  [(set (pc)
    (if_then_else (match_operator 0 "ix86_fp_comparison_operator"
            [(match_operand 1 "register_operand" "f")
             (match_operand 2 "register_operand" "f")])
      (pc)
      (label_ref (match_operand 3 "" ""))))
   (clobber (reg:CCFP FPSR_REG))
   (clobber (reg:CCFP FLAGS_REG))
   (clobber (match_scratch:HI 4 "=a"))]
  "X87_FLOAT_MODE_P (GET_MODE (operands[1]))
   && GET_MODE (operands[1]) == GET_MODE (operands[2])
   && !TARGET_CMOVE"
  "#")

(define_insn "*fp_jcc_3_387"
  [(set (pc)
    (if_then_else (match_operator 0 "ix86_fp_comparison_operator"
            [(match_operand 1 "register_operand" "f")
             (match_operand 2 "const0_operand" "")])
      (label_ref (match_operand 3 "" ""))
      (pc)))
   (clobber (reg:CCFP FPSR_REG))
   (clobber (reg:CCFP FLAGS_REG))
   (clobber (match_scratch:HI 4 "=a"))]
  "X87_FLOAT_MODE_P (GET_MODE (operands[1]))
   && GET_MODE (operands[1]) == GET_MODE (operands[2])
   && SELECT_CC_MODE (GET_CODE (operands[0]),
              operands[1], operands[2]) == CCFPmode
   && !TARGET_CMOVE"
  "#")

:}

concrete .split instantiates.in set_if_then_else_match_operator_clobber_clobber
{
   root (pc,(0=ix86_fp_comparison_operator,register_operand:NULL:"",nonimmediate_operand:NULL:""),NULL:NULL:"",NULL:NULL:"",reg(CCFP:FPSR_REG),reg(CCFP:FLAGS_REG));
}
cmd_spec.in
{:
  "reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
 {
  ix86_split_fp_branch (GET_CODE (operands[0]), operands[1], operands[2],
                        operands[3], operands[4], NULL_RTX, NULL_RTX);
  DONE;
}
:}


concrete .split instantiates.in set_if_then_else_match_operator_clobber_clobber_clobber
{
        root (pc,(0=ix86_fp_comparison_operator,register_operand:NULL:"",general_operand:NULL:""),NULL:NULL:"",NULL:NULL:"",reg(CCFP:FPSR_REG),reg(CCFP:FLAGS_REG),5=HI:"=a");
}
cmd_spec.in
{:
  "reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
  {
  ix86_split_fp_branch (GET_CODE (operands[0]), operands[1], operands[2],
                        operands[3], operands[4], operands[5], NULL_RTX);
  DONE;
}
:}


{:
;; The order of operands in *fp_jcc_4_387 is forced by combine in
;; simplify_comparison () function. Float operator is treated as RTX_OBJ
;; with a precedence over other operators and is always put in the first
;; place. Swap condition and operands to match ficom instruction.
:}

abstract set_if_then_else_match_operator_match_operator_label_ref_clobber_clobber_clobber extends set_if_then_else_match_operator_label_ref_clobber_clobber_clobber
{
    root.1.2.1.1:=match_operator;
}

{:
(define_insn "*fp_jcc_4_<mode>_387"
  [(set (pc)
    (if_then_else
      (match_operator 0 "ix86_swapped_fp_comparison_operator"
        [(match_operator 1 "float_operator"
          [(match_operand:SWI24 2 "nonimmediate_operand" "m,?r")])
         (match_operand 3 "register_operand" "f,f")])
      (label_ref (match_operand 4 "" ""))
      (pc)))
   (clobber (reg:CCFP FPSR_REG))
   (clobber (reg:CCFP FLAGS_REG))
   (clobber (match_scratch:HI 5 "=a,a"))]
  "X87_FLOAT_MODE_P (GET_MODE (operands[3]))
   && (TARGET_USE_<MODE>MODE_FIOP || optimize_function_for_size_p (cfun))
   && GET_MODE (operands[1]) == GET_MODE (operands[3])
   && ix86_fp_compare_mode (swap_condition (GET_CODE (operands[0]))) == CCFPmode
   && !TARGET_CMOVE"
  "#")
:}

abstract set_label_ref extends set
{
    root.2:=label_ref;
}

abstract set_if_then_else_match_operator_match_operator_clobber_clobber_clobber extends set_if_then_else_match_operator_clobber_clobber_clobber
{
    root.1.2.1.1:=match_operator;
}

{:
(define_split
  [(set (pc)
    (if_then_else
      (match_operator 0 "ix86_swapped_fp_comparison_operator"
        [(match_operator 1 "float_operator"
          [(match_operand:SWI24 2 "memory_operand" "")])
         (match_operand 3 "register_operand" "")])
      (match_operand 4 "" "")
      (match_operand 5 "" "")))
   (clobber (reg:CCFP FPSR_REG))
   (clobber (reg:CCFP FLAGS_REG))
   (clobber (match_scratch:HI 6 "=a"))]
  "reload_completed"
  [(const_int 0)]
{
  operands[7] = gen_rtx_FLOAT (GET_MODE (operands[1]), operands[2]);

  ix86_split_fp_branch (swap_condition (GET_CODE (operands[0])),
            operands[3], operands[7],
            operands[4], operands[5], operands[6], NULL_RTX);
  DONE;
})
:}

{:
;; %%% Kill this when reload knows how to do it.
(define_split
  [(set (pc)
    (if_then_else
      (match_operator 0 "ix86_swapped_fp_comparison_operator"
        [(match_operator 1 "float_operator"
          [(match_operand:SWI24 2 "register_operand" "")])
         (match_operand 3 "register_operand" "")])
      (match_operand 4 "" "")
      (match_operand 5 "" "")))
   (clobber (reg:CCFP FPSR_REG))
   (clobber (reg:CCFP FLAGS_REG))
   (clobber (match_scratch:HI 6 "=a"))]
  "reload_completed"
  [(const_int 0)]
{
  operands[7] = ix86_force_to_memory (GET_MODE (operands[2]), operands[2]);
  operands[7] = gen_rtx_FLOAT (GET_MODE (operands[1]), operands[7]);

  ix86_split_fp_branch (swap_condition (GET_CODE (operands[0])),
            operands[3], operands[7],
            operands[4], operands[5], operands[6], operands[2]);
  DONE;
})
:}

{:

;; Unconditional and other jump instructions
:}

concrete  jump.insn instantiates set_label_ref
{
	root (pc,NULL:NULL:"");
}
{:
  ""
  "jmp\t%l0"
  [(set_attr "type" "ibr")
   (set (attr "length")
       (if_then_else (and (ge (minus (match_dup 0) (pc))
                  (const_int -126))
                  (lt (minus (match_dup 0) (pc))
                  (const_int 128)))
         (const_int 2)
         (const_int 5)))
   (set_attr "modrm" "0")]
:}

concrete indirect_jump.exp instantiates set
{
	root (pc,indirect_branch_operand:NULL:"");
}
{:
:}

concrete *indirect_jump.insn instantiates set
{
	root (pc,indirect_branch_operand:P:"rw");
}
{:
  ""
  "jmp\t%A0"
  [(set_attr "type" "ibr")
   (set_attr "length_immediate" "0")]
:}

abstract use_label_ref extends use
{
    root.1:=label_ref;
}

abstract parallel_set_use_label_ref extends parallel
{
    root.1:=set;
    root.2:=use_label_ref;
}

abstract set_use_label_ref extends sequence
{
    root.1:=set;
    root.2:=use_label_ref;
}

concrete tablejump.exp instantiates parallel_set_use_label_ref
{
	root (pc,indirect_branch_operand:NULL:"",NULL:NULL:"");
}
{:
  ""
{
  /* In PIC mode, the table entries are stored GOT (32-bit) or PC (64-bit)
     relative.  Convert the relative address to an absolute address.  */
  if (flag_pic)
    {
      rtx op0, op1;
      enum rtx_code code;

      /* We can't use @GOTOFF for text labels on VxWorks;
     see gotoff_operand.  */
      if (TARGET_64BIT || TARGET_VXWORKS_RTP)
    {
      code = PLUS;
      op0 = operands[0];
      op1 = gen_rtx_LABEL_REF (Pmode, operands[1]);
    }
      else if (TARGET_MACHO || HAVE_AS_GOTOFF_IN_DATA)
    {
      code = PLUS;
      op0 = operands[0];
      op1 = pic_offset_table_rtx;
    }
      else
    {
      code = MINUS;
      op0 = pic_offset_table_rtx;
      op1 = operands[0];
    }

      operands[0] = expand_simple_binop (Pmode, code, op0, op1, NULL_RTX, 0,
                     OPTAB_DIRECT);
    }
	else if (TARGET_X32)
	    operands[0] = convert_memory_address (Pmode, operands[0]);

}
:}

concrete *tablejump_1.insn instantiates set_use_label_ref
{
	root (pc,indirect_branch_operand:P:"rw",NULL:NULL:"");
}
{:
  ""
  "jmp\t%A0"
  [(set_attr "type" "ibr")
   (set_attr "length_immediate" "0")]
:}
{:

;; Convert setcc + movzbl to xor + setcc if operands don't overlap.
:}

abstract set_set_match_operator_set_zero_extend extends sequence
{
    root.1:=set;
    root.2:=set_match_operator;
    root.3:=set;
    root.3.2:=zero_extend;
}

abstract set_set_strict_low_part extends sequence
{
    root.1:=set;
    root.2:=set_strict_low_part1;
}

concrete .peep2 instantiates.in set_set_match_operator_set_zero_extend
{
    root (reg(NULL:FLAGS_REG),NULL:NULL:"",register_operand:QI:"",(2=ix86_comparison_operator,reg(NULL:FLAGS_REG),const_int:0),q_regs_operand:NULL:"",duplicate 1);
root.2.2.mode:=QI;
}
cmd_spec.in
{:
  "(peep2_reg_dead_p (3, operands[1])
    || operands_match_p (operands[1], operands[3]))
   && ! reg_overlap_mentioned_p (operands[3], operands[0])"
:}
instantiates.out set_set_strict_low_part
{
	root (duplicate 4,duplicate 0,duplicate 5,duplicate 2);
}
cmd_spec.out
{:
  {
  operands[4] = gen_rtx_REG (GET_MODE (operands[0]), FLAGS_REG);
  operands[5] = gen_lowpart (QImode, operands[3]);
  ix86_expand_clear (operands[3]);
}
:}

{:
;; Similar, but match zero_extendhisi2_and, which adds a clobber.
:}

abstract set_set_match_operator_parallel_set_zero_extend_clobber extends set_set_match_operator_set_zero_extend
{
    root.3:=parallel;
    root.3.1:=set;
    root.3.1.2:=zero_extend;
    root.3.2:=clobber;


}


concrete .peep2 instantiates.in set_set_match_operator_parallel_set_zero_extend_clobber
{
    root (reg(NULL:FLAGS_REG),NULL:NULL:"",register_operand:QI:"",(2=ix86_comparison_operator,reg(NULL:FLAGS_REG),const_int:0),q_regs_operand:NULL:"",duplicate 1,reg(CC:FLAGS_REG));
root.2.2.mode:=QI;
}
cmd_spec.in
{:
  "(peep2_reg_dead_p (3, operands[1])
    || operands_match_p (operands[1], operands[3]))
   && ! reg_overlap_mentioned_p (operands[3], operands[0])"
:}
instantiates.out set_set_strict_low_part
{
	root (duplicate 4,duplicate 0,duplicate 5,duplicate 2);
}
cmd_spec.out
{:
  {
  operands[4] = gen_rtx_REG (GET_MODE (operands[0]), FLAGS_REG);
  operands[5] = gen_lowpart (QImode, operands[3]);
  ix86_expand_clear (operands[3]);
}
:}

{:

;; Call instructions.

;; The predicates normally associated with named expanders are not properly
;; checked for calls.  This is a bug in the generic code, but it isn't that
;; easy to fix.  Ignore it for now and be prepared to fix things up.

;; P6 processors will jump to the address after the decrement when %esp
;; is used as a call operand, so they will execute return address as a code.
;; See Pentium Pro errata 70, Pentium 2 errata A33 and Pentium 3 errata E17.

;; Register constraint for call instruction.
(define_mode_attr c [(SI "l") (DI "r")])

;; Call subroutine returning no value.
:}

abstract call_use extends sequence
{
    root.1:=call;
    root.2:=use;
}

concrete call.exp instantiates call_use
{
	root (NULL:QI:"",NULL:NULL:"",NULL:NULL:"");
}
{:
  ""
{
  ix86_expand_call (NULL, operands[0], operands[1], operands[2], NULL, false);
  DONE;
}
:}

concrete sibcall.exp overrides call.exp
{
    root.1.1.mode:=QI;
}
{:
""
{
  ix86_expand_call (NULL, operands[0], operands[1], operands[2], NULL, true);
  DONE;
}
:}

abstract call_mem_unspec extends sequence
{
    root.1:=call;
    root.1.1:=mem;
    root.2:=unspec;
}

concrete *call_vzeroupper.insn_and_split instantiates.in call_mem_unspec
{
    root (call_insn_operand:P:"<c>zw",NULL:NULL:"",(const_int_operand:NULL:"" ,<UNSPEC_CALL_NEEDS_VZEROUPPER>));
root.1.1.mode:=QI;
}
cmd_spec.in
{:
  "TARGET_VZEROUPPER && !SIBLING_CALL_P (insn)"
  "#"
  "&& reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
  "ix86_split_call_vzeroupper (curr_insn, operands[2]); DONE;"
[(set_attr "type" "call")]
:}

abstract call_mem extends call
{
    root.1:=mem;
}

concrete *call.insn instantiates call_mem
{
	root (call_insn_operand:P:"<c>zw",NULL:NULL:"");
    root.1.mode:=QI;
}
{:
    "!SIBLING_CALL_P (insn)"
  "* return ix86_output_call_insn (insn, operands[0]);"
  [(set_attr "type" "call")]
:}

abstract call_mem_unspec_clobber12_unspec extends sequence
{
    root.1:=call_mem;
    root.2:=unspec;
    root.3:=clobber;
    root.4:=clobber;
    root.5:=clobber;
    root.6:=clobber;
    root.7:=clobber;
    root.8:=clobber;
    root.9:=clobber;
    root.10:=clobber;
    root.11:=clobber;
    root.12:=clobber;
    root.13:=clobber;
    root.14:=clobber;
    root.15:=unspec;
}



concrete *call_rex64_ms_sysv_vzeroupper.insn_and_split instantiates.in call_mem_unspec_clobber12_unspec
{
    root (call_insn_operand:DI:"rzw",NULL:NULL:"",(const_int:0 ,<UNSPEC_MS_TO_SYSV_CALL>),reg(TI:XMM6_REG),reg(TI:XMM7_REG),reg(TI:XMM8_REG),reg(TI:XMM9_REG),reg(TI:XMM10_REG),reg(TI:XMM11_REG),reg(TI:XMM12_REG),reg(TI:XMM13_REG),reg(TI:XMM14_REG),reg(TI:XMM15_REG),reg(DI:SI_REG),reg(DI:DI_REG),(const_int_operand:NULL:"" ,<UNSPEC_CALL_NEEDS_VZEROUPPER>));
root.1.1.mode:=QI;
}
cmd_spec.in
{:
  "TARGET_VZEROUPPER && TARGET_64BIT && !SIBLING_CALL_P (insn)"
  "#"
  "&& reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
  "ix86_split_call_vzeroupper (curr_insn, operands[2]); DONE;"
[(set_attr "type" "call")]
:}


abstract call_mem_unspec_clobber12 extends sequence
{
    root.1:=call;
    root.1.1:=mem;
    root.2:=unspec;
    root.3:=clobber;
    root.4:=clobber;
    root.5:=clobber;
    root.6:=clobber;
    root.7:=clobber;
    root.8:=clobber;
    root.9:=clobber;
    root.10:=clobber;
    root.11:=clobber;
    root.12:=clobber;
    root.13:=clobber;
    root.14:=clobber;
}


concrete *call_rex64_ms_sysv.insn instantiates call_mem_unspec_clobber12
{
    root (call_insn_operand:DI:"rzw",NULL:NULL:"",(const_int:0,<UNSPEC_MS_TO_SYSV_CALL>),reg(TI:XMM6_REG),reg(TI:XMM7_REG),reg(TI:XMM8_REG),reg(TI:XMM9_REG),reg(TI:XMM10_REG),reg(TI:XMM11_REG),reg(TI:XMM12_REG),reg(TI:XMM13_REG),reg(TI:XMM14_REG),reg(TI:XMM15_REG),reg(DI:SI_REG),reg(DI:DI_REG));
    root.1.1.mode:=QI;
}
{:
  "TARGET_64BIT && !SIBLING_CALL_P (insn)"
  " * return ix86_output_call_insn (insn, operands[0]); "
  [(set_attr "type" "call")]
:}


concrete *sibcall_vzeroupper.insn_and_split instantiates.in call_mem_unspec
{
    root (sibcall_insn_operand:P:"Uz",NULL:NULL:"",(const_int_operand:NULL:"" ,<UNSPEC_CALL_NEEDS_VZEROUPPER>));
root.1.1.mode:=QI;
}
cmd_spec.in
{:
  "TARGET_VZEROUPPER && SIBLING_CALL_P (insn)"
  "#"
  "&& reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
  "ix86_split_call_vzeroupper (curr_insn, operands[2]); DONE;"
[(set_attr "type" "call")]
:}

abstract call_mem1 extends call{
	root.1:=mem;
}

concrete *sibcall.insn instantiates call_mem1
{
	root (0=sibcall_insn_operand:P:"Uz",1=NULL:NULL:"");
	root.1.mode:=QI;
}
{:
  "SIBLING_CALL_P (insn)"
  "* return ix86_output_call_insn (insn, operands[0]);"
  [(set_attr "type" "call")]
:}

abstract parallel_call_set_plus2 extends parallel
{
	root.1:=call;
	root.2:=set_plus2;
}


concrete call_pop.exp instantiates parallel_call_set_plus2
{
	root ((0=NULL:QI:"", 1=NULL:SI:"", reg(SI:SP_REG),
		reg(SI:SP_REG), 3=NULL:SI:""));
	root.2.2.mode:=SI;
}
{:
  "!TARGET_64BIT"
{
  ix86_expand_call (NULL, operands[0], operands[1],
		    operands[2], operands[3], false);
  DONE;
}
:}

abstract call_mem1_set_plus2_unspec extends sequence
{
	root.1:=call_mem1;
	root.2:=set_plus2;
	root.3:=unspec;
}


concrete *call_pop_vzeroupper.insn_and_split instantiates.in call_mem1_set_plus2_unspec
{
	root (0=call_insn_operand:SI:"lzm",1=NULL:SI:"",reg(SI:SP_REG),reg(SI:SP_REG), 2=immediate_operand:SI:"i",(3=const_int_operand:NULL:"", <UNSPEC_CALL_NEEDS_VZEROUPPER>));
	root.1.1.mode:=QI;
	root.2.2.mode:=SI;
}
cmd_spec.in
{:
  "TARGET_VZEROUPPER && !TARGET_64BIT && !SIBLING_CALL_P (insn)"
  "#"
  "&& reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
  "ix86_split_call_vzeroupper (curr_insn, operands[3]); DONE;"
  [(set_attr "type" "call")]
:}

abstract call_mem1_set_plus2 extends sequence
{
	root.1:=call_mem1;
	root.2:=set_plus2;
}

concrete *call_pop.insn instantiates call_mem1_set_plus2
{
	root (0=call_insn_operand:SI:"lzm",1=NULL:NULL:"",reg(SI:SP_REG), reg(SI:SP_REG), 2=immediate_operand:SI:"i");
	root.1.1.mode:=QI;
	root.2.2.mode:=SI;
}
{:
  "!TARGET_64BIT && !SIBLING_CALL_P (insn)"
  "* return ix86_output_call_insn (insn, operands[0]);"
  [(set_attr "type" "call")]
:}

concrete *sibcall_pop_vzeroupper.insn_and_split instantiates.in call_mem1_set_plus2_unspec
{
	root (0=sibcall_insn_operand:SI:"Uz",1=NULL:NULL:"",reg(SI:SP_REG), reg(SI:SP_REG),2=immediate_operand:SI:"i",(3=const_int_operand:NULL:"", <UNSPEC_CALL_NEEDS_VZEROUPPER>));
	root.1.1.mode:=QI;
	root.2.2.mode:=SI;
}
cmd_spec.in
{:
  "TARGET_VZEROUPPER && !TARGET_64BIT && SIBLING_CALL_P (insn)"
  "#"
  "&& reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
  "ix86_split_call_vzeroupper (curr_insn, operands[3]); DONE;"
  [(set_attr "type" "call")]
:}

concrete *sibcall_pop.insn instantiates call_mem1_set_plus2
{
	root (0=sibcall_insn_operand:SI:"Uz",1=NULL:NULL:"",reg(SI:SP_REG), reg(SI:SP_REG), 2=immediate_operand:SI:"i");
	root.1.1.mode:=QI;
	root.2.2.mode:=SI;
}
{:
  "!TARGET_64BIT && SIBLING_CALL_P (insn)"
  "* return ix86_output_call_insn (insn, operands[0]);"
  [(set_attr "type" "call")]
:}

{:
;; Call subroutine, returning value in operand 0
:}

abstract set_call2_use extends sequence
{
	root.1:=set;
	root.1.2:=call;
	root.2:=use;
}


concrete call_value.exp instantiates set_call2_use
{
	root (0=NULL:NULL:"",1=NULL:QI:"",2=NULL:NULL:"",3=NULL:NULL:"");
}
{:
  ""
{
  ix86_expand_call (operands[0], operands[1], operands[2],
		    operands[3], NULL, false);
  DONE;
}
:}

concrete sibcall_value.exp overrides call_value.exp
{
    root.1.predicate:=NULL;
}
{:
  ""
{
  ix86_expand_call (operands[0], operands[1], operands[2],
		    operands[3], NULL, true);
  DONE;
}
:}

abstract set_call2 extends set
{
	root.2:=call;
}

abstract set_call2_mem1 extends set_call2
{
	root.2.1:=mem;
}

abstract set_call2_mem1_unspec extends sequence
{
	root.1:=set_call2_mem1;
	root.2:=unspec;
}

concrete *call_value_vzeroupper.insn_and_split instantiates.in set_call2_mem1_unspec
{
	root (0=NULL:NULL:"",1=call_insn_operand:P:"<c>zw",2=NULL:NULL:"",(3=const_int_operand:NULL:"",<UNSPEC_CALL_NEEDS_VZEROUPPER>));
	root.1.2.1.mode:=QI;
}
cmd_spec.in
{:
  "TARGET_VZEROUPPER && !SIBLING_CALL_P (insn)"
  "#"
  "&& reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
  "ix86_split_call_vzeroupper (curr_insn, operands[3]); DONE;"
  [(set_attr "type" "callv")]
:}


concrete *call_value.insn instantiates set_call2_mem1
{
	root (0=NULL:NULL:"", 1=call_insn_operand:P:"<c>zw",2=NULL:NULL:"");
	root.2.1.mode:=QI;
}
{:
  "!SIBLING_CALL_P (insn)"
  "* return ix86_output_call_insn (insn, operands[1]);"
  [(set_attr "type" "callv")]
:}

concrete *sibcall_value_vzeroupper.insn_and_split instantiates.in set_call2_mem1_unspec
{
	root (0=NULL:NULL:"", 1=sibcall_insn_operand:P:"Uz", 2=NULL:NULL:"", (3=const_int_operand:NULL:"",<UNSPEC_CALL_NEEDS_VZEROUPPER>));
	root.1.2.1.mode:=QI;
}
cmd_spec.in
{:
  "TARGET_VZEROUPPER && SIBLING_CALL_P (insn)"
  "#"
  "&& reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
  "ix86_split_call_vzeroupper (curr_insn, operands[3]); DONE;"
  [(set_attr "type" "callv")]
:}

concrete *sibcall_value.insn instantiates set_call2_mem1
{
	root (0=NULL:NULL:"", 1=sibcall_insn_operand:P:"Uz", 2=NULL:NULL:"");
	root.2.1.mode:=QI;
}
{:
  "SIBLING_CALL_P (insn)"
  "* return ix86_output_call_insn (insn, operands[1]);"
  [(set_attr "type" "callv")]
:}

abstract set_call2_mem1_unspec_clobber12_unspec extends sequence
{
	root.1:=set_call2_mem1;
	root.2:=unspec;
	root.3:=clobber;
	root.4:=clobber;
	root.5:=clobber;
	root.6:=clobber;
	root.7:=clobber;
	root.8:=clobber;
	root.9:=clobber;
	root.10:=clobber;
	root.11:=clobber;
	root.12:=clobber;
	root.13:=clobber;
	root.14:=clobber;
	root.15:=unspec;
}
concrete *call_value_rex64_ms_sysv_vzeroupper.insn_and_split instantiates.in set_call2_mem1_unspec_clobber12_unspec
{
	root (0=NULL:NULL:"", 1=call_insn_operand:DI:"rzw", 2=NULL:NULL:"", (const_int:0,<UNSPEC_MS_TO_SYSV_CALL>), reg(TI:XMM6_REG), reg(TI:XMM7_REG),  reg(TI:XMM8_REG), reg(TI:XMM9_REG), reg(TI:XMM10_REG), reg(TI:XMM11_REG), reg(TI:XMM12_REG), reg(TI:XMM13_REG), reg(TI:XMM14_REG), reg(TI:XMM15_REG), reg(DI:SI_REG), reg(DI:DI_REG), (3=const_int_operand:NULL:"", <UNSPEC_CALL_NEEDS_VZEROUPPER>));

	root.1.2.1.mode:=QI;
}
cmd_spec.in
{:
	"TARGET_VZEROUPPER && TARGET_64BIT && !SIBLING_CALL_P (insn)"
	"#"
	"&& reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
  "ix86_split_call_vzeroupper (curr_insn, operands[3]); DONE;"
  [(set_attr "type" "callv")]
:}

abstract set_call2_mem1_unspec_clobber12 extends sequence
{
	root.1:=set_call2_mem1;
	root.2:=unspec;
	root.3:=clobber;
	root.4:=clobber;
	root.5:=clobber;
	root.6:=clobber;
	root.7:=clobber;
	root.8:=clobber;
	root.9:=clobber;
	root.10:=clobber;
	root.11:=clobber;
	root.12:=clobber;
	root.13:=clobber;
	root.14:=clobber;
}
concrete *call_value_rex64_ms_sysv.insn instantiates set_call2_mem1_unspec_clobber12
{
	root (0=NULL:NULL:"",1=call_insn_operand:DI:"rzw",2=NULL:NULL:"",(const_int:0,<UNSPEC_MS_TO_SYSV_CALL>),reg(TI:XMM6_REG),reg(TI:XMM7_REG),reg(TI:XMM8_REG),reg(TI:XMM9_REG),reg(TI:XMM10_REG),reg(TI:XMM11_REG),reg(TI:XMM12_REG),reg(TI:XMM13_REG),reg(TI:XMM14_REG),reg(TI:XMM15_REG),reg(DI:SI_REG), reg(DI:DI_REG));
	root.1.2.1.mode:=QI;
}
{:
  "TARGET_64BIT && !SIBLING_CALL_P (insn)"
  "* return ix86_output_call_insn (insn, operands[1]);"
  [(set_attr "type" "callv")]
:}

abstract parallel_set_call2_set_plus2 extends parallel
{
	root.1:=set_call2;
	root.2:=set_plus2;
}


concrete call_value_pop.exp instantiates parallel_set_call2_set_plus2
{
	root (0=NULL:NULL:"", 1=NULL:QI:"", 2=NULL:SI:"",
		reg(SI:SP_REG), reg(SI:SP_REG), 4=NULL:SI:"");
	root.2.2.mode:=SI;
}
{:
  "!TARGET_64BIT"
{
  ix86_expand_call (operands[0], operands[1], operands[2],
		    operands[3], operands[4], false);
  DONE;
}
:}

abstract set_call2_mem1_set_plus2_unspec extends sequence
{
	root.1:=set_call2_mem1;
	root.2:=set_plus2;
	root.3:=unspec;
}


concrete *call_value_pop_vzeroupper.insn_and_split instantiates.in set_call2_mem1_set_plus2_unspec
{
	root (0=NULL:NULL:"", 1=call_insn_operand:SI:"lzm", 
		2=NULL:NULL:"", reg(SI:SP_REG), reg(SI:SP_REG), 3=immediate_operand:SI:"i",
		(4=const_int_operand:NULL:"", <UNSPEC_CALL_NEEDS_VZEROUPPER>));
	root.1.2.1.mode:=QI;
	root.2.2.mode:=SI;
}
cmd_spec.in
{:
  "TARGET_VZEROUPPER && !TARGET_64BIT && !SIBLING_CALL_P (insn)"
  "#"
  "&& reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
  "ix86_split_call_vzeroupper (curr_insn, operands[4]); DONE;"
  [(set_attr "type" "callv")]
:}

abstract set_call2_mem1_set_plus2  extends sequence
{
	root.1:=set_call2_mem1;
	root.2:=set_plus2;
}

concrete *call_value_pop.insn instantiates set_call2_mem1_set_plus2
{
	root (0=NULL:NULL:"", 1=call_insn_operand:SI:"lzm",
		2=NULL:NULL:"", reg(SI:SP_REG), reg(SI:SP_REG), 
		3=immediate_operand:SI:"i");
	root.1.2.1.mode:=QI;
	root.2.2.mode:=SI;	
}
{:
  "!TARGET_64BIT && !SIBLING_CALL_P (insn)"
  "* return ix86_output_call_insn (insn, operands[1]);"
  [(set_attr "type" "callv")]
:}

concrete *sibcall_value_pop_vzeroupper.insn_and_split instantiates.in set_call2_mem1_set_plus2_unspec
{
	root (0=NULL:NULL:"", 
		1=sibcall_insn_operand:SI:"Uz", 2=NULL:NULL:"",
		reg(SI:SP_REG), reg(SI:SP_REG), 3=immediate_operand:SI:"i",
		(4=const_int_operand:NULL:"",<UNSPEC_CALL_NEEDS_VZEROUPPER>));
	root.1.2.1.mode:=QI;
	root.2.2.mode:=SI;
}
cmd_spec.in
{:
  "TARGET_VZEROUPPER && !TARGET_64BIT && SIBLING_CALL_P (insn)"
  "#"
  "&& reload_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
  "ix86_split_call_vzeroupper (curr_insn, operands[4]); DONE;"
  [(set_attr "type" "callv")]
:}

concrete *sibcall_value_pop.insn instantiates set_call2_mem1_set_plus2
{
	root (0=NULL:NULL:"", 1=sibcall_insn_operand:SI:"Uz",
		2=NULL:NULL:"", reg(SI:SP_REG), reg(SI:SP_REG), 
		3=immediate_operand:SI:"i");
	root.1.2.1.mode:=QI;
	root.2.2.mode:=SI;
}
{:
  "!TARGET_64BIT && SIBLING_CALL_P (insn)"
  "* return ix86_output_call_insn (insn, operands[1]);"
  [(set_attr "type" "callv")]
:}

{:
;; Call subroutine returning any type.
;; TODO MatchOperand in parallel/sequence
:}

abstract parallel_call_sequence_sequence extends parallel
{
	root.1:=call;
	root.2:=sequence;
	root.3:=sequence;
}

{:
(define_expand "untyped_call"
  [(parallel [(call (match_operand 0 "" "")
            (const_int 0))
          (match_operand 1 "" "")
          (match_operand 2 "" "")])]
  ""
{
  int i;

  /* In order to give reg-stack an easier job in validating two
     coprocessor registers as containing a possible return value,
     simply pretend the untyped call returns a complex long double
     value.

     We can't use SSE_REGPARM_MAX here since callee is unprototyped
     and should have the default ABI.  */

  ix86_expand_call ((TARGET_FLOAT_RETURNS_IN_80387
             ? gen_rtx_REG (XCmode, FIRST_FLOAT_REG) : NULL),
            operands[0], const0_rtx,
            GEN_INT ((TARGET_64BIT
                  ? (ix86_abi == SYSV_ABI
                 ? X86_64_SSE_REGPARM_MAX
                 : X86_64_MS_SSE_REGPARM_MAX)
                  : X86_32_SSE_REGPARM_MAX)
                     - 1),
            NULL, false);

  for (i = 0; i < XVECLEN (operands[2], 0); i++)
    {
      rtx set = XVECEXP (operands[2], 0, i);
      emit_move_insn (SET_DEST (set), SET_SRC (set));
    }

  /* The optimizer does not know that the call sets the function value
     registers we stored in the result block.  We avoid problems by
     claiming that all hard registers are used and clobbered at this
     point.  */
  emit_insn (gen_blockage ());

  DONE;
})
:}

{:

;; Prologue and epilogue instructions

;; UNSPEC_VOLATILE is considered to use and clobber all hard registers and
;; all of memory.  This blocks insns from being moved across this point.
:}

concrete blockage.insn instantiates unspec_volatile
{
	root ((const_int:0, <UNSPECV_BLOCKAGE>));
}
{:
  ""
  ""
  [(set_attr "length" "0")]
:}

{:
;; Do not schedule instructions accessing memory across this point.
:}

concrete memory_blockage.exp instantiates set_unspec2
{
	root (duplicate 0, (duplicate 0, <UNSPEC_MEMORY_BLOCKAGE>));
	root.2.mode:=BLK;
}
{:
  ""
{
  operands[0] = gen_rtx_MEM (BLKmode, gen_rtx_SCRATCH (Pmode));
  MEM_VOLATILE_P (operands[0]) = 1;
}
:}

concrete *memory_blockage.insn overrides memory_blockage.exp
{
	root.1:=NULL:BLK:"";
}
{:
  ""
  ""
  [(set_attr "length" "0")]
:}
{:
;; As USE insns aren't meaningful after reload, this is used instead
;; to prevent deleting instructions setting registers for PIC code
:}

concrete prologue_use.insn instantiates unspec_volatile
{
	root ((0=NULL:NULL:"", <UNSPECV_PROLOGUE_USE>));
}
{:
  ""
  ""
  [(set_attr "length" "0")]
:}

{:
;; Insn emitted into the body of a function to return from a function.
;; This is only done if the function's epilogue is known to be simple.
;; See comments for ix86_can_use_return_insn_p in i386.c.
;; TODO Error:Error in register specification simple_return
(define_expand "return"
  [(simple_return)]
  "ix86_can_use_return_insn_p ()"
{
  ix86_maybe_emit_epilogue_vzeroupper ();
  if (crtl->args.pops_args)
    {
      rtx popc = GEN_INT (crtl->args.pops_args);
      emit_jump_insn (gen_simple_return_pop_internal (popc));
      DONE;
    }
})

;; We need to disable this for TARGET_SEH, as otherwise
;; shrink-wrapped prologue gets enabled too.  This might exceed
;; the maximum size of prologue in unwind information.

(define_expand "simple_return"
  [(simple_return)]
  "!TARGET_SEH"
{
  ix86_maybe_emit_epilogue_vzeroupper ();
  if (crtl->args.pops_args)
    {
      rtx popc = GEN_INT (crtl->args.pops_args);
      emit_jump_insn (gen_simple_return_pop_internal (popc));
      DONE;
    }
})

(define_insn "simple_return_internal"
  [(simple_return)]
  "reload_completed"
  "ret"
  [(set_attr "length" "1")
   (set_attr "atom_unit" "jeu")
   (set_attr "length_immediate" "0")
   (set_attr "modrm" "0")])

;; Used by x86_machine_dependent_reorg to avoid penalty on single byte RET
;; instruction Athlon and K8 have.

(define_insn "simple_return_internal_long"
  [(simple_return)
   (unspec [(const_int 0)] UNSPEC_REP)]
  "reload_completed"
  "rep\;ret"
  [(set_attr "length" "2")
   (set_attr "atom_unit" "jeu")
   (set_attr "length_immediate" "0")
   (set_attr "prefix_rep" "1")
   (set_attr "modrm" "0")])

(define_insn "simple_return_pop_internal"
  [(simple_return)
   (use (match_operand:SI 0 "const_int_operand" ""))]
  "reload_completed"
  "ret\t%0"
  [(set_attr "length" "3")
   (set_attr "atom_unit" "jeu")
   (set_attr "length_immediate" "2")
   (set_attr "modrm" "0")])

(define_insn "simple_return_indirect_internal"
  [(simple_return)
   (use (match_operand:SI 0 "register_operand" "r"))]
  "reload_completed"
  "jmp\t%A0"
  [(set_attr "type" "ibr")
   (set_attr "length_immediate" "0")])
:}

concrete nop.insn instantiates sequence
{
	root (const_int:0);
}
{:
  ""
  "nop"
  [(set_attr "length" "1")
   (set_attr "length_immediate" "0")
   (set_attr "modrm" "0")]
:}
{:
;; Generate nops.  Operand 0 is the number of nops, up to 8.
:}

concrete nops.insn instantiates unspec_volatile
{
	root ((0=const_int_operand:NULL:"", <UNSPECV_NOPS>));
}
{:
  "reload_completed"
{
  int num = INTVAL (operands[0]);

  gcc_assert (num >= 1 && num <= 8);

  while (num--)
    fputs ("\tnop\n", asm_out_file);

  return "";
}
  [(set (attr "length") (symbol_ref "INTVAL (operands[0])"))
   (set_attr "length_immediate" "0")
   (set_attr "modrm" "0")]
:}

{:
;; Pad to 16-byte boundary, max skip in op0.  Used to avoid
;; branch prediction penalty for the third jump in a 16-byte
;; block on K8.
:}

concrete pad.insn instantiates unspec_volatile
{
	root ((0=NULL:NULL:"", <UNSPECV_ALIGN>));
}
{:
  ""
{
#ifdef ASM_OUTPUT_MAX_SKIP_PAD
  ASM_OUTPUT_MAX_SKIP_PAD (asm_out_file, 4, (int)INTVAL (operands[0]));
#else
  /* It is tempting to use ASM_OUTPUT_ALIGN here, but we don't want to do that.
     The align insn is used to avoid 3 jump instructions in the row to improve
     branch prediction and the benefits hardly outweigh the cost of extra 8
     nops on the average inserted by full alignment pseudo operation.  */
#endif
  return "";
}
  [(set_attr "length" "16")]
:}

concrete prologue.exp instantiates sequence
{
	root (const_int:0);
}
{:
  ""
  "ix86_expand_prologue (); DONE;"
:}


concrete set_got.insn instantiates set_unspec2_clobber
{
	root (0=register_operand:SI:"=r",
		(const_int:0, <UNSPEC_SET_GOT>), reg(CC:FLAGS_REG));
	root.1.2.mode:=SI;
}
{:
  "!TARGET_64BIT"
  "* return output_set_got (operands[0], NULL_RTX);"
  [(set_attr "type" "multi")
   (set_attr "length" "12")]
:}

abstract set_unspec2_label_ref1_clobber extends set_unspec2_clobber
{
	root.1.2.1:=label_ref;
}

concrete set_got_labelled.insn instantiates set_unspec2_label_ref1_clobber
{
	root (0=register_operand:SI:"=r",
		(1=NULL:NULL:"", <UNSPEC_SET_GOT>), reg(CC:FLAGS_REG));
	root.1.2.mode:=SI;
}
{:
  "!TARGET_64BIT"
  "* return output_set_got (operands[0], operands[1]);"
  [(set_attr "type" "multi")
   (set_attr "length" "12")]
:}

concrete set_got_rex64.insn instantiates set_unspec2
{
	root (0=register_operand:DI:"=r", (const_int:0,
		<UNSPEC_SET_GOT>));
	root.2.mode:=DI;
}
{:
  "TARGET_64BIT"
  "lea{q}\t{_GLOBAL_OFFSET_TABLE_(%%rip), %0|%0, _GLOBAL_OFFSET_TABLE_[rip]}"
  [(set_attr "type" "lea")
   (set_attr "length_address" "4")
   (set_attr "mode" "DI")]
:}

abstract set_unspec2_label_ref1 extends set_unspec2
{
	root.2.1:=label_ref;
}

concrete set_rip_rex64.insn instantiates set_unspec2_label_ref1
{
	root (0=register_operand:DI:"=r", (1=NULL:NULL:"", 
		<UNSPEC_SET_RIP>));
	root.2.mode:=DI;
}
{:
  "TARGET_64BIT"
  "lea{q}\t{%l1(%%rip), %0|%0, %l1[rip]}"
  [(set_attr "type" "lea")
   (set_attr "length_address" "4")
   (set_attr "mode" "DI")]
:}

concrete set_got_offset_rex64.insn instantiates set_unspec2_label_ref1
{
	root (0=register_operand:DI:"=r",
		(1=NULL:NULL:"", <UNSPEC_SET_GOT_OFFSET>));
	root.2.mode:=DI;
}
{:
  "TARGET_LP64"
  "movabs{q}\t{$_GLOBAL_OFFSET_TABLE_-%l1, %0|%0, OFFSET FLAT:_GLOBAL_OFFSET_TABLE_-%l1}"
  [(set_attr "type" "imov")
   (set_attr "length_immediate" "0")
   (set_attr "length_address" "8")
   (set_attr "mode" "DI")]
:}

concrete epilogue.exp instantiates sequence
{
	root (const_int:0);
}
{:
  ""
  "ix86_expand_epilogue (1); DONE;"
:}

concrete sibcall_epilogue.exp instantiates sequence
{
	root (const_int:0);
}
{:
  ""
  "ix86_expand_epilogue (0); DONE;"
:}

concrete eh_return.exp instantiates use
{
	root (register_operand:NULL:"");
}
{:
  ""
{
  rtx tmp, sa = EH_RETURN_STACKADJ_RTX, ra = operands[0];

  /* Tricky bit: we write the address of the handler to which we will
     be returning into someone else's stack frame, one word below the
     stack address we wish to restore.  */
  tmp = gen_rtx_PLUS (Pmode, arg_pointer_rtx, sa);
  tmp = plus_constant (tmp, -UNITS_PER_WORD);
  tmp = gen_rtx_MEM (Pmode, tmp);
  emit_move_insn (tmp, ra);

  emit_jump_insn (gen_eh_return_internal ());
  emit_barrier ();
  DONE;
}
:}

abstract set_plus2_set_mem_clobber_mem extends sequence
{
    root.1:=set_plus2;
    root.2:=set;
    root.2.2:=mem;
    root.3:=clobber;
    root.3.1:=mem;
}





concrete eh_return_internal.insn_and_split instantiates.in sequence
{
	root (eh_return);
}
cmd_spec.in
{:
  ""
  "#"
  "epilogue_completed"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
  "ix86_expand_epilogue (2); DONE;"
:}


concrete leave.insn instantiates set_plus2_set_mem_clobber_mem
{
    root (reg(SI:SP_REG),reg(SI:BP_REG),const_int:4,reg(SI:BP_REG),reg(SI:BP_REG),scratch);
    root.1.2.mode:=SI;
    root.2.2.mode:=SI;
    root.3.1.mode:=BLK;
}
{:
  "!TARGET_64BIT"
  "leave"
  [(set_attr "type" "leave")]
:}

concrete leave_rex64.insn overrides leave.insn
{
    SI->DI;
    root.1.2.2.operand:=const_int:8;
}
{:
  "TARGET_64BIT"
  "leave"
  [(set_attr "type" "leave")]
:}

concrete split_stack_prologue.exp instantiates sequence
{
	root (const_int:0);
}
{:
  ""
{
  ix86_expand_split_stack_prologue ();
  DONE;
}
:}

concrete split_stack_return.insn instantiates unspec_volatile
{
    root((const_int_operand:SI:"",<UNSPECV_SPLIT_STACK_RETURN>));
}
{:
  ""
{
  if (operands[0] == const0_rtx)
    return "ret";
  else
    return "ret\t%0";
}
  [(set_attr "atom_unit" "jeu")
   (set_attr "modrm" "0")
   (set (attr "length")
    (if_then_else (match_operand:SI 0 "const0_operand" "")
              (const_int 1)
              (const_int 3)))
   (set (attr "length_immediate")
    (if_then_else (match_operand:SI 0 "const0_operand" "")
              (const_int 0)
              (const_int 2)))]
:}

abstract set_is_then_else_ltu_minus_unspec_label_ref extends set
{
    root.2:=if_then_else;
    root.2.1:=ltu;
    root.2.1.1:=minus;
    root.2.1.2:=unspec;
    root.2.2:=label_ref;
}


concrete split_stack_space_check.exp instantiates set_is_then_else_ltu_minus_unspec_label_ref
{
    root (pc,reg(NULL:SP_REG),register_operand:NULL:"",(const_int:0,<UNSPEC_STACK_CHECK>),NULL:NULL:"",pc);
}
{:
  ""
{
  rtx reg, size, limit;

  reg = gen_reg_rtx (Pmode);
  size = force_reg (Pmode, operands[0]);
  emit_insn (gen_sub3_insn (reg, stack_pointer_rtx, size));
  limit = gen_rtx_UNSPEC (Pmode, gen_rtvec (1, const0_rtx),
              UNSPEC_STACK_CHECK);
  limit = gen_rtx_MEM (Pmode, gen_rtx_CONST (Pmode, limit));
  ix86_expand_branch (GEU, reg, limit, operands[1]);

  DONE;
}
:}

{:

;; Bit manipulation instructions.

(define_expand "ffs<mode>2"
  [(set (match_dup 2) (const_int -1))
   (parallel [(set (reg:CCZ FLAGS_REG)
		   (compare:CCZ
		     (match_operand:SWI48 1 "nonimmediate_operand" "")
		     (const_int 0)))
	      (set (match_operand:SWI48 0 "register_operand" "")
		   (ctz:SWI48 (match_dup 1)))])
   (set (match_dup 0) (if_then_else:SWI48
			(eq (reg:CCZ FLAGS_REG) (const_int 0))
			(match_dup 2)
			(match_dup 0)))
   (parallel [(set (match_dup 0) (plus:SWI48 (match_dup 0) (const_int 1)))
	      (clobber (reg:CC FLAGS_REG))])]
  ""
{
  if (<MODE>mode == SImode && !TARGET_CMOVE)
    {
      emit_insn (gen_ffssi2_no_cmove (operands[0], operands [1]));
      DONE;
    }
  operands[2] = gen_reg_rtx (<MODE>mode);
})

(define_insn_and_split "ffssi2_no_cmove"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(ffs:SI (match_operand:SI 1 "nonimmediate_operand" "rm")))
   (clobber (match_scratch:SI 2 "=&q"))
   (clobber (reg:CC FLAGS_REG))]
  "!TARGET_CMOVE"
  "#"
  "&& reload_completed"
  [(parallel [(set (reg:CCZ FLAGS_REG)
		   (compare:CCZ (match_dup 1) (const_int 0)))
	      (set (match_dup 0) (ctz:SI (match_dup 1)))])
   (set (strict_low_part (match_dup 3))
	(eq:QI (reg:CCZ FLAGS_REG) (const_int 0)))
   (parallel [(set (match_dup 2) (neg:SI (match_dup 2)))
	      (clobber (reg:CC FLAGS_REG))])
   (parallel [(set (match_dup 0) (ior:SI (match_dup 0) (match_dup 2)))
	      (clobber (reg:CC FLAGS_REG))])
   (parallel [(set (match_dup 0) (plus:SI (match_dup 0) (const_int 1)))
	      (clobber (reg:CC FLAGS_REG))])]
{
  operands[3] = gen_lowpart (QImode, operands[2]);
  ix86_expand_clear (operands[2]);
})
:}

abstract set_ctz2 extends set
{
	root.2:=ctz;
}

abstract set_compare2_set_ctz2 extends sequence
{
	root.1:=set_compare2;
	root.2:=set_ctz2;
}

concrete *ffs<mode>_1.insn instantiates set_compare2_set_ctz2
{
	root (reg(CCZ:FLAGS_REG), 1=nonimmediate_operand:SWI48:"rm",const_int:0,0=register_operand:SWI48:"=r",duplicate 1);
	root.1.2.mode:=CCZ;
	root.2.2.mode:=SWI48;
}
{:
  ""
  "bsf{<imodesuffix>}\t{%1, %0|%0, %1}"
  [(set_attr "type" "alu1")
   (set_attr "prefix_0f" "1")
   (set_attr "mode" "<MODE>")]
:}

abstract set_ctz2_clobber extends sequence
{
	root.1:=set_ctz2;
	root.2:=clobber;
}

concrete ctz<mode>2.insn instantiates set_ctz2_clobber
{
	root (0=register_operand:SWI248:"=r",1=nonimmediate_operand:SWI248:"rm",reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI248;
}
{:
  ""
{
  if (TARGET_BMI)
    return "tzcnt{<imodesuffix>}\t{%1, %0|%0, %1}";
  else
    return "bsf{<imodesuffix>}\t{%1, %0|%0, %1}";
}
  [(set_attr "type" "alu1")
   (set_attr "prefix_0f" "1")
   (set (attr "prefix_rep") (symbol_ref "TARGET_BMI"))
   (set_attr "mode" "<MODE>")]
:}

abstract parallel_set_minus2_clz2_clobber extends parallel
{
	root.1:=set_minus2;
	root.1.2.2:=clz;
	root.2:=clobber;
}

abstract set_xor2 extends set
{
	root.2:=xor;
}

abstract parallel_set_xor2_clobber extends parallel
{
	root.1:=set_xor2;
	root.2:=clobber;
}

abstract parallel_set_minus2_clz2_clobber_parallel_set_xor2_clobber extends sequence
{
	root.1:=parallel_set_minus2_clz2_clobber;
	root.2:=parallel_set_xor2_clobber;
}

concrete clz<mode>2.exp instantiates parallel_set_minus2_clz2_clobber_parallel_set_xor2_clobber
{
	root (
		(0=register_operand:SWI248:"", duplicate 2, 1=nonimmediate_operand:SWI248:"",
		reg(CC:FLAGS_REG)),(duplicate 0, duplicate 0, duplicate 2, reg(CC:FLAGS_REG)));
	root.1.1.2.mode:=SWI248;
	root.1.1.2.2.mode:=SWI248;
	root.2.1.2.mode:=SWI248;
}
{:
  ""
{
  if (TARGET_LZCNT)
    {
      emit_insn (gen_clz<mode>2_lzcnt (operands[0], operands[1]));
      DONE;
    }
  operands[2] = GEN_INT (GET_MODE_BITSIZE (<MODE>mode)-1);
}
:}

abstract set_clz2 extends set
{
	root.2:=clz;
}

abstract set_clz2_clobber extends sequence
{
	root.1:=set_clz2;
	root.2:=clobber;
}


concrete clz<mode>2_lzcnt.insn instantiates set_clz2_clobber
{
	root (0=register_operand:SWI248:"=r",1=nonimmediate_operand:SWI248:"rm",reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI248;
}
{:  
  "TARGET_LZCNT"
  "lzcnt{<imodesuffix>}\t{%1, %0|%0, %1}"
  [(set_attr "prefix_rep" "1")
   (set_attr "type" "bitmanip")
   (set_attr "mode" "<MODE>")]
:}
{:
;; BMI instructions.
:}

abstract set_and2_not extends set_and2
{
	root.2.1:=not;
}
abstract set_and2_not_clobber extends sequence
{
	root.1:=set_and2_not;
	root.2:=clobber;
}

concrete *bmi_andn_<mode>.insn instantiates set_and2_not_clobber
{
	root (0=register_operand:SWI48:"=r",1=register_operand:SWI48:"r",2=nonimmediate_operand:SWI48:"rm",reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
	root.1.2.1.mode:=SWI48;
}
{:  
  "TARGET_BMI"
  "andn\t{%2, %1, %0|%0, %1, %2}"
  [(set_attr "type" "bitmanip")
   (set_attr "mode" "<MODE>")]
:}

abstract set_unspec2_clobber extends sequence
{
	root.1:=set_unspec2;
	root.2:=clobber;
}

concrete bmi_bextr_<mode>.insn instantiates set_unspec2_clobber
{
	root (0=register_operand:SWI48:"=r",(1=register_operand:SWI48:"r",2=nonimmediate_operand:SWI48:"rm",<UNSPEC_BEXTR>),reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
}
{:
  "TARGET_BMI"
  "bextr\t{%2, %1, %0|%0, %1, %2}"
  [(set_attr "type" "bitmanip")
  (set_attr "mode" "<MODE>")]
:}

abstract set_and2_neg1 extends set_and2
{
	root.2.1:=neg;
}

abstract set_and2_neg1_clobber extends sequence
{
	root.1:=set_and2_neg1;
	root.2:=clobber;
}


concrete *bmi_blsi_<mode>.insn instantiates set_and2_neg1_clobber
{
	root (0=register_operand:SWI48:"=r",1=nonimmediate_operand:SWI48:"rm",duplicate 1,reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
	root.1.2.1.mode:=SWI48;
}
{:
  "TARGET_BMI"
  "blsi\t{%1, %0|%0, %1}"
  [(set_attr "type" "bitmanip")
   (set_attr "mode" "<MODE>")]
:}

abstract set_xor2_plus1 extends set
{
	root.2:=xor;
	root.2.1:=plus;
}

abstract set_xor2_plus1_clobber extends sequence
{
	root.1:=set_xor2_plus1;
	root.2:=clobber;
}

concrete *bmi_blsmsk_<mode>.insn instantiates set_xor2_plus1_clobber
{
	root (0=register_operand:SWI48:"=r",1=nonimmediate_operand:SWI48:"rm",const_int:-1,duplicate 1, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
	root.1.2.1.mode:=SWI48;
}
{:
  "TARGET_BMI"
  "blsmsk\t{%1, %0|%0, %1}"
  [(set_attr "type" "bitmanip")
   (set_attr "mode" "<MODE>")]
:}

abstract set_and2_plus1 extends set_and2
{
	root.2.1:=plus;
}

abstract set_and2_plus1_clobber extends sequence
{
	root.1:=set_and2_plus1;
	root.2:=clobber;
}

concrete *bmi_blsr_<mode>.insn instantiates set_and2_plus1_clobber{
	root (0=register_operand:SWI48:"=r",1=nonimmediate_operand:SWI48:"rm",const_int:-1,duplicate 1,reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
	root.1.2.1.mode:=SWI48;
}
{:
   "TARGET_BMI"
   "blsr\t{%1, %0|%0, %1}"
  [(set_attr "type" "bitmanip")
   (set_attr "mode" "<MODE>")]
:}

{:
;; BMI2 instructions.
:}
abstract set_and2_lshiftrt2 extends set_and2
{
	root.2.2:=lshiftrt;
}

abstract set_and2_lshiftrt2_clobber extends sequence
{
	root.1:=set_and2_lshiftrt2;
	root.2:=clobber;
}

concrete bmi2_bzhi_<mode>3.insn instantiates set_and2_lshiftrt2_clobber
{
	root (0=register_operand:SWI48:"=r",1=register_operand:SWI48:"r",const_int:-1,2=nonimmediate_operand:SWI48:"rm",reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
	root.1.2.2.mode:=SWI48;
}
{:
  "TARGET_BMI2"
  "bzhi\t{%2, %1, %0|%0, %1, %2}"
  [(set_attr "type" "bitmanip")
   (set_attr "prefix" "vex")
   (set_attr "mode" "<MODE>")]
:}

concrete bmi2_pdep_<mode>3.insn instantiates set_unspec2
{
	root (0=register_operand:SWI48:"=r",(1=register_operand:SWI48:"r",2=nonimmediate_operand:SWI48:"rm",<UNSPEC_PDEP>));
	root.2.mode:=SWI48;
}
{:
  "TARGET_BMI2"
  "pdep\t{%2, %1, %0|%0, %1, %2}"
  [(set_attr "type" "bitmanip")
   (set_attr "prefix" "vex")
   (set_attr "mode" "<MODE>")]
:}

concrete bmi2_pext_<mode>3.insn instantiates set_unspec2 
{
	root (0=register_operand:SWI48:"=r",(1=register_operand:SWI48:"r",2=nonimmediate_operand:SWI48:"rm",<UNSPEC_PEXT>));
	root.2.mode:=SWI48;
}
{:
  "TARGET_BMI2"
  "pext\t{%2, %1, %0|%0, %1, %2}"
  [(set_attr "type" "bitmanip")
   (set_attr "prefix" "vex")
   (set_attr "mode" "<MODE>")]
:}

{: 
;; TBM instructions.
:}

abstract set_zero_extract2_clobber extends sequence
{
	root.1:=set_zero_extract2;
	root.2:=clobber;
}

concrete tbm_bextri_<mode>.insn instantiates set_zero_extract2_clobber
{
	root (0=register_operand:SWI48:"=r", 1=nonimmediate_operand:SWI48:"rm", 2=const_0_to_255_operand:SWI48:"n", 3=const_0_to_255_operand:SWI48:"n", reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
} 
{:
   "TARGET_TBM"
{
  operands[2] = GEN_INT (INTVAL (operands[2]) << 8 | INTVAL (operands[3]));
  return "bextr\t{%2, %1, %0|%0, %1, %2}";
}
  [(set_attr "type" "bitmanip")
   (set_attr "mode" "<MODE>")]
:}

abstract set_and2_plus1_clobber extends sequence
{
	root.1:=set_and2;
	root.1.2.1:=plus;
	root.2:=clobber;
}

concrete *tbm_blcfill_<mode>.insn instantiates set_and2_plus1_clobber
{
	root (0=register_operand:SWI48:"=r", 1=nonimmediate_operand:SWI48:"rm", const_int:1, duplicate 1, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
	root.1.2.1.mode:=SWI48;
}
{:
   "TARGET_TBM"
   "blcfill\t{%1, %0|%0, %1}"
  [(set_attr "type" "bitmanip")
   (set_attr "mode" "<MODE>")]
:}

abstract set_ior2_not_plus_clobber extends sequence
{
	root.1:=set;
	root.1.2:=ior;
	root.1.2.1:=not;
	root.1.2.1.1:=plus;
	root.2:=clobber;
}

concrete *tbm_blci_<mode>.insn instantiates set_ior2_not_plus_clobber
{
	 root (0=register_operand:SWI48:"=r", 1=nonimmediate_operand:SWI48:"rm", const_int:1, duplicate 1, reg(CC:FLAGS_REG));
	 root.1.2.mode:=SWI48;
	 root.1.2.1.mode:=SWI48;
	 root.1.2.1.1.mode:=SWI48;
}
{:
   "TARGET_TBM"
   "blci\t{%1, %0|%0, %1}"
  [(set_attr "type" "bitmanip")
   (set_attr "mode" "<MODE>")]
:}

abstract set_and2_plus1_not2_clobber extends sequence
{
	root.1:=set_and2;
	root.1.2.1:=plus;
	root.1.2.2:=not;
	root.2:=clobber;
}

concrete *tbm_blcic_<mode>.insn instantiates set_and2_plus1_not2_clobber
{
	root (0=register_operand:SWI48:"=r", 1=nonimmediate_operand:SWI48:"rm", const_int:1, duplicate 1, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
	root.1.2.1.mode:=SWI48;
	root.1.2.2.mode:=SWI48;
}
{:
   "TARGET_TBM"
   "blcic\t{%1, %0|%0, %1}"
  [(set_attr "type" "bitmanip")
   (set_attr "mode" "<MODE>")]
:}

concrete *tbm_blcmsk_<mode>.insn instantiates set_xor2_plus1_clobber
{
	root (0=register_operand:SWI48:"=r", 1=nonimmediate_operand:SWI48:"rm", const_int:1, duplicate 1, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
	root.1.2.1.mode:=SWI48;
}
{:
   "TARGET_TBM"
   "blcmsk\t{%1, %0|%0, %1}"
  [(set_attr "type" "bitmanip")
   (set_attr "mode" "<MODE>")]
:}

abstract set_ior2_plus1_clobber extends sequence
{
	root.1:=set;
	root.1.2:=ior;
	root.1.2.1:=plus;
	root.2:=clobber;
}

concrete *tbm_blcs_<mode>.insn instantiates set_ior2_plus1_clobber
{
	root (0=register_operand:SWI48:"=r", 1=nonimmediate_operand:SWI48:"rm", const_int:1, duplicate 1, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
	root.1.2.1.mode:=SWI48;
}
{:
   "TARGET_TBM"
   "blcs\t{%1, %0|%0, %1}"
  [(set_attr "type" "bitmanip")
   (set_attr "mode" "<MODE>")]
:}

concrete *tbm_blsfill_<mode>.insn overrides *tbm_blcs_<mode>.insn
{
	root.1.2.1.2.operand:=const_int:-1;
}
{:
   "TARGET_TBM"
   "blsfill\t{%1, %0|%0, %1}"
  [(set_attr "type" "bitmanip")
   (set_attr "mode" "<MODE>")]
:}

abstract set_ior2_plus1_not2_clobber extends set_ior2_plus1_clobber
{
	root.1.2.2:=not;
}

concrete *tbm_blsic_<mode>.insn instantiates set_ior2_plus1_not2_clobber
{
	root (0=register_operand:SWI48:"=r", 1=nonimmediate_operand:SWI48:"rm", const_int:-1, duplicate 1, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
	root.1.2.1.mode:=SWI48;
	root.1.2.2.mode:=SWI48;
}
{:
   "TARGET_TBM"
   "blsic\t{%1, %0|%0, %1}"
  [(set_attr "type" "bitmanip")
   (set_attr "mode" "<MODE>")]
:}

concrete *tbm_t1mskc_<mode>.insn overrides *tbm_blsic_<mode>.insn
{
	root.1.2.1.2.operand:=const_int:1;
}
{:
   "TARGET_TBM"
   "t1mskc\t{%1, %0|%0, %1}"
  [(set_attr "type" "bitmanip")
   (set_attr "mode" "<MODE>")]
:}

concrete *tbm_tzmsk_<mode>.insn instantiates set_and2_plus1_not2_clobber
{
	root (0=register_operand:SWI48:"=r",1=nonimmediate_operand:SWI48:"rm", const_int:-1, duplicate 1, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
	root.1.2.1.mode:=SWI48;
	root.1.2.2.mode:=SWI48;
}	
{:
   "TARGET_TBM"
   "tzmsk\t{%1, %0|%0, %1}"
  [(set_attr "type" "bitmanip")
   (set_attr "mode" "<MODE>")]
:}

abstract set_minus2_clz2_clobber extends set_minus2_clobber
{
	root.1.2.2:=clz;
}

concrete bsr_rex64.insn instantiates set_minus2_clz2_clobber
{
	root (0=register_operand:DI:"=r",const_int:63, 1=nonimmediate_operand:DI:"rm", reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.2.mode:=DI;
}
{:
  "TARGET_64BIT"
  "bsr{q}\t{%1, %0|%0, %1}"
  [(set_attr "type" "alu1")
   (set_attr "prefix_0f" "1")
   (set_attr "mode" "DI")]
:}

concrete bsr.insn instantiates set_minus2_clz2_clobber
{
	root (0=register_operand:SI:"=r",const_int:31, 1=nonimmediate_operand:SI:"rm", reg(CC:FLAGS_REG));
	root.1.2.mode:=SI;
	root.1.2.2.mode:=SI;
}
{:
  ""
  "bsr{l}\t{%1, %0|%0, %1}"
  [(set_attr "type" "alu1")
   (set_attr "prefix_0f" "1")
   (set_attr "mode" "SI")]
:}
concrete *bsrhi.insn instantiates set_minus2_clz2_clobber
{
	root (0=register_operand:HI:"=r", const_int:15, 1=nonimmediate_operand:HI:"rm", reg(CC:FLAGS_REG));
	root.1.2.mode:=HI;
	root.1.2.2.mode:=HI;
}
{:
  ""
  "bsr{w}\t{%1, %0|%0, %1}"
  [(set_attr "type" "alu1")
   (set_attr "prefix_0f" "1")
   (set_attr "mode" "HI")]
:}

abstract set_popcount2 extends set
{
	root.2:=popcount;
}

abstract set_popcount2_clobber extends sequence
{
	root.1:=set_popcount2;
	root.2:=clobber;
}

concrete popcount<mode>2.insn instantiates set_popcount2_clobber
{
	root (0=register_operand:SWI248:"=r", 1=nonimmediate_operand:SWI248:"rm", reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI248;
}
{:
  "TARGET_POPCNT"
{
#if TARGET_MACHO
  return "popcnt\t{%1, %0|%0, %1}";
#else
  return "popcnt{<imodesuffix>}\t{%1, %0|%0, %1}";
#endif
}
  [(set_attr "prefix_rep" "1")
   (set_attr "type" "bitmanip")
   (set_attr "mode" "<MODE>")]
:}

abstract set_compare2_popcount1 extends set_compare2
{
	root.2.1:=popcount;
}

abstract set_compare2_popcount1_set_popcount2 extends sequence
{
	root.1:=set_compare2_popcount1;
	root.2:=set_popcount2;
}

concrete *popcount<mode>2_cmp.insn instantiates set_compare2_popcount1_set_popcount2
{
	root (reg(NULL:FLAGS_REG), 1=nonimmediate_operand:SWI248:"rm",const_int:0, 0=register_operand:SWI248:"=r",duplicate 1);
	root.1.2.1.mode:=SWI248;
	root.2.2.mode:=SWI248;
}
{:
  "TARGET_POPCNT && ix86_match_ccmode (insn, CCZmode)"
{
#if TARGET_MACHO
  return "popcnt\t{%1, %0|%0, %1}";
#else
  return "popcnt{<imodesuffix>}\t{%1, %0|%0, %1}";
#endif
}
  [(set_attr "prefix_rep" "1")
   (set_attr "type" "bitmanip")
   (set_attr "mode" "<MODE>")]
:}

abstract set_compare2_popcount1_set_zero_extend2_popcount extends set_compare2_popcount1_set_popcount2
{
	root.2.2:=zero_extend;
	root.2.2.1:=popcount;
}


concrete *popcountsi2_cmp_zext.insn instantiates set_compare2_popcount1_set_zero_extend2_popcount
{
	root (reg(NULL:FLAGS_REG), 1=nonimmediate_operand:SI:"rm", const_int:0, 0=register_operand:DI:"=r", duplicate 1);
	root.1.2.1.mode:=SI;
	root.2.2.mode:=DI;
	root.2.2.1.mode:=SI;
}
{:
  "TARGET_64BIT && TARGET_POPCNT && ix86_match_ccmode (insn, CCZmode)"
{
#if TARGET_MACHO
  return "popcnt\t{%1, %0|%0, %1}";
#else
  return "popcnt{l}\t{%1, %0|%0, %1}";
#endif
}
  [(set_attr "prefix_rep" "1")
   (set_attr "type" "bitmanip")
   (set_attr "mode" "SI")]
:}

abstract set_bswap2 extends set
{
	root.2:=bswap;
}

concrete bswap<mode>2.exp instantiates set_bswap2
{
	root (0=register_operand:SWI48:"", 1=register_operand:SWI48:"");
	root.2.mode:=SWI48;
}
{:
  ""
{
  if (<MODE>mode == SImode && !(TARGET_BSWAP || TARGET_MOVBE))
    {
      rtx x = operands[0];

      emit_move_insn (x, operands[1]);
      emit_insn (gen_bswaphi_lowpart (gen_lowpart (HImode, x)));
      emit_insn (gen_rotlsi3 (x, x, GEN_INT (16)));
      emit_insn (gen_bswaphi_lowpart (gen_lowpart (HImode, x)));
      DONE;
    }
}
:}

concrete *bswap<mode>2_movbe.insn overrides bswap<mode>2.exp
{
	root.1:=nonimmediate_operand:SWI48:"=r,r,m"; root.2:=nonimmediate_operand:SWI48:"0,m,r";
}
{:
  "TARGET_MOVBE
   && !(MEM_P (operands[0]) && MEM_P (operands[1]))"
  "@
    bswap\t%0
    movbe\t{%1, %0|%0, %1}
    movbe\t{%1, %0|%0, %1}"
  [(set_attr "type" "bitmanip,imov,imov")
   (set_attr "modrm" "0,1,1")
   (set_attr "prefix_0f" "*,1,1")
   (set_attr "prefix_extra" "*,1,1")
   (set_attr "mode" "<MODE>")]
:}

concrete *bswap<mode>2_1.insn overrides bswap<mode>2.exp
{
	allconstraints:=("=r","0");
}
{:
  "TARGET_BSWAP"
  "bswap\t%0"
  [(set_attr "type" "bitmanip")
   (set_attr "modrm" "0")
   (set_attr "mode" "<MODE>")]
:}

abstract set_strict_low_part1_bswap2_clobber extends sequence
{
	root.1:=set_bswap2;
	root.1.1:=strict_low_part;
	root.2:=clobber;
}

concrete *bswaphi_lowpart_1.insn instantiates set_strict_low_part1_bswap2_clobber
{
	root (0=register_operand:HI:"+Q,r", duplicate 0, reg(CC:FLAGS_REG));
	root.1.2.mode:=HI;
}
{:  
  "TARGET_USE_XCHGB || optimize_function_for_size_p (cfun)"
  "@
    xchg{b}\t{%h0, %b0|%b0, %h0}
    rol{w}\t{$8, %0|%0, 8}"
  [(set_attr "length" "2,4")
   (set_attr "mode" "QI,HI")]
:}

concrete bswaphi_lowpart.insn instantiates set_strict_low_part1_bswap2_clobber
{
	root (0=register_operand:HI:"+r", duplicate 0, reg(CC:FLAGS_REG));
	root.1.2.mode:=HI;
}
{:
  ""
  "rol{w}\t{$8, %0|%0, 8}"
  [(set_attr "length" "4")
   (set_attr "mode" "HI")]
:}

concrete paritydi2.exp instantiates set_parity2
{
	root (0=register_operand:DI:"", 1=register_operand:DI:"");
	root.2.mode:=DI;
}
{:
  "! TARGET_POPCNT"
{
  rtx scratch = gen_reg_rtx (QImode);
  rtx cond;

  emit_insn (gen_paritydi2_cmp (NULL_RTX, NULL_RTX,
				NULL_RTX, operands[1]));

  cond = gen_rtx_fmt_ee (ORDERED, QImode,
			 gen_rtx_REG (CCmode, FLAGS_REG),
			 const0_rtx);
  emit_insn (gen_rtx_SET (VOIDmode, scratch, cond));

  if (TARGET_64BIT)
    emit_insn (gen_zero_extendqidi2 (operands[0], scratch));
  else
    {
      rtx tmp = gen_reg_rtx (SImode);

      emit_insn (gen_zero_extendqisi2 (tmp, scratch));
      emit_insn (gen_zero_extendsidi2 (operands[0], tmp));
    }
  DONE;
}
:}

concrete paritysi2.exp overrides paritydi2.exp
{
	root.1.mode:=SI;
	root.2.mode:=SI;
	root.2.1.mode:=SI;
}
{:  
  "! TARGET_POPCNT"
{
  rtx scratch = gen_reg_rtx (QImode);
  rtx cond;

  emit_insn (gen_paritysi2_cmp (NULL_RTX, NULL_RTX, operands[1]));

  cond = gen_rtx_fmt_ee (ORDERED, QImode,
			 gen_rtx_REG (CCmode, FLAGS_REG),
			 const0_rtx);
  emit_insn (gen_rtx_SET (VOIDmode, scratch, cond));

  emit_insn (gen_zero_extendqisi2 (operands[0], scratch));
  DONE;
}
:}

abstract set_unspec2_clobber_clobber_clobber extends sequence
{
	root.1:=set_unspec2;
	root.2:=clobber;
	root.3:=clobber;
	root.4:=clobber;
}

abstract parallel_set_xor2_clobber_parallel_set_unspec2_clobber_clobber extends sequence
{
	root.1:=parallel;
	root.1.1:=set_xor2;
	root.1.2:=clobber;
	root.2:=parallel;
	root.2.1:=set_unspec2;
	root.2.2:=clobber;
	root.2.3:=clobber;
}

{:
(define_insn_and_split "paritydi2_cmp"
  [(set (reg:CC FLAGS_REG)
    (unspec:CC [(match_operand:DI 3 "register_operand" "0")]
           UNSPEC_PARITY))
   (clobber (match_scratch:DI 0 "=r"))
   (clobber (match_scratch:SI 1 "=&r"))
   (clobber (match_scratch:HI 2 "=Q"))]
  "! TARGET_POPCNT"
  "#"
  "&& reload_completed"
  [(parallel
     [(set (match_dup 1)
       (xor:SI (match_dup 1) (match_dup 4)))
      (clobber (reg:CC FLAGS_REG))])
   (parallel
     [(set (reg:CC FLAGS_REG)
       (unspec:CC [(match_dup 1)] UNSPEC_PARITY))
      (clobber (match_dup 1))
      (clobber (match_dup 2))])]
{
  operands[4] = gen_lowpart (SImode, operands[3]);

  if (TARGET_64BIT)
    {
      emit_move_insn (operands[1], gen_lowpart (SImode, operands[3]));
      emit_insn (gen_lshrdi3 (operands[3], operands[3], GEN_INT (32)));
    }
  else
    operands[1] = gen_highpart (SImode, operands[3]);
})

(define_insn_and_split "paritysi2_cmp"
  [(set (reg:CC FLAGS_REG)
	(unspec:CC [(match_operand:SI 2 "register_operand" "0")]
		   UNSPEC_PARITY))
   (clobber (match_scratch:SI 0 "=r"))
   (clobber (match_scratch:HI 1 "=&Q"))]
  "! TARGET_POPCNT"
  "#"
  "&& reload_completed"
  [(parallel
     [(set (match_dup 1)
	   (xor:HI (match_dup 1) (match_dup 3)))
      (clobber (reg:CC FLAGS_REG))])
   (parallel
     [(set (reg:CC FLAGS_REG)
	   (unspec:CC [(match_dup 1)] UNSPEC_PARITY))
      (clobber (match_dup 1))])]
{
  operands[3] = gen_lowpart (HImode, operands[2]);

  emit_move_insn (operands[1], gen_lowpart (HImode, operands[2]));
  emit_insn (gen_lshrsi3 (operands[2], operands[2], GEN_INT (16)));
})
:}

concrete *parityhi2_cmp.insn instantiates set_unspec2_clobber
{
	root (reg(CC:FLAGS_REG), (1=register_operand:HI:"0",<UNSPEC_PARITY>),0=HI:"=Q");
	root.1.2.mode:=CC;
}
{:
  "! TARGET_POPCNT"
  "xor{b}\t{%h0, %b0|%b0, %h0}"
  [(set_attr "length" "2")
   (set_attr "mode" "HI")]
:}
{:

;; Thread-local storage patterns for ELF.
;;
;; Note that these code sequences must appear exactly as shown
;; in order to allow linker relaxation.
:}

concrete *tls_global_dynamic_32_gnu.insn instantiates set_unspec2_clobber_clobber_clobber{
	root (0=register_operand:SI:"=a", (1=register_operand:SI:"b", 2=tls_symbolic_operand:SI:"", 3=constant_call_address_operand:SI:"z",<UNSPEC_TLS_GD>),4=SI:"=d", 5=SI:"=c",reg(CC:FLAGS_REG));
	root.1.2.mode:=SI;
}
{:
  "!TARGET_64BIT && TARGET_GNU_TLS"
{
  output_asm_insn
    ("lea{l}\t{%E2@tlsgd(,%1,1), %0|%0, %E2@tlsgd[%1*1]}", operands);
  if (TARGET_SUN_TLS)
#ifdef HAVE_AS_IX86_TLSGDPLT
    return "call\t%a2@tlsgdplt";
#else
    return "call\t%p3@plt";
#endif
  return "call\t%P3";
}
  [(set_attr "type" "multi")
   (set_attr "length" "12")]
:}

abstract parallel_set_unspec2_clobber_clobber_clobber extends sequence
{
	root.1:=parallel;
	root.1.1:=set_unspec2_clobber_clobber_clobber;
}

concrete tls_global_dynamic_32.exp instantiates parallel_set_unspec2_clobber_clobber_clobber
{
	root (0=register_operand:SI:"", (2=register_operand:SI:"", 1=tls_symbolic_operand:SI:"", 3=constant_call_address_operand:SI:"",<UNSPEC_TLS_GD>), 4=SI:"", 5=SI:"",reg(CC:FLAGS_REG));
	root.1.1.1.2.mode:=SI;
}
{:
:}

abstract set_call2_mem1_unspec2 extends sequence
{
	root.1:=set;
	root.1.2:=call;
	root.1.2.1:=mem;
	root.2:=unspec;
}


concrete *tls_global_dynamic_64.insn instantiates set_call2_mem1_unspec2
{
	root (0=register_operand:DI:"=a", 2=constant_call_address_operand:DI:"z", 3=NULL:DI:"",(1=tls_symbolic_operand:NULL:"",<UNSPEC_TLS_GD>));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=QI;
	root.2.mode:=DI;
}
{:
  "TARGET_64BIT"
{
  if (!TARGET_X32)
    fputs (ASM_BYTE "0x66\n", asm_out_file);
  output_asm_insn
    ("lea{q}\t{%E1@tlsgd(%%rip), %%rdi|rdi, %E1@tlsgd[rip]}", operands);
  fputs (ASM_SHORT "0x6666\n", asm_out_file);
  fputs ("\trex64\n", asm_out_file);
  if (TARGET_SUN_TLS)
    return "call\t%p2@plt";
  return "call\t%P2";
}
  [(set_attr "type" "multi")
   (set (attr "length")
	(symbol_ref "TARGET_X32 ? 15 : 16"))]
:}

abstract parallel_set_call2_mem1_unspec2 extends sequence
{
	root.1:=parallel;
	root.1.1:=set_call2_mem1_unspec2;
}

concrete tls_global_dynamic_64.exp instantiates parallel_set_call2_mem1_unspec2
{
	root ((0=register_operand:DI:"", 2=constant_call_address_operand:DI:"",const_int:0,(1=tls_symbolic_operand:NULL:"",<UNSPEC_TLS_GD>)));
	root.1.1.1.2.mode:=DI;
	root.1.1.1.2.1.mode:=QI;
	root.1.1.2.mode:=DI;
}
{:
:}

{:
(define_insn "*tls_local_dynamic_base_32_gnu"
  [(set (match_operand:SI 0 "register_operand" "=a")
    (unspec:SI
     [(match_operand:SI 1 "register_operand" "b")
      (match_operand:SI 2 "constant_call_address_operand" "z")]
     UNSPEC_TLS_LD_BASE))
   (clobber (match_scratch:SI 3 "=d"))
   (clobber (match_scratch:SI 4 "=c"))
   (clobber (reg:CC FLAGS_REG))]
  "!TARGET_64BIT && TARGET_GNU_TLS"
{
  output_asm_insn
    ("lea{l}\t{%&@tlsldm(%1), %0|%0, %&@tlsldm[%1]}", operands);
  if (TARGET_SUN_TLS)
#ifdef HAVE_AS_IX86_TLSLDMPLT
    return "call\t%&@tlsldmplt";
#else
    return "call\t%p2@plt";
#endif
  return "call\t%P2";
}
  [(set_attr "type" "multi")
   (set_attr "length" "11")])


(define_expand "tls_local_dynamic_base_32"
  [(parallel
     [(set (match_operand:SI 0 "register_operand" "")
       (unspec:SI
        [(match_operand:SI 1 "register_operand" "")
         (match_operand:SI 2 "constant_call_address_operand" "")]
        UNSPEC_TLS_LD_BASE))
      (clobber (match_scratch:SI 3 ""))
      (clobber (match_scratch:SI 4 ""))
      (clobber (reg:CC FLAGS_REG))])])

:}




concrete *tls_local_dynamic_base_64.insn instantiates set_call2_mem1_unspec2
{
	root (0=register_operand:DI:"=a", 1=constant_call_address_operand:DI:"z",2=NULL:DI:"",(const_int:0,<UNSPEC_TLS_LD_BASE>));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=QI;
	root.2.mode:=DI;
}
{:
  "TARGET_64BIT"
{
  output_asm_insn
    ("lea{q}\t{%&@tlsld(%%rip), %%rdi|rdi, %&@tlsld[rip]}", operands);
  if (TARGET_SUN_TLS)
    return "call\t%p1@plt";
  return "call\t%P1";
}
  [(set_attr "type" "multi")
   (set_attr "length" "12")]
:}

concrete tls_local_dynamic_base_64.exp instantiates parallel_set_call2_mem1_unspec2
{
	root ((0=register_operand:DI:"", 1=constant_call_address_operand:DI:"",const_int:0, (const_int:0, <UNSPEC_TLS_LD_BASE>)));
	root.1.1.1.2.mode:=DI;
	root.1.1.1.2.1.mode:=QI;
	root.1.1.2.mode:=DI;
}
{:
:}

{:
;; Local dynamic of a single variable is a lose.  Show combine how
;; to convert that back to global dynamic.
:}

abstract set_plus2_unspec1_const2_unspec1 extends set_plus2
{
	root.2.1:=unspec;
	root.2.2:=const;
	root.2.2.1:=unspec;
}

abstract set_plus2_unspec1_const2_unspec1_clobber_x3 extends sequence
{
	root.1:=set_plus2_unspec1_const2_unspec1;
	root.2:=clobber;
	root.3:=clobber;
	root.4:=clobber;
}

abstract parallel_set_unspec2_clobber_x3 extends parallel
{
	root.1:=set_unspec2;
	root.2:=clobber;
	root.3:=clobber;
	root.4:=clobber;
}

concrete *tls_local_dynamic_32_once.insn_and_split instantiates.in  set_plus2_unspec1_const2_unspec1_clobber_x3
{
	root (0=register_operand:SI:"=a", (1=register_operand:SI:"b",
		2=constant_call_address_operand:SI:"z",<UNSPEC_TLS_LD_BASE>),
		(3=tls_symbolic_operand:SI:"", <UNSPEC_DTPOFF>),
		4=SI:"=d",5=SI:"=c",reg(CC:FLAGS_REG));
	root.1.2.mode:=SI;
	root.1.2.1.mode:=SI;
	root.1.2.2.mode:=SI;
	root.1.2.2.1.mode:=SI;
}
cmd_spec.in
{:
  ""
  "#"
  ""
:}
instantiates.out parallel_set_unspec2_clobber_x3
{
	root(duplicate 0, (duplicate 1, duplicate 3, duplicate 2,<UNSPEC_TLS_GD>),
		duplicate 4, duplicate 5, reg(CC:FLAGS_REG));
	root.1.2.mode:=SI;
}
cmd_spec.out
{:
:}

{:

;; Segment register for the thread base ptr load
(define_mode_attr tp_seg [(SI "gs") (DI "fs")])

;; Load and add the thread base pointer from %<tp_seg>:0.
:}

concrete *load_tp_x32.insn instantiates set_unspec2
{
	root (0=register_operand:SI:"=r", (const_int:0, <UNSPEC_TP>));
	root.2.mode:=SI;	
}
{:
  "TARGET_X32"
  "mov{l}\t{%%fs:0, %0|%0, DWORD PTR fs:0}"
  [(set_attr "type" "imov")
   (set_attr "modrm" "0")
   (set_attr "length" "7")
   (set_attr "memory" "load")
   (set_attr "imm_disp" "false")]
:}

abstract set_zero_extend2_unspec1 extends set_zero_extend2
{
	root.2.1:=unspec;
}

concrete *load_tp_x32_zext.insn instantiates set_zero_extend2_unspec1
{
	root (0=register_operand:DI:"=r", (const_int:0,<UNSPEC_TP>));
	root.2.mode:=DI;
	root.2.1.mode:=SI;
}
{:
  "TARGET_X32"
  "mov{l}\t{%%fs:0, %k0|%k0, DWORD PTR fs:0}"
  [(set_attr "type" "imov")
   (set_attr "modrm" "0")
   (set_attr "length" "7")
   (set_attr "memory" "load")
   (set_attr "imm_disp" "false")]
:}

concrete *load_tp_<mode>.insn instantiates set_unspec2
{
	root (0=register_operand:P:"=r",(const_int:0, <UNSPEC_TP>));
	root.2.mode:=P;
}
{:
  "!TARGET_X32"
  "mov{<imodesuffix>}\t{%%<tp_seg>:0, %0|%0, <iptrsize> PTR <tp_seg>:0}"
  [(set_attr "type" "imov")
   (set_attr "modrm" "0")
   (set_attr "length" "7")
   (set_attr "memory" "load")
   (set_attr "imm_disp" "false")]
:}

abstract set_plus2_unspec1_clobber extends set_plus2_clobber
{
	root.1.2.1:=unspec;
}

concrete *add_tp_x32.insn instantiates set_plus2_unspec1_clobber
{
	root (0=register_operand:SI:"=r", (const_int:0,<UNSPEC_TP>), 1=register_operand:SI:"0",reg(CC:FLAGS_REG));
	root.1.2.mode:=SI;
	root.1.2.1.mode:=SI;
}
{:
  "TARGET_X32"
  "add{l}\t{%%fs:0, %0|%0, DWORD PTR fs:0}"
  [(set_attr "type" "alu")
   (set_attr "modrm" "0")
   (set_attr "length" "7")
   (set_attr "memory" "load")
   (set_attr "imm_disp" "false")]
:}

abstract set_zero_extend2_clobber extends sequence
{
	root.1:=set_zero_extend2;
	root.2:=clobber;
}


abstract set_zero_extend2_plus1_unspec1_clobber extends set_zero_extend2_clobber
{
	root.1.2.1:=plus;
	root.1.2.1.1:=unspec;
}

concrete *add_tp_x32_zext.insn instantiates set_zero_extend2_plus1_unspec1_clobber
{
	root (0=register_operand:DI:"=r", (const_int:0, <UNSPEC_TP>), 1=register_operand:SI:"0", reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=SI;
	root.1.2.1.1.mode:=SI;
}

{:
  "TARGET_X32"
  "add{l}\t{%%fs:0, %k0|%k0, DWORD PTR fs:0}"
  [(set_attr "type" "alu")
   (set_attr "modrm" "0")
   (set_attr "length" "7")
   (set_attr "memory" "load")
   (set_attr "imm_disp" "false")]
:}

concrete *add_tp_<mode>.insn instantiates set_plus2_unspec1_clobber
{
	root (0=register_operand:P:"=r", (const_int:0, <UNSPEC_TP>), 1=register_operand:P:"0", reg(CC:FLAGS_REG));
	root.1.2.mode:=P;
	root.1.2.1.mode:=P;
}
{:
  "!TARGET_X32"
  "add{<imodesuffix>}\t{%%<tp_seg>:0, %0|%0, <iptrsize> PTR <tp_seg>:0}"
  [(set_attr "type" "alu")
   (set_attr "modrm" "0")
   (set_attr "length" "7")
   (set_attr "memory" "load")
   (set_attr "imm_disp" "false")]
:}
{:
;; The Sun linker took the AMD64 TLS spec literally and can only handle
;; %rax as destination of the initial executable code sequence.
:}

concrete tls_initial_exec_64_sun.insn instantiates set_unspec2_clobber
{
	root (0=register_operand:DI:"=a", (1=tls_symbolic_operand:DI:"",<UNSPEC_TLS_IE_SUN>), reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
}
{:
  "TARGET_64BIT && TARGET_SUN_TLS"
{
  output_asm_insn
    ("mov{q}\t{%%fs:0, %0|%0, QWORD PTR fs:0}", operands);
  return "add{q}\t{%a1@gottpoff(%%rip), %0|%0, %a1@gottpoff[rip]}";
}
  [(set_attr "type" "multi")]
:}
{:
;; GNU2 TLS patterns can be split.
:}

abstract set_plus2_const2_unspec1 extends set_plus2
{
	root.2.2:=const;
	root.2.2.1:=unspec;
}

abstract parallel_set_unspec2_clobber extends parallel
{
    root.1:=set_unspec2;
    root.2:=clobber;
}

abstract set_plus2_const2_unspec1_parallel_set_unspec2_clobber extends sequence
{
	root.1:=set_plus2_const2_unspec1;
	root.2:=parallel_set_unspec2_clobber;
}

{:
(define_expand "tls_dynamic_gnu2_32"
  [(set (match_dup 3)
    (plus:SI (match_operand:SI 2 "register_operand" "")
         (const:SI
          (unspec:SI [(match_operand:SI 1 "tls_symbolic_operand" "")]
                 UNSPEC_TLSDESC))))
   (parallel
    [(set (match_operand:SI 0 "register_operand" "")
      (unspec:SI [(match_dup 1) (match_dup 3)
              (match_dup 2) (reg:SI SP_REG)]
              UNSPEC_TLSDESC))
     (clobber (reg:CC FLAGS_REG))])]
  "!TARGET_64BIT && TARGET_GNU2_TLS"
{
  operands[3] = can_create_pseudo_p () ? gen_reg_rtx (Pmode) : operands[0];
  ix86_tls_descriptor_calls_expanded_in_cfun = true;
})
:}

abstract set_plus2_const2_unspec1 extends set_plus2
{
	root.2.2:=const;
	root.2.2.1:=unspec;
}

concrete *tls_dynamic_gnu2_lea_32.insn instantiates set_plus2_const2_unspec1
{
	root(0=register_operand:SI:"=r", 1=register_operand:SI:"b",(2=tls_symbolic_operand:SI:"",
		<UNSPEC_TLSDESC>));
	root.2.mode:=SI;
	root.2.2.mode:=SI;
	root.2.2.1.mode:=SI;
}
{:
  "!TARGET_64BIT && TARGET_GNU2_TLS"
  "lea{l}\t{%E2@TLSDESC(%1), %0|%0, %E2@TLSDESC[%1]}"
  [(set_attr "type" "lea")
   (set_attr "mode" "SI")
   (set_attr "length" "6")
   (set_attr "length_address" "4")]
:}

concrete *tls_dynamic_gnu2_call_32.insn instantiates set_unspec2_clobber
{
	root (0=register_operand:SI:"=a", (1=tls_symbolic_operand:SI:"",2=register_operand:SI:"0",3=register_operand:SI:"b",reg(SI:SP_REG),<UNSPEC_TLSDESC>),reg(CC:FLAGS_REG));
	root.1.2.mode:=SI;
}
{:  
  "!TARGET_64BIT && TARGET_GNU2_TLS"
  "call\t{*%a1@TLSCALL(%2)|[DWORD PTR [%2+%a1@TLSCALL]]}"
  [(set_attr "type" "call")
   (set_attr "length" "2")
   (set_attr "length_address" "0")]
:}

abstract set_plus2_unspec1_const2_unspec1 extends set_plus2
{
	root.2.1:=unspec;
	root.2.2:=const;
	root.2.2.1:=unspec;
}

abstract set_plus2_unspec1_const2_unspec1_clobber extends sequence
{
	root.1:=set_plus2_unspec1_const2_unspec1;
	root.2:=clobber;
}

concrete *tls_dynamic_gnu2_combine_32.insn_and_split instantiates.in set_plus2_unspec1_const2_unspec1_clobber
{
	root (0=register_operand:SI:"=&a", (3=tls_modbase_operand:SI:"",
		4=NULL:SI:"", 2=register_operand:SI:"b", reg(SI:SP_REG), <UNSPEC_TLSDESC>),
		(1=tls_symbolic_operand:SI:"",<UNSPEC_DTPOFF>), reg(CC:FLAGS_REG));
	root.1.2.mode:=SI;
	root.1.2.1.mode:=SI;
	root.1.2.2.mode:=SI;
	root.1.2.2.1.mode:=SI;
}
cmd_spec.in
{:
  "!TARGET_64BIT && TARGET_GNU2_TLS"
  "#"
  ""
:}
instantiates.out set
{
	root (duplicate 0, duplicate 5);
}
cmd_spec.out
{:
{
  operands[5] = can_create_pseudo_p () ? gen_reg_rtx (Pmode) : operands[0];
  emit_insn (gen_tls_dynamic_gnu2_32 (operands[5], operands[1], operands[2]));
}
:}

abstract parallel_set_unspec2_clobber extends parallel
{
	root.1:=set_unspec2_clobber;
}

abstract set_unspec2_parallel_set_unspec2_clobber extends sequence
{
	root.1:=set_unspec2;
	root.2:=parallel_set_unspec2_clobber;
}

{:
(define_expand "tls_dynamic_gnu2_64"
  [(set (match_dup 2)
    (unspec:DI [(match_operand 1 "tls_symbolic_operand" "")]
           UNSPEC_TLSDESC))
   (parallel
    [(set (match_operand:DI 0 "register_operand" "")
      (unspec:DI [(match_dup 1) (match_dup 2) (reg:DI SP_REG)]
             UNSPEC_TLSDESC))
     (clobber (reg:CC FLAGS_REG))])]
  "TARGET_64BIT && TARGET_GNU2_TLS"
{
  operands[2] = can_create_pseudo_p () ? gen_reg_rtx (Pmode) : operands[0];
  ix86_tls_descriptor_calls_expanded_in_cfun = true;
})
:}

concrete *tls_dynamic_gnu2_lea_64.insn instantiates set_unspec2
{
	root (0=register_operand:DI:"=r", (1=tls_symbolic_operand:NULL:"", <UNSPEC_TLSDESC>));
	root.2.mode:=DI;
}
{:
  "TARGET_64BIT && TARGET_GNU2_TLS"
  "lea{q}\t{%E1@TLSDESC(%%rip), %0|%0, %E1@TLSDESC[rip]}"
  [(set_attr "type" "lea")
   (set_attr "mode" "DI")
   (set_attr "length" "7")
   (set_attr "length_address" "4")]
:}

concrete *tls_dynamic_gnu2_call_64.insn instantiates set_unspec2_clobber
{
	root (0=register_operand:DI:"=a", (1=tls_symbolic_operand:NULL:"", 2=register_operand:DI:"0",reg(DI:SP_REG),<UNSPEC_TLSDESC>),reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
}
{:
  "TARGET_64BIT && TARGET_GNU2_TLS"
  "call\t{*%a1@TLSCALL(%2)|[QWORD PTR [%2+%a1@TLSCALL]]}"
  [(set_attr "type" "call")
   (set_attr "length" "2")
   (set_attr "length_address" "0")]
:}

concrete *tls_dynamic_gnu2_combine_64.insn_and_split instantiates.in set_plus2_unspec1_const2_unspec1_clobber
{
	root(0=register_operand:DI:"=&a", (2=tls_modbase_operand:DI:"", 3=NULL:DI:"", 
		reg(DI:SP_REG), <UNSPEC_TLSDESC>), (1=tls_symbolic_operand:NULL:"",
		<UNSPEC_DTPOFF>), reg(CC:FLAGS_REG));
	root.1.2.mode:=DI;
	root.1.2.1.mode:=DI;
	root.1.2.2.mode:=DI;
	root.1.2.2.1.mode:=DI;
}
cmd_spec.in
{:
  "TARGET_64BIT && TARGET_GNU2_TLS"
  "#"
  ""
:}
instantiates.out set
{
	root (duplicate 0, duplicate 4);
}
cmd_spec.out
{:
{
  operands[4] = can_create_pseudo_p () ? gen_reg_rtx (Pmode) : operands[0];
  emit_insn (gen_tls_dynamic_gnu2_64 (operands[4], operands[1]));
}
:}

{:

;; These patterns match the binary 387 instructions for addM3, subM3,
;; mulM3 and divM3.  There are three patterns for each of DFmode and
;; SFmode.  The first is the normal insn, the second the same insn but
;; with one operand a conversion, and the third the same insn but with
;; the other operand a conversion.  The conversion may be SFmode or
;; SImode if the target mode DFmode, but only SImode if the target mode
;; is SFmode.

;; Gcc is slightly more smart about handling normal two address instructions
;; so use special patterns for add and mull.
:}

concrete *fop_<mode>_comm_mixed.insn instantiates set_match_operator2
{
	root (0=register_operand:MODEF:"=f,x,x",(3=binary_fp_operator,1=nonimmediate_operand:MODEF:"%0,0,x",2=nonimmediate_operand:MODEF:"fm,xm,xm"));
	root.2.mode:=MODEF;
}
{:
  "SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_MIX_SSE_I387
   && COMMUTATIVE_ARITH_P (operands[3])
   && !(MEM_P (operands[1]) && MEM_P (operands[2]))"
  "* return output_387_binary_op (insn, operands);"
  [(set (attr "type")
	(if_then_else (eq_attr "alternative" "1,2")
	   (if_then_else (match_operand:MODEF 3 "mult_operator" "")
	      (const_string "ssemul")
	      (const_string "sseadd"))
	   (if_then_else (match_operand:MODEF 3 "mult_operator" "")
	      (const_string "fmul")
	      (const_string "fop"))))
   (set_attr "isa" "*,noavx,avx")
   (set_attr "prefix" "orig,orig,vex")
   (set_attr "mode" "<MODE>")]
:}

concrete *fop_<mode>_comm_sse.insn overrides *fop_<mode>_comm_mixed.insn
{
    allconstraints:=("=x,x", "%0,x","xm,xm");
}
{:
  "SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH
   && COMMUTATIVE_ARITH_P (operands[3])
   && !(MEM_P (operands[1]) && MEM_P (operands[2]))"
  "* return output_387_binary_op (insn, operands);"
  [(set (attr "type")
        (if_then_else (match_operand:MODEF 3 "mult_operator" "")
	   (const_string "ssemul")
	   (const_string "sseadd")))
   (set_attr "isa" "noavx,avx")
   (set_attr "prefix" "orig,vex")
   (set_attr "mode" "<MODE>")]
:}

concrete *fop_<mode>_comm_i387.insn overrides *fop_<mode>_comm_mixed.insn
{
	allconstraints:= ("=f", "%0","fm");
}
{:
  "TARGET_80387 && X87_ENABLE_ARITH (<MODE>mode)
   && COMMUTATIVE_ARITH_P (operands[3])
   && !(MEM_P (operands[1]) && MEM_P (operands[2]))"
  "* return output_387_binary_op (insn, operands);"
  [(set (attr "type")
	(if_then_else (match_operand:MODEF 3 "mult_operator" "")
	   (const_string "fmul")
	   (const_string "fop")))
   (set_attr "mode" "<MODE>")]
:}

concrete *fop_<mode>_1_mixed.insn  overrides *fop_<mode>_comm_mixed.insn
{
	allconstraints:=("=f,f,x,x","0,fm,0,x","fm,0,xm,xm");
}
{:
  "SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_MIX_SSE_I387
   && !COMMUTATIVE_ARITH_P (operands[3])
   && !(MEM_P (operands[1]) && MEM_P (operands[2]))"
  "* return output_387_binary_op (insn, operands);"
  [(set (attr "type")
        (cond [(and (eq_attr "alternative" "2,3")
	            (match_operand:MODEF 3 "mult_operator" ""))
                 (const_string "ssemul")
	       (and (eq_attr "alternative" "2,3")
	            (match_operand:MODEF 3 "div_operator" ""))
                 (const_string "ssediv")
	       (eq_attr "alternative" "2,3")
                 (const_string "sseadd")
	       (match_operand:MODEF 3 "mult_operator" "")
                 (const_string "fmul")
               (match_operand:MODEF 3 "div_operator" "")
                 (const_string "fdiv")
              ]
              (const_string "fop")))
   (set_attr "isa" "*,*,noavx,avx")
   (set_attr "prefix" "orig,orig,orig,vex")
   (set_attr "mode" "<MODE>")]
:}

concrete *rcpsf2_sse.insn instantiates set_unspec2
{
	root (0=register_operand:SF:"=x", (1=nonimmediate_operand:SF:"xm",  <UNSPEC_RCP>));
	root.2.mode:=SF;
}
{:
  "TARGET_SSE_MATH"
  "%vrcpss\t{%1, %d0|%d0, %1}"
  [(set_attr "type" "sse")
   (set_attr "atom_sse_attr" "rcp")
   (set_attr "prefix" "maybe_vex")
   (set_attr "mode" "SF")]
:}

concrete *fop_<mode>_1_sse.insn instantiates set_match_operator2
{
	root (0=register_operand:MODEF:"=x,x", (3=binary_fp_operator, 1=register_operand:MODEF:"0,x", 2=nonimmediate_operand:MODEF:"xm,xm"));
	root.2.mode:=MODEF;
}
{:
  "SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH
   && !COMMUTATIVE_ARITH_P (operands[3])"
  "* return output_387_binary_op (insn, operands);"
  [(set (attr "type")
        (cond [(match_operand:MODEF 3 "mult_operator" "")
                 (const_string "ssemul")
	       (match_operand:MODEF 3 "div_operator" "")
                 (const_string "ssediv")
              ]
              (const_string "sseadd")))
   (set_attr "isa" "noavx,avx")
   (set_attr "prefix" "orig,vex")
   (set_attr "mode" "<MODE>")]
:}
{:
;; This pattern is not fully shadowed by the pattern above.
:}

concrete *fop_<mode>_1_i387.insn overrides *fop_<mode>_comm_mixed.insn
{
    allconstraints:=("=f,f","0,fm","fm,0");
}
{:
  "TARGET_80387 && X87_ENABLE_ARITH (<MODE>mode)
   && !(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
   && !COMMUTATIVE_ARITH_P (operands[3])
   && !(MEM_P (operands[1]) && MEM_P (operands[2]))"
  "* return output_387_binary_op (insn, operands);"
  [(set (attr "type")
        (cond [(match_operand:MODEF 3 "mult_operator" "")
                 (const_string "fmul")
               (match_operand:MODEF 3 "div_operator" "")
                 (const_string "fdiv")
              ]
              (const_string "fop")))
   (set_attr "mode" "<MODE>")]
:}

{:
;; ??? Add SSE splitters for these!
:}

{:
(define_insn "*fop_<MODEF:mode>_2_i387"
  [(set (match_operand:MODEF 0 "register_operand" "=f,f")
	(match_operator:MODEF 3 "binary_fp_operator"
	  [(float:MODEF
	     (match_operand:SWI24 1 "nonimmediate_operand" "m,?r"))
	   (match_operand:MODEF 2 "register_operand" "0,0")]))]
  "TARGET_80387 && X87_ENABLE_FLOAT (<MODEF:MODE>mode, <SWI24:MODE>mode)
   && !(SSE_FLOAT_MODE_P (<MODEF:MODE>mode) && TARGET_SSE_MATH)
   && (TARGET_USE_<SWI24:MODE>MODE_FIOP || optimize_function_for_size_p (cfun))"
  "* return which_alternative ? \"#\" : output_387_binary_op (insn, operands);"
  [(set (attr "type")
        (cond [(match_operand:MODEF 3 "mult_operator" "")
                 (const_string "fmul")
               (match_operand:MODEF 3 "div_operator" "")
                 (const_string "fdiv")
              ]
              (const_string "fop")))
   (set_attr "fp_int_src" "true")
   (set_attr "mode" "<SWI24:MODE>")])

(define_insn "*fop_<MODEF:mode>_3_i387"
  [(set (match_operand:MODEF 0 "register_operand" "=f,f")
	(match_operator:MODEF 3 "binary_fp_operator"
	  [(match_operand:MODEF 1 "register_operand" "0,0")
	   (float:MODEF
	     (match_operand:SWI24 2 "nonimmediate_operand" "m,?r"))]))]
  "TARGET_80387 && X87_ENABLE_FLOAT (<MODEF:MODE>mode, <SWI24:MODE>mode)
   && !(SSE_FLOAT_MODE_P (<MODEF:MODE>mode) && TARGET_SSE_MATH)
   && (TARGET_USE_<SWI24:MODE>MODE_FIOP || optimize_function_for_size_p (cfun))"
  "* return which_alternative ? \"#\" : output_387_binary_op (insn, operands);"
  [(set (attr "type")
        (cond [(match_operand:MODEF 3 "mult_operator" "")
                 (const_string "fmul")
               (match_operand:MODEF 3 "div_operator" "")
                 (const_string "fdiv")
              ]
              (const_string "fop")))
   (set_attr "fp_int_src" "true")
   (set_attr "mode" "<MODE>")])
:}

abstract set_match_operator2_float_extend1 extends set_match_operator2
{
	root.2.2:=float_extend;
}

concrete *fop_df_4_i387.insn instantiates set_match_operator2_float_extend1
{
	root (0=register_operand:DF:"=f,f", (3=binary_fp_operator, 1=nonimmediate_operand:SF:"fm,0", 2=register_operand:DF:"0,f"));
	root.2.mode:=DF;
	root.2.2.mode:=DF;
}
{:
  "TARGET_80387 && X87_ENABLE_ARITH (DFmode)
   && !(TARGET_SSE2 && TARGET_SSE_MATH)
   && !(MEM_P (operands[1]) && MEM_P (operands[2]))"
  "* return output_387_binary_op (insn, operands);"
  [(set (attr "type")
        (cond [(match_operand:DF 3 "mult_operator" "")
                 (const_string "fmul")
               (match_operand:DF 3 "div_operator" "")
                 (const_string "fdiv")
              ]
              (const_string "fop")))
   (set_attr "mode" "SF")]
:}

abstract set_match_operator2_float_extend2 extends set_match_operator2
{
	root.2.3:=float_extend;
}

concrete *fop_df_5_i387.insn instantiates set_match_operator2_float_extend2
{
	root (0=register_operand:DF:"=f,f", (3=binary_fp_operator, 1=register_operand:DF:"0,f", 2=nonimmediate_operand:SF:"fm,0"));
	root.2.mode:=DF;
	root.2.3.mode:=DF;
}
{:
  "TARGET_80387 && X87_ENABLE_ARITH (DFmode)
   && !(TARGET_SSE2 && TARGET_SSE_MATH)"
  "* return output_387_binary_op (insn, operands);"
  [(set (attr "type")
        (cond [(match_operand:DF 3 "mult_operator" "")
                 (const_string "fmul")
               (match_operand:DF 3 "div_operator" "")
                 (const_string "fdiv")
              ]
              (const_string "fop")))
   (set_attr "mode" "SF")]
:}

abstract set_match_operator2_float_extend1_float_extend2 extends set_match_operator2
{
    root.2.2:=float_extend;
    root.2.3:=float_extend;
}

concrete *fop_df_6_i387.insn instantiates set_match_operator2_float_extend1_float_extend2
{
    root (0=register_operand:DF:"=f,f", (3=binary_fp_operator, 1=register_operand:SF:"0,f",
        2=nonimmediate_operand:SF:"fm,0"));
    root.2.mode:=DF;
    root.2.2.mode:=DF;
    root.2.3.mode:=DF;
}
{:
  "TARGET_80387 && X87_ENABLE_ARITH (DFmode)
   && !(TARGET_SSE2 && TARGET_SSE_MATH)"
  "* return output_387_binary_op (insn, operands);"
  [(set (attr "type")
        (cond [(match_operand:DF 3 "mult_operator" "")
                 (const_string "fmul")
               (match_operand:DF 3 "div_operator" "")
                 (const_string "fdiv")
              ]
              (const_string "fop")))
   (set_attr "mode" "SF")]
:}

concrete *fop_xf_comm_i387.insn instantiates set_match_operator2
{
	root (0=register_operand:XF:"=f", (3=binary_fp_operator, 1=register_operand:XF:"%0", 2=register_operand:XF:"f"));
	root.2.mode:=XF;
}
{:
  "TARGET_80387
   && COMMUTATIVE_ARITH_P (operands[3])"
  "* return output_387_binary_op (insn, operands);"
  [(set (attr "type")
        (if_then_else (match_operand:XF 3 "mult_operator" "")
           (const_string "fmul")
           (const_string "fop")))
   (set_attr "mode" "XF")]
:}

concrete *fop_xf_1_i387.insn instantiates set_match_operator2
{
	root (0=register_operand:XF:"=f,f", (3=binary_fp_operator, 1=register_operand:XF:"0,f", 2=register_operand:XF:"f,0"));
	root.2.mode:=XF;
}
{:
  "TARGET_80387
   && !COMMUTATIVE_ARITH_P (operands[3])"
  "* return output_387_binary_op (insn, operands);"
  [(set (attr "type")
        (cond [(match_operand:XF 3 "mult_operator" "")
                 (const_string "fmul")
               (match_operand:XF 3 "div_operator" "")
                 (const_string "fdiv")
              ]
              (const_string "fop")))
   (set_attr "mode" "XF")]
:}

abstract set_match_operator2_float1 extends set_match_operator2
{
	root.2.2:=float;
}

concrete *fop_xf_2_i387.insn instantiates set_match_operator2_float1
{
	root (0=register_operand:XF:"=f,f", (3=binary_fp_operator, 1=nonimmediate_operand:SWI24:"m,?r", 2= register_operand:XF:"0,0"));
	root.2.mode:=XF;
	root.2.2.mode:=XF;
}
{:
  "TARGET_80387 && (TARGET_USE_<MODE>MODE_FIOP || optimize_function_for_size_p (cfun))"
  "* return which_alternative ? \"#\" : output_387_binary_op (insn, operands);"
  [(set (attr "type")
        (cond [(match_operand:XF 3 "mult_operator" "")
                 (const_string "fmul")
               (match_operand:XF 3 "div_operator" "")
                 (const_string "fdiv")
              ]
              (const_string "fop")))
   (set_attr "fp_int_src" "true")
   (set_attr "mode" "<MODE>")]
:}

abstract set_match_operator2_float2 extends set_match_operator2
{
	root.2.3:=float;
}

concrete *fop_xf_3_i387.insn instantiates set_match_operator2_float2
{
	root (0=register_operand:XF:"=f,f", (3=binary_fp_operator, 1=register_operand:XF:"0,0", 2=nonimmediate_operand:SWI24:"m,?r"));
	root.2.3.mode:=XF;
	root.2.mode:=XF;
}
{:
  "TARGET_80387 && (TARGET_USE_<MODE>MODE_FIOP || optimize_function_for_size_p (cfun))"
  "* return which_alternative ? \"#\" : output_387_binary_op (insn, operands);"
  [(set (attr "type")
        (cond [(match_operand:XF 3 "mult_operator" "")
                 (const_string "fmul")
               (match_operand:XF 3 "div_operator" "")
                 (const_string "fdiv")
              ]
              (const_string "fop")))
   (set_attr "fp_int_src" "true")
   (set_attr "mode" "<MODE>")]
:}

concrete *fop_xf_4_i387.insn overrides *fop_df_4_i387.insn
{
    DF->XF; SF->MODEF; root.2.1.mode:=XF; root.2.2.mode:=XF;
}
{:
  "TARGET_80387"
  "* return output_387_binary_op (insn, operands);"
  [(set (attr "type")
        (cond [(match_operand:XF 3 "mult_operator" "")
                 (const_string "fmul")
               (match_operand:XF 3 "div_operator" "")
                 (const_string "fdiv")
              ]
              (const_string "fop")))
   (set_attr "mode" "<MODE>")]
:}

concrete *fop_xf_5_i387.insn overrides *fop_df_5_i387.insn
{
	root.2.mode:=XF;	root.2.3.mode:=XF;     DF->XF; SF->MODEF;
}
{:
  "TARGET_80387"
  "* return output_387_binary_op (insn, operands);"
  [(set (attr "type")
        (cond [(match_operand:XF 3 "mult_operator" "")
                 (const_string "fmul")
               (match_operand:XF 3 "div_operator" "")
                 (const_string "fdiv")
              ]
              (const_string "fop")))
   (set_attr "mode" "<MODE>")]
:}

{:
(define_insn "*fop_xf_6_i387"
  [(set (match_operand:XF 0 "register_operand" "=f,f")
    (match_operator:XF 3 "binary_fp_operator"
      [(float_extend:XF
         (match_operand:MODEF 1 "register_operand" "0,f"))
       (float_extend:XF
         (match_operand:MODEF 2 "nonimmediate_operand" "fm,0"))]))]
  "TARGET_80387"
  "* return output_387_binary_op (insn, operands);"
  [(set (attr "type")
        (cond [(match_operand:XF 3 "mult_operator" "")
                 (const_string "fmul")
               (match_operand:XF 3 "div_operator" "")
                 (const_string "fdiv")
              ]
              (const_string "fop")))
   (set_attr "mode" "<MODE>")])

:}

concrete .split instantiates.in set_match_operator2_float1
{
	root (0=register_operand:NULL:"", (3=binary_fp_operator, 1=register_operand:SWI24:"", 2=register_operand:NULL:""));
}
cmd_spec.in
{:
  "reload_completed
   && X87_FLOAT_MODE_P (GET_MODE (operands[0]))
   && X87_ENABLE_FLOAT (GET_MODE (operands[0]), GET_MODE (operands[1]))"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  operands[4] = ix86_force_to_memory (GET_MODE (operands[1]), operands[1]);
  operands[4] = gen_rtx_FLOAT (GET_MODE (operands[0]), operands[4]);
  emit_insn (gen_rtx_SET (VOIDmode, operands[0],
			  gen_rtx_fmt_ee (GET_CODE (operands[3]),
					  GET_MODE (operands[3]),
					  operands[4],
					  operands[2])));
  ix86_free_from_memory (GET_MODE (operands[1]));
  DONE;
}
:}

concrete .split instantiates.in set_match_operator2_float2
{
	root (0=register_operand:NULL:"", (3=binary_fp_operator, 1=register_operand:NULL:"", 2=register_operand:SWI24:""));
}
cmd_spec.in
{:
  "reload_completed
   && X87_FLOAT_MODE_P (GET_MODE (operands[0]))
   && X87_ENABLE_FLOAT (GET_MODE (operands[0]), GET_MODE (operands[2]))"
:}
instantiates.out sequence 
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  operands[4] = ix86_force_to_memory (GET_MODE (operands[2]), operands[2]);
  operands[4] = gen_rtx_FLOAT (GET_MODE (operands[0]), operands[4]);
  emit_insn (gen_rtx_SET (VOIDmode, operands[0],
			  gen_rtx_fmt_ee (GET_CODE (operands[3]),
					  GET_MODE (operands[3]),
					  operands[1],
					  operands[4])));
  ix86_free_from_memory (GET_MODE (operands[2]));
  DONE;
}
:}

{:

;; FPU special functions.

;; This pattern implements a no-op XFmode truncation for
;; all fancy i386 XFmode math functions.
:}

concrete truncxf<mode>2_i387_noop_unspec.insn instantiates set_unspec2
{
	root (0=register_operand:MODEF:"=f", (1=register_operand:XF:"f", <UNSPEC_TRUNC_NOOP>));
	root.2.mode:=MODEF;
}
{:
  "TARGET_USE_FANCY_MATH_387"
  "* return output_387_reg_move (insn, operands);"
  [(set_attr "type" "fmov")
   (set_attr "mode" "<MODE>")]
:}

abstract set_sqrt2 extends set
{
	root.2:=sqrt;
}

concrete sqrtxf2.insn instantiates set_sqrt2
{
	root (0=register_operand:XF:"=f", 1=register_operand:XF:"0");
	root.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387"
  "fsqrt"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")
   (set_attr "athlon_decode" "direct")
   (set_attr "amdfam10_decode" "direct")
   (set_attr "bdver1_decode" "direct")]
:}

abstract set_sqrt2_float_extend1 extends set_sqrt2
{	
	root.2.1:=float_extend;
}

concrete sqrt_extend<mode>xf2_i387.insn instantiates set_sqrt2_float_extend1
{
	root (0=register_operand:XF:"=f", 1=register_operand:MODEF:"0");
	root.2.mode:=XF;
	root.2.1.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387"
  "fsqrt"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")
   (set_attr "athlon_decode" "direct")
   (set_attr "amdfam10_decode" "direct")
   (set_attr "bdver1_decode" "direct")]
:}

concrete *rsqrtsf2_sse.insn instantiates set_unspec2
{
	root (0=register_operand:SF:"=x", (1=nonimmediate_operand:SF:"xm", <UNSPEC_RSQRT>));
	root.2.mode:=SF;
}	
{:
  "TARGET_SSE_MATH"
  "%vrsqrtss\t{%1, %d0|%d0, %1}"
  [(set_attr "type" "sse")
   (set_attr "atom_sse_attr" "rcp")
   (set_attr "prefix" "maybe_vex")
   (set_attr "mode" "SF")]
:}

concrete rsqrtsf2.exp instantiates set_unspec2
{
	root (0=register_operand:SF:"", (1=nonimmediate_operand:SF:"", <UNSPEC_RSQRT>));
	root.2.mode:=SF;
}
{:
  "TARGET_SSE_MATH"
{
  ix86_emit_swsqrtsf (operands[0], operands[1], SFmode, 1);
  DONE;
}
:}

concrete *sqrt<mode>2_sse.insn instantiates set_sqrt2
{
	root (0=register_operand:MODEF:"=x", 1=nonimmediate_operand:MODEF:"xm");
	root.2.mode:=MODEF;
}
{:
  "SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH"
  "%vsqrt<ssemodesuffix>\t{%1, %d0|%d0, %1}"
  [(set_attr "type" "sse")
   (set_attr "atom_sse_attr" "sqrt")
   (set_attr "prefix" "maybe_vex")
   (set_attr "mode" "<MODE>")
   (set_attr "athlon_decode" "*")
   (set_attr "amdfam10_decode" "*")
   (set_attr "bdver1_decode" "*")]
:}

concrete sqrt<mode>2.exp overrides *sqrt<mode>2_sse.insn
{
	allconstraints:=("","");
}
{:
  "(TARGET_USE_FANCY_MATH_387 && X87_ENABLE_ARITH (<MODE>mode))
   || (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)"
{
  if (<MODE>mode == SFmode
      && TARGET_SSE_MATH
      && TARGET_RECIP_SQRT
      && !optimize_function_for_size_p (cfun)
      && flag_finite_math_only && !flag_trapping_math
      && flag_unsafe_math_optimizations)
    {
      ix86_emit_swsqrtsf (operands[0], operands[1], SFmode, 0);
      DONE;
    }

  if (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH))
    {
      rtx op0 = gen_reg_rtx (XFmode);
      rtx op1 = force_reg (<MODE>mode, operands[1]);

      emit_insn (gen_sqrt_extend<mode>xf2_i387 (op0, op1));
      emit_insn (gen_truncxf<mode>2_i387_noop_unspec (operands[0], op0));
      DONE;
   }
}
:}

abstract set_unspec2_x3 extends sequence
{
	root.1:=set_unspec2;
	root.2:=set_unspec2;
	root.3:=set_unspec2;
}

concrete fpremxf4_i387.insn instantiates set_unspec2_x3
{
	root (0=register_operand:XF:"=f", (2=register_operand:XF:"0", 3=register_operand:XF:"1", <UNSPEC_FPREM_F>), 1=register_operand:XF:"=u", (duplicate 2, duplicate 3, <UNSPEC_FPREM_U>), reg(CCFP:FPSR_REG), (duplicate 2, duplicate 3, <UNSPEC_C2_FLAG>));
	root.1.2.mode:=XF;
	root.2.2.mode:=XF;
	root.3.2.mode:=CCFP;
}
{:
  "TARGET_USE_FANCY_MATH_387"
  "fprem"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}

concrete fmodxf3.exp instantiates use_x3
{
	root (0=register_operand:XF:"", 1=general_operand:XF:"", 2=general_operand:XF:"");
}
{:
  "TARGET_USE_FANCY_MATH_387"
{
  rtx label = gen_label_rtx ();

  rtx op1 = gen_reg_rtx (XFmode);
  rtx op2 = gen_reg_rtx (XFmode);

  emit_move_insn (op2, operands[2]);
  emit_move_insn (op1, operands[1]);

  emit_label (label);
  emit_insn (gen_fpremxf4_i387 (op1, op2, op1, op2));
  ix86_emit_fp_unordered_jump (label);
  LABEL_NUSES (label) = 1;

  emit_move_insn (operands[0], op1);
  DONE;
}
:}

concrete fmod<mode>3.exp overrides fmodxf3.exp
{
	XF->MODEF;
}
{:
  "TARGET_USE_FANCY_MATH_387"
{
  rtx (*gen_truncxf) (rtx, rtx);

  rtx label = gen_label_rtx ();

  rtx op1 = gen_reg_rtx (XFmode);
  rtx op2 = gen_reg_rtx (XFmode);

  emit_insn (gen_extend<mode>xf2 (op2, operands[2]));
  emit_insn (gen_extend<mode>xf2 (op1, operands[1]));

  emit_label (label);
  emit_insn (gen_fpremxf4_i387 (op1, op2, op1, op2));
  ix86_emit_fp_unordered_jump (label);
  LABEL_NUSES (label) = 1;

  /* Truncate the result properly for strict SSE math.  */
  if (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH
      && !TARGET_MIX_SSE_I387)
    gen_truncxf = gen_truncxf<mode>2;
  else
    gen_truncxf = gen_truncxf<mode>2_i387_noop_unspec;

  emit_insn (gen_truncxf (operands[0], op1));
  DONE;
}
:}

concrete fprem1xf4_i387.insn instantiates set_unspec2_x3
{
	root (0=register_operand:XF:"=f", (2=register_operand:XF:"0", 3=register_operand:XF:"1",<UNSPEC_FPREM1_F>), 1=register_operand:XF:"=u", (duplicate 2, duplicate 3,<UNSPEC_FPREM1_U>), reg(CCFP:FPSR_REG), (duplicate 2, duplicate 3, <UNSPEC_C2_FLAG>));
	root.1.2.mode:=XF;
	root.2.2.mode:=XF;
	root.3.2.mode:=CCFP;
}
{:
  "TARGET_USE_FANCY_MATH_387"
  "fprem1"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}

concrete remainderxf3.exp instantiates use_x3
{
	root (0=register_operand:XF:"", 1=general_operand:XF:"", 2=general_operand:XF:"");
}
{:
  "TARGET_USE_FANCY_MATH_387"
{
  rtx label = gen_label_rtx ();

  rtx op1 = gen_reg_rtx (XFmode);
  rtx op2 = gen_reg_rtx (XFmode);

  emit_move_insn (op2, operands[2]);
  emit_move_insn (op1, operands[1]);

  emit_label (label);
  emit_insn (gen_fprem1xf4_i387 (op1, op2, op1, op2));
  ix86_emit_fp_unordered_jump (label);
  LABEL_NUSES (label) = 1;

  emit_move_insn (operands[0], op1);
  DONE;
}
:}

concrete remainder<mode>3.exp overrides remainderxf3.exp
{
	root.1.1.mode:=MODEF;
	root.2.1.mode:=MODEF;
	root.3.1.mode:=MODEF;
}
{:
  "TARGET_USE_FANCY_MATH_387"
{
  rtx (*gen_truncxf) (rtx, rtx);

  rtx label = gen_label_rtx ();

  rtx op1 = gen_reg_rtx (XFmode);
  rtx op2 = gen_reg_rtx (XFmode);

  emit_insn (gen_extend<mode>xf2 (op2, operands[2]));
  emit_insn (gen_extend<mode>xf2 (op1, operands[1]));

  emit_label (label);

  emit_insn (gen_fprem1xf4_i387 (op1, op2, op1, op2));
  ix86_emit_fp_unordered_jump (label);
  LABEL_NUSES (label) = 1;

  /* Truncate the result properly for strict SSE math.  */
  if (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH
      && !TARGET_MIX_SSE_I387)
    gen_truncxf = gen_truncxf<mode>2;
  else
    gen_truncxf = gen_truncxf<mode>2_i387_noop_unspec;

  emit_insn (gen_truncxf (operands[0], op1));
  DONE;
}
:}

concrete *sinxf2_i387.insn instantiates set_unspec2
{
	root (0=register_operand:XF:"=f", (1=register_operand:XF:"0", <UNSPEC_SIN>));
	root.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "fsin"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}

abstract set_unspec2_float_extend1 extends set_unspec2
{
	root.2.1:=float_extend;
}

concrete *sin_extend<mode>xf2_i387.insn instantiates set_unspec2_float_extend1
{
	root (0=register_operand:XF:"=f", (1=register_operand:MODEF:"0",<UNSPEC_SIN>));
	root.2.mode:=XF;
	root.2.1.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
  "fsin"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}

concrete *cosxf2_i387.insn instantiates set_unspec2
{
	root (0=register_operand:XF:"=f", (1=register_operand:XF:"0", <UNSPEC_COS>));
	root.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "fcos"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}

concrete *cos_extend<mode>xf2_i387.insn instantiates set_unspec2_float_extend1
{
	root (0=register_operand:XF:"=f", (1=register_operand:MODEF:"0", <UNSPEC_COS>));
	root.2.mode:=XF;
	root.2.1.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
  "fcos"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}
{:
;; When sincos pattern is defined, sin and cos builtin functions will be
;; expanded to sincos pattern with one of its outputs left unused.
;; CSE pass will figure out if two sincos patterns can be combined,
;; otherwise sincos pattern will be split back to sin or cos pattern,
;; depending on the unused output.
:}
abstract set_unspec2_x2 extends sequence
{
	root.1:=set_unspec2;
	root.2:=set_unspec2;
}

concrete sincosxf3.insn instantiates set_unspec2_x2
{
	root (0=register_operand:XF:"=f", (2=register_operand:XF:"0", <UNSPEC_SINCOS_COS>), 1=register_operand:XF:"=u",(duplicate 2, <UNSPEC_SINCOS_SIN>));
	root.1.2.mode:=XF;
	root.2.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "fsincos"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}

concrete .split instantiates.in set_unspec2_x2
{
	root (0=register_operand:XF:"", (2=register_operand:XF:"", <UNSPEC_SINCOS_COS>), 1=register_operand:XF:"", (duplicate 2, <UNSPEC_SINCOS_SIN>));
	root.1.2.mode:=XF;
	root.2.2.mode:=XF;
}
cmd_spec.in
{:
  "find_regno_note (insn, REG_UNUSED, REGNO (operands[0]))
   && can_create_pseudo_p ()"
:}
instantiates.out set_unspec2
{
	root (duplicate 1, (duplicate 2, <UNSPEC_SIN>));
	root.2.mode:=XF;
}
cmd_spec.out
{:
:}

concrete .split instantiates.in set_unspec2_x2
{
	root (0=register_operand:XF:"", (2=register_operand:XF:"", <UNSPEC_SINCOS_COS>), 1=register_operand:XF:"", (duplicate 2, <UNSPEC_SINCOS_SIN>));
	root.1.2.mode:=XF;
	root.2.2.mode:=XF;
}
cmd_spec.in
{:
  "find_regno_note (insn, REG_UNUSED, REGNO (operands[1]))
   && can_create_pseudo_p ()"
:}
instantiates.out set_unspec2
{
	root (duplicate 0, (duplicate 2, <UNSPEC_COS>));
	root.2.mode:=XF;
}
cmd_spec.out
{:
:}

abstract set_unspec2_float_extend1_x2 extends set_unspec2_x2
{
	root.1.2.1:=float_extend;
	root.2.2.1:=float_extend;
}

concrete sincos_extend<mode>xf3_i387.insn instantiates set_unspec2_float_extend1_x2
{
	root (0=register_operand:XF:"=f", (2=register_operand:MODEF:"0",<UNSPEC_SINCOS_COS>), 1=register_operand:XF:"=u",(duplicate 2, <UNSPEC_SINCOS_SIN>));
	root.1.2.mode:=XF;
	root.1.2.1.mode:=XF;
	root.2.2.mode:=XF;
	root.2.2.1.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
  "fsincos"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}

concrete .split instantiates.in set_unspec2_float_extend1_x2
{
	root (0=register_operand:XF:"", (2=register_operand:MODEF:"", <UNSPEC_SINCOS_COS>), 1=register_operand:XF:"", (duplicate 2, <UNSPEC_SINCOS_SIN>));
	root.1.2.mode:=XF;
	root.1.2.1.mode:=XF;
	root.2.2.mode:=XF;
	root.2.2.1.mode:=XF;
}
cmd_spec.in
{:
  "find_regno_note (insn, REG_UNUSED, REGNO (operands[0]))
   && can_create_pseudo_p ()"
:}
instantiates.out set_unspec2_float_extend1
{
	root (duplicate 1, (duplicate 2, <UNSPEC_SIN>));
	root.2.mode:=XF;
	root.2.1.mode:=XF;
}
cmd_spec.out
{:
:}
concrete .split instantiates.in set_unspec2_float_extend1_x2
{
	root (0=register_operand:XF:"", (2=register_operand:MODEF:"", <UNSPEC_SINCOS_COS>), 1=register_operand:XF:"", (duplicate 2, <UNSPEC_SINCOS_SIN>));
	root.1.2.mode:=XF;
	root.1.2.1.mode:=XF;
	root.2.2.mode:=XF;
	root.2.2.1.mode:=XF;
}
cmd_spec.in
{:
  "find_regno_note (insn, REG_UNUSED, REGNO (operands[1]))
   && can_create_pseudo_p ()"
:}
instantiates.out set_unspec2_float_extend1
{
	root (duplicate 0, (duplicate 2, <UNSPEC_COS>));
	root.2.mode:=XF;
	root.2.1.mode:=XF;
}
cmd_spec.out
{:
:}

concrete sincos<mode>3.exp instantiates use_x3
{
	root (0=register_operand:MODEF:"", 1=register_operand:MODEF:"", 2=register_operand:MODEF:"");
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
{
  rtx op0 = gen_reg_rtx (XFmode);
  rtx op1 = gen_reg_rtx (XFmode);

  emit_insn (gen_sincos_extend<mode>xf3_i387 (op0, op1, operands[2]));
  emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
  emit_insn (gen_truncxf<mode>2_i387_noop (operands[1], op1));
  DONE;
}
:}

abstract set_set_unspec2 extends sequence
{
	root.1:=set;
	root.2:=set_unspec2;
}

concrete fptanxf4_i387.insn instantiates set_set_unspec2
{
	root (0=register_operand:XF:"=f", 3=const_double_operand:XF:"F", 1=register_operand:XF:"=u", (2=register_operand:XF:"0",<UNSPEC_TAN>));
	root.2.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations
   && standard_80387_constant_p (operands[3]) == 2"
  "fptan"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}

abstract set_set_unspec2_float_extend1 extends set_set_unspec2
{
	root.2.2.1:=float_extend;
}

concrete fptan_extend<mode>xf4_i387.insn instantiates set_set_unspec2_float_extend1 
{
	root (0=register_operand:MODEF:"=f", 3=const_double_operand:MODEF:"F", 1=register_operand:XF:"=u", (2=register_operand:MODEF:"0", <UNSPEC_TAN>));
	root.2.2.mode:=XF;
	root.2.2.1.mode:=XF;

}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations
   && standard_80387_constant_p (operands[3]) == 2"
  "fptan"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}

abstract use_x2 extends sequence
{
	root.1:=use;
	root.2:=use;
}

concrete tanxf2.exp instantiates use_x2
{
	root (0=register_operand:XF:"", 1=register_operand:XF:"");
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
{
  rtx one = gen_reg_rtx (XFmode);
  rtx op2 = CONST1_RTX (XFmode); /* fld1 */

  emit_insn (gen_fptanxf4_i387 (one, operands[0], operands[1], op2));
  DONE;
}
:}

concrete tan<mode>2.exp overrides tanxf2.exp
{
	XF->MODEF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
{
  rtx op0 = gen_reg_rtx (XFmode);

  rtx one = gen_reg_rtx (<MODE>mode);
  rtx op2 = CONST1_RTX (<MODE>mode); /* fld1 */

  emit_insn (gen_fptan_extend<mode>xf4_i387 (one, op0,
					     operands[1], op2));
  emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
  DONE;
}
:}

concrete *fpatanxf3_i387.insn instantiates set_unspec2_clobber
{
	root (0=register_operand:XF:"=f", (1=register_operand:XF:"0",2=register_operand:XF:"u", <UNSPEC_FPATAN>), 3=XF:"=2");
	root.1.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "fpatan"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}

abstract set_unspec2_float_extend1_float_extend2 extends set_unspec2
{
	root.2.1:=float_extend;
	root.2.2:=float_extend;
}


abstract set_unspec2_float_extend1_float_extend2_clobber extends sequence
{
	root.1:=set_unspec2_float_extend1_float_extend2;
	root.2:=clobber;
}

concrete fpatan_extend<mode>xf3_i387.insn instantiates set_unspec2_float_extend1_float_extend2_clobber
{
	root (0=register_operand:XF:"=f",(1=register_operand:MODEF:"0", 2=register_operand:MODEF:"u", <UNSPEC_FPATAN>), 3=XF:"=2");
	root.1.2.mode:=XF;
	root.1.2.1.mode:=XF;
	root.1.2.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
  "fpatan"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}

abstract parallel_set_unspec2_clobber extends parallel
{
	root.1:=set_unspec2;
	root.2:=clobber;
}

concrete atan2xf3.exp instantiates parallel_set_unspec2_clobber
{
	root (0=register_operand:XF:"", (2=register_operand:XF:"", 1=register_operand:XF:"", <UNSPEC_FPATAN>), 3=XF:"");
	root.1.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
:}

concrete atan2<mode>3.exp instantiates use_x3
{
	root (0=register_operand:MODEF:"", 1=register_operand:MODEF:"", 2=register_operand:MODEF:"");
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
{
  rtx op0 = gen_reg_rtx (XFmode);

  emit_insn (gen_fpatan_extend<mode>xf3_i387 (op0, operands[2], operands[1]));
  emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
  DONE;
}
:}

concrete atanxf2.exp instantiates parallel_set_unspec2_clobber
{
	root (0=register_operand:XF:"", (duplicate 2, 1=register_operand:XF:"", <UNSPEC_FPATAN>), 3=XF:"");
	root.1.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
{
  operands[2] = gen_reg_rtx (XFmode);
  emit_move_insn (operands[2], CONST1_RTX (XFmode));  /* fld1 */
}
:}
concrete atan<mode>2.exp overrides tanxf2.exp
{
	XF->MODEF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
{
  rtx op0 = gen_reg_rtx (XFmode);

  rtx op2 = gen_reg_rtx (<MODE>mode);
  emit_move_insn (op2, CONST1_RTX (<MODE>mode));  /* fld1 */

  emit_insn (gen_fpatan_extend<mode>xf3_i387 (op0, op2, operands[1]));
  emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
  DONE;
}
:}



abstract set_mult2_set_minus2_set_sqrt2_parallel_set_unspec2_clobber extends sequence
{
	root.1:=set_mult2;
	root.2:=set_minus2;
	root.3:=set_sqrt2;
	root.4:=parallel_set_unspec2_clobber;
}

{:
(define_expand "asinxf2"
  [(set (match_dup 2)
    (mult:XF (match_operand:XF 1 "register_operand" "")
         (match_dup 1)))
   (set (match_dup 4) (minus:XF (match_dup 3) (match_dup 2)))
   (set (match_dup 5) (sqrt:XF (match_dup 4)))
   (parallel [(set (match_operand:XF 0 "register_operand" "")
               (unspec:XF [(match_dup 5) (match_dup 1)]
                  UNSPEC_FPATAN))
          (clobber (match_scratch:XF 6 ""))])]
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
{
  int i;

  if (optimize_insn_for_size_p ())
    FAIL;

  for (i = 2; i < 6; i++)
    operands[i] = gen_reg_rtx (XFmode);

  emit_move_insn (operands[3], CONST1_RTX (XFmode));  /* fld1 */
})

:}

concrete asin<mode>2.exp overrides tanxf2.exp
{
	XF->MODEF;
	root.2.1.predicate:=general_operand;
}
{:
 "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
{
  rtx op0 = gen_reg_rtx (XFmode);
  rtx op1 = gen_reg_rtx (XFmode);

  if (optimize_insn_for_size_p ())
    FAIL;

  emit_insn (gen_extend<mode>xf2 (op1, operands[1]));
  emit_insn (gen_asinxf2 (op0, op1));
  emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
  DONE;
}
:}
{:
(define_expand "acosxf2"
  [(set (match_dup 2)
    (mult:XF (match_operand:XF 1 "register_operand" "")
         (match_dup 1)))
   (set (match_dup 4) (minus:XF (match_dup 3) (match_dup 2)))
   (set (match_dup 5) (sqrt:XF (match_dup 4)))
   (parallel [(set (match_operand:XF 0 "register_operand" "")
               (unspec:XF [(match_dup 1) (match_dup 5)]
                  UNSPEC_FPATAN))
          (clobber (match_scratch:XF 6 ""))])]
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
{
  int i;

  if (optimize_insn_for_size_p ())
    FAIL;

  for (i = 2; i < 6; i++)
    operands[i] = gen_reg_rtx (XFmode);

  emit_move_insn (operands[3], CONST1_RTX (XFmode));  /* fld1 */
})
:}

concrete acos<mode>2.exp overrides asin<mode>2.exp
{
   root.1.predicate:=register_operand; root.2.predicate:=general_operand; 
}
{:
 "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
{
  rtx op0 = gen_reg_rtx (XFmode);
  rtx op1 = gen_reg_rtx (XFmode);

  if (optimize_insn_for_size_p ())
    FAIL;

  emit_insn (gen_extend<mode>xf2 (op1, operands[1]));
  emit_insn (gen_acosxf2 (op0, op1));
  emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
  DONE;
}
:}

concrete fyl2xxf3_i387.insn instantiates set_unspec2_clobber
{
	root (0=register_operand:XF:"=f", (1=register_operand:XF:"0", 2=register_operand:XF:"u",<UNSPEC_FYL2X>),
		3=XF:"=2");
	root.1.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "fyl2x"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}

abstract set_unspec2_float_extend1_clobber extends sequence
{
	root.1:=set_unspec2_float_extend1;
	root.2:=clobber;
}


concrete fyl2x_extend<mode>xf3_i387.insn instantiates set_unspec2_float_extend1_clobber
{
	root (0=register_operand:XF:"=f",
		(1=register_operand:MODEF:"0", 2=register_operand:XF:"u",
		 <UNSPEC_FYL2X>), 3=XF:"=2");
	root.1.2.mode:=XF;
	root.1.2.1.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
  "fyl2x"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}

concrete logxf2.exp instantiates parallel_set_unspec2_clobber
{
	root (0=register_operand:XF:"", (1=register_operand:XF:"", 
		duplicate 2, <UNSPEC_FYL2X>), 3=XF:"");
	root.1.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
{
  operands[2] = gen_reg_rtx (XFmode);
  emit_move_insn (operands[2], standard_80387_constant_rtx (4)); /* fldln2 */
}
:}

concrete log<mode>2.exp instantiates use_x2
{
	root (0=register_operand:MODEF:"", 1=register_operand:MODEF:"");
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
{
  rtx op0 = gen_reg_rtx (XFmode);

  rtx op2 = gen_reg_rtx (XFmode);
  emit_move_insn (op2, standard_80387_constant_rtx (4)); /* fldln2 */

  emit_insn (gen_fyl2x_extend<mode>xf3_i387 (op0, operands[1], op2));
  emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
  DONE;
}
:}
concrete log10xf2.exp instantiates parallel_set_unspec2_clobber
{
	root (0=register_operand:XF:"", (1=register_operand:XF:"",
		duplicate 2, <UNSPEC_FYL2X>), 3=XF:"");
	root.1.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
{
  operands[2] = gen_reg_rtx (XFmode);
  emit_move_insn (operands[2], standard_80387_constant_rtx (3)); /* fldlg2 */
}
:}

concrete log10<mode>2.exp overrides log<mode>2.exp
{
    root.1.predicate:=register_operand;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
{
  rtx op0 = gen_reg_rtx (XFmode);

  rtx op2 = gen_reg_rtx (XFmode);
  emit_move_insn (op2, standard_80387_constant_rtx (3)); /* fldlg2 */

  emit_insn (gen_fyl2x_extend<mode>xf3_i387 (op0, operands[1], op2));
  emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
  DONE;
}
:}

concrete log2xf2.exp instantiates parallel_set_unspec2_clobber
{
	root (0=register_operand:XF:"", (1=register_operand:XF:"",
		duplicate 2, <UNSPEC_FYL2X>), 3=XF:"");
	root.1.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
{
  operands[2] = gen_reg_rtx (XFmode);
  emit_move_insn (operands[2], CONST1_RTX (XFmode)); /* fld1 */
}
:}

concrete log2<mode>2.exp overrides log<mode>2.exp
{
    root.1.predicate:=register_operand;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
{
  rtx op0 = gen_reg_rtx (XFmode);

  rtx op2 = gen_reg_rtx (XFmode);
  emit_move_insn (op2, CONST1_RTX (XFmode)); /* fld1 */

  emit_insn (gen_fyl2x_extend<mode>xf3_i387 (op0, operands[1], op2));
  emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
  DONE;
}
:}

concrete fyl2xp1xf3_i387.insn  instantiates set_unspec2_clobber
{
	root (0=register_operand:XF:"=f", (1=register_operand:XF:"0",
		2=register_operand:XF:"u", <UNSPEC_FYL2XP1>), 3=XF:"=2");
	root.1.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "fyl2xp1"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}


concrete fyl2xp1_extend<mode>xf3_i387.insn instantiates set_unspec2_float_extend1_clobber
{
	root (0=register_operand:XF:"=f", 
		(1=register_operand:MODEF:"0", 2=register_operand:XF:"u", <UNSPEC_FYL2XP1>),
		3=XF:"=2");
	root.1.2.mode:=XF;
	root.1.2.1.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
  "fyl2xp1"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}

concrete log1pxf2.exp instantiates use_x2
{
	root (0=register_operand:XF:"", 1=register_operand:XF:"");
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
{
  if (optimize_insn_for_size_p ())
    FAIL;

  ix86_emit_i387_log1p (operands[0], operands[1]);
  DONE;
}
:}

concrete log1p<mode>2.exp overrides log1pxf2.exp
{
	XF->MODEF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
{
  rtx op0;

  if (optimize_insn_for_size_p ())
    FAIL;

  op0 = gen_reg_rtx (XFmode);

  operands[1] = gen_rtx_FLOAT_EXTEND (XFmode, operands[1]);

  ix86_emit_i387_log1p (op0, operands[1]);
  emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
  DONE;
}
:}

concrete fxtractxf3_i387.insn instantiates set_unspec2_x2
{
	root (0=register_operand:XF:"=f", 
		(2=register_operand:XF:"0",<UNSPEC_XTRACT_FRACT>),
		1=register_operand:XF:"=u",
		(duplicate 2, <UNSPEC_XTRACT_EXP>));
	root.1.2.mode:=XF;
	root.2.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "fxtract"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}

concrete fxtract_extend<mode>xf3_i387.insn instantiates set_unspec2_float_extend1_x2
{
	root (0=register_operand:XF:"=f", (2=register_operand:MODEF:"0",
		<UNSPEC_XTRACT_FRACT>), 1=register_operand:XF:"=u", (duplicate 2, <UNSPEC_XTRACT_EXP>));
	
	root.1.2.mode:=XF;
	root.1.2.1.mode:=XF;

	root.2.2.mode:=XF;
	root.2.2.1.mode:=XF;
		
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
  "fxtract"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}

abstract parallel_set_unspec2_x2 extends parallel
{
	root.1:=set_unspec2; root.2:=set_unspec2;
}


concrete logbxf2.exp instantiates parallel_set_unspec2_x2
{
	root (duplicate 2, (1=register_operand:XF:"", 
		<UNSPEC_XTRACT_FRACT>), 0=register_operand:XF:"", 
		(duplicate 1, <UNSPEC_XTRACT_EXP>));
	root.1.2.mode:=XF;
	root.2.2.mode:=XF;
}
{:  
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "operands[2] = gen_reg_rtx (XFmode);"
:}

concrete logb<mode>2.exp instantiates use_x2
{
	root (0=register_operand:MODEF:"", 1=register_operand:MODEF:"");
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
{
  rtx op0 = gen_reg_rtx (XFmode);
  rtx op1 = gen_reg_rtx (XFmode);

  emit_insn (gen_fxtract_extend<mode>xf3_i387 (op0, op1, operands[1]));
  emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op1));
  DONE;
}
:}

concrete ilogbxf2.exp overrides log1pxf2.exp
{
	root.1.1.mode:=SI;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
{
  rtx op0, op1;

  if (optimize_insn_for_size_p ())
    FAIL;

  op0 = gen_reg_rtx (XFmode);
  op1 = gen_reg_rtx (XFmode);

  emit_insn (gen_fxtractxf3_i387 (op0, op1, operands[1]));
  emit_insn (gen_fix_truncxfsi2 (operands[0], op1));
  DONE;
}
:}

concrete ilogb<mode>2.exp overrides log1pxf2.exp
{
	root.1.1.mode:=SI; root.2.1.mode:=MODEF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
{
  rtx op0, op1;

  if (optimize_insn_for_size_p ())
    FAIL;

  op0 = gen_reg_rtx (XFmode);
  op1 = gen_reg_rtx (XFmode);

  emit_insn (gen_fxtract_extend<mode>xf3_i387 (op0, op1, operands[1]));
  emit_insn (gen_fix_truncxfsi2 (operands[0], op1));
  DONE;
}
:}

concrete *f2xm1xf2_i387.insn instantiates set_unspec2
{
	root (0=register_operand:XF:"=f", (1=register_operand:XF:"0",
		<UNSPEC_F2XM1>));
		root.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "f2xm1"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}

concrete *fscalexf4_i387.insn instantiates set_unspec2_x2
{
	root (0=register_operand:XF:"=f", (2=register_operand:XF:"0",
		3=register_operand:XF:"1",<UNSPEC_FSCALE_FRACT>),
		1=register_operand:XF:"=u", (duplicate 2, duplicate 3,
		<UNSPEC_FSCALE_EXP>));
	root.1.2.mode:=XF;
	root.2.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "fscale"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}

abstract parallel_set_unspec2_x2 extends parallel
{
	root.1:=set_unspec2;
	root.2:=set_unspec2;
}

abstract  set_mult2_set_unspec2_set_minus2_set_unspec2_set_plus2_parallel_set_unspec_x2 extends sequence
{
	root.1:=set_mult2;
	root.2:=set_unspec2;
	root.3:=set_minus2;
	root.4:=set_unspec2;
	root.5:=set_plus2;
	root.6:=parallel_set_unspec2_x2;
}

{:
(define_expand "expNcorexf3"
  [(set (match_dup 3) (mult:XF (match_operand:XF 1 "register_operand" "")
                   (match_operand:XF 2 "register_operand" "")))
   (set (match_dup 4) (unspec:XF [(match_dup 3)] UNSPEC_FRNDINT))
   (set (match_dup 5) (minus:XF (match_dup 3) (match_dup 4)))
   (set (match_dup 6) (unspec:XF [(match_dup 5)] UNSPEC_F2XM1))
   (set (match_dup 8) (plus:XF (match_dup 6) (match_dup 7)))
   (parallel [(set (match_operand:XF 0 "register_operand" "")
           (unspec:XF [(match_dup 8) (match_dup 4)]
                  UNSPEC_FSCALE_FRACT))
          (set (match_dup 9)
           (unspec:XF [(match_dup 8) (match_dup 4)]
                  UNSPEC_FSCALE_EXP))])]
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
{
  int i;

  if (optimize_insn_for_size_p ())
    FAIL;

  for (i = 3; i < 10; i++)
    operands[i] = gen_reg_rtx (XFmode);

  emit_move_insn (operands[7], CONST1_RTX (XFmode));  /* fld1 */
})
:}

concrete expxf2.exp overrides log1pxf2.exp
{
	root.1.1.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
{
  rtx op2;

  if (optimize_insn_for_size_p ())
    FAIL;

  op2 = gen_reg_rtx (XFmode);
  emit_move_insn (op2, standard_80387_constant_rtx (5)); /* fldl2e */

  emit_insn (gen_expNcorexf3 (operands[0], operands[1], op2));
  DONE;
}
:}

{:
(define_expand "exp<mode>2"
  [(use (match_operand:MODEF 0 "register_operand" ""))
   (use (match_operand:MODEF 1 "general_operand" ""))]
 "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
{
  rtx op0, op1;

  if (optimize_insn_for_size_p ())
    FAIL;

  op0 = gen_reg_rtx (XFmode);
  op1 = gen_reg_rtx (XFmode);

  emit_insn (gen_extend<mode>xf2 (op1, operands[1]));
  emit_insn (gen_expxf2 (op0, op1));
  emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
  DONE;
})
:}

concrete exp10xf2.exp overrides log1pxf2.exp
{
	root.1.1.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
{
  rtx op2;

  if (optimize_insn_for_size_p ())
    FAIL;

  op2 = gen_reg_rtx (XFmode);
  emit_move_insn (op2, standard_80387_constant_rtx (6)); /* fldl2t */

  emit_insn (gen_expNcorexf3 (operands[0], operands[1], op2));
  DONE;
}
:}

concrete exp10<mode>2.exp overrides log1pxf2.exp
{
	XF->MODEF;
	root.2.1.predicate:=general_operand;
}
{:
 "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
{
  rtx op0, op1;

  if (optimize_insn_for_size_p ())
    FAIL;

  op0 = gen_reg_rtx (XFmode);
  op1 = gen_reg_rtx (XFmode);

  emit_insn (gen_extend<mode>xf2 (op1, operands[1]));
  emit_insn (gen_exp10xf2 (op0, op1));
  emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
  DONE;
}
:}

concrete exp2xf2.exp overrides log1pxf2.exp
{
	root.2.1.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
{
  rtx op2;

  if (optimize_insn_for_size_p ())
    FAIL;

  op2 = gen_reg_rtx (XFmode);
  emit_move_insn (op2, CONST1_RTX (XFmode));  /* fld1 */

  emit_insn (gen_expNcorexf3 (operands[0], operands[1], op2));
  DONE;
}
:}

concrete exp2<mode>2.exp overrides log1pxf2.exp
{
	XF->MODEF; root.2.1.predicate:=general_operand;
}
{:
 "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
{
  rtx op0, op1;

  if (optimize_insn_for_size_p ())
    FAIL;

  op0 = gen_reg_rtx (XFmode);
  op1 = gen_reg_rtx (XFmode);

  emit_insn (gen_extend<mode>xf2 (op1, operands[1]));
  emit_insn (gen_exp2xf2 (op0, op1));
  emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
  DONE;
}
:}

abstract set_minus2_float_extend2 extends set_minus2
{
	root.2.2:=float_extend;
}


abstract set_mult2_set_unspec2_set_minus2_set_float_extend2_set_unspec2_parallel_set_unspec2_x2_set_minus2_float_extend2_set_plus2 extends sequence
{
	root.1:=set_mult2;
	root.2:=set_unspec2;
	root.3:=set_minus2;
	root.4:=set_float_extend2;
	root.5:=set_unspec2;
	root.6:=parallel_set_unspec2_x2;
	root.7:=parallel_set_unspec2_x2;
	root.8:=set_minus2_float_extend2;
	root.9:=set_plus2;
}

{:
(define_expand "expm1xf2"
  [(set (match_dup 3) (mult:XF (match_operand:XF 1 "register_operand" "")
                   (match_dup 2)))
   (set (match_dup 4) (unspec:XF [(match_dup 3)] UNSPEC_FRNDINT))
   (set (match_dup 5) (minus:XF (match_dup 3) (match_dup 4)))
   (set (match_dup 9) (float_extend:XF (match_dup 13)))
   (set (match_dup 6) (unspec:XF [(match_dup 5)] UNSPEC_F2XM1))
   (parallel [(set (match_dup 7)
           (unspec:XF [(match_dup 6) (match_dup 4)]
                  UNSPEC_FSCALE_FRACT))
          (set (match_dup 8)
           (unspec:XF [(match_dup 6) (match_dup 4)]
                  UNSPEC_FSCALE_EXP))])
   (parallel [(set (match_dup 10)
           (unspec:XF [(match_dup 9) (match_dup 8)]
                  UNSPEC_FSCALE_FRACT))
          (set (match_dup 11)
           (unspec:XF [(match_dup 9) (match_dup 8)]
                  UNSPEC_FSCALE_EXP))])
   (set (match_dup 12) (minus:XF (match_dup 10)
                 (float_extend:XF (match_dup 13))))
   (set (match_operand:XF 0 "register_operand" "")
    (plus:XF (match_dup 12) (match_dup 7)))]
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
{
  int i;

  if (optimize_insn_for_size_p ())
    FAIL;

  for (i = 2; i < 13; i++)
    operands[i] = gen_reg_rtx (XFmode);

  operands[13]
    = validize_mem (force_const_mem (SFmode, CONST1_RTX (SFmode))); /* fld1 */

  emit_move_insn (operands[2], standard_80387_constant_rtx (5)); /* fldl2e */
})
:}

concrete expm1<mode>2.exp instantiates use_x2
{
	root (0=register_operand:MODEF:"", 1=general_operand:MODEF:"");
}
{:
 "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
{
  rtx op0, op1;

  if (optimize_insn_for_size_p ())
    FAIL;

  op0 = gen_reg_rtx (XFmode);
  op1 = gen_reg_rtx (XFmode);

  emit_insn (gen_extend<mode>xf2 (op1, operands[1]));
  emit_insn (gen_expm1xf2 (op0, op1));
  emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
  DONE;
}
:}

abstract set_float2_parallel_set_unspec2_x2 extends sequence
{
	root.1:=set;
	root.1.2:=float;
	root.2:=parallel_set_unspec2_x2;
}

{:
(define_expand "ldexpxf3"
  [(set (match_dup 3)
    (float:XF (match_operand:SI 2 "register_operand" "")))
   (parallel [(set (match_operand:XF 0 " register_operand" "")
           (unspec:XF [(match_operand:XF 1 "register_operand" "")
                   (match_dup 3)]
                  UNSPEC_FSCALE_FRACT))
          (set (match_dup 4)
           (unspec:XF [(match_dup 1) (match_dup 3)]
                  UNSPEC_FSCALE_EXP))])]
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
{
  if (optimize_insn_for_size_p ())
    FAIL;

  operands[3] = gen_reg_rtx (XFmode);
  operands[4] = gen_reg_rtx (XFmode);
})
:}

concrete ldexp<mode>3.exp instantiates use_x3
{
	root (0=register_operand:MODEF:"",1=general_operand:MODEF:"",
	2=register_operand:SI:"");
}
{:
 "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
{
  rtx op0, op1;

  if (optimize_insn_for_size_p ())
    FAIL;

  op0 = gen_reg_rtx (XFmode);
  op1 = gen_reg_rtx (XFmode);

  emit_insn (gen_extend<mode>xf2 (op1, operands[1]));
  emit_insn (gen_ldexpxf3 (op0, op1, operands[2]));
  emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
  DONE;
}
:}

concrete scalbxf3.exp instantiates parallel_set_unspec2_x2
{
	root (0=register_operand:XF:"", (1=register_operand:XF:"",
		2=register_operand:XF:"", <UNSPEC_FSCALE_FRACT>),
		duplicate 3, (duplicate 1, duplicate 2, <UNSPEC_FSCALE_EXP>));

	root.1.2.mode:=XF;
	root.2.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
{
  if (optimize_insn_for_size_p ())
    FAIL;

  operands[3] = gen_reg_rtx (XFmode);
}
:}

concrete scalb<mode>3.exp instantiates use_x3
{
	root (0=register_operand:MODEF:"", 1=general_operand:MODEF:"",
		2=general_operand:MODEF:"");
}
{:
 "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
{
  rtx op0, op1, op2;

  if (optimize_insn_for_size_p ())
    FAIL;

  op0 = gen_reg_rtx (XFmode);
  op1 = gen_reg_rtx (XFmode);
  op2 = gen_reg_rtx (XFmode);

  emit_insn (gen_extend<mode>xf2 (op1, operands[1]));
  emit_insn (gen_extend<mode>xf2 (op2, operands[2]));
  emit_insn (gen_scalbxf3 (op0, op1, op2));
  emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
  DONE;
}
:}

concrete significandxf2.exp instantiates parallel_set_unspec2_x2
{
	root (0=register_operand:XF:"", (1=register_operand:XF:"",
		<UNSPEC_XTRACT_FRACT>), duplicate 2, (duplicate 1, <UNSPEC_XTRACT_EXP>));

	root.1.2.mode:=XF;
	root.2.2.mode:=XF;
}	
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "operands[2] = gen_reg_rtx (XFmode);"
:}

concrete significand<mode>2.exp instantiates use_x2
{
	root (0=register_operand:MODEF:"", 1=register_operand:MODEF:"");
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
{
  rtx op0 = gen_reg_rtx (XFmode);
  rtx op1 = gen_reg_rtx (XFmode);

  emit_insn (gen_fxtract_extend<mode>xf3_i387 (op0, op1, operands[1]));
  emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
  DONE;
}
:}

concrete sse4_1_round<mode>2.insn instantiates set_unspec2
{
	root (0=register_operand:MODEF:"=x",(1=register_operand:MODEF:"x",
		2=const_0_to_15_operand:SI:"n", <UNSPEC_ROUND>));
	root.2.mode:=MODEF;
}
{:
  "TARGET_ROUND"
  "%vround<ssemodesuffix>\t{%2, %1, %d0|%d0, %1, %2}"
  [(set_attr "type" "ssecvt")
   (set_attr "prefix_extra" "1")
   (set_attr "prefix" "maybe_vex")
   (set_attr "mode" "<MODE>")]
:}

concrete rintxf2.insn instantiates set_unspec2
{
	root (0=register_operand:XF:"=f", (1=register_operand:XF:"0",<UNSPEC_FRNDINT>));
	root.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "frndint"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "XF")]
:}

concrete rint<mode>2.exp overrides log1pxf2.exp
{
	XF->MODEF;
}
{:
  "(TARGET_USE_FANCY_MATH_387
    && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
	|| TARGET_MIX_SSE_I387)
    && flag_unsafe_math_optimizations)
   || (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH
       && !flag_trapping_math)"
{
  if (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH
      && !flag_trapping_math)
    {
      if (TARGET_ROUND)
	emit_insn (gen_sse4_1_round<mode>2
		   (operands[0], operands[1], GEN_INT (ROUND_MXCSR)));
      else if (optimize_insn_for_size_p ())
        FAIL;
      else
	ix86_expand_rint (operands[0], operands[1]);
    }
  else
    {
      rtx op0 = gen_reg_rtx (XFmode);
      rtx op1 = gen_reg_rtx (XFmode);

      emit_insn (gen_extend<mode>xf2 (op1, operands[1]));
      emit_insn (gen_rintxf2 (op0, op1));

      emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
    }
  DONE;
}
:}

concrete round<mode>2.exp instantiates sequence
{
	root (0=register_operand:X87MODEF:"",
		1=nonimmediate_operand:X87MODEF:"");
}
{:
  "(TARGET_USE_FANCY_MATH_387
    && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
	|| TARGET_MIX_SSE_I387)
    && flag_unsafe_math_optimizations)
   || (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH
       && !flag_trapping_math && !flag_rounding_math)"
{
  if (optimize_insn_for_size_p ())
    FAIL;

  if (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH
      && !flag_trapping_math && !flag_rounding_math)
    {
      if (TARGET_ROUND)
        {
	  operands[1] = force_reg (<MODE>mode, operands[1]);
	  ix86_expand_round_sse4 (operands[0], operands[1]);
	}
      else if (TARGET_64BIT || (<MODE>mode != DFmode))
	ix86_expand_round (operands[0], operands[1]);
      else
	ix86_expand_rounddf_32 (operands[0], operands[1]);
    }
  else
    {
      operands[1] = force_reg (<MODE>mode, operands[1]);
      ix86_emit_i387_round (operands[0], operands[1]);
    }
  DONE;
}
:}

concrete *fistdi2_1.insn_and_split instantiates.in set_unspec2
{
	root (0=nonimmediate_operand:DI:"", (1=register_operand:XF:"", <UNSPEC_FIST>));
	root.2.mode:=DI;
}
cmd_spec.in
{:
  "TARGET_USE_FANCY_MATH_387
   && can_create_pseudo_p ()"
  "#"
  "&& 1"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  if (memory_operand (operands[0], VOIDmode))
    emit_insn (gen_fistdi2 (operands[0], operands[1]));
  else
    {
      operands[2] = assign_386_stack_local (DImode, SLOT_TEMP);
      emit_insn (gen_fistdi2_with_temp (operands[0], operands[1],
					 operands[2]));
    }
  DONE;
}
  [(set_attr "type" "fpspc")
   (set_attr "mode" "DI")]
:}

concrete fistdi2.insn instantiates set_unspec2_clobber
{
	root (0=memory_operand:DI:"=m", (1=register_operand:XF:"f", <UNSPEC_FIST>),
	2=XF:"=&1f");
	root.1.2.mode:=DI;
}
{:
  "TARGET_USE_FANCY_MATH_387"
  "* return output_fix_trunc (insn, operands, false);"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "DI")]
:}

abstract set_unspec2_clobber_clobber extends sequence
{
	root.1:=set_unspec2;
	root.2:=clobber;
	root.3:=clobber;
}

concrete fistdi2_with_temp.insn instantiates set_unspec2_clobber_clobber
{
	root (0=nonimmediate_operand:DI:"=m,?r",
		(1=register_operand:XF:"f,f", <UNSPEC_FIST>),
		2=memory_operand:DI:"=X,m",
		3=XF:"=&1f,&1f");
	root.1.2.mode:=DI;
}
{:
  "TARGET_USE_FANCY_MATH_387"
  "#"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "DI")]
:}

{:
;; TODO
;; CAUSE: 3=NULL:"" not supported by the compiler.
:}
{:
(define_split
  [(set (match_operand:DI 0 "register_operand" "")
	(unspec:DI [(match_operand:XF 1 "register_operand" "")]
		   UNSPEC_FIST))
   (clobber (match_operand:DI 2 "memory_operand" ""))
   (clobber (match_scratch 3 ""))]
  "reload_completed"
  [(parallel [(set (match_dup 2) (unspec:DI [(match_dup 1)] UNSPEC_FIST))
	      (clobber (match_dup 3))])
   (set (match_dup 0) (match_dup 2))])
:}
{:
(define_split
  [(set (match_operand:DI 0 "memory_operand" "")
	(unspec:DI [(match_operand:XF 1 "register_operand" "")]
		   UNSPEC_FIST))
   (clobber (match_operand:DI 2 "memory_operand" ""))
   (clobber (match_scratch 3 ""))]
  "reload_completed"
  [(parallel [(set (match_dup 0) (unspec:DI [(match_dup 1)] UNSPEC_FIST))
	      (clobber (match_dup 3))])])
:}

concrete *fist<mode>2_1.insn_and_split instantiates.in set_unspec2
{
	root (0=register_operand:SWI24:"", (1=register_operand:XF:"", <UNSPEC_FIST>));
	root.2.mode:=SWI24;
}
cmd_spec.in
{:
  "TARGET_USE_FANCY_MATH_387
   && can_create_pseudo_p ()"
  "#"
  "&& 1"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  operands[2] = assign_386_stack_local (<MODE>mode, SLOT_TEMP);
  emit_insn (gen_fist<mode>2_with_temp (operands[0], operands[1],
					operands[2]));
  DONE;
}
  [(set_attr "type" "fpspc")
   (set_attr "mode" "<MODE>")]
:}

concrete fist<mode>2.insn instantiates set_unspec2
{
	root (0=memory_operand:SWI24:"=m", (1=register_operand:XF:"f", <UNSPEC_FIST>));
	root.2.mode:=SWI24;
}
{:
  "TARGET_USE_FANCY_MATH_387"
  "* return output_fix_trunc (insn, operands, false);"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "<MODE>")]
:}

concrete fist<mode>2_with_temp.insn instantiates set_unspec2_clobber
{
	root (0=register_operand:SWI24:"=r", (1=register_operand:XF:"f", <UNSPEC_FIST>),
		2=memory_operand:SWI24:"=m");
	root.1.2.mode:=SWI24;
}
{:
  "TARGET_USE_FANCY_MATH_387"
  "#"
  [(set_attr "type" "fpspc")
   (set_attr "mode" "<MODE>")]
:}

abstract set_unspec2_set extends sequence
{
	root.1:=set_unspec2;
	root.2:=set;
}


concrete .split instantiates.in set_unspec2_clobber
{
	root (0=register_operand:SWI24:"", (1=register_operand:XF:"",
		<UNSPEC_FIST>), 2=memory_operand:SWI24:"");
	root.1.2.mode:=SWI24;
}
cmd_spec.in
{:
  "reload_completed"
:}
instantiates.out set_unspec2_set
{
	root (duplicate 2, (duplicate 1, <UNSPEC_FIST>), duplicate 0, duplicate 2);
	root.1.2.mode:=SWI24;
}
cmd_spec.out
{:
:}

{:
(define_split
  [(set (match_operand:SWI24 0 "memory_operand" "")
    (unspec:SWI24 [(match_operand:XF 1 "register_operand" "")]
              UNSPEC_FIST))
   (clobber (match_operand:SWI24 2 "memory_operand" ""))]
  "reload_completed"
  [(set (match_dup 0) (unspec:SWI24 [(match_dup 1)] UNSPEC_FIST))])
:}


concrete lrintxf<mode>2.exp instantiates set_unspec2
{
	root (0=nonimmediate_operand:SWI248x:"", (1=register_operand:XF:"",<UNSPEC_FIST>));
	root.2.mode:=SWI248x;
}
{:
  "TARGET_USE_FANCY_MATH_387"
:}

{:
;; TODO
(define_expand "lrint<MODEF:mode><SWI48x:mode>2"
  [(set (match_operand:SWI48x 0 "nonimmediate_operand" "")
     (unspec:SWI48x [(match_operand:MODEF 1 "register_operand" "")]
			UNSPEC_FIX_NOTRUNC))]
  "SSE_FLOAT_MODE_P (<MODEF:MODE>mode) && TARGET_SSE_MATH
   && ((<SWI48x:MODE>mode != DImode) || TARGET_64BIT)")

(define_expand "lround<X87MODEF:mode><SWI248x:mode>2"
  [(match_operand:SWI248x 0 "nonimmediate_operand" "")
   (match_operand:X87MODEF 1 "register_operand" "")]
  "(TARGET_USE_FANCY_MATH_387
    && (!(SSE_FLOAT_MODE_P (<X87MODEF:MODE>mode) && TARGET_SSE_MATH)
	|| TARGET_MIX_SSE_I387)
    && flag_unsafe_math_optimizations)
   || (SSE_FLOAT_MODE_P (<X87MODEF:MODE>mode) && TARGET_SSE_MATH
       && <SWI248x:MODE>mode != HImode 
       && ((<SWI248x:MODE>mode != DImode) || TARGET_64BIT)
       && !flag_trapping_math && !flag_rounding_math)"
{
  if (optimize_insn_for_size_p ())
    FAIL;

  if (SSE_FLOAT_MODE_P (<X87MODEF:MODE>mode) && TARGET_SSE_MATH
      && <SWI248x:MODE>mode != HImode
      && ((<SWI248x:MODE>mode != DImode) || TARGET_64BIT)
      && !flag_trapping_math && !flag_rounding_math)
    ix86_expand_lround (operands[0], operands[1]);
  else
    ix86_emit_i387_round (operands[0], operands[1]);
  DONE;
})

;; Rounding mode control word calculation could clobber FLAGS_REG.
:}

concrete frndintxf2_floor.insn_and_split instantiates.in set_unspec2_clobber
{
	root (0=register_operand:XF:"", (1=register_operand:XF:"",
		<UNSPEC_FRNDINT_FLOOR>), reg(CC:FLAGS_REG));
	root.1.2.mode:=XF;
}
cmd_spec.in
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations
   && can_create_pseudo_p ()"
  "#"
  "&& 1"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  ix86_optimize_mode_switching[I387_FLOOR] = 1;

  operands[2] = assign_386_stack_local (HImode, SLOT_CW_STORED);
  operands[3] = assign_386_stack_local (HImode, SLOT_CW_FLOOR);

  emit_insn (gen_frndintxf2_floor_i387 (operands[0], operands[1],
					operands[2], operands[3]));
  DONE;
}
  [(set_attr "type" "frndint")
   (set_attr "i387_cw" "floor")
   (set_attr "mode" "XF")]
:}

abstract set_unspec2_use_x2 extends sequence
{
	root.1:=set_unspec2;
	root.2:=use;
	root.3:=use;
}

concrete frndintxf2_floor_i387.insn instantiates set_unspec2_use_x2
{
	root (0=register_operand:XF:"=f", (
		1=register_operand:XF:"0",<UNSPEC_FRNDINT_FLOOR>),
		2=memory_operand:HI:"m",
		3=memory_operand:HI:"m");
	root.1.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "fldcw\t%3\n\tfrndint\n\tfldcw\t%2"
  [(set_attr "type" "frndint")
   (set_attr "i387_cw" "floor")
   (set_attr "mode" "XF")]
:}

concrete floorxf2.exp overrides log1pxf2.exp
{	
	root.2.1.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
{
  if (optimize_insn_for_size_p ())
    FAIL;
  emit_insn (gen_frndintxf2_floor (operands[0], operands[1]));
  DONE;
}
:}

concrete floor<mode>2.exp  overrides log1pxf2.exp
{
	XF->MODEF;
}	
{:
  "(TARGET_USE_FANCY_MATH_387
    && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
	|| TARGET_MIX_SSE_I387)
    && flag_unsafe_math_optimizations)
   || (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH
       && !flag_trapping_math)"
{
  if (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH
      && !flag_trapping_math)
    {
      if (TARGET_ROUND)
	emit_insn (gen_sse4_1_round<mode>2
		   (operands[0], operands[1], GEN_INT (ROUND_FLOOR)));
      else if (optimize_insn_for_size_p ())
        FAIL;
      else if (TARGET_64BIT || (<MODE>mode != DFmode))
	ix86_expand_floorceil (operands[0], operands[1], true);
      else
	ix86_expand_floorceildf_32 (operands[0], operands[1], true);
    }
  else
    {
      rtx op0, op1;

      if (optimize_insn_for_size_p ())
	FAIL;

      op0 = gen_reg_rtx (XFmode);
      op1 = gen_reg_rtx (XFmode);
      emit_insn (gen_extend<mode>xf2 (op1, operands[1]));
      emit_insn (gen_frndintxf2_floor (op0, op1));

      emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
    }
  DONE;
}
:}

concrete *fist<mode>2_floor_1.insn_and_split instantiates.in set_unspec2_clobber
{
	root (0=nonimmediate_operand:SWI248x:"",
		(1=register_operand:XF:"", <UNSPEC_FIST_FLOOR>)
		, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI248x;
}
cmd_spec.in
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations
   && can_create_pseudo_p ()"
  "#"
  "&& 1"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  ix86_optimize_mode_switching[I387_FLOOR] = 1;

  operands[2] = assign_386_stack_local (HImode, SLOT_CW_STORED);
  operands[3] = assign_386_stack_local (HImode, SLOT_CW_FLOOR);
  if (memory_operand (operands[0], VOIDmode))
    emit_insn (gen_fist<mode>2_floor (operands[0], operands[1],
				      operands[2], operands[3]));
  else
    {
      operands[4] = assign_386_stack_local (<MODE>mode, SLOT_TEMP);
      emit_insn (gen_fist<mode>2_floor_with_temp (operands[0], operands[1],
						  operands[2], operands[3],
						  operands[4]));
    }
  DONE;
}
  [(set_attr "type" "fistp")
   (set_attr "i387_cw" "floor")
   (set_attr "mode" "<MODE>")]
:}

abstract set_unspec2_use_x2_clobber extends set_unspec2_use_x2
{
	root.4:=clobber;
}

concrete fistdi2_floor.insn instantiates set_unspec2_use_x2_clobber
{
	root (0=memory_operand:DI:"=m",
		(1=register_operand:XF:"f",<UNSPEC_FIST_FLOOR>),
		2=memory_operand:HI:"m",
		3=memory_operand:HI:"m",
		4=XF:"=&1f");
	root.1.2.mode:=DI;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "* return output_fix_trunc (insn, operands, false);"
  [(set_attr "type" "fistp")
   (set_attr "i387_cw" "floor")
   (set_attr "mode" "DI")]
:}

abstract set_unspec2_use_x2_clobber_x2 extends set_unspec2_use_x2_clobber
{
	root.5:=clobber;
}

concrete fistdi2_floor_with_temp.insn instantiates set_unspec2_use_x2_clobber_x2
{
	root (0=nonimmediate_operand:DI:"=m,?r",
		(1=register_operand:XF:"f,f",<UNSPEC_FIST_FLOOR>),
		2=memory_operand:HI:"m,m", 3=memory_operand:HI:"m,m",
		4=memory_operand:DI:"=X,m", 5=XF:"=&1f,&1f");
	root.1.2.mode:=DI;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "#"
  [(set_attr "type" "fistp")
   (set_attr "i387_cw" "floor")
   (set_attr "mode" "DI")]
:}

{:
;; TODO Cause NULL in match_scratch
(define_split
  [(set (match_operand:DI 0 "register_operand" "")
	(unspec:DI [(match_operand:XF 1 "register_operand" "")]
		   UNSPEC_FIST_FLOOR))
   (use (match_operand:HI 2 "memory_operand" ""))
   (use (match_operand:HI 3 "memory_operand" ""))
   (clobber (match_operand:DI 4 "memory_operand" ""))
   (clobber (match_scratch 5 ""))]
  "reload_completed"
  [(parallel [(set (match_dup 4)
		   (unspec:DI [(match_dup 1)] UNSPEC_FIST_FLOOR))
	      (use (match_dup 2))
	      (use (match_dup 3))
	      (clobber (match_dup 5))])
   (set (match_dup 0) (match_dup 4))])

(define_split
  [(set (match_operand:DI 0 "memory_operand" "")
	(unspec:DI [(match_operand:XF 1 "register_operand" "")]
		   UNSPEC_FIST_FLOOR))
   (use (match_operand:HI 2 "memory_operand" ""))
   (use (match_operand:HI 3 "memory_operand" ""))
   (clobber (match_operand:DI 4 "memory_operand" ""))
   (clobber (match_scratch 5 ""))]
  "reload_completed"
  [(parallel [(set (match_dup 0)
		   (unspec:DI [(match_dup 1)] UNSPEC_FIST_FLOOR))
	      (use (match_dup 2))
	      (use (match_dup 3))
	      (clobber (match_dup 5))])])
:}

concrete fist<mode>2_floor.insn instantiates set_unspec2_use_x2
{
	root (0=memory_operand:SWI24:"=m",
		(1=register_operand:XF:"f", <UNSPEC_FIST_FLOOR>),
		2=memory_operand:HI:"m", 3=memory_operand:HI:"m");
	root.1.2.mode:=SWI24;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "* return output_fix_trunc (insn, operands, false);"
  [(set_attr "type" "fistp")
   (set_attr "i387_cw" "floor")
   (set_attr "mode" "<MODE>")]
:}

concrete fist<mode>2_floor_with_temp.insn instantiates set_unspec2_use_x2_clobber
{
	root (0=nonimmediate_operand:SWI24:"=m,?r",
		(1=register_operand:XF:"f,f", <UNSPEC_FIST_FLOOR>),
		2=memory_operand:HI:"m,m",
		3=memory_operand:HI:"m,m",4=memory_operand:SWI24:"=X,m");
	root.1.2.mode:=SWI24;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "#"
  [(set_attr "type" "fistp")
   (set_attr "i387_cw" "floor")
   (set_attr "mode" "<MODE>")]
:}

abstract parallel_set_unspec2_use_x2 extends parallel
{
	root.1:=set_unspec2;
	root.2:=use;
	root.3:=use;
}


abstract parallel_set_unspec2_use_x2_set extends sequence
{
	root.1:=parallel_set_unspec2_use_x2;
	root.2:=set;
}

concrete .split instantiates.in set_unspec2_use_x2_clobber
{
	root (0=register_operand:SWI24:"",
		(1=register_operand:XF:"", <UNSPEC_FIST_FLOOR>),
		2=memory_operand:HI:"", 3=memory_operand:HI:"",
		4=memory_operand:SWI24:"");
	root.1.2.mode:=SWI24;
}
cmd_spec.in
{:
  "reload_completed"
:}
instantiates.out parallel_set_unspec2_use_x2_set
{
	root ((duplicate 4, (duplicate 1, <UNSPEC_FIST_FLOOR>),
		duplicate 2, duplicate 3), duplicate 0, duplicate 4);
	root.1.1.2.mode:=SWI24;
}
cmd_spec.out
{:
:}

concrete .split instantiates.in set_unspec2_use_x2_clobber
{
	root (0=memory_operand:SWI24:"", 
		(1=register_operand:XF:"", <UNSPEC_FIST_FLOOR>),
		2=memory_operand:HI:"", 3=memory_operand:HI:"",
		4=memory_operand:SWI24:"");
	root.1.2.mode:=SWI24;
}
cmd_spec.in
{:
  "reload_completed"
:}
instantiates.out parallel_set_unspec2_use_x2
{
	root (duplicate 0, (duplicate 1,
		<UNSPEC_FIST_FLOOR>), duplicate 2, duplicate 3);
	root.1.2.mode:=SWI24;
}
cmd_spec.out
{:
:}

concrete lfloorxf<mode>2.exp instantiates parallel_set_unspec2_clobber
{
	root (0=nonimmediate_operand:SWI248x:"",
		(1=register_operand:XF:"", <UNSPEC_FIST_FLOOR>),
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI248x;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!TARGET_SSE_MATH || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
:}
{:
;;TODO
(define_expand "lfloor<MODEF:mode><SWI48:mode>2"
  [(match_operand:SWI48 0 "nonimmediate_operand" "")
   (match_operand:MODEF 1 "register_operand" "")]
  "SSE_FLOAT_MODE_P (<MODEF:MODE>mode) && TARGET_SSE_MATH
   && !flag_trapping_math"
{
  if (TARGET_64BIT && optimize_insn_for_size_p ())
    FAIL;
  ix86_expand_lfloorceil (operands[0], operands[1], true);
  DONE;
})

;; Rounding mode control word calculation could clobber FLAGS_REG.
:}

concrete frndintxf2_ceil.insn_and_split instantiates.in set_unspec2_clobber
{
	root (0=register_operand:XF:"", 
		(1=register_operand:XF:"", <UNSPEC_FRNDINT_CEIL>),
		reg(CC:FLAGS_REG));
	
	root.1.2.mode:=XF;
}
cmd_spec.in
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations
   && can_create_pseudo_p ()"
  "#"
  "&& 1"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  ix86_optimize_mode_switching[I387_CEIL] = 1;

  operands[2] = assign_386_stack_local (HImode, SLOT_CW_STORED);
  operands[3] = assign_386_stack_local (HImode, SLOT_CW_CEIL);

  emit_insn (gen_frndintxf2_ceil_i387 (operands[0], operands[1],
				       operands[2], operands[3]));
  DONE;
}
  [(set_attr "type" "frndint")
   (set_attr "i387_cw" "ceil")
   (set_attr "mode" "XF")]
:}

concrete frndintxf2_ceil_i387.insn instantiates set_unspec2_use_x2
{
	root (0=register_operand:XF:"=f",
		(1=register_operand:XF:"0", <UNSPEC_FRNDINT_CEIL>),
		2=memory_operand:HI:"m",
		3=memory_operand:HI:"m");
	root.1.2.mode:=XF;
}
{:  
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "fldcw\t%3\n\tfrndint\n\tfldcw\t%2"
  [(set_attr "type" "frndint")
   (set_attr "i387_cw" "ceil")
   (set_attr "mode" "XF")]
:}

concrete ceilxf2.exp overrides log1pxf2.exp
{
	root.2.1.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
{
  if (optimize_insn_for_size_p ())
    FAIL;
  emit_insn (gen_frndintxf2_ceil (operands[0], operands[1]));
  DONE;
}
:}

concrete ceil<mode>2.exp overrides log1pxf2.exp
{
	XF->MODEF;
}
{:
  "(TARGET_USE_FANCY_MATH_387
    && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
	|| TARGET_MIX_SSE_I387)
    && flag_unsafe_math_optimizations)
   || (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH
       && !flag_trapping_math)"
{
  if (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH
      && !flag_trapping_math)
    {
      if (TARGET_ROUND)
	emit_insn (gen_sse4_1_round<mode>2
		   (operands[0], operands[1], GEN_INT (ROUND_CEIL)));
      else if (optimize_insn_for_size_p ())
	FAIL;
      else if (TARGET_64BIT || (<MODE>mode != DFmode))
	ix86_expand_floorceil (operands[0], operands[1], false);
      else
	ix86_expand_floorceildf_32 (operands[0], operands[1], false);
    }
  else
    {
      rtx op0, op1;

      if (optimize_insn_for_size_p ())
	FAIL;

      op0 = gen_reg_rtx (XFmode);
      op1 = gen_reg_rtx (XFmode);
      emit_insn (gen_extend<mode>xf2 (op1, operands[1]));
      emit_insn (gen_frndintxf2_ceil (op0, op1));

      emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
    }
  DONE;
}
:}

concrete *fist<mode>2_ceil_1.insn_and_split instantiates.in set_unspec2_clobber
{
	root (0=nonimmediate_operand:SWI248x:"",
		(1=register_operand:XF:"", <UNSPEC_FIST_CEIL>),
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI248x;
}
cmd_spec.in
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations
   && can_create_pseudo_p ()"
  "#"
  "&& 1"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  ix86_optimize_mode_switching[I387_CEIL] = 1;

  operands[2] = assign_386_stack_local (HImode, SLOT_CW_STORED);
  operands[3] = assign_386_stack_local (HImode, SLOT_CW_CEIL);
  if (memory_operand (operands[0], VOIDmode))
    emit_insn (gen_fist<mode>2_ceil (operands[0], operands[1],
				     operands[2], operands[3]));
  else
    {
      operands[4] = assign_386_stack_local (<MODE>mode, SLOT_TEMP);
      emit_insn (gen_fist<mode>2_ceil_with_temp (operands[0], operands[1],
						 operands[2], operands[3],
						 operands[4]));
    }
  DONE;
}
  [(set_attr "type" "fistp")
   (set_attr "i387_cw" "ceil")
   (set_attr "mode" "<MODE>")]
:}


concrete fistdi2_ceil.insn instantiates set_unspec2_use_x2_clobber
{
	root (0=memory_operand:DI:"=m",
		(1=register_operand:XF:"f", <UNSPEC_FIST_CEIL>),
		2=memory_operand:HI:"m",
		3=memory_operand:HI:"m",
		4=XF:"=&1f");
	root.1.2.mode:=DI;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "* return output_fix_trunc (insn, operands, false);"
  [(set_attr "type" "fistp")
   (set_attr "i387_cw" "ceil")
   (set_attr "mode" "DI")]
:}

concrete fistdi2_ceil_with_temp.insn instantiates set_unspec2_use_x2_clobber_x2
{
	root (0=nonimmediate_operand:DI:"=m,?r",
		(1=register_operand:XF:"f,f", <UNSPEC_FIST_CEIL>),
		2=memory_operand:HI:"m,m", 3=memory_operand:HI:"m,m",
		4=memory_operand:DI:"=X,m",5=XF:"=&1f,&1f");
	root.1.2.mode:=DI;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "#"
  [(set_attr "type" "fistp")
   (set_attr "i387_cw" "ceil")
   (set_attr "mode" "DI")]
:}
{:
;; TOOD Cause: NULL in match_scratch
(define_split
  [(set (match_operand:DI 0 "register_operand" "")
	(unspec:DI [(match_operand:XF 1 "register_operand" "")]
		   UNSPEC_FIST_CEIL))
   (use (match_operand:HI 2 "memory_operand" ""))
   (use (match_operand:HI 3 "memory_operand" ""))
   (clobber (match_operand:DI 4 "memory_operand" ""))
   (clobber (match_scratch 5 ""))]
  "reload_completed"
  [(parallel [(set (match_dup 4)
		   (unspec:DI [(match_dup 1)] UNSPEC_FIST_CEIL))
	      (use (match_dup 2))
	      (use (match_dup 3))
	      (clobber (match_dup 5))])
   (set (match_dup 0) (match_dup 4))])

(define_split
  [(set (match_operand:DI 0 "memory_operand" "")
	(unspec:DI [(match_operand:XF 1 "register_operand" "")]
		   UNSPEC_FIST_CEIL))
   (use (match_operand:HI 2 "memory_operand" ""))
   (use (match_operand:HI 3 "memory_operand" ""))
   (clobber (match_operand:DI 4 "memory_operand" ""))
   (clobber (match_scratch 5 ""))]
  "reload_completed"
  [(parallel [(set (match_dup 0)
		   (unspec:DI [(match_dup 1)] UNSPEC_FIST_CEIL))
	      (use (match_dup 2))
	      (use (match_dup 3))
	      (clobber (match_dup 5))])])
:}

concrete fist<mode>2_ceil.insn instantiates set_unspec2_use_x2
{
	root (0=memory_operand:SWI24:"=m", 
	(1=register_operand:XF:"f", <UNSPEC_FIST_CEIL>),
	2=memory_operand:HI:"m", 3=memory_operand:HI:"m");
	root.1.2.mode:=SWI24;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "* return output_fix_trunc (insn, operands, false);"
  [(set_attr "type" "fistp")
   (set_attr "i387_cw" "ceil")
   (set_attr "mode" "<MODE>")]
:}

concrete fist<mode>2_ceil_with_temp.insn instantiates set_unspec2_use_x2_clobber
{
	root (0=nonimmediate_operand:SWI24:"=m,?r",
		(1=register_operand:XF:"f,f", <UNSPEC_FIST_CEIL>),
		2=memory_operand:HI:"m,m", 3=memory_operand:HI:"m,m",
		4=memory_operand:SWI24:"=X,m");
	root.1.2.mode:=SWI24;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "#"
  [(set_attr "type" "fistp")
   (set_attr "i387_cw" "ceil")
   (set_attr "mode" "<MODE>")]
:}

concrete .split instantiates.in set_unspec2_use_x2_clobber
{
	root (0=register_operand:SWI24:"", 
		(1=register_operand:XF:"", <UNSPEC_FIST_CEIL>),
		2=memory_operand:HI:"", 3=memory_operand:HI:"", 
		4=memory_operand:SWI24:"");
	root.1.2.mode:=SWI24;
}
cmd_spec.in
{:
  "reload_completed"
:}
instantiates.out parallel_set_unspec2_use_x2_set
{
	root ((duplicate 4, 
		(duplicate 1, <UNSPEC_FIST_CEIL>),
		duplicate 2, duplicate 3),
		duplicate 0, duplicate 4);
	root.1.1.2.mode:=SWI24;
}
cmd_spec.out
{:
:}

concrete .split instantiates.in set_unspec2_use_x2_clobber
{
	root (0=memory_operand:SWI24:"",
		(1=register_operand:XF:"", <UNSPEC_FIST_CEIL>),
		2=memory_operand:HI:"", 3=memory_operand:HI:"",
		4=memory_operand:SWI24:"");
	root.1.2.mode:=SWI24;
}
cmd_spec.in
{:
  "reload_completed"
:}
instantiates.out parallel_set_unspec2_use_x2
{
	root (duplicate 0,
		(duplicate 1, <UNSPEC_FIST_CEIL>),
		duplicate 2, duplicate 3);
	root.1.2.mode:=SWI24;
}
cmd_spec.out
{:
:}

concrete lceilxf<mode>2.exp instantiates parallel_set_unspec2_clobber
{
	root (0=nonimmediate_operand:SWI248x:"",
		(1=register_operand:XF:"", <UNSPEC_FIST_CEIL>),
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI248x;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!TARGET_SSE_MATH || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
:}

{:
;; TODO
(define_expand "lceil<MODEF:mode><SWI48:mode>2"
  [(match_operand:SWI48 0 "nonimmediate_operand" "")
   (match_operand:MODEF 1 "register_operand" "")]
  "SSE_FLOAT_MODE_P (<MODEF:MODE>mode) && TARGET_SSE_MATH
   && !flag_trapping_math"
{
  ix86_expand_lfloorceil (operands[0], operands[1], false);
  DONE;
})

;; Rounding mode control word calculation could clobber FLAGS_REG.
:}

concrete frndintxf2_trunc.insn_and_split instantiates.in set_unspec2_clobber
{
	root (0=register_operand:XF:"", 
		(1=register_operand:XF:"", <UNSPEC_FRNDINT_TRUNC>),
		reg(CC:FLAGS_REG));
	root.1.2.mode:=XF;
}
cmd_spec.in
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations
   && can_create_pseudo_p ()"
  "#"
  "&& 1"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  ix86_optimize_mode_switching[I387_TRUNC] = 1;

  operands[2] = assign_386_stack_local (HImode, SLOT_CW_STORED);
  operands[3] = assign_386_stack_local (HImode, SLOT_CW_TRUNC);

  emit_insn (gen_frndintxf2_trunc_i387 (operands[0], operands[1],
					operands[2], operands[3]));
  DONE;
}
  [(set_attr "type" "frndint")
   (set_attr "i387_cw" "trunc")
   (set_attr "mode" "XF")]
:}

concrete frndintxf2_trunc_i387.insn instantiates set_unspec2_use_x2
{
	root (0=register_operand:XF:"=f", 
		(1=register_operand:XF:"0",<UNSPEC_FRNDINT_TRUNC>),
		2=memory_operand:HI:"m", 3=memory_operand:HI:"m");
	root.1.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "fldcw\t%3\n\tfrndint\n\tfldcw\t%2"
  [(set_attr "type" "frndint")
   (set_attr "i387_cw" "trunc")
   (set_attr "mode" "XF")]
:}

concrete btruncxf2.exp overrides log1pxf2.exp
{
	root.2.1.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
{
  if (optimize_insn_for_size_p ())
    FAIL;
  emit_insn (gen_frndintxf2_trunc (operands[0], operands[1]));
  DONE;
}
:}

concrete btrunc<mode>2.exp overrides log1pxf2.exp
{
	XF->MODEF;
}
{:
  "(TARGET_USE_FANCY_MATH_387
    && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
	|| TARGET_MIX_SSE_I387)
    && flag_unsafe_math_optimizations)
   || (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH
       && !flag_trapping_math)"
{
  if (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH
      && !flag_trapping_math)
    {
      if (TARGET_ROUND)
	emit_insn (gen_sse4_1_round<mode>2
		   (operands[0], operands[1], GEN_INT (ROUND_TRUNC)));
      else if (optimize_insn_for_size_p ())
	FAIL;
      else if (TARGET_64BIT || (<MODE>mode != DFmode))
	ix86_expand_trunc (operands[0], operands[1]);
      else
	ix86_expand_truncdf_32 (operands[0], operands[1]);
    }
  else
    {
      rtx op0, op1;

      if (optimize_insn_for_size_p ())
	FAIL;

      op0 = gen_reg_rtx (XFmode);
      op1 = gen_reg_rtx (XFmode);
      emit_insn (gen_extend<mode>xf2 (op1, operands[1]));
      emit_insn (gen_frndintxf2_trunc (op0, op1));

      emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
    }
  DONE;
}
:}
{:
;; Rounding mode control word calculation could clobber FLAGS_REG.
:}

concrete frndintxf2_mask_pm.insn_and_split instantiates.in set_unspec2_clobber
{
	root (0=register_operand:XF:"", 
		(1=register_operand:XF:"", <UNSPEC_FRNDINT_MASK_PM>),
		reg(CC:FLAGS_REG));
	root.1.2.mode:=XF;
}
cmd_spec.in
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations
   && can_create_pseudo_p ()"
  "#"
  "&& 1"
:}
instantiates.out sequence
{
	root (const_int:0);
}
cmd_spec.out
{:
{
  ix86_optimize_mode_switching[I387_MASK_PM] = 1;

  operands[2] = assign_386_stack_local (HImode, SLOT_CW_STORED);
  operands[3] = assign_386_stack_local (HImode, SLOT_CW_MASK_PM);

  emit_insn (gen_frndintxf2_mask_pm_i387 (operands[0], operands[1],
					  operands[2], operands[3]));
  DONE;
}
  [(set_attr "type" "frndint")
   (set_attr "i387_cw" "mask_pm")
   (set_attr "mode" "XF")]
:}

concrete frndintxf2_mask_pm_i387.insn instantiates set_unspec2_use_x2
{
	root (0=register_operand:XF:"=f", 
		(1=register_operand:XF:"0",<UNSPEC_FRNDINT_MASK_PM>),
		2=memory_operand:HI:"m", 3=memory_operand:HI:"m");
	root.1.2.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
  "fldcw\t%3\n\tfrndint\n\tfclex\n\tfldcw\t%2"
  [(set_attr "type" "frndint")
   (set_attr "i387_cw" "mask_pm")
   (set_attr "mode" "XF")]
:}

concrete nearbyintxf2.exp overrides log1pxf2.exp
{
	root.2.1.mode:=XF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && flag_unsafe_math_optimizations"
{
  emit_insn (gen_frndintxf2_mask_pm (operands[0], operands[1]));
  DONE;
}
:}

concrete nearbyint<mode>2.exp overrides log1pxf2.exp
{
	XF->MODEF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && (!(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)
       || TARGET_MIX_SSE_I387)
   && flag_unsafe_math_optimizations"
{
  rtx op0 = gen_reg_rtx (XFmode);
  rtx op1 = gen_reg_rtx (XFmode);

  emit_insn (gen_extend<mode>xf2 (op1, operands[1]));
  emit_insn (gen_frndintxf2_mask_pm (op0, op1));

  emit_insn (gen_truncxf<mode>2_i387_noop (operands[0], op0));
  DONE;
}
:}

concrete fxam<mode>2_i387.insn instantiates set_unspec2
{
	root (0=register_operand:HI:"=a",
		(1=register_operand:X87MODEF:"f", <UNSPEC_FXAM>));
	root.2.mode:=HI;
}
{:
  "TARGET_USE_FANCY_MATH_387"
  "fxam\n\tfnstsw\t%0"
  [(set_attr "type" "multi")
   (set_attr "length" "4")
   (set_attr "unit" "i387")
   (set_attr "mode" "<MODE>")]
:}

concrete fxam<mode>2_i387_with_temp.insn_and_split instantiates.in set_unspec2
{
	root (0=register_operand:HI:"",
		(1=memory_operand:MODEF:"",<UNSPEC_FXAM_MEM>));
	root.2.mode:=HI;
}
cmd_spec.in
{:
  "TARGET_USE_FANCY_MATH_387
   && can_create_pseudo_p ()"
  "#"
  "&& 1"
:}
instantiates.out set_set_unspec2
{
	root (duplicate 2,duplicate 1, duplicate 0,
		(duplicate 2, <UNSPEC_FXAM>));
	root.2.2.mode:=HI;
}
cmd_spec.out
{:
{
  operands[2] = gen_reg_rtx (<MODE>mode);

  MEM_VOLATILE_P (operands[1]) = 1;
}
  [(set_attr "type" "multi")
   (set_attr "unit" "i387")
   (set_attr "mode" "<MODE>")]
:}

concrete isinfxf2.exp overrides log1pxf2.exp
{
	root.1.1.mode:=SI;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && TARGET_C99_FUNCTIONS"
{
  rtx mask = GEN_INT (0x45);
  rtx val = GEN_INT (0x05);

  rtx cond;

  rtx scratch = gen_reg_rtx (HImode);
  rtx res = gen_reg_rtx (QImode);

  emit_insn (gen_fxamxf2_i387 (scratch, operands[1]));

  emit_insn (gen_andqi_ext_0 (scratch, scratch, mask));
  emit_insn (gen_cmpqi_ext_3 (scratch, val));
  cond = gen_rtx_fmt_ee (EQ, QImode,
			 gen_rtx_REG (CCmode, FLAGS_REG),
			 const0_rtx);
  emit_insn (gen_rtx_SET (VOIDmode, res, cond));
  emit_insn (gen_zero_extendqisi2 (operands[0], res));
  DONE;
}
:}

concrete isinf<mode>2.exp overrides log1pxf2.exp
{
	root.1.1.mode:=SI; root.2.1.mode:=MODEF;
	root.2.1.predicate:=nonimmediate_operand;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && TARGET_C99_FUNCTIONS
   && !(SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)"
{
  rtx mask = GEN_INT (0x45);
  rtx val = GEN_INT (0x05);

  rtx cond;

  rtx scratch = gen_reg_rtx (HImode);
  rtx res = gen_reg_rtx (QImode);

  /* Remove excess precision by forcing value through memory. */
  if (memory_operand (operands[1], VOIDmode))
    emit_insn (gen_fxam<mode>2_i387_with_temp (scratch, operands[1]));
  else
    {
      enum ix86_stack_slot slot = (virtuals_instantiated
				   ? SLOT_TEMP
				   : SLOT_VIRTUAL);
      rtx temp = assign_386_stack_local (<MODE>mode, slot);

      emit_move_insn (temp, operands[1]);
      emit_insn (gen_fxam<mode>2_i387_with_temp (scratch, temp));
    }

  emit_insn (gen_andqi_ext_0 (scratch, scratch, mask));
  emit_insn (gen_cmpqi_ext_3 (scratch, val));
  cond = gen_rtx_fmt_ee (EQ, QImode,
			 gen_rtx_REG (CCmode, FLAGS_REG),
			 const0_rtx);
  emit_insn (gen_rtx_SET (VOIDmode, res, cond));
  emit_insn (gen_zero_extendqisi2 (operands[0], res));
  DONE;
}
:}

concrete signbitxf2.exp overrides log1pxf2.exp
{
	root.1.1.mode:=SI;
}
{:
  "TARGET_USE_FANCY_MATH_387"
{
  rtx scratch = gen_reg_rtx (HImode);

  emit_insn (gen_fxamxf2_i387 (scratch, operands[1]));
  emit_insn (gen_andsi3 (operands[0],
	     gen_lowpart (SImode, scratch), GEN_INT (0x200)));
  DONE;
}
:}

concrete movmsk_df.insn instantiates set_unspec2
{
	root (0=register_operand:SI:"=r", 
		(1=register_operand:DF:"x", <UNSPEC_MOVMSK>));
	root.2.mode:=SI;
}
{:
  "SSE_FLOAT_MODE_P (DFmode) && TARGET_SSE_MATH"
  "%vmovmskpd\t{%1, %0|%0, %1}"
  [(set_attr "type" "ssemov")
   (set_attr "prefix" "maybe_vex")
   (set_attr "mode" "DF")]
:}
{:
;; Use movmskpd in SSE mode to avoid store forwarding stall
;; for 32bit targets and movq+shrq sequence for 64bit targets.
:}

concrete signbitdf2.exp overrides log1pxf2.exp
{
	root.1.1.mode:=SI; root.2.1.mode:=DF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   || (SSE_FLOAT_MODE_P (DFmode) && TARGET_SSE_MATH)"
{
  if (SSE_FLOAT_MODE_P (DFmode) && TARGET_SSE_MATH)
    {
      emit_insn (gen_movmsk_df (operands[0], operands[1]));
      emit_insn (gen_andsi3 (operands[0], operands[0], const1_rtx));
    }
  else
    {
      rtx scratch = gen_reg_rtx (HImode);

      emit_insn (gen_fxamdf2_i387 (scratch, operands[1]));
      emit_insn (gen_andsi3 (operands[0],
		 gen_lowpart (SImode, scratch), GEN_INT (0x200)));
    }
  DONE;
}
:}

concrete signbitsf2.exp overrides log1pxf2.exp
{
	root.1.1.mode:=SI;	root.2.1.mode:=SF;
}
{:
  "TARGET_USE_FANCY_MATH_387
   && !(SSE_FLOAT_MODE_P (SFmode) && TARGET_SSE_MATH)"
{
  rtx scratch = gen_reg_rtx (HImode);

  emit_insn (gen_fxamsf2_i387 (scratch, operands[1]));
  emit_insn (gen_andsi3 (operands[0],
	     gen_lowpart (SImode, scratch), GEN_INT (0x200)));
  DONE;
}
:}
{:

;; Block operation instructions
:}

concrete cld.insn instantiates unspec_volatile
{
	root ((const_int:0, <UNSPECV_CLD>));
}
{:
  ""
  "cld"
  [(set_attr "length" "1")
   (set_attr "length_immediate" "0")
   (set_attr "modrm" "0")]
:}

abstract use_x6 extends use_x2
{
	root.3:=use;
	root.4:=use;
	root.5:=use;
	root.6:=use;
}

concrete movmem<mode>.exp instantiates use_x6
{
	root (0=memory_operand:BLK:"", 1=memory_operand:BLK:"",
		2=nonmemory_operand:SWI48:"", 3=const_int_operand:SWI48:"",
		4=const_int_operand:SI:"", 5=const_int_operand:SI:"");
}
{:
  ""{
 if (ix86_expand_movmem (operands[0], operands[1], operands[2], operands[3],
			 operands[4], operands[5]))
   DONE;
 else
   FAIL;
}
:}
{:
;; Most CPUs don't like single string operations
;; Handle this case here to simplify previous expander.
:}

abstract parallel_set_clobber extends parallel
{
	root.1:=set;
	root.2:=clobber;
}

abstract set_set_parallel_set_clobber_x2 extends sequence
{
	root.1:=set;
	root.2:=set;
	root.3:=parallel_set_clobber;
	root.4:=parallel_set_clobber;
}

concrete strmov.exp instantiates set_set_parallel_set_clobber_x2
{
	root (duplicate 4, 3=memory_operand:NULL:"",
		1=memory_operand:NULL:"", duplicate 4,
		(0=register_operand:NULL:"", duplicate 5, reg(CC:FLAGS_REG)),
		(2=register_operand:NULL:"", duplicate 6, reg(CC:FLAGS_REG)));
}
{:
  ""
{
  rtx adjust = GEN_INT (GET_MODE_SIZE (GET_MODE (operands[1])));

  /* If .md ever supports :P for Pmode, these can be directly
     in the pattern above.  */
  operands[5] = gen_rtx_PLUS (Pmode, operands[0], adjust);
  operands[6] = gen_rtx_PLUS (Pmode, operands[2], adjust);

  /* Can't use this if the user has appropriated esi or edi.  */
  if ((TARGET_SINGLE_STRINGOP || optimize_insn_for_size_p ())
      && !(fixed_regs[SI_REG] || fixed_regs[DI_REG]))
    {
      emit_insn (gen_strmov_singleop (operands[0], operands[1],
				      operands[2], operands[3],
				      operands[5], operands[6]));
      DONE;
    }

  operands[4] = gen_reg_rtx (GET_MODE (operands[1]));
}
:}

abstract parallel_set_set_set extends parallel
{
	root.1:=set;
	root.2:=set;
	root.3:=set;
}

concrete strmov_singleop.exp instantiates parallel_set_set_set
{
	root (1=memory_operand:NULL:"", 3=memory_operand:NULL:"",
		0=register_operand:NULL:"", 4=NULL:NULL:"", 2=register_operand:NULL:"",
		5=NULL:NULL:"");
}
{:
  ""
  "ix86_current_function_needs_cld = 1;"
:}

abstract set_mem1_mem2 extends set
{
	root.1:=mem;
	root.2:=mem;
}

abstract set_mem1_mem2_set_plus2_x2 extends sequence
{
	root.1:=set_mem1_mem2;
	root.2:=set_plus2;
	root.3:=set_plus2;
}

concrete *strmovdi_rex_1.insn instantiates set_mem1_mem2_set_plus2_x2
{
	root (2=register_operand:DI:"0",
		3=register_operand:DI:"1", 0=register_operand:DI:"=D",
		duplicate 2, const_int:8, 1=register_operand:DI:"=S",
		duplicate 3, const_int:8);
	root.1.1.mode:=DI;
	root.1.2.mode:=DI;
	root.2.2.mode:=DI;
	root.3.2.mode:=DI;
}
{:
  "TARGET_64BIT
   && !(fixed_regs[SI_REG] || fixed_regs[DI_REG])"
  "movsq"
  [(set_attr "type" "str")
   (set_attr "memory" "both")
   (set_attr "mode" "DI")]
:}
concrete *strmovsi_1.insn instantiates set_mem1_mem2_set_plus2_x2
{
	root (2=register_operand:P:"0",
		3=register_operand:P:"1", 0=register_operand:P:"=D",
		duplicate 2, const_int:4, 1=register_operand:P:"=S",
		duplicate 3, const_int:4);
	root.1.1.mode:=SI;
	root.1.2.mode:=SI;
	root.2.2.mode:=P;
	root.3.2.mode:=P;
}
{:
  "!(fixed_regs[SI_REG] || fixed_regs[DI_REG])"
  "movs{l|d}"
  [(set_attr "type" "str")
   (set_attr "memory" "both")
   (set_attr "mode" "SI")]
:}

concrete *strmovhi_1.insn instantiates set_mem1_mem2_set_plus2_x2
{
	root (2=register_operand:P:"0", 3=register_operand:P:"1",
		0=register_operand:P:"=D", duplicate 2, const_int:2,
		1=register_operand:P:"=S",duplicate 3, const_int:2);
	root.1.1.mode:=HI;
	root.1.2.mode:=HI;

	root.2.2.mode:=P;
	root.3.2.mode:=P;
}
{:
  "!(fixed_regs[SI_REG] || fixed_regs[DI_REG])"
  "movsw"
  [(set_attr "type" "str")
   (set_attr "memory" "both")
   (set_attr "mode" "HI")]
:}

concrete *strmovqi_1.insn instantiates set_mem1_mem2_set_plus2_x2
{
	root (2=register_operand:P:"0", 
		3=register_operand:P:"1", 0=register_operand:P:"=D",
		duplicate 2, const_int:1, 1=register_operand:P:"=S",
		duplicate 3, const_int:1);
	root.1.1.mode:=QI;
	root.1.2.mode:=QI;

	root.2.2.mode:=P;
	root.3.2.mode:=P;
}
{:
  "!(fixed_regs[SI_REG] || fixed_regs[DI_REG])"
  "movsb"
  [(set_attr "type" "str")
   (set_attr "memory" "both")
   (set (attr "prefix_rex")
	(if_then_else
	  (match_test "<P:MODE>mode == DImode")
	  (const_string "0")
	  (const_string "*")))
   (set_attr "mode" "QI")]
:}

abstract parallel_set_x4_use extends parallel_set_set_set
{
	root.4:=set;
	root.5:=use;
}


concrete rep_mov.exp instantiates parallel_set_x4_use
{
	root (4=register_operand:NULL:"", const_int:0,
		0=register_operand:NULL:"", 5=NULL:NULL:"",
		2=register_operand:NULL:"", 6=NULL:NULL:"",
		1=memory_operand:NULL:"",3=memory_operand:NULL:"",
		duplicate 4);
}
{:
  ""
  "ix86_current_function_needs_cld = 1;"
:}

abstract set_plus2_ashift1 extends set_plus2
{
	root.2.1:=ashift;
}


abstract set_set_plus2_ashift1_x2_set_mem1_mem2_use extends sequence
{
	root.1:=set;
	root.2:=set_plus2_ashift1;
	root.3:=set_plus2_ashift1;
	root.4:=set_mem1_mem2;
	root.5:=use;
}


concrete *rep_movdi_rex64.insn instantiates set_set_plus2_ashift1_x2_set_mem1_mem2_use
{
	root (2=register_operand:DI:"=c", const_int:0,
		0=register_operand:DI:"=D", 5=register_operand:DI:"2",const_int:3,
		3=register_operand:DI:"0", 1=register_operand:DI:"=S",
		duplicate 5, const_int:3, 4=register_operand:DI:"1", duplicate 3, duplicate 4,
		duplicate 5);
	root.2.2.mode:=DI;
	root.2.2.1.mode:=DI;
	root.3.2.mode:=DI;
	root.3.2.1.mode:=DI;
	root.4.1.mode:=BLK;
	root.4.2.mode:=BLK;
}
{:
  "TARGET_64BIT
   && !(fixed_regs[CX_REG] || fixed_regs[SI_REG] || fixed_regs[DI_REG])"
  "rep{%;} movsq"
  [(set_attr "type" "str")
   (set_attr "prefix_rep" "1")
   (set_attr "memory" "both")
   (set_attr "mode" "DI")]
:}

concrete *rep_movsi.insn overrides *rep_movdi_rex64.insn
{
	DI->P;
	root.2.2.1.2.operand:=const_int:2;
	root.3.2.1.2.operand:=const_int:2;
}
{:
  "!(fixed_regs[CX_REG] || fixed_regs[SI_REG] || fixed_regs[DI_REG])"
  "rep{%;} movs{l|d}"
  [(set_attr "type" "str")
   (set_attr "prefix_rep" "1")
   (set_attr "memory" "both")
   (set_attr "mode" "SI")]
:}

abstract set_set_plus2_x2_set_mem1_mem2_use	extends sequence
{
	root.1:=set;
	root.2:=set_plus2;
	root.3:=set_plus2;
	root.4:=set_mem1_mem2;
	root.5:=use;
}

concrete *rep_movqi.insn instantiates  set_set_plus2_x2_set_mem1_mem2_use
{
	root (2=register_operand:P:"=c", const_int:0,
		0=register_operand:P:"=D",3=register_operand:P:"0", 5=register_operand:P:"2",
		1=register_operand:P:"=S", 4=register_operand:P:"1", duplicate 5,
		duplicate 3, duplicate 4, duplicate 5);
	
	root.2.2.mode:=P;
	root.3.2.mode:=P;
	root.4.1.mode:=BLK;
	root.4.2.mode:=BLK;
}
{:
  "!(fixed_regs[CX_REG] || fixed_regs[SI_REG] || fixed_regs[DI_REG])"
  "rep{%;} movsb"
  [(set_attr "type" "str")
   (set_attr "prefix_rep" "1")
   (set_attr "memory" "both")
   (set_attr "mode" "QI")]
:}

concrete setmem<mode>.exp instantiates use_x6
{
	root (0=memory_operand:BLK:"", 1=nonmemory_operand:SWI48:"", 
		2=nonmemory_operand:QI:"", 3=const_int_operand:NULL:"",
		4=const_int_operand:SI:"", 5=const_int_operand:SI:"");
}
{:
  ""
{
 if (ix86_expand_setmem (operands[0], operands[1],
			 operands[2], operands[3],
			 operands[4], operands[5]))
   DONE;
 else
   FAIL;
}
:}

{:
;; Most CPUs don't like single string operations
;; Handle this case here to simplify previous expander.
:}

abstract  parallel_set_clobber extends parallel
{
	root.1:=set;
	root.2:=clobber;
}

abstract set_parallel_set_clobber extends sequence
{
	root.1:=set;
	root.2:=parallel_set_clobber;
}

concrete strset.exp instantiates set_parallel_set_clobber
{
	root (1=memory_operand:NULL:"", 2=register_operand:NULL:"",
		(0=register_operand:NULL:"", duplicate 3, reg(CC:FLAGS_REG)));
}
{:
  ""
{
  if (GET_MODE (operands[1]) != GET_MODE (operands[2]))
    operands[1] = adjust_address_nv (operands[1], GET_MODE (operands[2]), 0);

  /* If .md ever supports :P for Pmode, this can be directly
     in the pattern above.  */
  operands[3] = gen_rtx_PLUS (Pmode, operands[0],
			      GEN_INT (GET_MODE_SIZE (GET_MODE
						      (operands[2]))));
  /* Can't use this if the user has appropriated eax or edi.  */
  if ((TARGET_SINGLE_STRINGOP || optimize_insn_for_size_p ())
      && !(fixed_regs[AX_REG] || fixed_regs[DI_REG]))
    {
      emit_insn (gen_strset_singleop (operands[0], operands[1], operands[2],
				      operands[3]));
      DONE;
    }
}
:}

abstract parallel_set_set extends parallel
{
	root.1:=set;
	root.2:=set;
}

concrete strset_singleop.exp instantiates parallel_set_set
{
	root (1=memory_operand:NULL:"", 2=register_operand:NULL:"",
		0=register_operand:NULL:"", 3=NULL:NULL:"");
}
{:
  ""
  "ix86_current_function_needs_cld = 1;"
:}

abstract set_mem1  extends set
{
	root.1:=mem;
}

abstract set_mem1_set_plus2 extends sequence
{
	root.1:=set_mem1;
	root.2:=set_plus2;
}

concrete *strsetdi_rex_1.insn instantiates set_mem1_set_plus2
{
	root (1=register_operand:DI:"0",
		2=register_operand:DI:"a", 
		0=register_operand:DI:"=D",duplicate 1, const_int:8);
	root.1.1.mode:=DI;
	root.2.2.mode:=DI;
}
{:
  "TARGET_64BIT
   && !(fixed_regs[AX_REG] || fixed_regs[DI_REG])"
  "stosq"
  [(set_attr "type" "str")
   (set_attr "memory" "store")
   (set_attr "mode" "DI")]
:}

concrete *strsetsi_1.insn instantiates set_mem1_set_plus2
{
	root (1=register_operand:P:"0", 2=register_operand:SI:"a",
		0=register_operand:P:"=D", duplicate 1, const_int:4);
	root.1.1.mode:=SI;
	root.2.2.mode:=P;
}
{:
  "!(fixed_regs[AX_REG] || fixed_regs[DI_REG])"
  "stos{l|d}"
  [(set_attr "type" "str")
   (set_attr "memory" "store")
   (set_attr "mode" "SI")]
:}


concrete *strsethi_1.insn instantiates set_mem1_set_plus2
{
	root (1=register_operand:P:"0", 
		2=register_operand:HI:"a", 0=register_operand:P:"=D",
		duplicate 1, const_int:2);
	root.1.1.mode:=HI;
	root.2.2.mode:=P;
}
{:
  "!(fixed_regs[AX_REG] || fixed_regs[DI_REG])"
  "stosw"
  [(set_attr "type" "str")
   (set_attr "memory" "store")
   (set_attr "mode" "HI")]
:}

concrete *strsetqi_1.insn instantiates set_mem1_set_plus2
{
	root (1=register_operand:P:"0",
		2=register_operand:QI:"a", 0=register_operand:P:"=D",
		duplicate 1, const_int:1);
	root.1.1.mode:=QI;
	root.2.2.mode:=P;
}
{:
  "!(fixed_regs[AX_REG] || fixed_regs[DI_REG])"
  "stosb"
  [(set_attr "type" "str")
   (set_attr "memory" "store")
   (set (attr "prefix_rex")
	(if_then_else
	  (match_test "<P:MODE>mode == DImode")
	  (const_string "0")
	  (const_string "*")))
   (set_attr "mode" "QI")]
:}

abstract parallel_set_x3_use_x2 extends parallel
{
	root.1:=set;
	root.2:=set;
	root.3:=set;
	root.4:=use;
	root.5:=use;
}

concrete rep_stos.exp instantiates parallel_set_x3_use_x2
{
	root (1=register_operand:NULL:"", const_int:0,
		0=register_operand:NULL:"", 4=NULL:NULL:"",
		2=memory_operand:NULL:"", const_int:0,
		3=register_operand:NULL:"", duplicate 1);
}
{:
  ""
  "ix86_current_function_needs_cld = 1;"
:}

abstract set_set_plus2_ashift1_set_mem1_use_x2 extends sequence
{
	root.1:=set;
	root.2:=set_plus2_ashift1;
	root.3:=set_mem1;
	root.4:=use;
	root.5:=use;
}


concrete *rep_stosdi_rex64.insn instantiates set_set_plus2_ashift1_set_mem1_use_x2
{
	root (1=register_operand:DI:"=c", const_int:0,
		0=register_operand:DI:"=D", 4=register_operand:DI:"1",
		const_int:3, 3=register_operand:DI:"0", duplicate 3, const_int:0,
		2=register_operand:DI:"a",duplicate 4);
	root.2.2.mode:=DI;
	root.2.2.1.mode:=DI;
	root.3.1.mode:=BLK;
}	
{:
  "TARGET_64BIT
   && !(fixed_regs[AX_REG] || fixed_regs[CX_REG] || fixed_regs[DI_REG])"
  "rep{%;} stosq"
  [(set_attr "type" "str")
   (set_attr "prefix_rep" "1")
   (set_attr "memory" "store")
   (set_attr "mode" "DI")]
:}

abstract set_set_plus2_ashift1_set_mem1_use_x2 extends sequence
{
	root.1:=set;
	root.2:=set_plus2_ashift1;
	root.3:=set_mem1;
	root.4:=use;
	root.5:=use;
}

concrete *rep_stossi.insn instantiates set_set_plus2_ashift1_set_mem1_use_x2
{
	root (1=register_operand:P:"=c", const_int:0,
		0=register_operand:P:"=D",4=register_operand:P:"1", const_int:2,
		3=register_operand:P:"0",duplicate 3, const_int:0,
		2=register_operand:SI:"a", duplicate 4);
	root.2.2.mode:=P;
	root.2.2.1.mode:=P;
	root.3.1.mode:=BLK;
}
{:
  "!(fixed_regs[AX_REG] || fixed_regs[CX_REG] || fixed_regs[DI_REG])"
  "rep{%;} stos{l|d}"
  [(set_attr "type" "str")
   (set_attr "prefix_rep" "1")
   (set_attr "memory" "store")
   (set_attr "mode" "SI")]
:}

abstract set_set_plus2_set_mem1_use_x2 extends sequence
{
	root.1:=set;
	root.2:=set_plus2;
	root.3:=set_mem1;
	root.4:=use;
	root.5:=use;
}


concrete *rep_stosqi.insn instantiates set_set_plus2_set_mem1_use_x2
{
	root (1=register_operand:P:"=c", const_int:0,
		0=register_operand:P:"=D", 3=register_operand:P:"0",
		4=register_operand:P:"1", duplicate 3, const_int:0,
		2=register_operand:QI:"a", duplicate 4);
	root.2.2.mode:=P;
	root.3.1.mode:=BLK;
}
{:
  "!(fixed_regs[AX_REG] || fixed_regs[CX_REG] || fixed_regs[DI_REG])"
  "rep{%;} stosb"
  [(set_attr "type" "str")
   (set_attr "prefix_rep" "1")
   (set_attr "memory" "store")
   (set (attr "prefix_rex")
	(if_then_else
	  (match_test "<P:MODE>mode == DImode")
	  (const_string "0")
	  (const_string "*")))
   (set_attr "mode" "QI")]
:}

abstract set_compare2_use_x2 extends sequence
{
	root.1:=set_compare2;
	root.2:=use;
	root.3:=use;
}

concrete cmpstrnsi.exp instantiates set_compare2_use_x2
{
	root (0=register_operand:SI:"", 1=general_operand:BLK:"",
		2=general_operand:BLK:"", 3=general_operand:NULL:"",
		4=immediate_operand:NULL:"");
	root.1.2.mode:=SI;
}
{:
  ""
{
  rtx addr1, addr2, out, outlow, count, countreg, align;

  if (optimize_insn_for_size_p () && !TARGET_INLINE_ALL_STRINGOPS)
    FAIL;

  /* Can't use this if the user has appropriated ecx, esi or edi.  */
  if (fixed_regs[CX_REG] || fixed_regs[SI_REG] || fixed_regs[DI_REG])
    FAIL;

  out = operands[0];
  if (!REG_P (out))
    out = gen_reg_rtx (SImode);

  addr1 = copy_to_mode_reg (Pmode, XEXP (operands[1], 0));
  addr2 = copy_to_mode_reg (Pmode, XEXP (operands[2], 0));
  if (addr1 != XEXP (operands[1], 0))
    operands[1] = replace_equiv_address_nv (operands[1], addr1);
  if (addr2 != XEXP (operands[2], 0))
    operands[2] = replace_equiv_address_nv (operands[2], addr2);

  count = operands[3];
  countreg = ix86_zero_extend_to_Pmode (count);

  /* %%% Iff we are testing strict equality, we can use known alignment
     to good advantage.  This may be possible with combine, particularly
     once cc0 is dead.  */
  align = operands[4];

  if (CONST_INT_P (count))
    {
      if (INTVAL (count) == 0)
	{
	  emit_move_insn (operands[0], const0_rtx);
	  DONE;
	}
      emit_insn (gen_cmpstrnqi_nz_1 (addr1, addr2, countreg, align,
				     operands[1], operands[2]));
    }
  else
    {
      rtx (*gen_cmp) (rtx, rtx);

      gen_cmp = (TARGET_64BIT
		 ? gen_cmpdi_1 : gen_cmpsi_1);

      emit_insn (gen_cmp (countreg, countreg));
      emit_insn (gen_cmpstrnqi_1 (addr1, addr2, countreg, align,
				  operands[1], operands[2]));
    }

  outlow = gen_lowpart (QImode, out);
  emit_insn (gen_cmpintqi (outlow));
  emit_move_insn (out, gen_rtx_SIGN_EXTEND (SImode, outlow));

  if (operands[0] != out)
    emit_move_insn (operands[0], out);

  DONE;
}
:}
{:
;; Produce a tri-state integer (-1, 0, 1) from condition codes.
:}

abstract parallel_set_minus2_clobber extends parallel
{
	root.1:=set_minus2;
	root.2:=clobber;
}

abstract set_gtu2_set_ltu2_parallel_set_minus2_clobber extends sequence
{
	root.1:=set_gtu2;
	root.2:=set_ltu2;
	root.3:=parallel_set_minus2_clobber;
}


concrete cmpintqi.exp instantiates set_gtu2_set_ltu2_parallel_set_minus2_clobber
{
	root (duplicate 1, reg(CC:FLAGS_REG), const_int:0, duplicate 2, reg(CC:FLAGS_REG), const_int:0, 0=register_operand:QI:"",
		duplicate 1, duplicate 2, reg(CC:FLAGS_REG));
	root.1.2.mode:=QI;
	root.2.2.mode:=QI;
	root.3.1.2.mode:=QI;
}
{:
  ""
{
  operands[1] = gen_reg_rtx (QImode);
  operands[2] = gen_reg_rtx (QImode);
}
:}

{:
;; memcmp recognizers.  The `cmpsb' opcode does nothing if the count is
;; zero.  Emit extra code to make sure that a zero-length compare is EQ.
:}

abstract set_compare2_mem1_mem2_use_x2_clobber_x3 extends sequence 
{
	root.1:=set_compare2;
	root.1.2.1:=mem;
	root.1.2.2:=mem;
	root.2:=use;
	root.3:=use;
	root.4:=clobber;
	root.5:=clobber;
	root.6:=clobber;
}

abstract parallel_set_compare2_use_x2_clobber_x3 extends parallel
{
    root.1:=set_compare2;
    root.2:=use;
    root.3:=use;
    root.4:=clobber;
    root.5:=clobber;
    root.6:=clobber;
	
}

concrete cmpstrnqi_nz_1.exp instantiates parallel_set_compare2_use_x2_clobber_x3
{
	root (reg(CC:FLAGS_REG), 4=memory_operand:NULL:"",
		5=memory_operand:NULL:"", 2=register_operand:NULL:"",
		3=immediate_operand:SI:"", 0=register_operand:NULL:"",
		1=register_operand:NULL:"", duplicate 2);
	root.1.2.mode:=CC;
}
{:
  ""
  "ix86_current_function_needs_cld = 1;"
:}

concrete *cmpstrnqi_nz_1.insn instantiates set_compare2_mem1_mem2_use_x2_clobber_x3
{
	root (reg(CC:FLAGS_REG), 4=register_operand:P:"0",
		5=register_operand:P:"1", 6=register_operand:P:"2", 3=immediate_operand:SI:"i",
		0=register_operand:P:"=S", 1=register_operand:P:"=D", 
		2=register_operand:P:"=c");
	root.1.2.mode:=CC;
	root.1.2.1.mode:=BLK;
	root.1.2.2.mode:=BLK;
}
{:
  "!(fixed_regs[CX_REG] || fixed_regs[SI_REG] || fixed_regs[DI_REG])"
  "repz{%;} cmpsb"
  [(set_attr "type" "str")
   (set_attr "mode" "QI")
   (set (attr "prefix_rex")
	(if_then_else
	  (match_test "<P:MODE>mode == DImode")
	  (const_string "0")
	  (const_string "*")))
   (set_attr "prefix_rep" "1")]
:}
{:
;; The same, but the count is not known to not be zero.
:}

abstract set_if_then_else2 extends set
{
	root.2:=if_then_else;
}

abstract set_if_then_else2_ne1_compare2_mem1_mem2_use_x2_clobber_x3 extends sequence
{
	root.1:=set_if_then_else2;
	root.1.2.1:=ne;
	root.1.2.2:=compare;
	root.1.2.2.1:=mem;
	root.1.2.2.2:=mem;
	root.2:=use;
	root.3:=use;
	root.4:=clobber;
	root.5:=clobber;
	root.6:=clobber;
}

abstract parallel_set_if_then_else2_ne1_compare2_use_x2_clobber_x3 extends parallel
{
    root.1:=set_if_then_else2;
    root.1.2.1:=ne;
    root.1.2.2:=compare;
    root.2:=use;
    root.3:=use;
    root.4:=clobber;
    root.5:=clobber;
    root.6:=clobber;
											
}

concrete cmpstrnqi_1.exp instantiates parallel_set_if_then_else2_ne1_compare2_use_x2_clobber_x3{
	root (
		reg(CC:FLAGS_REG), 2=register_operand:NULL:"", const_int:0,
		4=memory_operand:NULL:"", 5=memory_operand:NULL:"", const_int:0,
		3=immediate_operand:SI:"", reg(CC:FLAGS_REG),
		0=register_operand:NULL:"", 1=register_operand:NULL:"",
		duplicate 2);
	root.1.2.mode:=CC;
	root.1.2.2.mode:=CC;
}
{:
  ""
  "ix86_current_function_needs_cld = 1;"
:}

concrete *cmpstrnqi_1.insn instantiates set_if_then_else2_ne1_compare2_mem1_mem2_use_x2_clobber_x3{
	root (
		reg(CC:FLAGS_REG), 6=register_operand:P:"2", const_int:0,
		4=register_operand:P:"0",5=register_operand:P:"1", const_int:0,
		3=immediate_operand:SI:"i", reg(CC:FLAGS_REG),
		0=register_operand:P:"=S", 1=register_operand:P:"=D",
		2=register_operand:P:"=c");
	root.1.2.mode:=CC;
	root.1.2.2.mode:=CC;
	root.1.2.2.1.mode:=BLK;
	root.1.2.2.2.mode:=BLK;
}
{:
  "!(fixed_regs[CX_REG] || fixed_regs[SI_REG] || fixed_regs[DI_REG])"
  "repz{%;} cmpsb"
  [(set_attr "type" "str")
   (set_attr "mode" "QI")
   (set (attr "prefix_rex")
	(if_then_else
	  (match_test "<P:MODE>mode == DImode")
	  (const_string "0")
	  (const_string "*")))
   (set_attr "prefix_rep" "1")]
:}

concrete strlen<mode>.exp instantiates set_unspec2
{
	root (0=register_operand:P:"", 
		(1=general_operand:BLK:"", 2=immediate_operand:QI:"",
		3=immediate_operand:NULL:"", <UNSPEC_SCAS>));
	root.2.mode:=P;
}
{:
  ""
{
 if (ix86_expand_strlen (operands[0], operands[1], operands[2], operands[3]))
   DONE;
 else
   FAIL;
}
:}

abstract parallel_set_clobber_x2 extends parallel
{
	root.1:=set;
	root.2:=clobber;
	root.3:=clobber;
}

concrete strlenqi_1.exp instantiates parallel_set_clobber_x2
{
	root (0=register_operand:NULL:"", 2=NULL:NULL:"",
		1=register_operand:NULL:"", reg(CC:FLAGS_REG));
}
{:
  ""
  "ix86_current_function_needs_cld = 1;"
:}

abstract set_unspec2_mem1_clobber_x2 extends sequence
{
	root.1:=set_unspec2;
	root.1.2.1:=mem;
	root.2:=clobber;
	root.3:=clobber;
}

concrete *strlenqi_1.insn instantiates set_unspec2_mem1_clobber_x2
{
	root (0=register_operand:P:"=&c", 
		(5=register_operand:P:"1", 2=register_operand:QI:"a",
		3=immediate_operand:P:"i", 4=register_operand:P:"0",
		<UNSPEC_SCAS>), 1=register_operand:P:"=D", reg(CC:FLAGS_REG));
	root.1.2.mode:=P;
	root.1.2.1.mode:=BLK;
}
{:
  "!(fixed_regs[AX_REG] || fixed_regs[CX_REG] || fixed_regs[DI_REG])"
  "repnz{%;} scasb"
  [(set_attr "type" "str")
   (set_attr "mode" "QI")
   (set (attr "prefix_rex")
	(if_then_else
	  (match_test "<P:MODE>mode == DImode")
	  (const_string "0")
	  (const_string "*")))
   (set_attr "prefix_rep" "1")]
:}
{:
;; Peephole optimizations to clean up after cmpstrn*.  This should be
;; handled in combine, but it is not currently up to the task.
;; When used for their truth value, the cmpstrn* expanders generate
;; code like this:
;;
;;   repz cmpsb
;;   seta 	%al
;;   setb 	%dl
;;   cmpb 	%al, %dl
;;   jcc	label
;;
;; The intermediate three instructions are unnecessary.

;; This one handles cmpstrn*_nz_1...
:}

abstract parallel_set_compare2_mem1_mem2_use_x2_clobber_x3 extends parallel
{
	root.1:=set_compare2;
	root.1.2.1:=mem;
	root.1.2.2:=mem;
	root.2:=use;
	root.3:=use;
	root.4:=clobber;
	root.5:=clobber;
	root.6:=clobber;
}

abstract parallel_set_compare2_mem1_mem2_use_x2_clobber_x3_set_gtu2_set_ltu2_set_compare2 extends sequence
{
	root.1:=parallel_set_compare2_mem1_mem2_use_x2_clobber_x3;
	root.2:=set_gtu2;
	root.3:=set_ltu2;
	root.4:=set_compare2;
}

abstract set_compare2_mem1_mem2 extends set_compare2
{
	root.2.1:=mem;
	root.2.2:=mem;
}

abstract parallel_set_compare2_mem1_mem2_use_x2_compare_x3 extends sequence
{
	root.1:=set_compare2_mem1_mem2;
	root.2:=use;
	root.3:=use;
	root.4:=clobber;
	root.5:=clobber;
	root.6:=clobber;	
}
{:
(define_peephole2
  [(parallel[
     (set (reg:CC FLAGS_REG)
      (compare:CC (mem:BLK (match_operand 4 "register_operand" ""))
              (mem:BLK (match_operand 5 "register_operand" ""))))
     (use (match_operand 6 "register_operand" ""))
     (use (match_operand:SI 3 "immediate_operand" ""))
     (clobber (match_operand 0 "register_operand" ""))
     (clobber (match_operand 1 "register_operand" ""))
     (clobber (match_operand 2 "register_operand" ""))])
   (set (match_operand:QI 7 "register_operand" "")
    (gtu:QI (reg:CC FLAGS_REG) (const_int 0)))
   (set (match_operand:QI 8 "register_operand" "")
    (ltu:QI (reg:CC FLAGS_REG) (const_int 0)))
   (set (reg FLAGS_REG)
    (compare (match_dup 7) (match_dup 8)))
  ]
  "peep2_reg_dead_p (4, operands[7]) && peep2_reg_dead_p (4, operands[8])"
  [(parallel[
     (set (reg:CC FLAGS_REG)
      (compare:CC (mem:BLK (match_dup 4))
              (mem:BLK (match_dup 5))))
     (use (match_dup 6))
     (use (match_dup 3))
     (clobber (match_dup 0))
     (clobber (match_dup 1))
     (clobber (match_dup 2))])])

:}

{:
;; ...and this one handles cmpstrn*_1.
:}

abstract parallel_set_if_then_else2_ne1_compare2_mem1_mem2_use_x2_clobber_x3 extends parallel
{
    root.1:=set_if_then_else2;
	root.1.2.1:=ne;
	root.1.2.2:=compare;
    root.1.2.2.1:=mem;
    root.1.2.2.2:=mem;
    root.2:=use;
    root.3:=use;
    root.4:=clobber;
    root.5:=clobber;
    root.6:=clobber;

}

abstract parallel_set_if_then_else2_ne1_compare2_mem1_mem2_use_x2_clobber_x3_set_gtu2_set_ltu2_set_compare2 extends sequence
{
	root.1:=parallel_set_if_then_else2_ne1_compare2_mem1_mem2_use_x2_clobber_x3;
	root.2:=set_gtu2;
	root.3:=set_ltu2;
	root.4:=set_compare2;
}

{:
(define_peephole2
  [(parallel[
     (set (reg:CC FLAGS_REG)
      (if_then_else:CC (ne (match_operand 6 "register_operand" "")
                   (const_int 0))
        (compare:CC (mem:BLK (match_operand 4 "register_operand" ""))
                (mem:BLK (match_operand 5 "register_operand" "")))
        (const_int 0)))
     (use (match_operand:SI 3 "immediate_operand" ""))
     (use (reg:CC FLAGS_REG))
     (clobber (match_operand 0 "register_operand" ""))
     (clobber (match_operand 1 "register_operand" ""))
     (clobber (match_operand 2 "register_operand" ""))])
   (set (match_operand:QI 7 "register_operand" "")
    (gtu:QI (reg:CC FLAGS_REG) (const_int 0)))
   (set (match_operand:QI 8 "register_operand" "")
    (ltu:QI (reg:CC FLAGS_REG) (const_int 0)))
   (set (reg FLAGS_REG)
    (compare (match_dup 7) (match_dup 8)))
  ]
  "peep2_reg_dead_p (4, operands[7]) && peep2_reg_dead_p (4, operands[8])"
  [(parallel[
     (set (reg:CC FLAGS_REG)
      (if_then_else:CC (ne (match_dup 6)
                   (const_int 0))
        (compare:CC (mem:BLK (match_dup 4))
            (mem:BLK (match_dup 5)))
        (const_int 0)))
     (use (match_dup 3))
     (use (reg:CC FLAGS_REG))
     (clobber (match_dup 0))
     (clobber (match_dup 1))
     (clobber (match_dup 2))])])

:}

{:	

;; Conditional move instructions.
:}

concrete mov<mode>cc.exp instantiates set_if_then_else2
{
	root (0=register_operand:SWIM:"", 1=ordered_comparison_operator:NULL:"",
		2=<general_operand>:SWIM:"", 3=<general_operand>:SWIM:"");
	root.2.mode:=SWIM;
}
{:
  ""
  "if (ix86_expand_int_movcc (operands)) DONE; else FAIL;"
:}

{:
;; Data flow gets confused by our desire for `sbbl reg,reg', and clearing
;; the register first winds up with `sbbl $0,reg', which is also weird.
;; So just document what we're doing explicitly.
:}

abstract set_if_then_else2_clobber extends sequence
{
	root.1:=set_if_then_else2;
	root.2:=clobber;
}

abstract parallel_set_if_then_else2_match_operator1_clobber extends parallel
{
	root.1:=set_if_then_else2;
	root.1.2.1:=match_operator;
	root.2:=clobber;
}

concrete x86_mov<mode>cc_0_m1.exp instantiates parallel_set_if_then_else2_match_operator1_clobber
{
	root (0=register_operand:SWI48:"",
		(2=ix86_carry_flag_operator,1=flags_reg_operand:NULL:"", const_int:0),
		const_int:-1, const_int:0, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
	root.1.2.1.mode:=SWI48;
}
{:
:}

abstract set_if_then_else2_match_operator1 extends set_if_then_else2
{
	root.2.1:=match_operator;
}

abstract set_if_then_else2_match_operator1_clobber extends sequence
{
	root.1:=set_if_then_else2_match_operator1;
	root.2:=clobber;
}


concrete *x86_mov<mode>cc_0_m1.insn instantiates set_if_then_else2_match_operator1_clobber
{
	root (0=register_operand:SWI48:"=r", 
		(1=ix86_carry_flag_operator,reg(NULL:FLAGS_REG), const_int:0),
		const_int:-1, const_int:0, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
}
{:
  ""
  "sbb{<imodesuffix>}\t%0, %0"
  ; Since we don't have the proper number of operands for an alu insn,
  ; fill in all the blanks.
  [(set_attr "type" "alu")
   (set_attr "use_carry" "1")
   (set_attr "pent_pair" "pu")
   (set_attr "memory" "none")
   (set_attr "imm_disp" "false")
   (set_attr "mode" "<MODE>")
   (set_attr "length_immediate" "0")]
:}

abstract set_sign_extract2_match_operator1_clobber extends sequence
{
	root.1:=set_sign_extract2;
	root.1.2.1:=match_operator;
	root.2:=clobber;
}

concrete *x86_mov<mode>cc_0_m1_se.insn instantiates set_sign_extract2_match_operator1_clobber
{
	root (0=register_operand:SWI48:"=r", 
		(1=ix86_carry_flag_operator, reg(NULL:FLAGS_REG), const_int:0),
		const_int:1, const_int:0, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
		
}
{:
  ""
  "sbb{<imodesuffix>}\t%0, %0"
  [(set_attr "type" "alu")
   (set_attr "use_carry" "1")
   (set_attr "pent_pair" "pu")
   (set_attr "memory" "none")
   (set_attr "imm_disp" "false")
   (set_attr "mode" "<MODE>")
   (set_attr "length_immediate" "0")]
:}

abstract set_neg2_match_operator1_clobber extends set_neg2_clobber
{
	root.1.2.1:=match_operator;
}

concrete *x86_mov<mode>cc_0_m1_neg.insn instantiates set_neg2_match_operator1_clobber
{
	root (0=register_operand:SWI48:"=r",
		(1=ix86_carry_flag_operator,reg(NULL:FLAGS_REG), const_int:0),
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
}
{:
  ""
  "sbb{<imodesuffix>}\t%0, %0"
  [(set_attr "type" "alu")
   (set_attr "use_carry" "1")
   (set_attr "pent_pair" "pu")
   (set_attr "memory" "none")
   (set_attr "imm_disp" "false")
   (set_attr "mode" "<MODE>")
   (set_attr "length_immediate" "0")]
:}

concrete *mov<mode>cc_noc.insn instantiates set_if_then_else2_match_operator1
{
	root (0=register_operand:SWI248:"=r,r",
		(1=ix86_comparison_operator,reg(NULL:FLAGS_REG), const_int:0),
		2=nonimmediate_operand:SWI248:"rm,0", 3=nonimmediate_operand:SWI248:"0,rm");
	root.2.mode:=SWI248;
}
{:
  "TARGET_CMOVE && !(MEM_P (operands[2]) && MEM_P (operands[3]))"
  "@
   cmov%O2%C1\t{%2, %0|%0, %2}
   cmov%O2%c1\t{%3, %0|%0, %3}"
  [(set_attr "type" "icmov")
   (set_attr "mode" "<MODE>")]
:}

concrete *movqicc_noc.insn instantiates set_if_then_else2_match_operator1
{
	root (0=register_operand:QI:"=r,r",
		(1=ix86_comparison_operator, reg(NULL:FLAGS_REG), const_int:0),
		2=register_operand:QI:"r,0", 3=register_operand:QI:"0,r");
	root.2.mode:=QI;
}
{:	
  "TARGET_CMOVE && !TARGET_PARTIAL_REG_STALL"
  "#"
  [(set_attr "type" "icmov")
   (set_attr "mode" "QI")]
:}

{:
;; TODO for below split
;; Wierd bug, where extra quotes are required in specRTL MD.
;; Check diff of gen and stock.
:}
concrete .split instantiates.in set_if_then_else2_match_operator1
{
	root (0=register_operand:NULL:"",
		(1=ix86_comparison_operator, reg(NULL:FLAGS_REG), const_int:0),
		2=register_operand:NULL:"", 3=register_operand:NULL:"");
}
cmd_spec.in
{:
  "TARGET_CMOVE && !TARGET_PARTIAL_REG_STALL
   && (GET_MODE (operands[0]) == QImode
       || GET_MODE (operands[0]) == HImode)
   && reload_completed"
:}
instantiates.out set_if_then_else2
{
	root (duplicate 0, duplicate 1, duplicate 2, duplicate 3);
	root.2.mode:=SI;
}
cmd_spec.out
{:
{
  operands[0] = gen_lowpart (SImode, operands[0]);
  operands[2] = gen_lowpart (SImode, operands[2]);
  operands[3] = gen_lowpart (SImode, operands[3]);
}
:}

concrete mov<mode>cc.exp instantiates set_if_then_else2
{
	root (0=register_operand:X87MODEF:"", 
		1=ix86_fp_comparison_operator:NULL:"",
		2=register_operand:X87MODEF:"",
		3=register_operand:X87MODEF:"");
	root.2.mode:=X87MODEF;
}
{:
  "(TARGET_80387 && TARGET_CMOVE)
   || (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)"
  "if (ix86_expand_fp_movcc (operands)) DONE; else FAIL;"
:}

concrete *movxfcc_1.insn instantiates set_if_then_else2_match_operator1
{
	root (0=register_operand:XF:"=f,f",
		(1=fcmov_comparison_operator, reg(NULL:FLAGS_REG), const_int:0),
		2=register_operand:XF:"f,0", 3=register_operand:XF:"0,f");
	root.2.mode:=XF;
}
{:
  "TARGET_80387 && TARGET_CMOVE"
  "@
   fcmov%F1\t{%2, %0|%0, %2}
   fcmov%f1\t{%3, %0|%0, %3}"
  [(set_attr "type" "fcmov")
   (set_attr "mode" "XF")]
:}

concrete *movdfcc_1_rex64.insn instantiates set_if_then_else2_match_operator1
{
	root (0=register_operand:DF:"=f,f,r,r",
		(1=fcmov_comparison_operator, reg(NULL:FLAGS_REG), const_int:0),
		2=nonimmediate_operand:DF:"f,0,rm,0",
		3=nonimmediate_operand:DF:"0,f,0,rm");
	root.2.mode:=DF;
}
{:
  "TARGET_64BIT && TARGET_80387 && TARGET_CMOVE
   && !(MEM_P (operands[2]) && MEM_P (operands[3]))"
  "@
   fcmov%F1\t{%2, %0|%0, %2}
   fcmov%f1\t{%3, %0|%0, %3}
   cmov%O2%C1\t{%2, %0|%0, %2}
   cmov%O2%c1\t{%3, %0|%0, %3}"
  [(set_attr "type" "fcmov,fcmov,icmov,icmov")
	   (set_attr "mode" "DF,DF,DI,DI")]
:}

concrete *movdfcc_1.insn instantiates set_if_then_else2_match_operator1
{
	root (0=register_operand:DF:"=f,f,&r,&r",
		(1=fcmov_comparison_operator,reg(NULL:FLAGS_REG), const_int:0),
		2=nonimmediate_operand:DF:"f,0,rm,0",
		3=nonimmediate_operand:DF:"0,f,0,rm");
	root.2.mode:=DF;
}
{:
  "!TARGET_64BIT && TARGET_80387 && TARGET_CMOVE
   && !(MEM_P (operands[2]) && MEM_P (operands[3]))"
  "@
   fcmov%F1\t{%2, %0|%0, %2}
   fcmov%f1\t{%3, %0|%0, %3}
   #
   #"
  [(set_attr "type" "fcmov,fcmov,multi,multi")
   (set_attr "mode" "DF,DF,DI,DI")]
:}

abstract set_if_then_else2_x2 extends sequence
{
	root.1:=set_if_then_else2;
	root.2:=set_if_then_else2;
}

concrete .split instantiates.in set_if_then_else2_match_operator1
{
	root (0=register_and_not_any_fp_reg_operand:DF:"",
		(1=fcmov_comparison_operator, reg(NULL:FLAGS_REG), const_int:0),
		2=nonimmediate_operand:DF:"", 3=nonimmediate_operand:DF:"");
	root.2.mode:=DF;
}
cmd_spec.in
{:
  "!TARGET_64BIT && reload_completed"
:}
instantiates.out set_if_then_else2_x2
{
	root (duplicate 2, duplicate 1,duplicate 4, duplicate 5,
		duplicate 3, duplicate 1, duplicate 6, duplicate 7);
	root.1.2.mode:=SI;
	root.2.2.mode:=SI;
}
cmd_spec.out
{:
{
  split_double_mode (DImode, &operands[2], 2, &operands[4], &operands[6]);
  split_double_mode (DImode, &operands[0], 1, &operands[2], &operands[3]);
}
:}

concrete *movsfcc_1_387.insn instantiates set_if_then_else2_match_operator1
{
	root (0=register_operand:SF:"=f,f,r,r",
		(1=fcmov_comparison_operator, reg(NULL:FLAGS_REG), const_int:0),
		2=nonimmediate_operand:SF:"f,0,rm,0", 3=nonimmediate_operand:SF:"0,f,0,rm");
	root.2.mode:=SF;
}
{:
  "TARGET_80387 && TARGET_CMOVE
   && !(MEM_P (operands[2]) && MEM_P (operands[3]))"
  "@
   fcmov%F1\t{%2, %0|%0, %2}
   fcmov%f1\t{%3, %0|%0, %3}
   cmov%O2%C1\t{%2, %0|%0, %2}
   cmov%O2%c1\t{%3, %0|%0, %3}"
  [(set_attr "type" "fcmov,fcmov,icmov,icmov")
   (set_attr "mode" "SF,SF,SI,SI")]
:}

{:
;; All moves in XOP pcmov instructions are 128 bits and hence we restrict
;; the scalar versions to have only XMM registers as operands.

;; XOP conditional move
:}

concrete *xop_pcmov_<mode>.insn instantiates set_if_then_else2
{
	root (0=register_operand:MODEF:"=x",
		1=register_operand:MODEF:"x",2=register_operand:MODEF:"x",
		3=register_operand:MODEF:"x");
	root.2.mode:=MODEF;
}
{:
  "TARGET_XOP"
  "vpcmov\t{%1, %3, %2, %0|%0, %2, %3, %1}"
  [(set_attr "type" "sse4arg")]
:}

{:
;; These versions of the min/max patterns are intentionally ignorant of
;; their behavior wrt -0.0 and NaN (via the commutative operand mark).
;; Since both the tree-level MAX_EXPR and the rtl-level SMAX operator
;; are undefined in this condition, we're certain this is correct.
:}

abstract set_smaxmin2 extends set
{
	root.2:=smaxmin;
}

concrete <code><mode>3.insn instantiates set_smaxmin2
{
	root (0=register_operand:MODEF:"=x,x",1=nonimmediate_operand:MODEF:"%0,x",
		2=nonimmediate_operand:MODEF:"xm,xm");
	root.2.mode:=MODEF;
}
{:  
  "SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH"
  "@
   <maxmin_float><ssemodesuffix>\t{%2, %0|%0, %2}
   v<maxmin_float><ssemodesuffix>\t{%2, %1, %0|%0, %1, %2}"
  [(set_attr "isa" "noavx,avx")
   (set_attr "prefix" "orig,vex")
   (set_attr "type" "sseadd")
   (set_attr "mode" "<MODE>")]
:}

{:
;; These versions of the min/max patterns implement exactly the operations
;;   min = (op1 < op2 ? op1 : op2)
;;   max = (!(op1 < op2) ? op1 : op2)
;; Their operands are not commutative, and thus they may be used in the
;; presence of -0.0 and NaN.
:}

concrete *ieee_smin<mode>3.insn instantiates set_unspec2
{
	root (0=register_operand:MODEF:"=x,x",
		(1=register_operand:MODEF:"0,x", 2=nonimmediate_operand:MODEF:"xm,xm",
			<UNSPEC_IEEE_MIN>));
	root.2.mode:=MODEF;
}
{:
  "SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH"
  "@
   min<ssemodesuffix>\t{%2, %0|%0, %2}
   vmin<ssemodesuffix>\t{%2, %1, %0|%0, %1, %2}"
  [(set_attr "isa" "noavx,avx")
   (set_attr "prefix" "orig,vex")
   (set_attr "type" "sseadd")
   (set_attr "mode" "<MODE>")]
:}

concrete *ieee_smax<mode>3.insn instantiates set_unspec2
{
	root (0=register_operand:MODEF:"=x,x", 
		(1=register_operand:MODEF:"0,x", 2=nonimmediate_operand:MODEF:"xm,xm",
		<UNSPEC_IEEE_MAX>));
	root.2.mode:=MODEF;
}
{:
  "SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH"
  "@
   max<ssemodesuffix>\t{%2, %0|%0, %2}
   vmax<ssemodesuffix>\t{%2, %1, %0|%0, %1, %2}"
  [(set_attr "isa" "noavx,avx")
   (set_attr "prefix" "orig,vex")
   (set_attr "type" "sseadd")
   (set_attr "mode" "<MODE>")]
:}
{:
;; Make two stack loads independent:
;;   fld aa              fld aa
;;   fld %st(0)     ->   fld bb
;;   fmul bb             fmul %st(1), %st
;;
;; Actually we only match the last two instructions for simplicity.
(define_peephole2
  [(set (match_operand 0 "fp_register_operand" "")
	(match_operand 1 "fp_register_operand" ""))
   (set (match_dup 0)
	(match_operator 2 "binary_fp_operator"
	   [(match_dup 0)
	    (match_operand 3 "memory_operand" "")]))]
  "REGNO (operands[0]) != REGNO (operands[1])"
  [(set (match_dup 0) (match_dup 3))
   (set (match_dup 0) (match_dup 4))]

  ;; The % modifier is not operational anymore in peephole2's, so we have to
  ;; swap the operands manually in the case of addition and multiplication.
{
  rtx op0, op1;

  if (COMMUTATIVE_ARITH_P (operands[2]))
    op0 = operands[0], op1 = operands[1];
  else
    op0 = operands[1], op1 = operands[0];

  operands[4] = gen_rtx_fmt_ee (GET_CODE (operands[2]),
				GET_MODE (operands[2]),
				op0, op1);
})

;; Conditional addition patterns
:}

concrete add<mode>cc.exp instantiates sequence
{
	root (0=register_operand:SWI:"",
		1=ordered_comparison_operator:NULL:"",
		2=register_operand:SWI:"",
		3=const_int_operand:SWI:"");
}
{:
  ""
  "if (ix86_expand_int_addcc (operands)) DONE; else FAIL;"
:}
{:

;; Misc patterns (?)

;; This pattern exists to put a dependency on all ebp-based memory accesses.
;; Otherwise there will be nothing to keep
;;
;; [(set (reg ebp) (reg esp))]
;; [(set (reg esp) (plus (reg esp) (const_int -160000)))
;;  (clobber (eflags)]
;; [(set (mem (plus (reg ebp) (const_int -160000))) (const_int 0))]
;;
;; in proper program order.
:}

abstract set_plus2_clobber_clobber_mem1 extends set_plus2_clobber
{
	root.3:=clobber;
	root.3.1:=mem;
}

concrete pro_epilogue_adjust_stack_<mode>_add.insn instantiates set_plus2_clobber_clobber_mem1
{
	root (0=register_operand:P:"=r,r", 
		1=register_operand:P:"0,r", 2=<nonmemory_operand>:P:"r<i>,l<i>",
		reg(CC:FLAGS_REG), scratch);
	root.1.2.mode:=P;
	root.3.1.mode:=BLK;
	
}
{:
  ""
{
  switch (get_attr_type (insn))
    {
    case TYPE_IMOV:
      return "mov{<imodesuffix>}\t{%1, %0|%0, %1}";

    case TYPE_ALU:
      gcc_assert (rtx_equal_p (operands[0], operands[1]));
      if (x86_maybe_negate_const_int (&operands[2], <MODE>mode))
	return "sub{<imodesuffix>}\t{%2, %0|%0, %2}";

      return "add{<imodesuffix>}\t{%2, %0|%0, %2}";

    default:
      operands[2] = SET_SRC (XVECEXP (PATTERN (insn), 0, 0));
      return "lea{<imodesuffix>}\t{%E2, %0|%0, %E2}";
    }
}
  [(set (attr "type")
	(cond [(and (eq_attr "alternative" "0")
		    (not (match_test "TARGET_OPT_AGU")))
		 (const_string "alu")
	       (match_operand:<MODE> 2 "const0_operand" "")
		 (const_string "imov")
	      ]
	      (const_string "lea")))
   (set (attr "length_immediate")
	(cond [(eq_attr "type" "imov")
		 (const_string "0")
	       (and (eq_attr "type" "alu")
		    (match_operand 2 "const128_operand" ""))
		 (const_string "1")
	      ]
	      (const_string "*")))
   (set_attr "mode" "<MODE>")]
:}

abstract set_minus2_clobber_clobber_mem1 extends set_plus2_clobber_clobber_mem1
{
	root.1.2:=minus;
}

concrete pro_epilogue_adjust_stack_<mode>_sub.insn instantiates set_minus2_clobber_clobber_mem1
{
	root (0=register_operand:P:"=r", 1=register_operand:P:"0",
		2=register_operand:P:"r", reg(CC:FLAGS_REG), scratch);
	root.1.2.mode:=P;
	root.3.1.mode:=BLK;
}
{:
  ""
  "sub{<imodesuffix>}\t{%2, %0|%0, %2}"
  [(set_attr "type" "alu")
   (set_attr "mode" "<MODE>")]
:}

abstract set_unspec_volatile2 extends set
{
	root.2:=unspec_volatile;
}

abstract set_unspec_volatile2_clobber extends sequence
{
	root.1:=set_unspec_volatile2;
	root.2:=clobber;
}

concrete allocate_stack_worker_probe_<mode>.insn instantiates set_unspec_volatile2_clobber{
	root (0=register_operand:P:"=a", 
		(1=register_operand:P:"0", <UNSPECV_STACK_PROBE>),
		reg(CC:FLAGS_REG));
	root.1.2.mode:=P;
}
{:
  "ix86_target_stack_probe ()"
  "call\t___chkstk_ms"
  [(set_attr "type" "multi")
   (set_attr "length" "5")]
:}

concrete allocate_stack.exp instantiates sequence
{
	root (0=register_operand:NULL:"", 1=general_operand:NULL:"");
}
{:
  "ix86_target_stack_probe ()"
{
  rtx x;

#ifndef CHECK_STACK_LIMIT
#define CHECK_STACK_LIMIT 0
#endif

  if (CHECK_STACK_LIMIT && CONST_INT_P (operands[1])
      && INTVAL (operands[1]) < CHECK_STACK_LIMIT)
    {
      x = expand_simple_binop (Pmode, MINUS, stack_pointer_rtx, operands[1],
			       stack_pointer_rtx, 0, OPTAB_DIRECT);
      if (x != stack_pointer_rtx)
	emit_move_insn (stack_pointer_rtx, x);
    }
  else
    {
      x = copy_to_mode_reg (Pmode, operands[1]);
      if (TARGET_64BIT)
        emit_insn (gen_allocate_stack_worker_probe_di (x, x));
      else
        emit_insn (gen_allocate_stack_worker_probe_si (x, x));
      x = expand_simple_binop (Pmode, MINUS, stack_pointer_rtx, x,
			       stack_pointer_rtx, 0, OPTAB_DIRECT);
      if (x != stack_pointer_rtx)
	emit_move_insn (stack_pointer_rtx, x);
    }

  emit_move_insn (operands[0], virtual_stack_dynamic_rtx);
  DONE;
}
:}

{:
;; Use IOR for stack probes, this is shorter.
:}

concrete probe_stack.exp instantiates sequence
{
	root (0=memory_operand:NULL:"");
}
{:
  ""
{
  rtx (*gen_ior3) (rtx, rtx, rtx);

  gen_ior3 = (GET_MODE (operands[0]) == DImode
	      ? gen_iordi3 : gen_iorsi3);

  emit_insn (gen_ior3 (operands[0], operands[0], const0_rtx));
  DONE;
}
:}

abstract set_unspec_volatile2_set_minus2_clobber_clobber_mem1 extends sequence
{
	root.1:=set_unspec_volatile2;
	root.2:=set_minus2;
	root.3:=clobber;
	root.4:=clobber;
	root.4.1:=mem;
}

concrete adjust_stack_and_probe<mode>.insn instantiates set_unspec_volatile2_set_minus2_clobber_clobber_mem1
{
	root (0=register_operand:P:"=r", 
		(1=register_operand:P:"0", <UNSPECV_PROBE_STACK_RANGE>),
		reg(P:SP_REG), reg(P:SP_REG), 2=const_int_operand:P:"n",
		reg(CC:FLAGS_REG), scratch);
	root.1.2.mode:=P;
	root.2.2.mode:=P;
	root.4.1.mode:=BLK;
}
{:
  ""
  "* return output_adjust_stack_and_probe (operands[0]);"
  [(set_attr "type" "multi")]
:}

concrete probe_stack_range<mode>.insn instantiates set_unspec_volatile2_clobber
{
	root (0=register_operand:P:"=r",
		(1=register_operand:P:"0", 2=const_int_operand:P:"n",
		<UNSPECV_PROBE_STACK_RANGE>), reg(CC:FLAGS_REG));
	root.1.2.mode:=P;
}
{:
  ""
  "* return output_probe_stack_range (operands[0], operands[2]);"
  [(set_attr "type" "multi")]
:}

concrete builtin_setjmp_receiver.exp instantiates label_ref
{
	root (0=NULL:NULL:"");
}
{:
  "!TARGET_64BIT && flag_pic"
{
#if TARGET_MACHO
  if (TARGET_MACHO)
    {
      rtx xops[3];
      rtx picreg = gen_rtx_REG (Pmode, PIC_OFFSET_TABLE_REGNUM);
      rtx label_rtx = gen_label_rtx ();
      emit_insn (gen_set_got_labelled (pic_offset_table_rtx, label_rtx));
      xops[0] = xops[1] = picreg;
      xops[2] = machopic_gen_offset (gen_rtx_LABEL_REF (SImode, label_rtx));
      ix86_expand_binary_operator (MINUS, SImode, xops);
    }
  else
#endif
    emit_insn (gen_set_got (pic_offset_table_rtx));
  DONE;
}
:}
{:

;; Avoid redundant prefixes by splitting HImode arithmetic to SImode.
:}

abstract set_match_operator2_clobber extends sequence
{
	root.1:=set_match_operator2;
	root.2:=clobber;
}

abstract parallel_set_match_op_dup2_clobber extends parallel
{
	root.1:=set_match_op_dup2;
	root.2:=clobber;
}

concrete .split instantiates.in set_match_operator2_clobber
{
	root (0=register_operand:NULL:"", 
		(3=promotable_binary_operator, 1=register_operand:NULL:"",
		2=aligned_operand:NULL:""),	reg(CC:FLAGS_REG));
}
cmd_spec.in
{:
  "! TARGET_PARTIAL_REG_STALL && reload_completed
   && ((GET_MODE (operands[0]) == HImode
	&& ((optimize_function_for_speed_p (cfun) && !TARGET_FAST_PREFIX)
            /* ??? next two lines just !satisfies_constraint_K (...) */
	    || !CONST_INT_P (operands[2])
	    || satisfies_constraint_K (operands[2])))
       || (GET_MODE (operands[0]) == QImode
	   && (TARGET_PROMOTE_QImode || optimize_function_for_size_p (cfun))))"
:}
instantiates.out parallel_set_match_op_dup2_clobber
{
	root (duplicate 0, (<3>,duplicate 1, duplicate 2),
		reg(CC:FLAGS_REG));
}
cmd_spec.out
{:
{
  operands[0] = gen_lowpart (SImode, operands[0]);
  operands[1] = gen_lowpart (SImode, operands[1]);
  if (GET_CODE (operands[3]) != ASHIFT)
    operands[2] = gen_lowpart (SImode, operands[2]);
  PUT_MODE (operands[3], SImode);
}
:}

{:
; Promote the QImode tests, as i386 has encoding of the AND
; instruction with 32-bit sign-extended immediate and thus the
; instruction size is unchanged, except in the %eax case for
; which it is increased by one byte, hence the ! optimize_size.
:}

abstract set_match_operator2_and1_set_and2 extends sequence
{
	root.1:=set_match_operator2;
	root.1.2.2:=and;
	root.2:=set_and2;
}

abstract parallel_set_match_op_dup2_and1_set_and2 extends parallel
{
	root.1:=set_match_op_dup2;
	root.1.2.1:=and;
	root.2:=set_and2;
}

concrete .split instantiates.in set_match_operator2_and1_set_and2
{
	root (0=flags_reg_operand:NULL:"", 
		(2=compare_operator, 3=aligned_operand:NULL:"",
		4=const_int_operand:NULL:"", const_int:0),
		1=register_operand:NULL:"", duplicate 3, duplicate 4);
}
cmd_spec.in
{:
  "! TARGET_PARTIAL_REG_STALL && reload_completed
   && optimize_insn_for_speed_p ()
   && ((GET_MODE (operands[1]) == HImode && ! TARGET_FAST_PREFIX)
       || (GET_MODE (operands[1]) == QImode && TARGET_PROMOTE_QImode))
   /* Ensure that the operand will remain sign-extended immediate.  */
   && ix86_match_ccmode (insn, INTVAL (operands[4]) >= 0 ? CCNOmode : CCZmode)"
:}
instantiates.out parallel_set_match_op_dup2_and1_set_and2
{
	root (duplicate 0, (<2>, duplicate 3, duplicate 4,
		const_int:0), duplicate 1, duplicate 3, duplicate 4);
	root.1.2.1.mode:=SI;
	root.2.2.mode:=SI;
}
cmd_spec.out
{:
{
  operands[4]
    = gen_int_mode (INTVAL (operands[4])
		    & GET_MODE_MASK (GET_MODE (operands[1])), SImode);
  operands[1] = gen_lowpart (SImode, operands[1]);
  operands[3] = gen_lowpart (SImode, operands[3]);
}
:}

{:
; Don't promote the QImode tests, as i386 doesn't have encoding of
; the TEST instruction with 32-bit sign-extended immediate and thus
; the instruction size would at least double, which is not what we
; want even with ! optimize_size.
:}

abstract set_match_operator2_and1 extends set_match_operator2
{
	root.2.2:=and;
}

abstract set_match_op_dup2_and1 extends set_match_op_dup2
{
	root.2.1:=and;
}

concrete .split instantiates.in set_match_operator2_and1
{
	root (0=flags_reg_operand:NULL:"", 
		(1=compare_operator, 2=aligned_operand:HI:"",
		3=const_int_operand:HI:"", const_int:0));
}
cmd_spec.in
{:
  "! TARGET_PARTIAL_REG_STALL && reload_completed
   && ! TARGET_FAST_PREFIX
   && optimize_insn_for_speed_p ()
   /* Ensure that the operand will remain sign-extended immediate.  */
   && ix86_match_ccmode (insn, INTVAL (operands[3]) >= 0 ? CCNOmode : CCZmode)"
:}
instantiates.out set_match_op_dup2_and1
{
	root (duplicate 0, (<1>, duplicate 2, duplicate 3,const_int:0));
	root.2.1.mode:=SI;
}
cmd_spec.out
{:
{
  operands[3]
    = gen_int_mode (INTVAL (operands[3])
		    & GET_MODE_MASK (GET_MODE (operands[2])), SImode);
  operands[2] = gen_lowpart (SImode, operands[2]);
}
:}

abstract parallel_set_neg2_clobber extends parallel
{
	root.1:=set_neg2;
	root.2:=clobber;
}

concrete .split instantiates.in set_neg2_clobber
{
	root (0=register_operand:NULL:"", 1=register_operand:NULL:"",
		reg(CC:FLAGS_REG));
}
cmd_spec.in
{:
  "! TARGET_PARTIAL_REG_STALL && reload_completed
   && (GET_MODE (operands[0]) == HImode
       || (GET_MODE (operands[0]) == QImode
	   && (TARGET_PROMOTE_QImode
	       || optimize_insn_for_size_p ())))"
:}
instantiates.out parallel_set_neg2_clobber
{
	root (duplicate 0, duplicate 1, reg(CC:FLAGS_REG));
	root.1.2.mode:=SI;
}
cmd_spec.out
{:
{
  operands[0] = gen_lowpart (SImode, operands[0]);
  operands[1] = gen_lowpart (SImode, operands[1]);
}
:}

abstract set_not2 extends set
{
	root.2:=not;
}

concrete .split instantiates.in set_not2
{
	root (0=register_operand:NULL:"", 1=register_operand:NULL:"");
}
cmd_spec.in
{:
  "! TARGET_PARTIAL_REG_STALL && reload_completed
   && (GET_MODE (operands[0]) == HImode
       || (GET_MODE (operands[0]) == QImode
	   && (TARGET_PROMOTE_QImode
	       || optimize_insn_for_size_p ())))"
:}
instantiates.out set_not2
{
	root (duplicate 0, duplicate 1);
	root.2.mode:=SI;
}
cmd_spec.out
{:
{
  operands[0] = gen_lowpart (SImode, operands[0]);
  operands[1] = gen_lowpart (SImode, operands[1]);
}
:}
{:

;; RTL Peephole optimizations, run before sched2.  These primarily look to
;; transform a complex memory operation into two memory to register operations.

;; Don't push memory operands
:}

abstract set_sequence extends sequence
{
  root.1:=set;
  root.2:=sequence;
}

concrete .peep2 instantiates.in set_sequence
{
	root (0=push_operand:SWI:"", 1=memory_operand:SWI:"",
    2=SWI:"<r>");
}
cmd_spec.in
{:
  "!(TARGET_PUSH_MEMORY || optimize_insn_for_size_p ())
   && !RTX_FRAME_RELATED_P (peep2_next_insn (0))"
:}
instantiates.out set_set
{
	root (duplicate 2, duplicate 1, duplicate 0, duplicate 2);
}
cmd_spec.out
{:
:}

{:
;; We need to handle SFmode only, because DFmode and XFmode are split to
;; SImode pushes.
:}

concrete .peep2 instantiates.in set_sequence
{
	root (0=push_operand:SF:"", 1=memory_operand:SF:"",
		2=SF:"r");
}
cmd_spec.in
{:
  "!(TARGET_PUSH_MEMORY || optimize_insn_for_size_p ())
   && !RTX_FRAME_RELATED_P (peep2_next_insn (0))"
:}
instantiates.out set_set
{
	root (duplicate 2, duplicate 1, duplicate 0, duplicate 2);
}
cmd_spec.out
{:
:}
{:
;; Don't move an immediate directly to memory when the instruction
;; gets too big.
:}

abstract sequence_set extends sequence
{
	root.1:=sequence;
	root.2:=set;
}

abstract parallel_set_clobber_set extends sequence
{
	root.1:=parallel_set_clobber;
	root.2:=set;
}

{:
(define_peephole2
  [(match_scratch:SWI124 1 "<r>")
   (set (match_operand:SWI124 0 "memory_operand" "")
        (const_int 0))]
  "optimize_insn_for_speed_p ()
   && !TARGET_USE_MOV0
   && TARGET_SPLIT_LONG_MOVES
   && get_attr_length (insn) >= ix86_cur_cost ()->large_insn
   && peep2_regno_dead_p (0, FLAGS_REG)"
  [(parallel [(set (match_dup 2) (const_int 0))
          (clobber (reg:CC FLAGS_REG))])
   (set (match_dup 0) (match_dup 1))]
  "operands[2] = gen_lowpart (SImode, operands[1]);")

(define_peephole2
  [(match_scratch:SWI124 2 "<r>")
   (set (match_operand:SWI124 0 "memory_operand" "")
        (match_operand:SWI124 1 "immediate_operand" ""))]
  "optimize_insn_for_speed_p ()
   && TARGET_SPLIT_LONG_MOVES
   && get_attr_length (insn) >= ix86_cur_cost ()->large_insn"
  [(set (match_dup 2) (match_dup 1))
   (set (match_dup 0) (match_dup 2))])

:}

{:
;; Don't compare memory with zero, load and use a test instead.
:}

abstract set_match_operator2_sequence extends sequence
{
	root.1:=set_match_operator2;
	root.2:=sequence;
}

abstract set_set_match_op_dup2 extends sequence
{
	root.1:=set;
	root.2:=set_match_op_dup2;
}

concrete .peep2 instantiates.in set_match_operator2_sequence
{
	root ((0=flags_reg_operand:NULL:"",1=compare_operator, 2=memory_operand:SI:"",
		const_int:0), 3=SI:"r");
}
cmd_spec.in
{:
  "optimize_insn_for_speed_p () && ix86_match_ccmode (insn, CCNOmode)"
:}
instantiates.out set_set_match_op_dup2
{
	root (duplicate 3, duplicate 2, duplicate 0, 
		(1=<NULL>, duplicate 3, const_int:0));
}
cmd_spec.out
{:
:}
{:
;; NOT is not pairable on Pentium, while XOR is, but one byte longer.
;; Don't split NOTs with a displacement operand, because resulting XOR
;; will not be pairable anyway.
;;
;; On AMD K6, NOT is vector decoded with memory operand that cannot be
;; represented using a modRM byte.  The XOR replacement is long decoded,
;; so this split helps here as well.
;;
;; Note: Can't do this as a regular split because we can't get proper
;; lifetime information then.
:}

abstract parallel_set_xor2_clobber extends parallel
{
	root.1:=set_xor2;
	root.2:=clobber;
}

concrete .peep2 instantiates.in set_not2
{
	root (0=nonimmediate_operand:SWI124:"", 1=nonimmediate_operand:SWI124:"");
	root.2.mode:=SWI124;
}
cmd_spec.in
{:
  "optimize_insn_for_speed_p ()
   && ((TARGET_NOT_UNPAIRABLE
	&& (!MEM_P (operands[0])
	    || !memory_displacement_operand (operands[0], <MODE>mode)))
       || (TARGET_NOT_VECTORMODE
	   && long_memory_operand (operands[0], <MODE>mode)))
   && peep2_regno_dead_p (0, FLAGS_REG)"
:}
instantiates.out parallel_set_xor2_clobber
{
	root (duplicate 0, duplicate 1, const_int:-1,
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI124;
}
cmd_spec.out
{:
:}
{:
;; Non pairable "test imm, reg" instructions can be translated to
;; "and imm, reg" if reg dies.  The "and" form is also shorter (one
;; byte opcode instead of two, have a short form for byte operands),
;; so do it for other CPUs as well.  Given that the value was dead,
;; this should not create any new dependencies.  Pass on the sub-word
;; versions if we're concerned about partial register stalls.
:}

concrete .peep2 instantiates.in set_match_operator2_and1
{
	root (0=flags_reg_operand:NULL:"", 
		(1=compare_operator, 2=register_operand:SI:"", 
		3=immediate_operand:SI:"",const_int:0));
	root.2.2.mode:=SI;
}
cmd_spec.in
{:
  "ix86_match_ccmode (insn, CCNOmode)
   && (true_regnum (operands[2]) != AX_REG
       || satisfies_constraint_K (operands[3]))
   && peep2_reg_dead_p (1, operands[2])"
:}
instantiates.out parallel_set_match_op_dup2_and1_set_and2
{
	root (duplicate 0, 
		(<1>, duplicate 2, duplicate 3, const_int:0), 
		duplicate 2, duplicate 2, duplicate 3);
	root.1.2.1.mode:=SI;
	root.2.2.mode:=SI;
}
cmd_spec.out
{:
:}
{:
;; We don't need to handle HImode case, because it will be promoted to SImode
;; on ! TARGET_PARTIAL_REG_STALL
:}
concrete .peep2 instantiates.in set_match_operator2_and1
{
	root (0=flags_reg_operand:NULL:"", 
		(1=compare_operator, 2=register_operand:QI:"", 
		3=immediate_operand:QI:"", const_int:0));
	root.2.2.mode:=QI;
}
cmd_spec.in
{:
  "! TARGET_PARTIAL_REG_STALL
   && ix86_match_ccmode (insn, CCNOmode)
   && true_regnum (operands[2]) != AX_REG
   && peep2_reg_dead_p (1, operands[2])"
:}
instantiates.out parallel_set_match_op_dup2_and1_set_and2
{
	root (duplicate 0, 
		(<1>, duplicate 2, duplicate 3, const_int:0),
		duplicate 2, duplicate 2, duplicate 3);
	root.1.2.1.mode:=QI;
	root.2.2.mode:=QI;
}
cmd_spec.out
{:
:}


{:
(define_peephole2
  [(set (match_operand 0 "flags_reg_operand" "")
	(match_operator 1 "compare_operator"
	  [(and:SI
	     (zero_extract:SI
	       (match_operand 2 "ext_register_operand" "")
	       (const_int 8)
	       (const_int 8))
	     (match_operand 3 "const_int_operand" ""))
	   (const_int 0)]))]
  "! TARGET_PARTIAL_REG_STALL
   && ix86_match_ccmode (insn, CCNOmode)
   && true_regnum (operands[2]) != AX_REG
   && peep2_reg_dead_p (1, operands[2])"
  [(parallel [(set (match_dup 0)
		   (match_op_dup 1
		     [(and:SI
			(zero_extract:SI
			  (match_dup 2)
			  (const_int 8)
			  (const_int 8))
			(match_dup 3))
		      (const_int 0)]))
	      (set (zero_extract:SI (match_dup 2)
				    (const_int 8)
				    (const_int 8))
		   (and:SI
		     (zero_extract:SI
		       (match_dup 2)
		       (const_int 8)
		       (const_int 8))
		     (match_dup 3)))])])

;; Don't do logical operations with memory inputs.
(define_peephole2
  [(match_scratch:SI 2 "r")
   (parallel [(set (match_operand:SI 0 "register_operand" "")
                   (match_operator:SI 3 "arith_or_logical_operator"
                     [(match_dup 0)
                      (match_operand:SI 1 "memory_operand" "")]))
              (clobber (reg:CC FLAGS_REG))])]
  "!(TARGET_READ_MODIFY || optimize_insn_for_size_p ())"
  [(set (match_dup 2) (match_dup 1))
   (parallel [(set (match_dup 0)
                   (match_op_dup 3 [(match_dup 0) (match_dup 2)]))
              (clobber (reg:CC FLAGS_REG))])])

(define_peephole2
  [(match_scratch:SI 2 "r")
   (parallel [(set (match_operand:SI 0 "register_operand" "")
                   (match_operator:SI 3 "arith_or_logical_operator"
                     [(match_operand:SI 1 "memory_operand" "")
                      (match_dup 0)]))
              (clobber (reg:CC FLAGS_REG))])]
  "!(TARGET_READ_MODIFY || optimize_insn_for_size_p ())"
  [(set (match_dup 2) (match_dup 1))
   (parallel [(set (match_dup 0)
                   (match_op_dup 3 [(match_dup 2) (match_dup 0)]))
              (clobber (reg:CC FLAGS_REG))])])

;; Prefer Load+RegOp to Mov+MemOp.  Watch out for cases when the memory address
;; refers to the destination of the load!

(define_peephole2
  [(set (match_operand:SI 0 "register_operand" "")
        (match_operand:SI 1 "register_operand" ""))
   (parallel [(set (match_dup 0)
                   (match_operator:SI 3 "commutative_operator"
                     [(match_dup 0)
                      (match_operand:SI 2 "memory_operand" "")]))
              (clobber (reg:CC FLAGS_REG))])]
  "REGNO (operands[0]) != REGNO (operands[1])
   && GENERAL_REGNO_P (REGNO (operands[0]))
   && GENERAL_REGNO_P (REGNO (operands[1]))"
  [(set (match_dup 0) (match_dup 4))
   (parallel [(set (match_dup 0)
                   (match_op_dup 3 [(match_dup 0) (match_dup 1)]))
              (clobber (reg:CC FLAGS_REG))])]
  "operands[4] = replace_rtx (operands[2], operands[0], operands[1]);")

(define_peephole2
  [(set (match_operand 0 "register_operand" "")
        (match_operand 1 "register_operand" ""))
   (set (match_dup 0)
                   (match_operator 3 "commutative_operator"
                     [(match_dup 0)
                      (match_operand 2 "memory_operand" "")]))]
  "REGNO (operands[0]) != REGNO (operands[1])
   && ((MMX_REG_P (operands[0]) && MMX_REG_P (operands[1])) 
       || (SSE_REG_P (operands[0]) && SSE_REG_P (operands[1])))"
  [(set (match_dup 0) (match_dup 2))
   (set (match_dup 0)
        (match_op_dup 3 [(match_dup 0) (match_dup 1)]))])

; Don't do logical operations with memory outputs
;
; These two don't make sense for PPro/PII -- we're expanding a 4-uop
; instruction into two 1-uop insns plus a 2-uop insn.  That last has
; the same decoder scheduling characteristics as the original.

(define_peephole2
  [(match_scratch:SI 2 "r")
   (parallel [(set (match_operand:SI 0 "memory_operand" "")
                   (match_operator:SI 3 "arith_or_logical_operator"
                     [(match_dup 0)
                      (match_operand:SI 1 "nonmemory_operand" "")]))
              (clobber (reg:CC FLAGS_REG))])]
  "!(TARGET_READ_MODIFY_WRITE || optimize_insn_for_size_p ())
   /* Do not split stack checking probes.  */
   && GET_CODE (operands[3]) != IOR && operands[1] != const0_rtx"
  [(set (match_dup 2) (match_dup 0))
   (parallel [(set (match_dup 2)
                   (match_op_dup 3 [(match_dup 2) (match_dup 1)]))
              (clobber (reg:CC FLAGS_REG))])
   (set (match_dup 0) (match_dup 2))])

(define_peephole2
  [(match_scratch:SI 2 "r")
   (parallel [(set (match_operand:SI 0 "memory_operand" "")
                   (match_operator:SI 3 "arith_or_logical_operator"
                     [(match_operand:SI 1 "nonmemory_operand" "")
                      (match_dup 0)]))
              (clobber (reg:CC FLAGS_REG))])]
  "!(TARGET_READ_MODIFY_WRITE || optimize_insn_for_size_p ())
   /* Do not split stack checking probes.  */
   && GET_CODE (operands[3]) != IOR && operands[1] != const0_rtx"
  [(set (match_dup 2) (match_dup 0))
   (parallel [(set (match_dup 2)
                   (match_op_dup 3 [(match_dup 1) (match_dup 2)]))
              (clobber (reg:CC FLAGS_REG))])
   (set (match_dup 0) (match_dup 2))])

;; Attempt to use arith or logical operations with memory outputs with
;; setting of flags.
(define_peephole2
  [(set (match_operand:SWI 0 "register_operand" "")
	(match_operand:SWI 1 "memory_operand" ""))
   (parallel [(set (match_dup 0)
		   (match_operator:SWI 3 "plusminuslogic_operator"
		     [(match_dup 0)
		      (match_operand:SWI 2 "<nonmemory_operand>" "")]))
	      (clobber (reg:CC FLAGS_REG))])
   (set (match_dup 1) (match_dup 0))
   (set (reg FLAGS_REG) (compare (match_dup 0) (const_int 0)))]
  "(TARGET_READ_MODIFY_WRITE || optimize_insn_for_size_p ())
   && peep2_reg_dead_p (4, operands[0])
   && !reg_overlap_mentioned_p (operands[0], operands[1])
   && (<MODE>mode != QImode
       || immediate_operand (operands[2], QImode)
       || q_regs_operand (operands[2], QImode))
   && ix86_match_ccmode (peep2_next_insn (3),
			 (GET_CODE (operands[3]) == PLUS
			  || GET_CODE (operands[3]) == MINUS)
			 ? CCGOCmode : CCNOmode)"
  [(parallel [(set (match_dup 4) (match_dup 5))
	      (set (match_dup 1) (match_op_dup 3 [(match_dup 1)
						  (match_dup 2)]))])]
{
  operands[4] = SET_DEST (PATTERN (peep2_next_insn (3)));
  operands[5] = gen_rtx_fmt_ee (GET_CODE (operands[3]), <MODE>mode,
				copy_rtx (operands[1]),
				copy_rtx (operands[2]));
  operands[5] = gen_rtx_COMPARE (GET_MODE (operands[4]),
				 operands[5], const0_rtx);
})

(define_peephole2
  [(parallel [(set (match_operand:SWI 0 "register_operand" "")
		   (match_operator:SWI 2 "plusminuslogic_operator"
		     [(match_dup 0)
		      (match_operand:SWI 1 "memory_operand" "")]))
	      (clobber (reg:CC FLAGS_REG))])
   (set (match_dup 1) (match_dup 0))
   (set (reg FLAGS_REG) (compare (match_dup 0) (const_int 0)))]
  "(TARGET_READ_MODIFY_WRITE || optimize_insn_for_size_p ())
   && GET_CODE (operands[2]) != MINUS
   && peep2_reg_dead_p (3, operands[0])
   && !reg_overlap_mentioned_p (operands[0], operands[1])
   && ix86_match_ccmode (peep2_next_insn (2),
			 GET_CODE (operands[2]) == PLUS
			 ? CCGOCmode : CCNOmode)"
  [(parallel [(set (match_dup 3) (match_dup 4))
	      (set (match_dup 1) (match_op_dup 2 [(match_dup 1)
						  (match_dup 0)]))])]
{
  operands[3] = SET_DEST (PATTERN (peep2_next_insn (2)));
  operands[4] = gen_rtx_fmt_ee (GET_CODE (operands[2]), <MODE>mode,
				copy_rtx (operands[1]),
				copy_rtx (operands[0]));
  operands[4] = gen_rtx_COMPARE (GET_MODE (operands[3]),
				 operands[4], const0_rtx);
})

(define_peephole2
  [(set (match_operand:SWI12 0 "register_operand" "")
	(match_operand:SWI12 1 "memory_operand" ""))
   (parallel [(set (match_operand:SI 4 "register_operand" "")
		   (match_operator:SI 3 "plusminuslogic_operator"
		     [(match_dup 4)
		      (match_operand:SI 2 "nonmemory_operand" "")]))
	      (clobber (reg:CC FLAGS_REG))])
   (set (match_dup 1) (match_dup 0))
   (set (reg FLAGS_REG) (compare (match_dup 0) (const_int 0)))]
  "(TARGET_READ_MODIFY_WRITE || optimize_insn_for_size_p ())
   && REG_P (operands[0]) && REG_P (operands[4])
   && REGNO (operands[0]) == REGNO (operands[4])
   && peep2_reg_dead_p (4, operands[0])
   && (<MODE>mode != QImode
       || immediate_operand (operands[2], SImode)
       || q_regs_operand (operands[2], SImode))
   && !reg_overlap_mentioned_p (operands[0], operands[1])
   && ix86_match_ccmode (peep2_next_insn (3),
			 (GET_CODE (operands[3]) == PLUS
			  || GET_CODE (operands[3]) == MINUS)
			 ? CCGOCmode : CCNOmode)"
  [(parallel [(set (match_dup 4) (match_dup 5))
	      (set (match_dup 1) (match_dup 6))])]
{
  operands[2] = gen_lowpart (<MODE>mode, operands[2]);
  operands[4] = SET_DEST (PATTERN (peep2_next_insn (3)));
  operands[5] = gen_rtx_fmt_ee (GET_CODE (operands[3]), <MODE>mode,
				copy_rtx (operands[1]), operands[2]);
  operands[5] = gen_rtx_COMPARE (GET_MODE (operands[4]),
				 operands[5], const0_rtx);
  operands[6] = gen_rtx_fmt_ee (GET_CODE (operands[3]), <MODE>mode,
				copy_rtx (operands[1]),
				copy_rtx (operands[2]));
})

;; Attempt to always use XOR for zeroing registers.
:}

concrete .peep2 instantiates.in set
{
	root (0=register_operand:NULL:"", 1=const0_operand:NULL:"");
}
cmd_spec.in
{:
  "GET_MODE_SIZE (GET_MODE (operands[0])) <= UNITS_PER_WORD
   && (! TARGET_USE_MOV0 || optimize_insn_for_size_p ())
   && GENERAL_REG_P (operands[0])
   && peep2_regno_dead_p (0, FLAGS_REG)"
:}
instantiates.out parallel_set_clobber
{
	root (duplicate 0, const_int:0, reg(CC:FLAGS_REG));
}
cmd_spec.out
{:
  "operands[0] = gen_lowpart (word_mode, operands[0]);"
:}

abstract parallel_set_strict_low_part1_clobber extends parallel
{
	root.1:=set_strict_low_part1;
	root.2:=clobber;
}

concrete .peep2 instantiates.in set_strict_low_part1
{
	root (0=register_operand:NULL:"", const_int:0);
}
cmd_spec.in
{:
  "(GET_MODE (operands[0]) == QImode
    || GET_MODE (operands[0]) == HImode)
   && (! TARGET_USE_MOV0 || optimize_insn_for_size_p ())
   && peep2_regno_dead_p (0, FLAGS_REG)"
:}
instantiates.out parallel_set_strict_low_part1_clobber
{
	root (duplicate 0, const_int:0, reg(CC:FLAGS_REG));
}
cmd_spec.out
{:
:}

{:
;; For HI, SI and DI modes, or $-1,reg is smaller than mov $-1,reg.
:}

concrete .peep2 instantiates.in set
{
	root (0=register_operand:SWI248:"", const_int:-1);
}
cmd_spec.in
{:
  "(optimize_insn_for_size_p () || TARGET_MOVE_M1_VIA_OR)
   && peep2_regno_dead_p (0, FLAGS_REG)"
:}
instantiates.out parallel_set_clobber
{
	root (duplicate 0, const_int:-1, reg(CC:FLAGS_REG));
}
cmd_spec.out
{:
{
  if (GET_MODE_SIZE (<MODE>mode) < GET_MODE_SIZE (SImode))
    operands[0] = gen_lowpart (SImode, operands[0]);
}
:}

{:
;; Attempt to convert simple lea to add/shift.
;; These can be created by move expanders.
:}


abstract parallel_set_plus2_clobber extends parallel
{
	root.1:=set_plus2;
	root.2:=clobber;
}

concrete .peep2 instantiates.in set_plus2
{
	root(0=register_operand:SWI48:"", duplicate 0,
		1=<nonmemory_operand>:SWI48:"");
	root.2.mode:=SWI48;	
}
cmd_spec.in
{:
  "peep2_regno_dead_p (0, FLAGS_REG)"
:}
instantiates.out parallel_set_plus2_clobber
{
	root(duplicate 0, duplicate 0, duplicate 1,
		reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
}
cmd_spec.out
{:
:}

abstract set_subreg2 extends set
{
	root.2:=subreg;
}

abstract set_subreg2_plus1 extends set_subreg2
{
	root.2.1:=plus;
}

concrete .peep2 instantiates.in set_subreg2_plus1
{
	root(0=register_operand:SI:"", 1=register_operand:DI:"",
			2=nonmemory_operand:DI:"", <0>);
	root.2.mode:=SI;
	root.2.1.mode:=DI;
}
cmd_spec.in
{:
  "TARGET_64BIT
   && peep2_regno_dead_p (0, FLAGS_REG)
   && REGNO (operands[0]) == REGNO (operands[1])"
:}
instantiates.out parallel_set_plus2_clobber
{
	root(duplicate 0, duplicate 0, duplicate 2, reg(CC:FLAGS_REG));
	root.1.2.mode:=SI;
}
cmd_spec.out
{:
  "operands[2] = gen_lowpart (SImode, operands[2]);"
:}

concrete .peep2 instantiates.in set_mult2
{
	root(0=register_operand:SWI48:"", duplicate 0,
		1=const_int_operand:SWI48:"");
	root.2.mode:=SWI48;
}
cmd_spec.in
{:
  "exact_log2 (INTVAL (operands[1])) >= 0
   && peep2_regno_dead_p (0, FLAGS_REG)"
:}
instantiates.out parallel_set_ashift2_clobber
{
	root(duplicate 0, duplicate 0, duplicate 2, reg(CC:FLAGS_REG));
	root.1.2.mode:=SWI48;
}
cmd_spec.out
{:
  "operands[2] = GEN_INT (exact_log2 (INTVAL (operands[1])));"
:}

abstract set_subreg2_mult1 extends set_subreg2
{
	root.2.1:=mult;
}

concrete .peep2 instantiates.in set_subreg2_mult1
{
	root(0=register_operand:SI:"", 1=register_operand:DI:"",
		2=const_int_operand:DI:"",0);
	root.2.mode:=SI;
	root.2.1.mode:=DI;
}
cmd_spec.in
{:
  "TARGET_64BIT
   && exact_log2 (INTVAL (operands[2])) >= 0
   && REGNO (operands[0]) == REGNO (operands[1])
   && peep2_regno_dead_p (0, FLAGS_REG)"
:}
instantiates.out parallel_set_ashift2_clobber
{
	root(duplicate 0, duplicate 0, duplicate 2, reg(CC:FLAGS_REG));
	root.1.2.mode:=SI;
}
cmd_spec.out
{:
  "operands[2] = GEN_INT (exact_log2 (INTVAL (operands[2])));"
:}

{:
;; The ESP adjustments can be done by the push and pop instructions.  Resulting
;; code is shorter, since push is only 1 byte, while add imm, %esp is 3 bytes.
;; On many CPUs it is also faster, since special hardware to avoid esp
;; dependencies is present.

;; While some of these conversions may be done using splitters, we use
;; peepholes in order to allow combine_stack_adjustments pass to see
;; nonobfuscated RTL.

;; Convert prologue esp subtractions to push.
;; We need register to push.  In order to keep verify_flow_info happy we have
;; two choices
;; - use scratch and clobber it in order to avoid dependencies
;; - use already live register
;; We can't use the second way right now, since there is no reliable way how to
;; verify that given register is live.  First choice will also most likely in
;; fewer dependencies.  On the place of esp adjustments it is very likely that
;; call clobbered registers are dead.  We may want to use base pointer as an
;; alternative when no register is available later.

(define_peephole2
  [(match_scratch:P 1 "r")
   (parallel [(set (reg:P SP_REG)
		   (plus:P (reg:P SP_REG)
			   (match_operand:P 0 "const_int_operand" "")))
	      (clobber (reg:CC FLAGS_REG))
	      (clobber (mem:BLK (scratch)))])]
  "(TARGET_SINGLE_PUSH || optimize_insn_for_size_p ())
   && INTVAL (operands[0]) == -GET_MODE_SIZE (Pmode)"
  [(clobber (match_dup 1))
   (parallel [(set (mem:P (pre_dec:P (reg:P SP_REG))) (match_dup 1))
	      (clobber (mem:BLK (scratch)))])])

(define_peephole2
  [(match_scratch:P 1 "r")
   (parallel [(set (reg:P SP_REG)
		   (plus:P (reg:P SP_REG)
			   (match_operand:P 0 "const_int_operand" "")))
	      (clobber (reg:CC FLAGS_REG))
	      (clobber (mem:BLK (scratch)))])]
  "(TARGET_DOUBLE_PUSH || optimize_insn_for_size_p ())
   && INTVAL (operands[0]) == -2*GET_MODE_SIZE (Pmode)"
  [(clobber (match_dup 1))
   (set (mem:P (pre_dec:P (reg:P SP_REG))) (match_dup 1))
   (parallel [(set (mem:P (pre_dec:P (reg:P SP_REG))) (match_dup 1))
	      (clobber (mem:BLK (scratch)))])])

;; Convert esp subtractions to push.
(define_peephole2
  [(match_scratch:P 1 "r")
   (parallel [(set (reg:P SP_REG)
		   (plus:P (reg:P SP_REG)
			   (match_operand:P 0 "const_int_operand" "")))
	      (clobber (reg:CC FLAGS_REG))])]
  "(TARGET_SINGLE_PUSH || optimize_insn_for_size_p ())
   && INTVAL (operands[0]) == -GET_MODE_SIZE (Pmode)"
  [(clobber (match_dup 1))
   (set (mem:P (pre_dec:P (reg:P SP_REG))) (match_dup 1))])

(define_peephole2
  [(match_scratch:P 1 "r")
   (parallel [(set (reg:P SP_REG)
		   (plus:P (reg:P SP_REG)
			   (match_operand:P 0 "const_int_operand" "")))
	      (clobber (reg:CC FLAGS_REG))])]
  "(TARGET_DOUBLE_PUSH || optimize_insn_for_size_p ())
   && INTVAL (operands[0]) == -2*GET_MODE_SIZE (Pmode)"
  [(clobber (match_dup 1))
   (set (mem:P (pre_dec:P (reg:P SP_REG))) (match_dup 1))
   (set (mem:P (pre_dec:P (reg:P SP_REG))) (match_dup 1))])

;; Convert epilogue deallocator to pop.
(define_peephole2
  [(match_scratch:P 1 "r")
   (parallel [(set (reg:P SP_REG)
		   (plus:P (reg:P SP_REG)
			   (match_operand:P 0 "const_int_operand" "")))
	      (clobber (reg:CC FLAGS_REG))
	      (clobber (mem:BLK (scratch)))])]
  "(TARGET_SINGLE_POP || optimize_insn_for_size_p ())
   && INTVAL (operands[0]) == GET_MODE_SIZE (Pmode)"
  [(parallel [(set (match_dup 1) (mem:P (post_inc:P (reg:P SP_REG))))
	      (clobber (mem:BLK (scratch)))])])

;; Two pops case is tricky, since pop causes dependency
;; on destination register.  We use two registers if available.
(define_peephole2
  [(match_scratch:P 1 "r")
   (match_scratch:P 2 "r")
   (parallel [(set (reg:P SP_REG)
		   (plus:P (reg:P SP_REG)
			   (match_operand:P 0 "const_int_operand" "")))
	      (clobber (reg:CC FLAGS_REG))
	      (clobber (mem:BLK (scratch)))])]
  "(TARGET_DOUBLE_POP || optimize_insn_for_size_p ())
   && INTVAL (operands[0]) == 2*GET_MODE_SIZE (Pmode)"
  [(parallel [(set (match_dup 1) (mem:P (post_inc:P (reg:P SP_REG))))
	      (clobber (mem:BLK (scratch)))])
   (set (match_dup 2) (mem:P (post_inc:P (reg:P SP_REG))))])

(define_peephole2
  [(match_scratch:P 1 "r")
   (parallel [(set (reg:P SP_REG)
		   (plus:P (reg:P SP_REG)
			   (match_operand:P 0 "const_int_operand" "")))
	      (clobber (reg:CC FLAGS_REG))
	      (clobber (mem:BLK (scratch)))])]
  "optimize_insn_for_size_p ()
   && INTVAL (operands[0]) == 2*GET_MODE_SIZE (Pmode)"
  [(parallel [(set (match_dup 1) (mem:P (post_inc:P (reg:P SP_REG))))
	      (clobber (mem:BLK (scratch)))])
   (set (match_dup 1) (mem:P (post_inc:P (reg:P SP_REG))))])

;; Convert esp additions to pop.
(define_peephole2
  [(match_scratch:P 1 "r")
   (parallel [(set (reg:P SP_REG)
		   (plus:P (reg:P SP_REG)
			   (match_operand:P 0 "const_int_operand" "")))
	      (clobber (reg:CC FLAGS_REG))])]
  "INTVAL (operands[0]) == GET_MODE_SIZE (Pmode)"
  [(set (match_dup 1) (mem:P (post_inc:P (reg:P SP_REG))))])

;; Two pops case is tricky, since pop causes dependency
;; on destination register.  We use two registers if available.
(define_peephole2
  [(match_scratch:P 1 "r")
   (match_scratch:P 2 "r")
   (parallel [(set (reg:P SP_REG)
		   (plus:P (reg:P SP_REG)
			   (match_operand:P 0 "const_int_operand" "")))
	      (clobber (reg:CC FLAGS_REG))])]
  "INTVAL (operands[0]) == 2*GET_MODE_SIZE (Pmode)"
  [(set (match_dup 1) (mem:P (post_inc:P (reg:P SP_REG))))
   (set (match_dup 2) (mem:P (post_inc:P (reg:P SP_REG))))])

(define_peephole2
  [(match_scratch:P 1 "r")
   (parallel [(set (reg:P SP_REG)
		   (plus:P (reg:P SP_REG)
			   (match_operand:P 0 "const_int_operand" "")))
	      (clobber (reg:CC FLAGS_REG))])]
  "optimize_insn_for_size_p ()
   && INTVAL (operands[0]) == 2*GET_MODE_SIZE (Pmode)"
  [(set (match_dup 1) (mem:P (post_inc:P (reg:P SP_REG))))
   (set (match_dup 1) (mem:P (post_inc:P (reg:P SP_REG))))])

;; Convert compares with 1 to shorter inc/dec operations when CF is not
;; required and register dies.  Similarly for 128 to -128.
(define_peephole2
  [(set (match_operand 0 "flags_reg_operand" "")
	(match_operator 1 "compare_operator"
	  [(match_operand 2 "register_operand" "")
	   (match_operand 3 "const_int_operand" "")]))]
  "(((!TARGET_FUSE_CMP_AND_BRANCH || optimize_insn_for_size_p ())
     && incdec_operand (operands[3], GET_MODE (operands[3])))
    || (!TARGET_FUSE_CMP_AND_BRANCH
	&& INTVAL (operands[3]) == 128))
   && ix86_match_ccmode (insn, CCGCmode)
   && peep2_reg_dead_p (1, operands[2])"
  [(parallel [(set (match_dup 0)
		   (match_op_dup 1 [(match_dup 2) (match_dup 3)]))
	      (clobber (match_dup 2))])])

;; Convert imul by three, five and nine into lea
(define_peephole2
  [(parallel
    [(set (match_operand:SWI48 0 "register_operand" "")
	  (mult:SWI48 (match_operand:SWI48 1 "register_operand" "")
		      (match_operand:SWI48 2 "const359_operand" "")))
     (clobber (reg:CC FLAGS_REG))])]
  "!TARGET_PARTIAL_REG_STALL
   || <MODE>mode == SImode
   || optimize_function_for_size_p (cfun)"
  [(set (match_dup 0)
	(plus:SWI48 (mult:SWI48 (match_dup 1) (match_dup 2))
		    (match_dup 1)))]
  "operands[2] = GEN_INT (INTVAL (operands[2]) - 1);")

(define_peephole2
  [(parallel
    [(set (match_operand:SWI48 0 "register_operand" "")
	  (mult:SWI48 (match_operand:SWI48 1 "nonimmediate_operand" "")
		      (match_operand:SWI48 2 "const359_operand" "")))
     (clobber (reg:CC FLAGS_REG))])]
  "optimize_insn_for_speed_p ()
   && (!TARGET_PARTIAL_REG_STALL || <MODE>mode == SImode)"
  [(set (match_dup 0) (match_dup 1))
   (set (match_dup 0)
	(plus:SWI48 (mult:SWI48 (match_dup 0) (match_dup 2))
		    (match_dup 0)))]
  "operands[2] = GEN_INT (INTVAL (operands[2]) - 1);")

;; imul $32bit_imm, mem, reg is vector decoded, while
;; imul $32bit_imm, reg, reg is direct decoded.
(define_peephole2
  [(match_scratch:SWI48 3 "r")
   (parallel [(set (match_operand:SWI48 0 "register_operand" "")
		   (mult:SWI48 (match_operand:SWI48 1 "memory_operand" "")
			       (match_operand:SWI48 2 "immediate_operand" "")))
	      (clobber (reg:CC FLAGS_REG))])]
  "TARGET_SLOW_IMUL_IMM32_MEM && optimize_insn_for_speed_p ()
   && !satisfies_constraint_K (operands[2])"
  [(set (match_dup 3) (match_dup 1))
   (parallel [(set (match_dup 0) (mult:SWI48 (match_dup 3) (match_dup 2)))
	      (clobber (reg:CC FLAGS_REG))])])

(define_peephole2
  [(match_scratch:SI 3 "r")
   (parallel [(set (match_operand:DI 0 "register_operand" "")
		   (zero_extend:DI
		     (mult:SI (match_operand:SI 1 "memory_operand" "")
			      (match_operand:SI 2 "immediate_operand" ""))))
	      (clobber (reg:CC FLAGS_REG))])]
  "TARGET_64BIT
   && TARGET_SLOW_IMUL_IMM32_MEM && optimize_insn_for_speed_p ()
   && !satisfies_constraint_K (operands[2])"
  [(set (match_dup 3) (match_dup 1))
   (parallel [(set (match_dup 0)
		   (zero_extend:DI (mult:SI (match_dup 3) (match_dup 2))))
	      (clobber (reg:CC FLAGS_REG))])])

;; imul $8/16bit_imm, regmem, reg is vector decoded.
;; Convert it into imul reg, reg
;; It would be better to force assembler to encode instruction using long
;; immediate, but there is apparently no way to do so.
(define_peephole2
  [(parallel [(set (match_operand:SWI248 0 "register_operand" "")
		   (mult:SWI248
		    (match_operand:SWI248 1 "nonimmediate_operand" "")
		    (match_operand:SWI248 2 "const_int_operand" "")))
	      (clobber (reg:CC FLAGS_REG))])
   (match_scratch:SWI248 3 "r")]
  "TARGET_SLOW_IMUL_IMM8 && optimize_insn_for_speed_p ()
   && satisfies_constraint_K (operands[2])"
  [(set (match_dup 3) (match_dup 2))
   (parallel [(set (match_dup 0) (mult:SWI248 (match_dup 0) (match_dup 3)))
	      (clobber (reg:CC FLAGS_REG))])]
{
  if (!rtx_equal_p (operands[0], operands[1]))
    emit_move_insn (operands[0], operands[1]);
})

;; After splitting up read-modify operations, array accesses with memory
;; operands might end up in form:
;;  sall    $2, %eax
;;  movl    4(%esp), %edx
;;  addl    %edx, %eax
;; instead of pre-splitting:
;;  sall    $2, %eax
;;  addl    4(%esp), %eax
;; Turn it into:
;;  movl    4(%esp), %edx
;;  leal    (%edx,%eax,4), %eax

(define_peephole2
  [(match_scratch:P 5 "r")
   (parallel [(set (match_operand 0 "register_operand" "")
		   (ashift (match_operand 1 "register_operand" "")
			   (match_operand 2 "const_int_operand" "")))
	       (clobber (reg:CC FLAGS_REG))])
   (parallel [(set (match_operand 3 "register_operand" "")
		   (plus (match_dup 0)
			 (match_operand 4 "x86_64_general_operand" "")))
		   (clobber (reg:CC FLAGS_REG))])]
  "IN_RANGE (INTVAL (operands[2]), 1, 3)
   /* Validate MODE for lea.  */
   && ((!TARGET_PARTIAL_REG_STALL
	&& (GET_MODE (operands[0]) == QImode
	    || GET_MODE (operands[0]) == HImode))
       || GET_MODE (operands[0]) == SImode
       || (TARGET_64BIT && GET_MODE (operands[0]) == DImode))
   && (rtx_equal_p (operands[0], operands[3])
       || peep2_reg_dead_p (2, operands[0]))
   /* We reorder load and the shift.  */
   && !reg_overlap_mentioned_p (operands[0], operands[4])"
  [(set (match_dup 5) (match_dup 4))
   (set (match_dup 0) (match_dup 1))]
{
  enum machine_mode op1mode = GET_MODE (operands[1]);
  enum machine_mode mode = op1mode == DImode ? DImode : SImode;
  int scale = 1 << INTVAL (operands[2]);
  rtx index = gen_lowpart (Pmode, operands[1]);
  rtx base = gen_lowpart (Pmode, operands[5]);
  rtx dest = gen_lowpart (mode, operands[3]);

  operands[1] = gen_rtx_PLUS (Pmode, base,
  			      gen_rtx_MULT (Pmode, index, GEN_INT (scale)));
  operands[5] = base;
  if (mode != Pmode)
    operands[1] = gen_rtx_SUBREG (mode, operands[1], 0);
  if (op1mode != Pmode)
    operands[5] = gen_rtx_SUBREG (op1mode, operands[5], 0);
  operands[0] = dest;
})

;; We used to use "int $5", in honor of #BR which maps to interrupt vector 5.
;; That, however, is usually mapped by the OS to SIGSEGV, which is often
;; caught for use by garbage collectors and the like.  Using an insn that
;; maps to SIGILL makes it more likely the program will rightfully die.
;; Keeping with tradition, "6" is in honor of #UD.
:}

concrete trap.insn instantiates trap_if
{
	root(const_int:1, const_int:6);
}
{:
  ""
  { return ASM_SHORT "0x0b0f"; }
  [(set_attr "length" "2")]
:}

concrete prefetch.exp instantiates prefetch
{
	root (0=address_operand:NULL:"", 1=const_int_operand:SI:"",
		2=const_int_operand:SI:"");
}
{:
  "TARGET_PREFETCH_SSE || TARGET_3DNOW"
{
  int rw = INTVAL (operands[1]);
  int locality = INTVAL (operands[2]);

  gcc_assert (rw == 0 || rw == 1);
  gcc_assert (IN_RANGE (locality, 0, 3));

  if (TARGET_PREFETCHW && rw)
    operands[2] = GEN_INT (3);
  /* Use 3dNOW prefetch in case we are asking for write prefetch not
     supported by SSE counterpart or the SSE prefetch is not available
     (K6 machines).  Otherwise use SSE prefetch as it allows specifying
     of locality.  */
  else if (TARGET_3DNOW && (!TARGET_PREFETCH_SSE || rw))
    operands[2] = GEN_INT (3);
  else
    operands[1] = const0_rtx;
}
:}

concrete *prefetch_sse.insn instantiates prefetch
{
	root (0=address_operand:NULL:"p", const_int:0, 1=const_int_operand:SI:"");
}
{:
  "TARGET_PREFETCH_SSE"
{
  static const char * const patterns[4] = {
   "prefetchnta\t%a0", "prefetcht2\t%a0", "prefetcht1\t%a0", "prefetcht0\t%a0"
  };

  int locality = INTVAL (operands[1]);
  gcc_assert (IN_RANGE (locality, 0, 3));

  return patterns[locality];
}
  [(set_attr "type" "sse")
   (set_attr "atom_sse_attr" "prefetch")
   (set (attr "length_address")
	(symbol_ref "memory_address_length (operands[0])"))
   (set_attr "memory" "none")]
:}

concrete *prefetch_3dnow.insn instantiates prefetch
{
	root (0=address_operand:NULL:"p", 
		1=const_int_operand:SI:"n", const_int:3);
}
{:
  "TARGET_3DNOW || TARGET_PREFETCHW"
{
  if (INTVAL (operands[1]) == 0)
    return "prefetch\t%a0";
  else
    return "prefetchw\t%a0";
}
  [(set_attr "type" "mmx")
   (set (attr "length_address")
	(symbol_ref "memory_address_length (operands[0])"))
   (set_attr "memory" "none")]
:}

concrete stack_protect_set.exp instantiates sequence
{
	root (0=memory_operand:NULL:"", 1=memory_operand:NULL:"");
}
{:
  "!TARGET_HAS_BIONIC"
{
  rtx (*insn)(rtx, rtx);

#ifdef TARGET_THREAD_SSP_OFFSET
  operands[1] = GEN_INT (TARGET_THREAD_SSP_OFFSET);
  insn = (TARGET_LP64
	  ? gen_stack_tls_protect_set_di
	  : gen_stack_tls_protect_set_si);
#else
  insn = (TARGET_LP64
	  ? gen_stack_protect_set_di
	  : gen_stack_protect_set_si);
#endif

  emit_insn (insn (operands[0], operands[1]));
  DONE;
}
:}

abstract set_unspec2_set_clobber extends sequence
{
	root.1:=set_unspec2;
	root.2:=set;
	root.3:=clobber;
	root.1:=set_unspec2;
	root.2:=set;
	root.3:=clobber;
}

concrete stack_protect_set_<mode>.insn instantiates set_unspec2_set_clobber
{
	root (0=memory_operand:PTR:"=m", (1=memory_operand:PTR:"m",
		<UNSPEC_SP_SET>),2=PTR:"=&r",const_int:0, reg(CC:FLAGS_REG));
	root.1.2.mode:=PTR;
}
{:
  "!TARGET_HAS_BIONIC"
  "mov{<imodesuffix>}\t{%1, %2|%2, %1}\;mov{<imodesuffix>}\t{%2, %0|%0, %2}\;xor{l}\t%k2, %k2"
  [(set_attr "type" "multi")]
:}

concrete stack_tls_protect_set_<mode>.insn instantiates set_unspec2_set_clobber
{
	root (0=memory_operand:PTR:"=m", (1=const_int_operand:PTR:"i",
		<UNSPEC_SP_TLS_SET>), 2=PTR:"=&r", const_int:0, reg(CC:FLAGS_REG));
	root.1.2.mode:=PTR;
}
{:
  ""
  "mov{<imodesuffix>}\t{%@:%P1, %2|%2, <iptrsize> PTR %@:%P1}\;mov{<imodesuffix>}\t{%2, %0|%0, %2}\;xor{l}\t%k2, %k2"
  [(set_attr "type" "multi")]
:}

concrete stack_protect_test.exp instantiates sequence
{
	root (0=memory_operand:NULL:"", 1=memory_operand:NULL:"", 2=NULL:NULL:"");
}
{:
  "!TARGET_HAS_BIONIC"
{
  rtx flags = gen_rtx_REG (CCZmode, FLAGS_REG);

  rtx (*insn)(rtx, rtx, rtx);

#ifdef TARGET_THREAD_SSP_OFFSET
  operands[1] = GEN_INT (TARGET_THREAD_SSP_OFFSET);
  insn = (TARGET_LP64
	  ? gen_stack_tls_protect_test_di
	  : gen_stack_tls_protect_test_si);
#else
  insn = (TARGET_LP64
	  ? gen_stack_protect_test_di
	  : gen_stack_protect_test_si);
#endif

  emit_insn (insn (flags, operands[0], operands[1]));

  emit_jump_insn (gen_cbranchcc4 (gen_rtx_EQ (VOIDmode, flags, const0_rtx),
				  flags, const0_rtx, operands[2]));
  DONE;
}
:}

concrete stack_protect_test_<mode>.insn instantiates set_unspec2_clobber
{
	root (0=flags_reg_operand:CCZ:"", (1=memory_operand:PTR:"m",
		2=memory_operand:PTR:"m", <UNSPEC_SP_TEST>), 3=PTR:"=&r");
	root.1.2.mode:=CCZ;
}
{:
  "!TARGET_HAS_BIONIC"
  "mov{<imodesuffix>}\t{%1, %3|%3, %1}\;xor{<imodesuffix>}\t{%2, %3|%3, %2}"
  [(set_attr "type" "multi")]
:}

concrete stack_tls_protect_test_<mode>.insn instantiates set_unspec2_clobber
{
	root (0=flags_reg_operand:CCZ:"", (1=memory_operand:PTR:"m",
		2=const_int_operand:PTR:"i", <UNSPEC_SP_TLS_TEST>), 3=PTR:"=r");
	root.1.2.mode:=CCZ;
}
{:
  ""
  "mov{<imodesuffix>}\t{%1, %3|%3, %1}\;xor{<imodesuffix>}\t{%@:%P2, %3|%3, <iptrsize> PTR %@:%P2}"
  [(set_attr "type" "multi")]
:}

concrete sse4_2_crc32<mode>.insn instantiates set_unspec2
{
	root (0=register_operand:SI:"=r", (1=register_operand:SI:"0",
		2=nonimmediate_operand:SWI124:"<r>m", <UNSPEC_CRC32>));
	root.2.mode:=SI;
}
{:
  "TARGET_SSE4_2 || TARGET_CRC32"
  "crc32{<imodesuffix>}\t{%2, %0|%0, %2}"
  [(set_attr "type" "sselog1")
   (set_attr "prefix_rep" "1")
   (set_attr "prefix_extra" "1")
   (set (attr "prefix_data16")
     (if_then_else (match_operand:HI 2 "" "")
       (const_string "1")
       (const_string "*")))
   (set (attr "prefix_rex")
     (if_then_else (match_operand:QI 2 "ext_QIreg_operand" "")
       (const_string "1")
       (const_string "*")))
   (set_attr "mode" "SI")]
:}

concrete sse4_2_crc32di.insn instantiates set_unspec2
{
	root (0=register_operand:DI:"=r", (1=register_operand:DI:"0",
		2=nonimmediate_operand:DI:"rm",<UNSPEC_CRC32>));
	root.2.mode:=DI;
}
{:
  "TARGET_64BIT && (TARGET_SSE4_2 || TARGET_CRC32)"
  "crc32{q}\t{%2, %0|%0, %2}"
  [(set_attr "type" "sselog1")
   (set_attr "prefix_rep" "1")
   (set_attr "prefix_extra" "1")
   (set_attr "mode" "DI")]
:}

concrete rdpmc.exp instantiates sequence
{
	root (0=register_operand:DI:"", 1=register_operand:SI:"");
}
{:
  ""
{
  rtx reg = gen_reg_rtx (DImode);
  rtx si;

  /* Force operand 1 into ECX.  */
  rtx ecx = gen_rtx_REG (SImode, CX_REG);
  emit_insn (gen_rtx_SET (VOIDmode, ecx, operands[1]));
  si = gen_rtx_UNSPEC_VOLATILE (DImode, gen_rtvec (1, ecx),
				UNSPECV_RDPMC);

  if (TARGET_64BIT)
    {
      rtvec vec = rtvec_alloc (2);
      rtx load = gen_rtx_PARALLEL (VOIDmode, vec);
      rtx upper = gen_reg_rtx (DImode);
      rtx di = gen_rtx_UNSPEC_VOLATILE (DImode,
					gen_rtvec (1, const0_rtx),
					UNSPECV_RDPMC);
      RTVEC_ELT (vec, 0) = gen_rtx_SET (VOIDmode, reg, si);
      RTVEC_ELT (vec, 1) = gen_rtx_SET (VOIDmode, upper, di);
      emit_insn (load);
      upper = expand_simple_binop (DImode, ASHIFT, upper, GEN_INT (32),
				   NULL, 1, OPTAB_DIRECT);
      reg = expand_simple_binop (DImode, IOR, reg, upper, reg, 1,
				 OPTAB_DIRECT);
    }
  else
    emit_insn (gen_rtx_SET (VOIDmode, reg, si));
  emit_insn (gen_rtx_SET (VOIDmode, operands[0], reg));
  DONE;
}
:}

concrete *rdpmc.insn instantiates set_unspec_volatile2
{
	root (0=register_operand:DI:"=A", (1=register_operand:SI:"c", <UNSPECV_RDPMC>));
	root.2.mode:=DI;
}
{:
  "!TARGET_64BIT"
  "rdpmc"
  [(set_attr "type" "other")
   (set_attr "length" "2")]
:}

abstract set_unspec_volatile2_x2 extends sequence
{
	root.1:=set_unspec_volatile2;
	root.2:=set_unspec_volatile2;
}

abstract set_unspec_volatile2_x3 extends set_unspec_volatile2_x2
{
	root.3:=set_unspec_volatile2;
}

concrete *rdpmc_rex64.insn instantiates set_unspec_volatile2_x2
{
	root (0=register_operand:DI:"=a", (2=register_operand:SI:"c", <UNSPECV_RDPMC>), 1=register_operand:DI:"=d", (const_int:0, <UNSPECV_RDPMC>));
	root.1.2.mode:=DI;
	root.2.2.mode:=DI;
}
{:
  "TARGET_64BIT"
  "rdpmc"
  [(set_attr "type" "other")
   (set_attr "length" "2")]
:}

concrete rdtsc.exp instantiates set_unspec_volatile2
{
	root (0=register_operand:DI:"", (const_int:0, <UNSPECV_RDTSC>));
	root.2.mode:=DI;
}
{:
  ""
{
  if (TARGET_64BIT)
    {
      rtvec vec = rtvec_alloc (2);
      rtx load = gen_rtx_PARALLEL (VOIDmode, vec);
      rtx upper = gen_reg_rtx (DImode);
      rtx lower = gen_reg_rtx (DImode);
      rtx src = gen_rtx_UNSPEC_VOLATILE (DImode,
					 gen_rtvec (1, const0_rtx),
					 UNSPECV_RDTSC);
      RTVEC_ELT (vec, 0) = gen_rtx_SET (VOIDmode, lower, src);
      RTVEC_ELT (vec, 1) = gen_rtx_SET (VOIDmode, upper, src);
      emit_insn (load);
      upper = expand_simple_binop (DImode, ASHIFT, upper, GEN_INT (32),
				   NULL, 1, OPTAB_DIRECT);
      lower = expand_simple_binop (DImode, IOR, lower, upper, lower, 1,
				   OPTAB_DIRECT);
      emit_insn (gen_rtx_SET (VOIDmode, operands[0], lower));
      DONE;
    }
}
:}

concrete *rdtsc.insn instantiates set_unspec_volatile2
{
	root (0=register_operand:DI:"=A", (const_int:0, <UNSPECV_RDTSC>));
	root.2.mode:=DI;
}
{:
  "!TARGET_64BIT"
  "rdtsc"
  [(set_attr "type" "other")
   (set_attr "length" "2")]
:}

concrete *rdtsc_rex64.insn instantiates set_unspec_volatile2_x2
{
	root (0=register_operand:DI:"=a", (const_int:0,<UNSPECV_RDTSC>),
		1=register_operand:DI:"=d", (const_int:0, <UNSPECV_RDTSC>));
	root.1.2.mode:=DI;
	root.2.2.mode:=DI;
}
{:
  "TARGET_64BIT"
  "rdtsc"
  [(set_attr "type" "other")
   (set_attr "length" "2")]
:}

concrete rdtscp.exp instantiates sequence 
{
	root (0=register_operand:DI:"", 1=memory_operand:SI:"");
}
{:
  ""
{
  rtx di = gen_rtx_UNSPEC_VOLATILE (DImode,
				    gen_rtvec (1, const0_rtx),
				    UNSPECV_RDTSCP);
  rtx si = gen_rtx_UNSPEC_VOLATILE (SImode,
				    gen_rtvec (1, const0_rtx),
				    UNSPECV_RDTSCP);
  rtx reg = gen_reg_rtx (DImode);
  rtx tmp = gen_reg_rtx (SImode);

  if (TARGET_64BIT)
    {
      rtvec vec = rtvec_alloc (3);
      rtx load = gen_rtx_PARALLEL (VOIDmode, vec);
      rtx upper = gen_reg_rtx (DImode);
      RTVEC_ELT (vec, 0) = gen_rtx_SET (VOIDmode, reg, di);
      RTVEC_ELT (vec, 1) = gen_rtx_SET (VOIDmode, upper, di);
      RTVEC_ELT (vec, 2) = gen_rtx_SET (VOIDmode, tmp, si);
      emit_insn (load);
      upper = expand_simple_binop (DImode, ASHIFT, upper, GEN_INT (32),
				   NULL, 1, OPTAB_DIRECT);
      reg = expand_simple_binop (DImode, IOR, reg, upper, reg, 1,
				 OPTAB_DIRECT);
    }
  else
    {
      rtvec vec = rtvec_alloc (2);
      rtx load = gen_rtx_PARALLEL (VOIDmode, vec);
      RTVEC_ELT (vec, 0) = gen_rtx_SET (VOIDmode, reg, di);
      RTVEC_ELT (vec, 1) = gen_rtx_SET (VOIDmode, tmp, si);
      emit_insn (load);
    }
  emit_insn (gen_rtx_SET (VOIDmode, operands[0], reg));
  emit_insn (gen_rtx_SET (VOIDmode, operands[1], tmp));
  DONE;
}
:}
concrete *rdtscp.insn instantiates set_unspec_volatile2_x2
{
	root (0=register_operand:DI:"=A", (const_int:0, <UNSPECV_RDTSCP>),
		1=register_operand:SI:"=c", (const_int:0,<UNSPECV_RDTSCP>));
	root.1.2.mode:=DI;
	root.2.2.mode:=SI;
}
{:
  "!TARGET_64BIT"
  "rdtscp"
  [(set_attr "type" "other")
   (set_attr "length" "3")]
:}

concrete *rdtscp_rex64.insn instantiates set_unspec_volatile2_x3
{
	root (0=register_operand:DI:"=a", (const_int:0, <UNSPECV_RDTSCP>),
		1=register_operand:DI:"=d", (const_int:0, <UNSPECV_RDTSCP>),
		2=register_operand:SI:"=c", (const_int:0, <UNSPECV_RDTSCP>));
	root.1.2.mode:=DI;
	root.2.2.mode:=DI;
	root.3.2.mode:=SI;
}
{:
  "TARGET_64BIT"
  "rdtscp"
  [(set_attr "type" "other")
   (set_attr "length" "3")]
:}
{:
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;
;; LWP instructions
;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
:}

concrete lwp_llwpcb.exp instantiates unspec_volatile
{
	root ((0=register_operand:NULL:"r",<UNSPECV_LLWP_INTRINSIC>));
}
{:
  "TARGET_LWP"
:}

concrete *lwp_llwpcb<mode>1.insn instantiates unspec_volatile
{
	root ((0=register_operand:P:"r", <UNSPECV_LLWP_INTRINSIC>));
}
{:
  "TARGET_LWP"
  "llwpcb\t%0"
  [(set_attr "type" "lwp")
   (set_attr "mode" "<MODE>")
   (set_attr "length" "5")]
:}

concrete lwp_slwpcb.exp instantiates set_unspec_volatile2
{
	root (0=register_operand:NULL:"=r", (const_int:0, 
		<UNSPECV_SLWP_INTRINSIC>));
}
{:
  "TARGET_LWP"
{
  rtx (*insn)(rtx);

  insn = (TARGET_64BIT
	  ? gen_lwp_slwpcbdi
	  : gen_lwp_slwpcbsi);

  emit_insn (insn (operands[0]));
  DONE;
}
:}

concrete lwp_slwpcb<mode>.insn instantiates set_unspec_volatile2
{
	root (0=register_operand:P:"=r", (const_int:0, <UNSPECV_SLWP_INTRINSIC>));
	root.2.mode:=P;
}
{:
  "TARGET_LWP"
  "slwpcb\t%0"
  [(set_attr "type" "lwp")
   (set_attr "mode" "<MODE>")
   (set_attr "length" "5")]
:}

concrete lwp_lwpval<mode>3.exp instantiates unspec_volatile
{
	root ((1=register_operand:SWI48:"r", 2=nonimmediate_operand:SI:"rm",
		3=const_int_operand:SI:"i",<UNSPECV_LWPVAL_INTRINSIC>));
}
{:
  "TARGET_LWP"
  ;; Avoid unused variable warning.
  "(void) operands[0];"
:}

concrete *lwp_lwpval<mode>3_1.insn instantiates unspec_volatile
{
	root ((0=register_operand:SWI48:"r", 1=nonimmediate_operand:SI:"rm",
		2=const_int_operand:SI:"i", <UNSPECV_LWPVAL_INTRINSIC>));
}
{:
  "TARGET_LWP"
  "lwpval\t{%2, %1, %0|%0, %1, %2}"
  [(set_attr "type" "lwp")
   (set_attr "mode" "<MODE>")
   (set (attr "length")
        (symbol_ref "ix86_attr_length_address_default (insn) + 9"))]
:}

abstract set_unspec_volatile2_set_eq2 extends sequence
{
	root.1:=set_unspec_volatile2;
	root.2:=set;
	root.2.2:=eq;
}

concrete lwp_lwpins<mode>3.exp instantiates set_unspec_volatile2_set_eq2
{
	root (reg(CCC:FLAGS_REG), (1=register_operand:SWI48:"r",
		2=nonimmediate_operand:SI:"rm", 3=const_int_operand:SI:"i", 
		<UNSPECV_LWPINS_INTRINSIC>), 0=nonimmediate_operand:QI:"=qm", reg(CCC:FLAGS_REG), const_int:0);
	root.1.2.mode:=CCC;
	root.2.2.mode:=QI;
}
{:
  "TARGET_LWP"
:}

concrete *lwp_lwpins<mode>3_1.insn instantiates set_unspec_volatile2
{
	root (reg(CCC:FLAGS_REG), (0=register_operand:SWI48:"r",
		1=nonimmediate_operand:SI:"rm", 2=const_int_operand:SI:"i", 
		<UNSPECV_LWPINS_INTRINSIC>));
	root.2.mode:=CCC;
}
{:
  "TARGET_LWP"
  "lwpins\t{%2, %1, %0|%0, %1, %2}"
  [(set_attr "type" "lwp")
   (set_attr "mode" "<MODE>")
   (set (attr "length")
        (symbol_ref "ix86_attr_length_address_default (insn) + 9"))]
:}

concrete rdfsbase<mode>.insn instantiates set_unspec_volatile2
{
	root (0=register_operand:SWI48:"=r", (const_int:0,
		<UNSPECV_RDFSBASE>));
	root.2.mode:=SWI48;
}
{:
  "TARGET_64BIT && TARGET_FSGSBASE"
  "rdfsbase %0"
  [(set_attr "type" "other")
   (set_attr "prefix_extra" "2")]
:}

concrete rdgsbase<mode>.insn instantiates set_unspec_volatile2
{
	root (0=register_operand:SWI48:"=r", (const_int:0, <UNSPECV_RDGSBASE>));
	root.2.mode:=SWI48;
}
{:
  "TARGET_64BIT && TARGET_FSGSBASE"
  "rdgsbase %0"
  [(set_attr "type" "other")
   (set_attr "prefix_extra" "2")]
:}

concrete wrfsbase<mode>.insn instantiates unspec_volatile
{
	root ((0=register_operand:SWI48:"r", <UNSPECV_WRFSBASE>));
}
{:
  "TARGET_64BIT && TARGET_FSGSBASE"
  "wrfsbase %0"
  [(set_attr "type" "other")
   (set_attr "prefix_extra" "2")]
:}

concrete wrgsbase<mode>.insn instantiates unspec_volatile
{
	root ((0=register_operand:SWI48:"r", <UNSPECV_WRGSBASE>));
}
{:
  "TARGET_64BIT && TARGET_FSGSBASE"
  "wrgsbase %0"
  [(set_attr "type" "other")
   (set_attr "prefix_extra" "2")]
:}

concrete rdrand<mode>_1.insn instantiates set_unspec_volatile2_x2
{
	root (0=register_operand:SWI248:"=r", (const_int:0, <UNSPECV_RDRAND>),
		reg(CCC:FLAGS_REG), (const_int:0, <UNSPECV_RDRAND>));
	root.1.2.mode:=SWI248;
	root.2.2.mode:=CCC;
}
{:
  "TARGET_RDRND"
  "rdrand\t%0"
  [(set_attr "type" "other")
   (set_attr "prefix_extra" "1")]
:}

concrete pause.exp instantiates set_unspec2
{
	root (duplicate 0, (duplicate 0, <UNSPEC_PAUSE>));
	root.2.mode:=BLK;
}
{:
  ""
{
  operands[0] = gen_rtx_MEM (BLKmode, gen_rtx_SCRATCH (Pmode));
  MEM_VOLATILE_P (operands[0]) = 1;
}
:}
{:
;; Use "rep; nop", instead of "pause", to support older assemblers.
;; They have the same encoding.
:}

concrete *pause.insn instantiates set_unspec2
{
	root (0=NULL:BLK:"", (duplicate 0, <UNSPEC_PAUSE>));
	root.2.mode:=BLK;
}
{:
  ""
  "rep; nop"
  [(set_attr "length" "2")
   (set_attr "memory" "unknown")]
:}

{:
(include "mmx.md")
(include "sse.md")
(include "sync.md")
:}
